ARM GAS  /tmp/ccalvPdg.s 			page 1


   1              		.cpu cortex-m4
   2              		.arch armv7e-m
   3              		.fpu fpv4-sp-d16
   4              		.eabi_attribute 27, 1
   5              		.eabi_attribute 28, 1
   6              		.eabi_attribute 20, 1
   7              		.eabi_attribute 21, 1
   8              		.eabi_attribute 23, 3
   9              		.eabi_attribute 24, 1
  10              		.eabi_attribute 25, 1
  11              		.eabi_attribute 26, 1
  12              		.eabi_attribute 30, 1
  13              		.eabi_attribute 34, 1
  14              		.eabi_attribute 18, 4
  15              		.file	"request.c"
  16              		.text
  17              	.Ltext0:
  18              		.cfi_sections	.debug_frame
  19              		.file 1 "./block/request.c"
  20              		.section	.text.request_alloc,"ax",%progbits
  21              		.align	1
  22              		.global	request_alloc
  23              		.syntax unified
  24              		.thumb
  25              		.thumb_func
  27              	request_alloc:
  28              	.LVL0:
  29              	.LFB960:
   1:./block/request.c **** #include <linux/blkdev.h>
   2:./block/request.c **** #include <linux/slab.h>
   3:./block/request.c **** #include <linux/errno.h>
   4:./block/request.c **** #include <linux/string.h>
   5:./block/request.c **** #include <linux/time.h>
   6:./block/request.c **** #include <linux/list.h>
   7:./block/request.c **** #include <linux/atomic.h>
   8:./block/request.c **** 
   9:./block/request.c **** 
  10:./block/request.c **** struct request *request_alloc(struct request_queue *q, blk_opf_t opf, gfp_t gfp_mask)
  11:./block/request.c **** {
  30              		.loc 1 11 1 view -0
  31              		.cfi_startproc
  32              		@ args = 0, pretend = 0, frame = 0
  33              		@ frame_needed = 0, uses_anonymous_args = 0
  34              		.loc 1 11 1 is_stmt 0 view .LVU1
  35 0000 70B5     		push	{r4, r5, r6, lr}
  36              	.LCFI0:
  37              		.cfi_def_cfa_offset 16
  38              		.cfi_offset 4, -16
  39              		.cfi_offset 5, -12
  40              		.cfi_offset 6, -8
  41              		.cfi_offset 14, -4
  42 0002 0646     		mov	r6, r0
  43 0004 0D46     		mov	r5, r1
  12:./block/request.c ****     struct request *rq = kmalloc(sizeof(struct request), gfp_mask);
  44              		.loc 1 12 5 is_stmt 1 view .LVU2
  45              	.LVL1:
  46              	.LBB25:
ARM GAS  /tmp/ccalvPdg.s 			page 2


  47              	.LBI25:
  48              		.file 2 "./include/linux/slab.h"
   1:./include/linux/slab.h **** /* SPDX-License-Identifier: GPL-2.0 */
   2:./include/linux/slab.h **** /*
   3:./include/linux/slab.h ****  * Written by Mark Hemment, 1996 (markhe@nextd.demon.co.uk).
   4:./include/linux/slab.h ****  *
   5:./include/linux/slab.h ****  * (C) SGI 2006, Christoph Lameter
   6:./include/linux/slab.h ****  * 	Cleaned up and restructured to ease the addition of alternative
   7:./include/linux/slab.h ****  * 	implementations of SLAB allocators.
   8:./include/linux/slab.h ****  * (C) Linux Foundation 2008-2013
   9:./include/linux/slab.h ****  *      Unified interface for all slab allocators
  10:./include/linux/slab.h ****  */
  11:./include/linux/slab.h **** 
  12:./include/linux/slab.h **** #ifndef _LINUX_SLAB_H
  13:./include/linux/slab.h **** #define	_LINUX_SLAB_H
  14:./include/linux/slab.h **** 
  15:./include/linux/slab.h **** #include <linux/cache.h>
  16:./include/linux/slab.h **** #include <linux/overflow.h>
  17:./include/linux/slab.h **** #include <linux/types.h>
  18:./include/linux/slab.h **** #include <linux/raid/pq.h>
  19:./include/linux/slab.h **** #include <linux/gfp_types.h>
  20:./include/linux/slab.h **** #include <linux/numa.h>
  21:./include/linux/slab.h **** #include <linux/reciprocal_div.h>
  22:./include/linux/slab.h **** #include <linux/spinlock.h>
  23:./include/linux/slab.h **** 
  24:./include/linux/slab.h **** enum _slab_flag_bits {
  25:./include/linux/slab.h **** 	_SLAB_CONSISTENCY_CHECKS,
  26:./include/linux/slab.h **** 	_SLAB_RED_ZONE,
  27:./include/linux/slab.h **** 	_SLAB_POISON,
  28:./include/linux/slab.h **** 	_SLAB_KMALLOC,
  29:./include/linux/slab.h **** 	_SLAB_HWCACHE_ALIGN,
  30:./include/linux/slab.h **** 	_SLAB_CACHE_DMA,
  31:./include/linux/slab.h **** 	_SLAB_CACHE_DMA32,
  32:./include/linux/slab.h **** 	_SLAB_STORE_USER,
  33:./include/linux/slab.h **** 	_SLAB_PANIC,
  34:./include/linux/slab.h **** 	_SLAB_TYPESAFE_BY_RCU,
  35:./include/linux/slab.h **** 	_SLAB_TRACE,
  36:./include/linux/slab.h **** #ifdef CONFIG_DEBUG_OBJECTS
  37:./include/linux/slab.h **** 	_SLAB_DEBUG_OBJECTS,
  38:./include/linux/slab.h **** #endif
  39:./include/linux/slab.h **** 	_SLAB_NOLEAKTRACE,
  40:./include/linux/slab.h **** 	_SLAB_NO_MERGE,
  41:./include/linux/slab.h **** #ifdef CONFIG_FAILSLAB
  42:./include/linux/slab.h **** 	_SLAB_FAILSLAB,
  43:./include/linux/slab.h **** #endif
  44:./include/linux/slab.h **** #ifdef CONFIG_MEMCG
  45:./include/linux/slab.h **** 	_SLAB_ACCOUNT,
  46:./include/linux/slab.h **** #endif
  47:./include/linux/slab.h **** #ifdef CONFIG_KASAN_GENERIC
  48:./include/linux/slab.h **** 	_SLAB_KASAN,
  49:./include/linux/slab.h **** #endif
  50:./include/linux/slab.h **** 	_SLAB_NO_USER_FLAGS,
  51:./include/linux/slab.h **** #ifdef CONFIG_KFENCE
  52:./include/linux/slab.h **** 	_SLAB_SKIP_KFENCE,
  53:./include/linux/slab.h **** #endif
  54:./include/linux/slab.h **** #ifndef CONFIG_SLUB_TINY
  55:./include/linux/slab.h **** 	_SLAB_RECLAIM_ACCOUNT,
ARM GAS  /tmp/ccalvPdg.s 			page 3


  56:./include/linux/slab.h **** #endif
  57:./include/linux/slab.h **** 	_SLAB_OBJECT_POISON,
  58:./include/linux/slab.h **** 	_SLAB_CMPXCHG_DOUBLE,
  59:./include/linux/slab.h **** #ifdef CONFIG_SLAB_OBJ_EXT
  60:./include/linux/slab.h **** 	_SLAB_NO_OBJ_EXT,
  61:./include/linux/slab.h **** #endif
  62:./include/linux/slab.h **** 	_SLAB_FLAGS_LAST_BIT
  63:./include/linux/slab.h **** };
  64:./include/linux/slab.h **** 
  65:./include/linux/slab.h **** 
  66:./include/linux/slab.h **** 
  67:./include/linux/slab.h **** #define __SLAB_FLAG_BIT(nr)	((slab_flags_t __force)(1U << (nr)))
  68:./include/linux/slab.h **** #define __SLAB_FLAG_UNUSED	((slab_flags_t __force)(0U))
  69:./include/linux/slab.h **** 
  70:./include/linux/slab.h **** /*
  71:./include/linux/slab.h ****  * Flags to pass to kmem_cache_create().
  72:./include/linux/slab.h ****  * The ones marked DEBUG need CONFIG_SLUB_DEBUG enabled, otherwise are no-op
  73:./include/linux/slab.h ****  */
  74:./include/linux/slab.h **** /* DEBUG: Perform (expensive) checks on alloc/free */
  75:./include/linux/slab.h **** #define SLAB_CONSISTENCY_CHECKS	__SLAB_FLAG_BIT(_SLAB_CONSISTENCY_CHECKS)
  76:./include/linux/slab.h **** /* DEBUG: Red zone objs in a cache */
  77:./include/linux/slab.h **** #define SLAB_RED_ZONE		__SLAB_FLAG_BIT(_SLAB_RED_ZONE)
  78:./include/linux/slab.h **** /* DEBUG: Poison objects */
  79:./include/linux/slab.h **** #define SLAB_POISON		__SLAB_FLAG_BIT(_SLAB_POISON)
  80:./include/linux/slab.h **** /* Indicate a kmalloc slab */
  81:./include/linux/slab.h **** #define SLAB_KMALLOC		__SLAB_FLAG_BIT(_SLAB_KMALLOC)
  82:./include/linux/slab.h **** /**
  83:./include/linux/slab.h ****  * define SLAB_HWCACHE_ALIGN - Align objects on cache line boundaries.
  84:./include/linux/slab.h ****  *
  85:./include/linux/slab.h ****  * Sufficiently large objects are aligned on cache line boundary. For object
  86:./include/linux/slab.h ****  * size smaller than a half of cache line size, the alignment is on the half of
  87:./include/linux/slab.h ****  * cache line size. In general, if object size is smaller than 1/2^n of cache
  88:./include/linux/slab.h ****  * line size, the alignment is adjusted to 1/2^n.
  89:./include/linux/slab.h ****  *
  90:./include/linux/slab.h ****  * If explicit alignment is also requested by the respective
  91:./include/linux/slab.h ****  * &struct kmem_cache_args field, the greater of both is alignments is applied.
  92:./include/linux/slab.h ****  */
  93:./include/linux/slab.h **** #define SLAB_HWCACHE_ALIGN	__SLAB_FLAG_BIT(_SLAB_HWCACHE_ALIGN)
  94:./include/linux/slab.h **** /* Use GFP_DMA memory */
  95:./include/linux/slab.h **** #define SLAB_CACHE_DMA		__SLAB_FLAG_BIT(_SLAB_CACHE_DMA)
  96:./include/linux/slab.h **** /* Use GFP_DMA32 memory */
  97:./include/linux/slab.h **** #define SLAB_CACHE_DMA32	__SLAB_FLAG_BIT(_SLAB_CACHE_DMA32)
  98:./include/linux/slab.h **** /* DEBUG: Store the last owner for bug hunting */
  99:./include/linux/slab.h **** #define SLAB_STORE_USER		__SLAB_FLAG_BIT(_SLAB_STORE_USER)
 100:./include/linux/slab.h **** /* Panic if kmem_cache_create() fails */
 101:./include/linux/slab.h **** #define SLAB_PANIC		__SLAB_FLAG_BIT(_SLAB_PANIC)
 102:./include/linux/slab.h **** /**
 103:./include/linux/slab.h ****  * define SLAB_TYPESAFE_BY_RCU - **WARNING** READ THIS!
 104:./include/linux/slab.h ****  *
 105:./include/linux/slab.h ****  * This delays freeing the SLAB page by a grace period, it does _NOT_
 106:./include/linux/slab.h ****  * delay object freeing. This means that if you do kmem_cache_free()
 107:./include/linux/slab.h ****  * that memory location is free to be reused at any time. Thus it may
 108:./include/linux/slab.h ****  * be possible to see another object there in the same RCU grace period.
 109:./include/linux/slab.h ****  *
 110:./include/linux/slab.h ****  * This feature only ensures the memory location backing the object
 111:./include/linux/slab.h ****  * stays valid, the trick to using this is relying on an independent
 112:./include/linux/slab.h ****  * object validation pass. Something like:
ARM GAS  /tmp/ccalvPdg.s 			page 4


 113:./include/linux/slab.h ****  *
 114:./include/linux/slab.h ****  * ::
 115:./include/linux/slab.h ****  *
 116:./include/linux/slab.h ****  *  begin:
 117:./include/linux/slab.h ****  *   rcu_read_lock();
 118:./include/linux/slab.h ****  *   obj = lockless_lookup(key);
 119:./include/linux/slab.h ****  *   if (obj) {
 120:./include/linux/slab.h ****  *     if (!try_get_ref(obj)) // might fail for free objects
 121:./include/linux/slab.h ****  *       rcu_read_unlock();
 122:./include/linux/slab.h ****  *       goto begin;
 123:./include/linux/slab.h ****  *
 124:./include/linux/slab.h ****  *     if (obj->key != key) { // not the object we expected
 125:./include/linux/slab.h ****  *       put_ref(obj);
 126:./include/linux/slab.h ****  *       rcu_read_unlock();
 127:./include/linux/slab.h ****  *       goto begin;
 128:./include/linux/slab.h ****  *     }
 129:./include/linux/slab.h ****  *   }
 130:./include/linux/slab.h ****  *  rcu_read_unlock();
 131:./include/linux/slab.h ****  *
 132:./include/linux/slab.h ****  * This is useful if we need to approach a kernel structure obliquely,
 133:./include/linux/slab.h ****  * from its address obtained without the usual locking. We can lock
 134:./include/linux/slab.h ****  * the structure to stabilize it and check it's still at the given address,
 135:./include/linux/slab.h ****  * only if we can be sure that the memory has not been meanwhile reused
 136:./include/linux/slab.h ****  * for some other kind of object (which our subsystem's lock might corrupt).
 137:./include/linux/slab.h ****  *
 138:./include/linux/slab.h ****  * rcu_read_lock before reading the address, then rcu_read_unlock after
 139:./include/linux/slab.h ****  * taking the spinlock within the structure expected at that address.
 140:./include/linux/slab.h ****  *
 141:./include/linux/slab.h ****  * Note that it is not possible to acquire a lock within a structure
 142:./include/linux/slab.h ****  * allocated with SLAB_TYPESAFE_BY_RCU without first acquiring a reference
 143:./include/linux/slab.h ****  * as described above.  The reason is that SLAB_TYPESAFE_BY_RCU pages
 144:./include/linux/slab.h ****  * are not zeroed before being given to the slab, which means that any
 145:./include/linux/slab.h ****  * locks must be initialized after each and every kmem_struct_alloc().
 146:./include/linux/slab.h ****  * Alternatively, make the ctor passed to kmem_cache_create() initialize
 147:./include/linux/slab.h ****  * the locks at page-allocation time, as is done in __i915_request_ctor(),
 148:./include/linux/slab.h ****  * sighand_ctor(), and anon_vma_ctor().  Such a ctor permits readers
 149:./include/linux/slab.h ****  * to safely acquire those ctor-initialized locks under rcu_read_lock()
 150:./include/linux/slab.h ****  * protection.
 151:./include/linux/slab.h ****  *
 152:./include/linux/slab.h ****  * Note that SLAB_TYPESAFE_BY_RCU was originally named SLAB_DESTROY_BY_RCU.
 153:./include/linux/slab.h ****  */
 154:./include/linux/slab.h **** #define SLAB_TYPESAFE_BY_RCU	__SLAB_FLAG_BIT(_SLAB_TYPESAFE_BY_RCU)
 155:./include/linux/slab.h **** /* Trace allocations and frees */
 156:./include/linux/slab.h **** #define SLAB_TRACE		__SLAB_FLAG_BIT(_SLAB_TRACE)
 157:./include/linux/slab.h **** 
 158:./include/linux/slab.h **** /* Flag to prevent checks on free */
 159:./include/linux/slab.h **** #ifdef CONFIG_DEBUG_OBJECTS
 160:./include/linux/slab.h **** # define SLAB_DEBUG_OBJECTS	__SLAB_FLAG_BIT(_SLAB_DEBUG_OBJECTS)
 161:./include/linux/slab.h **** #else
 162:./include/linux/slab.h **** # define SLAB_DEBUG_OBJECTS	__SLAB_FLAG_UNUSED
 163:./include/linux/slab.h **** #endif
 164:./include/linux/slab.h **** 
 165:./include/linux/slab.h **** /* Avoid kmemleak tracing */
 166:./include/linux/slab.h **** #define SLAB_NOLEAKTRACE	__SLAB_FLAG_BIT(_SLAB_NOLEAKTRACE)
 167:./include/linux/slab.h **** 
 168:./include/linux/slab.h **** /*
 169:./include/linux/slab.h ****  * Prevent merging with compatible kmem caches. This flag should be used
ARM GAS  /tmp/ccalvPdg.s 			page 5


 170:./include/linux/slab.h ****  * cautiously. Valid use cases:
 171:./include/linux/slab.h ****  *
 172:./include/linux/slab.h ****  * - caches created for self-tests (e.g. kunit)
 173:./include/linux/slab.h ****  * - general caches created and used by a subsystem, only when a
 174:./include/linux/slab.h ****  *   (subsystem-specific) debug option is enabled
 175:./include/linux/slab.h ****  * - performance critical caches, should be very rare and consulted with slab
 176:./include/linux/slab.h ****  *   maintainers, and not used together with CONFIG_SLUB_TINY
 177:./include/linux/slab.h ****  */
 178:./include/linux/slab.h **** #define SLAB_NO_MERGE		__SLAB_FLAG_BIT(_SLAB_NO_MERGE)
 179:./include/linux/slab.h **** 
 180:./include/linux/slab.h **** /* Fault injection mark */
 181:./include/linux/slab.h **** #ifdef CONFIG_FAILSLAB
 182:./include/linux/slab.h **** # define SLAB_FAILSLAB		__SLAB_FLAG_BIT(_SLAB_FAILSLAB)
 183:./include/linux/slab.h **** #else
 184:./include/linux/slab.h **** # define SLAB_FAILSLAB		__SLAB_FLAG_UNUSED
 185:./include/linux/slab.h **** #endif
 186:./include/linux/slab.h **** /**
 187:./include/linux/slab.h ****  * define SLAB_ACCOUNT - Account allocations to memcg.
 188:./include/linux/slab.h ****  *
 189:./include/linux/slab.h ****  * All object allocations from this cache will be memcg accounted, regardless of
 190:./include/linux/slab.h ****  * __GFP_ACCOUNT being or not being passed to individual allocations.
 191:./include/linux/slab.h ****  */
 192:./include/linux/slab.h **** #ifdef CONFIG_MEMCG
 193:./include/linux/slab.h **** # define SLAB_ACCOUNT		__SLAB_FLAG_BIT(_SLAB_ACCOUNT)
 194:./include/linux/slab.h **** #else
 195:./include/linux/slab.h **** # define SLAB_ACCOUNT		__SLAB_FLAG_UNUSED
 196:./include/linux/slab.h **** #endif
 197:./include/linux/slab.h **** 
 198:./include/linux/slab.h **** #ifdef CONFIG_KASAN_GENERIC
 199:./include/linux/slab.h **** #define SLAB_KASAN		__SLAB_FLAG_BIT(_SLAB_KASAN)
 200:./include/linux/slab.h **** #else
 201:./include/linux/slab.h **** #define SLAB_KASAN		__SLAB_FLAG_UNUSED
 202:./include/linux/slab.h **** #endif
 203:./include/linux/slab.h **** 
 204:./include/linux/slab.h **** /*
 205:./include/linux/slab.h ****  * Ignore user specified debugging flags.
 206:./include/linux/slab.h ****  * Intended for caches created for self-tests so they have only flags
 207:./include/linux/slab.h ****  * specified in the code and other flags are ignored.
 208:./include/linux/slab.h ****  */
 209:./include/linux/slab.h **** #define SLAB_NO_USER_FLAGS	__SLAB_FLAG_BIT(_SLAB_NO_USER_FLAGS)
 210:./include/linux/slab.h **** 
 211:./include/linux/slab.h **** #ifdef CONFIG_KFENCE
 212:./include/linux/slab.h **** #define SLAB_SKIP_KFENCE	__SLAB_FLAG_BIT(_SLAB_SKIP_KFENCE)
 213:./include/linux/slab.h **** #else
 214:./include/linux/slab.h **** #define SLAB_SKIP_KFENCE	__SLAB_FLAG_UNUSED
 215:./include/linux/slab.h **** #endif
 216:./include/linux/slab.h **** 
 217:./include/linux/slab.h **** /* The following flags affect the page allocator grouping pages by mobility */
 218:./include/linux/slab.h **** /**
 219:./include/linux/slab.h ****  * define SLAB_RECLAIM_ACCOUNT - Objects are reclaimable.
 220:./include/linux/slab.h ****  *
 221:./include/linux/slab.h ****  * Use this flag for caches that have an associated shrinker. As a result, slab
 222:./include/linux/slab.h ****  * pages are allocated with __GFP_RECLAIMABLE, which affects grouping pages by
 223:./include/linux/slab.h ****  * mobility, and are accounted in SReclaimable counter in /proc/meminfo
 224:./include/linux/slab.h ****  */
 225:./include/linux/slab.h **** #ifndef CONFIG_SLUB_TINY
 226:./include/linux/slab.h **** #define SLAB_RECLAIM_ACCOUNT	__SLAB_FLAG_BIT(_SLAB_RECLAIM_ACCOUNT)
ARM GAS  /tmp/ccalvPdg.s 			page 6


 227:./include/linux/slab.h **** #else
 228:./include/linux/slab.h **** #define SLAB_RECLAIM_ACCOUNT	__SLAB_FLAG_UNUSED
 229:./include/linux/slab.h **** #endif
 230:./include/linux/slab.h **** #define SLAB_TEMPORARY		SLAB_RECLAIM_ACCOUNT	/* Objects are short-lived */
 231:./include/linux/slab.h **** 
 232:./include/linux/slab.h **** /* Slab created using create_boot_cache */
 233:./include/linux/slab.h **** #ifdef CONFIG_SLAB_OBJ_EXT
 234:./include/linux/slab.h **** #define SLAB_NO_OBJ_EXT		__SLAB_FLAG_BIT(_SLAB_NO_OBJ_EXT)
 235:./include/linux/slab.h **** #else
 236:./include/linux/slab.h **** #define SLAB_NO_OBJ_EXT		__SLAB_FLAG_UNUSED
 237:./include/linux/slab.h **** #endif
 238:./include/linux/slab.h **** 
 239:./include/linux/slab.h **** /*
 240:./include/linux/slab.h ****  * freeptr_t represents a SLUB freelist pointer, which might be encoded
 241:./include/linux/slab.h ****  * and not dereferenceable if CONFIG_SLAB_FREELIST_HARDENED is enabled.
 242:./include/linux/slab.h ****  */
 243:./include/linux/slab.h **** typedef struct { unsigned long v; } freeptr_t;
 244:./include/linux/slab.h **** 
 245:./include/linux/slab.h **** /*
 246:./include/linux/slab.h ****  * ZERO_SIZE_PTR will be returned for zero sized kmalloc requests.
 247:./include/linux/slab.h ****  *
 248:./include/linux/slab.h ****  * Dereferencing ZERO_SIZE_PTR will lead to a distinct access fault.
 249:./include/linux/slab.h ****  *
 250:./include/linux/slab.h ****  * ZERO_SIZE_PTR can be passed to kfree though in the same way that NULL can.
 251:./include/linux/slab.h ****  * Both make kfree a no-op.
 252:./include/linux/slab.h ****  */
 253:./include/linux/slab.h **** #define ZERO_SIZE_PTR ((void *)16)
 254:./include/linux/slab.h **** 
 255:./include/linux/slab.h **** #define ZERO_OR_NULL_PTR(x) ((unsigned long)(x) <= \
 256:./include/linux/slab.h **** 				(unsigned long)ZERO_SIZE_PTR)
 257:./include/linux/slab.h **** 
 258:./include/linux/slab.h **** 
 259:./include/linux/slab.h **** 
 260:./include/linux/slab.h **** 
 261:./include/linux/slab.h **** 
 262:./include/linux/slab.h **** #ifdef CONFIG_SLUB_CPU_PARTIAL
 263:./include/linux/slab.h **** #define slub_percpu_partial(c)			((c)->partial)
 264:./include/linux/slab.h **** 
 265:./include/linux/slab.h **** #define slub_set_percpu_partial(c, p)		\
 266:./include/linux/slab.h **** ({						\
 267:./include/linux/slab.h **** 	slub_percpu_partial(c) = (p)->next;	\
 268:./include/linux/slab.h **** })
 269:./include/linux/slab.h **** 
 270:./include/linux/slab.h **** #define slub_percpu_partial_read_once(c)	READ_ONCE(slub_percpu_partial(c))
 271:./include/linux/slab.h **** #else
 272:./include/linux/slab.h **** #define slub_percpu_partial(c)			NULL
 273:./include/linux/slab.h **** 
 274:./include/linux/slab.h **** #define slub_set_percpu_partial(c, p)
 275:./include/linux/slab.h **** 
 276:./include/linux/slab.h **** #define slub_percpu_partial_read_once(c)	NULL
 277:./include/linux/slab.h **** 
 278:./include/linux/slab.h **** 
 279:./include/linux/slab.h **** #endif // CONFIG_SLUB_CPU_PARTIAL
 280:./include/linux/slab.h **** 
 281:./include/linux/slab.h **** /*
 282:./include/linux/slab.h **** 	* Word size structure that can be atomically updated or read and that
 283:./include/linux/slab.h **** 	* contains both the order and the number of objects that a slab of the
ARM GAS  /tmp/ccalvPdg.s 			page 7


 284:./include/linux/slab.h **** 	* given order would contain.
 285:./include/linux/slab.h **** 	*/				
 286:./include/linux/slab.h **** struct kmem_cache_order_objects {
 287:./include/linux/slab.h **** 	unsigned int x;
 288:./include/linux/slab.h **** };
 289:./include/linux/slab.h **** 
 290:./include/linux/slab.h **** struct kmem_cache_node {
 291:./include/linux/slab.h **** 	spinlock_t list_lock;
 292:./include/linux/slab.h **** 	unsigned long nr_partial;
 293:./include/linux/slab.h **** 	struct list_head partial;
 294:./include/linux/slab.h **** #ifdef CONFIG_SLUB_DEBUG
 295:./include/linux/slab.h **** 	atomic_long_t nr_slabs;
 296:./include/linux/slab.h **** 	atomic_long_t total_objects;
 297:./include/linux/slab.h **** 	struct list_head full;
 298:./include/linux/slab.h **** #endif
 299:./include/linux/slab.h **** };
 300:./include/linux/slab.h **** 
 301:./include/linux/slab.h **** struct kmem_cache {
 302:./include/linux/slab.h **** 	#ifndef CONFIG_SLUB_TINY
 303:./include/linux/slab.h **** 	//	struct kmem_cache_cpu __percpu *cpu_slab;
 304:./include/linux/slab.h **** 	#endif
 305:./include/linux/slab.h **** 		/* Used for retrieving partial slabs, etc. */
 306:./include/linux/slab.h **** 		slab_flags_t flags;
 307:./include/linux/slab.h **** 		unsigned long min_partial;
 308:./include/linux/slab.h **** 		unsigned int size;		/* Object size including metadata */
 309:./include/linux/slab.h **** 		unsigned int object_size;	/* Object size without metadata */
 310:./include/linux/slab.h **** 		struct reciprocal_value reciprocal_size;
 311:./include/linux/slab.h **** 		unsigned int offset;		/* Free pointer offset */
 312:./include/linux/slab.h **** 	#ifdef CONFIG_SLUB_CPU_PARTIAL
 313:./include/linux/slab.h **** 		/* Number of per cpu partial objects to keep around */
 314:./include/linux/slab.h **** 		unsigned int cpu_partial;
 315:./include/linux/slab.h **** 		/* Number of per cpu partial slabs to keep around */
 316:./include/linux/slab.h **** 		unsigned int cpu_partial_slabs;
 317:./include/linux/slab.h **** 	#endif
 318:./include/linux/slab.h **** 		struct kmem_cache_order_objects oo;
 319:./include/linux/slab.h **** 	
 320:./include/linux/slab.h **** 		/* Allocation and freeing of slabs */
 321:./include/linux/slab.h **** 		struct kmem_cache_order_objects min;
 322:./include/linux/slab.h **** 		gfp_t allocflags;		/* gfp flags to use on each alloc */
 323:./include/linux/slab.h **** 		int refcount;			/* Refcount for slab cache destroy */
 324:./include/linux/slab.h **** 		void (*ctor)(void *object);	/* Object constructor */
 325:./include/linux/slab.h **** 		unsigned int inuse;		/* Offset to metadata */
 326:./include/linux/slab.h **** 		unsigned int align;		/* Alignment */
 327:./include/linux/slab.h **** 		unsigned int red_left_pad;	/* Left redzone padding size */
 328:./include/linux/slab.h **** 		const char *name;		/* Name (only for display!) */
 329:./include/linux/slab.h **** 		struct list_head list;		/* List of slab caches */
 330:./include/linux/slab.h **** 	#ifdef CONFIG_SYSFS
 331:./include/linux/slab.h **** 		struct kobject kobj;		/* For sysfs */
 332:./include/linux/slab.h **** 	#endif
 333:./include/linux/slab.h **** 	#ifdef CONFIG_SLAB_FREELIST_HARDENED
 334:./include/linux/slab.h **** 		unsigned long random;
 335:./include/linux/slab.h **** 	#endif
 336:./include/linux/slab.h **** 	
 337:./include/linux/slab.h **** 	#ifdef CONFIG_NUMA
 338:./include/linux/slab.h **** 		/*
 339:./include/linux/slab.h **** 			* Defragmentation by allocating from a remote node.
 340:./include/linux/slab.h **** 			*/
ARM GAS  /tmp/ccalvPdg.s 			page 8


 341:./include/linux/slab.h **** 		unsigned int remote_node_defrag_ratio;
 342:./include/linux/slab.h **** 	#endif
 343:./include/linux/slab.h **** 	
 344:./include/linux/slab.h **** 	#ifdef CONFIG_SLAB_FREELIST_RANDOM
 345:./include/linux/slab.h **** 		unsigned int *random_seq;
 346:./include/linux/slab.h **** 	#endif
 347:./include/linux/slab.h **** 	
 348:./include/linux/slab.h **** 	#ifdef CONFIG_KASAN_GENERIC
 349:./include/linux/slab.h **** 		struct kasan_cache kasan_info;
 350:./include/linux/slab.h **** 	#endif
 351:./include/linux/slab.h **** 	
 352:./include/linux/slab.h **** 	#ifdef CONFIG_HARDENED_USERCOPY
 353:./include/linux/slab.h **** 		unsigned int useroffset;	/* Usercopy region offset */
 354:./include/linux/slab.h **** 		unsigned int usersize;		/* Usercopy region size */
 355:./include/linux/slab.h **** 	#endif
 356:./include/linux/slab.h **** 	
 357:./include/linux/slab.h **** 		struct kmem_cache_node *node[MAX_NUMNODES];
 358:./include/linux/slab.h **** 	};
 359:./include/linux/slab.h **** 					
 360:./include/linux/slab.h **** 
 361:./include/linux/slab.h **** 
 362:./include/linux/slab.h **** 
 363:./include/linux/slab.h **** 
 364:./include/linux/slab.h **** #define KMALLOC_WAIT 1
 365:./include/linux/slab.h **** 
 366:./include/linux/slab.h **** 
 367:./include/linux/slab.h **** extern void* __smalloc__(u32 size, gfp_t flags);
 368:./include/linux/slab.h **** extern void  __sfree__(void* addr);
 369:./include/linux/slab.h **** 
 370:./include/linux/slab.h **** 
 371:./include/linux/slab.h **** static void inline *vmalloc(unsigned long size){
 372:./include/linux/slab.h **** 	return __smalloc__(size,GFP_TRANSHUGE_LIGHT);
 373:./include/linux/slab.h **** }
 374:./include/linux/slab.h **** 
 375:./include/linux/slab.h **** static void inline vfree(void *addr){
 376:./include/linux/slab.h **** 	__sfree__(addr);
 377:./include/linux/slab.h **** }
 378:./include/linux/slab.h **** 
 379:./include/linux/slab.h **** static void inline *kmalloc(size_t size, gfp_t flags){
  49              		.loc 2 379 21 view .LVU3
  50              	.LBB26:
 380:./include/linux/slab.h **** 	return __smalloc__((u32)size,flags);
  51              		.loc 2 380 2 view .LVU4
  52              		.loc 2 380 9 is_stmt 0 view .LVU5
  53 0006 1146     		mov	r1, r2
  54              	.LVL2:
  55              		.loc 2 380 9 view .LVU6
  56 0008 5C20     		movs	r0, #92
  57              	.LVL3:
  58              		.loc 2 380 9 view .LVU7
  59 000a FFF7FEFF 		bl	__smalloc__
  60              	.LVL4:
  61              		.loc 2 380 9 view .LVU8
  62 000e 0446     		mov	r4, r0
  63              	.LVL5:
  64              		.loc 2 380 9 view .LVU9
  65              	.LBE26:
ARM GAS  /tmp/ccalvPdg.s 			page 9


  66              	.LBE25:
  13:./block/request.c ****     if (!rq)  -ENOMEM;
  67              		.loc 1 13 5 is_stmt 1 view .LVU10
  68              		.loc 1 13 15 discriminator 1 view .LVU11
  14:./block/request.c ****     memset(rq, 0, sizeof(struct request));
  69              		.loc 1 14 5 view .LVU12
  70 0010 5C22     		movs	r2, #92
  71 0012 0021     		movs	r1, #0
  72 0014 FFF7FEFF 		bl	memset
  73              	.LVL6:
  15:./block/request.c **** 
  16:./block/request.c ****     rq->q = q;
  74              		.loc 1 16 5 view .LVU13
  75              		.loc 1 16 11 is_stmt 0 view .LVU14
  76 0018 2660     		str	r6, [r4]
  17:./block/request.c **** 
  18:./block/request.c ****     rq->cmd_flags = opf;
  77              		.loc 1 18 5 is_stmt 1 view .LVU15
  78              		.loc 1 18 19 is_stmt 0 view .LVU16
  79 001a 6560     		str	r5, [r4, #4]
  19:./block/request.c ****     rq->__data_len = 0;
  80              		.loc 1 19 5 is_stmt 1 view .LVU17
  20:./block/request.c ****     rq->__sector = 0;
  81              		.loc 1 20 5 view .LVU18
  21:./block/request.c ****     rq->bio = rq->biotail = NULL;
  82              		.loc 1 21 5 view .LVU19
  22:./block/request.c ****     INIT_LIST_HEAD(&rq->queuelist);
  83              		.loc 1 22 5 view .LVU20
  84 001c 04F12803 		add	r3, r4, #40
  85              	.LVL7:
  86              	.LBB27:
  87              	.LBI27:
  88              		.file 3 "./include/linux/list.h"
   1:./include/linux/list.h **** /* SPDX-License-Identifier: GPL-2.0 */
   2:./include/linux/list.h **** #ifndef _LINUX_LIST_H
   3:./include/linux/list.h **** #define _LINUX_LIST_H
   4:./include/linux/list.h **** 
   5:./include/linux/list.h **** #include <linux/container_of.h>
   6:./include/linux/list.h **** #include <linux/types.h>
   7:./include/linux/list.h **** #include <linux/stddef.h>
   8:./include/linux/list.h **** #include <linux/poison.h>
   9:./include/linux/list.h **** #include <linux/const.h>
  10:./include/linux/list.h **** 
  11:./include/linux/list.h **** #include <asm/barrier.h>
  12:./include/linux/list.h **** #include <linux/rwonce.h>
  13:./include/linux/list.h **** /*
  14:./include/linux/list.h ****  * Circular doubly linked list implementation.
  15:./include/linux/list.h ****  *
  16:./include/linux/list.h ****  * Some of the internal functions ("__xxx") are useful when
  17:./include/linux/list.h ****  * manipulating whole lists rather than single entries, as
  18:./include/linux/list.h ****  * sometimes we already know the next/prev entries and we can
  19:./include/linux/list.h ****  * generate better code by using them directly rather than
  20:./include/linux/list.h ****  * using the generic single-entry routines.
  21:./include/linux/list.h ****  */
  22:./include/linux/list.h **** 
  23:./include/linux/list.h **** #define LIST_HEAD_INIT(name) { &(name), &(name) }
  24:./include/linux/list.h **** 
ARM GAS  /tmp/ccalvPdg.s 			page 10


  25:./include/linux/list.h **** #define LIST_HEAD(name) \
  26:./include/linux/list.h **** 	struct list_head name = LIST_HEAD_INIT(name)
  27:./include/linux/list.h **** 
  28:./include/linux/list.h **** /**
  29:./include/linux/list.h ****  * INIT_LIST_HEAD - Initialize a list_head structure
  30:./include/linux/list.h ****  * @list: list_head structure to be initialized.
  31:./include/linux/list.h ****  *
  32:./include/linux/list.h ****  * Initializes the list_head to point to itself.  If it is a list header,
  33:./include/linux/list.h ****  * the result is an empty list.
  34:./include/linux/list.h ****  */
  35:./include/linux/list.h **** static inline void INIT_LIST_HEAD(struct list_head *list)
  89              		.loc 3 35 20 view .LVU21
  90              	.LBB28:
  36:./include/linux/list.h **** {
  37:./include/linux/list.h **** 	WRITE_ONCE(list->next, list);
  91              		.loc 3 37 2 view .LVU22
  92              		.loc 3 37 2 view .LVU23
  93              	.LBB29:
  94              		.loc 3 37 2 view .LVU24
  95              		.loc 3 37 2 view .LVU25
  96              	.LBE29:
  97              		.loc 3 37 2 discriminator 2 view .LVU26
  98              		.loc 3 37 2 discriminator 2 view .LVU27
  99              		.loc 3 37 2 discriminator 2 view .LVU28
 100 0020 A362     		str	r3, [r4, #40]
 101              		.loc 3 37 2 discriminator 2 view .LVU29
 102              		.loc 3 37 2 discriminator 2 view .LVU30
  38:./include/linux/list.h **** 	WRITE_ONCE(list->prev, list);
 103              		.loc 3 38 2 view .LVU31
 104              		.loc 3 38 2 view .LVU32
 105              	.LBB30:
 106              		.loc 3 38 2 view .LVU33
 107              		.loc 3 38 2 view .LVU34
 108              	.LBE30:
 109              		.loc 3 38 2 discriminator 2 view .LVU35
 110              		.loc 3 38 2 discriminator 2 view .LVU36
 111              		.loc 3 38 2 discriminator 2 view .LVU37
 112 0022 E362     		str	r3, [r4, #44]
 113              		.loc 3 38 2 discriminator 2 view .LVU38
 114              		.loc 3 38 2 discriminator 2 view .LVU39
 115              	.LVL8:
 116              		.loc 3 38 2 is_stmt 0 discriminator 2 view .LVU40
 117              	.LBE28:
 118              	.LBE27:
  23:./block/request.c ****     atomic_set(&rq->ref, 1);
 119              		.loc 1 23 5 is_stmt 1 view .LVU41
 120              	.LBB31:
 121              	.LBI31:
 122              		.file 4 "./include/linux/atomic/atomic-instrumented.h"
   1:./include/linux/atomic/atomic-instrumented.h **** // SPDX-License-Identifier: GPL-2.0
   2:./include/linux/atomic/atomic-instrumented.h **** 
   3:./include/linux/atomic/atomic-instrumented.h **** // Generated by scripts/atomic/gen-atomic-instrumented.sh 
   4:./include/linux/atomic/atomic-instrumented.h **** // DO NOT MODIFY THIS FILE DIRECTLY
   5:./include/linux/atomic/atomic-instrumented.h **** 
   6:./include/linux/atomic/atomic-instrumented.h **** /*
   7:./include/linux/atomic/atomic-instrumented.h ****  * This file provoides atomic operations with explicit instrumentation (e.g.
   8:./include/linux/atomic/atomic-instrumented.h ****  * KASAN, KCSAN), which should be used unless it is necessary to avoid
ARM GAS  /tmp/ccalvPdg.s 			page 11


   9:./include/linux/atomic/atomic-instrumented.h ****  * instrumentation. Where it is necessary to aovid instrumenation, the
  10:./include/linux/atomic/atomic-instrumented.h ****  * raw_atomic*() operations should be used.
  11:./include/linux/atomic/atomic-instrumented.h ****  */
  12:./include/linux/atomic/atomic-instrumented.h **** #ifndef _LINUX_ATOMIC_INSTRUMENTED_H
  13:./include/linux/atomic/atomic-instrumented.h **** #define _LINUX_ATOMIC_INSTRUMENTED_H
  14:./include/linux/atomic/atomic-instrumented.h **** 
  15:./include/linux/atomic/atomic-instrumented.h **** #include <linux/build_bug.h>
  16:./include/linux/atomic/atomic-instrumented.h **** #include <linux/compiler.h>
  17:./include/linux/atomic/atomic-instrumented.h **** #include <linux/instrumented.h>
  18:./include/linux/atomic/atomic-instrumented.h **** 
  19:./include/linux/atomic/atomic-instrumented.h **** /**
  20:./include/linux/atomic/atomic-instrumented.h ****  * atomic_read() - atomic load with relaxed ordering
  21:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
  22:./include/linux/atomic/atomic-instrumented.h ****  *
  23:./include/linux/atomic/atomic-instrumented.h ****  * Atomically loads the value of @v with relaxed ordering.
  24:./include/linux/atomic/atomic-instrumented.h ****  *
  25:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_read() there.
  26:./include/linux/atomic/atomic-instrumented.h ****  *
  27:./include/linux/atomic/atomic-instrumented.h ****  * Return: The value loaded from @v.
  28:./include/linux/atomic/atomic-instrumented.h ****  */
  29:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
  30:./include/linux/atomic/atomic-instrumented.h **** atomic_read(const atomic_t *v)
  31:./include/linux/atomic/atomic-instrumented.h **** {
  32:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read(v, sizeof(*v));
  33:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_read(v);
  34:./include/linux/atomic/atomic-instrumented.h **** }
  35:./include/linux/atomic/atomic-instrumented.h **** 
  36:./include/linux/atomic/atomic-instrumented.h **** /**
  37:./include/linux/atomic/atomic-instrumented.h ****  * atomic_read_acquire() - atomic load with acquire ordering
  38:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
  39:./include/linux/atomic/atomic-instrumented.h ****  *
  40:./include/linux/atomic/atomic-instrumented.h ****  * Atomically loads the value of @v with acquire ordering.
  41:./include/linux/atomic/atomic-instrumented.h ****  *
  42:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_read_acquire() there.
  43:./include/linux/atomic/atomic-instrumented.h ****  *
  44:./include/linux/atomic/atomic-instrumented.h ****  * Return: The value loaded from @v.
  45:./include/linux/atomic/atomic-instrumented.h ****  */
  46:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
  47:./include/linux/atomic/atomic-instrumented.h **** atomic_read_acquire(const atomic_t *v)
  48:./include/linux/atomic/atomic-instrumented.h **** {
  49:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read(v, sizeof(*v));
  50:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_read_acquire(v);
  51:./include/linux/atomic/atomic-instrumented.h **** }
  52:./include/linux/atomic/atomic-instrumented.h **** 
  53:./include/linux/atomic/atomic-instrumented.h **** /**
  54:./include/linux/atomic/atomic-instrumented.h ****  * atomic_set() - atomic set with relaxed ordering
  55:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
  56:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value to assign
  57:./include/linux/atomic/atomic-instrumented.h ****  *
  58:./include/linux/atomic/atomic-instrumented.h ****  * Atomically sets @v to @i with relaxed ordering.
  59:./include/linux/atomic/atomic-instrumented.h ****  *
  60:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_set() there.
  61:./include/linux/atomic/atomic-instrumented.h ****  *
  62:./include/linux/atomic/atomic-instrumented.h ****  * Return: Nothing.
  63:./include/linux/atomic/atomic-instrumented.h ****  */
  64:./include/linux/atomic/atomic-instrumented.h **** static __always_inline void
  65:./include/linux/atomic/atomic-instrumented.h **** atomic_set(atomic_t *v, int i)
ARM GAS  /tmp/ccalvPdg.s 			page 12


 123              		.loc 4 65 1 view .LVU42
  66:./include/linux/atomic/atomic-instrumented.h **** {
  67:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_write(v, sizeof(*v));
 124              		.loc 4 67 2 view .LVU43
  68:./include/linux/atomic/atomic-instrumented.h **** 	raw_atomic_set(v, i);
 125              		.loc 4 68 2 view .LVU44
 126              	.LBB32:
 127              	.LBI32:
 128              		.file 5 "./include/linux/atomic/atomic-arch-fallback.h"
   1:./include/linux/atomic/atomic-arch-fallback.h **** // SPDX-License-Identifier: GPL-2.0
   2:./include/linux/atomic/atomic-arch-fallback.h **** 
   3:./include/linux/atomic/atomic-arch-fallback.h **** // Generated by scripts/atomic/gen-atomic-fallback.sh
   4:./include/linux/atomic/atomic-arch-fallback.h **** // DO NOT MODIFY THIS FILE DIRECTLY
   5:./include/linux/atomic/atomic-arch-fallback.h **** 
   6:./include/linux/atomic/atomic-arch-fallback.h **** #ifndef _LINUX_ATOMIC_FALLBACK_H
   7:./include/linux/atomic/atomic-arch-fallback.h **** #define _LINUX_ATOMIC_FALLBACK_H
   8:./include/linux/atomic/atomic-arch-fallback.h **** 
   9:./include/linux/atomic/atomic-arch-fallback.h **** #include <linux/compiler.h>
  10:./include/linux/atomic/atomic-arch-fallback.h **** 
  11:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_xchg)
  12:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg arch_xchg
  13:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_xchg_relaxed)
  14:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg(...) \
  15:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_fence(arch_xchg, __VA_ARGS__)
  16:./include/linux/atomic/atomic-arch-fallback.h **** #else
  17:./include/linux/atomic/atomic-arch-fallback.h **** extern void raw_xchg_not_implemented(void);
  18:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg(...) raw_xchg_not_implemented()
  19:./include/linux/atomic/atomic-arch-fallback.h **** #endif
  20:./include/linux/atomic/atomic-arch-fallback.h **** 
  21:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_xchg_acquire)
  22:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_acquire arch_xchg_acquire
  23:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_xchg_relaxed)
  24:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_acquire(...) \
  25:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_acquire(arch_xchg, __VA_ARGS__)
  26:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_xchg)
  27:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_acquire arch_xchg
  28:./include/linux/atomic/atomic-arch-fallback.h **** #else
  29:./include/linux/atomic/atomic-arch-fallback.h **** extern void raw_xchg_acquire_not_implemented(void);
  30:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_acquire(...) raw_xchg_acquire_not_implemented()
  31:./include/linux/atomic/atomic-arch-fallback.h **** #endif
  32:./include/linux/atomic/atomic-arch-fallback.h **** 
  33:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_xchg_release)
  34:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_release arch_xchg_release
  35:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_xchg_relaxed)
  36:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_release(...) \
  37:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_release(arch_xchg, __VA_ARGS__)
  38:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_xchg)
  39:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_release arch_xchg
  40:./include/linux/atomic/atomic-arch-fallback.h **** #else
  41:./include/linux/atomic/atomic-arch-fallback.h **** extern void raw_xchg_release_not_implemented(void);
  42:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_release(...) raw_xchg_release_not_implemented()
  43:./include/linux/atomic/atomic-arch-fallback.h **** #endif
  44:./include/linux/atomic/atomic-arch-fallback.h **** 
  45:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_xchg_relaxed)
  46:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_relaxed arch_xchg_relaxed
  47:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_xchg)
  48:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_relaxed arch_xchg
ARM GAS  /tmp/ccalvPdg.s 			page 13


  49:./include/linux/atomic/atomic-arch-fallback.h **** #else
  50:./include/linux/atomic/atomic-arch-fallback.h **** extern void raw_xchg_relaxed_not_implemented(void);
  51:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_relaxed(...) raw_xchg_relaxed_not_implemented()
  52:./include/linux/atomic/atomic-arch-fallback.h **** #endif
  53:./include/linux/atomic/atomic-arch-fallback.h **** 
  54:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg)
  55:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg arch_cmpxchg
  56:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg_relaxed)
  57:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg(...) \
  58:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_fence(arch_cmpxchg, __VA_ARGS__)
  59:./include/linux/atomic/atomic-arch-fallback.h **** #else
  60:./include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg_not_implemented(void);
  61:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg(...) raw_cmpxchg_not_implemented()
  62:./include/linux/atomic/atomic-arch-fallback.h **** #endif
  63:./include/linux/atomic/atomic-arch-fallback.h **** 
  64:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg_acquire)
  65:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_acquire arch_cmpxchg_acquire
  66:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg_relaxed)
  67:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_acquire(...) \
  68:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_acquire(arch_cmpxchg, __VA_ARGS__)
  69:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg)
  70:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_acquire arch_cmpxchg
  71:./include/linux/atomic/atomic-arch-fallback.h **** #else
  72:./include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg_acquire_not_implemented(void);
  73:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_acquire(...) raw_cmpxchg_acquire_not_implemented()
  74:./include/linux/atomic/atomic-arch-fallback.h **** #endif
  75:./include/linux/atomic/atomic-arch-fallback.h **** 
  76:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg_release)
  77:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_release arch_cmpxchg_release
  78:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg_relaxed)
  79:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_release(...) \
  80:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_release(arch_cmpxchg, __VA_ARGS__)
  81:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg)
  82:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_release arch_cmpxchg
  83:./include/linux/atomic/atomic-arch-fallback.h **** #else
  84:./include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg_release_not_implemented(void);
  85:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_release(...) raw_cmpxchg_release_not_implemented()
  86:./include/linux/atomic/atomic-arch-fallback.h **** #endif
  87:./include/linux/atomic/atomic-arch-fallback.h **** 
  88:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg_relaxed)
  89:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_relaxed arch_cmpxchg_relaxed
  90:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg)
  91:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_relaxed arch_cmpxchg
  92:./include/linux/atomic/atomic-arch-fallback.h **** #else
  93:./include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg_relaxed_not_implemented(void);
  94:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_relaxed(...) raw_cmpxchg_relaxed_not_implemented()
  95:./include/linux/atomic/atomic-arch-fallback.h **** #endif
  96:./include/linux/atomic/atomic-arch-fallback.h **** 
  97:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg64)
  98:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64 arch_cmpxchg64
  99:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg64_relaxed)
 100:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64(...) \
 101:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_fence(arch_cmpxchg64, __VA_ARGS__)
 102:./include/linux/atomic/atomic-arch-fallback.h **** #else
 103:./include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg64_not_implemented(void);
 104:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64(...) raw_cmpxchg64_not_implemented()
 105:./include/linux/atomic/atomic-arch-fallback.h **** #endif
ARM GAS  /tmp/ccalvPdg.s 			page 14


 106:./include/linux/atomic/atomic-arch-fallback.h **** 
 107:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg64_acquire)
 108:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_acquire arch_cmpxchg64_acquire
 109:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg64_relaxed)
 110:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_acquire(...) \
 111:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_acquire(arch_cmpxchg64, __VA_ARGS__)
 112:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg64)
 113:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_acquire arch_cmpxchg64
 114:./include/linux/atomic/atomic-arch-fallback.h **** #else
 115:./include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg64_acquire_not_implemented(void);
 116:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_acquire(...) raw_cmpxchg64_acquire_not_implemented()
 117:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 118:./include/linux/atomic/atomic-arch-fallback.h **** 
 119:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg64_release)
 120:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_release arch_cmpxchg64_release
 121:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg64_relaxed)
 122:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_release(...) \
 123:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_release(arch_cmpxchg64, __VA_ARGS__)
 124:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg64)
 125:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_release arch_cmpxchg64
 126:./include/linux/atomic/atomic-arch-fallback.h **** #else
 127:./include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg64_release_not_implemented(void);
 128:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_release(...) raw_cmpxchg64_release_not_implemented()
 129:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 130:./include/linux/atomic/atomic-arch-fallback.h **** 
 131:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg64_relaxed)
 132:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_relaxed arch_cmpxchg64_relaxed
 133:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg64)
 134:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_relaxed arch_cmpxchg64
 135:./include/linux/atomic/atomic-arch-fallback.h **** #else
 136:./include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg64_relaxed_not_implemented(void);
 137:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_relaxed(...) raw_cmpxchg64_relaxed_not_implemented()
 138:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 139:./include/linux/atomic/atomic-arch-fallback.h **** 
 140:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg128)
 141:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128 arch_cmpxchg128
 142:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg128_relaxed)
 143:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128(...) \
 144:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_fence(arch_cmpxchg128, __VA_ARGS__)
 145:./include/linux/atomic/atomic-arch-fallback.h **** #else
 146:./include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg128_not_implemented(void);
 147:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128(...) raw_cmpxchg128_not_implemented()
 148:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 149:./include/linux/atomic/atomic-arch-fallback.h **** 
 150:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg128_acquire)
 151:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_acquire arch_cmpxchg128_acquire
 152:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg128_relaxed)
 153:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_acquire(...) \
 154:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_acquire(arch_cmpxchg128, __VA_ARGS__)
 155:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg128)
 156:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_acquire arch_cmpxchg128
 157:./include/linux/atomic/atomic-arch-fallback.h **** #else
 158:./include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg128_acquire_not_implemented(void);
 159:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_acquire(...) raw_cmpxchg128_acquire_not_implemented()
 160:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 161:./include/linux/atomic/atomic-arch-fallback.h **** 
 162:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg128_release)
ARM GAS  /tmp/ccalvPdg.s 			page 15


 163:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_release arch_cmpxchg128_release
 164:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg128_relaxed)
 165:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_release(...) \
 166:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_release(arch_cmpxchg128, __VA_ARGS__)
 167:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg128)
 168:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_release arch_cmpxchg128
 169:./include/linux/atomic/atomic-arch-fallback.h **** #else
 170:./include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg128_release_not_implemented(void);
 171:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_release(...) raw_cmpxchg128_release_not_implemented()
 172:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 173:./include/linux/atomic/atomic-arch-fallback.h **** 
 174:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg128_relaxed)
 175:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_relaxed arch_cmpxchg128_relaxed
 176:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg128)
 177:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_relaxed arch_cmpxchg128
 178:./include/linux/atomic/atomic-arch-fallback.h **** #else
 179:./include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg128_relaxed_not_implemented(void);
 180:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_relaxed(...) raw_cmpxchg128_relaxed_not_implemented()
 181:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 182:./include/linux/atomic/atomic-arch-fallback.h **** 
 183:./include/linux/atomic/atomic-arch-fallback.h **** 
 184:./include/linux/atomic/atomic-arch-fallback.h **** 
 185:./include/linux/atomic/atomic-arch-fallback.h **** 
 186:./include/linux/atomic/atomic-arch-fallback.h **** 
 187:./include/linux/atomic/atomic-arch-fallback.h **** 
 188:./include/linux/atomic/atomic-arch-fallback.h **** 
 189:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg)
 190:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg arch_try_cmpxchg
 191:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg_relaxed)
 192:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg(...) \
 193:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_fence(arch_try_cmpxchg, __VA_ARGS__)
 194:./include/linux/atomic/atomic-arch-fallback.h **** #else
 195:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg(_ptr, _oldp, _new) \
 196:./include/linux/atomic/atomic-arch-fallback.h **** ({ \
 197:./include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 198:./include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg((_ptr), ___o, (_new)); \
 199:./include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 200:./include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 201:./include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 202:./include/linux/atomic/atomic-arch-fallback.h **** })
 203:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 204:./include/linux/atomic/atomic-arch-fallback.h **** 
 205:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg_acquire)
 206:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_acquire arch_try_cmpxchg_acquire
 207:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg_relaxed)
 208:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_acquire(...) \
 209:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_acquire(arch_try_cmpxchg, __VA_ARGS__)
 210:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg)
 211:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_acquire arch_try_cmpxchg
 212:./include/linux/atomic/atomic-arch-fallback.h **** #else
 213:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_acquire(_ptr, _oldp, _new) \
 214:./include/linux/atomic/atomic-arch-fallback.h **** ({ \
 215:./include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 216:./include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg_acquire((_ptr), ___o, (_new)); \
 217:./include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 218:./include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 219:./include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
ARM GAS  /tmp/ccalvPdg.s 			page 16


 220:./include/linux/atomic/atomic-arch-fallback.h **** })
 221:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 222:./include/linux/atomic/atomic-arch-fallback.h **** 
 223:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg_release)
 224:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_release arch_try_cmpxchg_release
 225:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg_relaxed)
 226:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_release(...) \
 227:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_release(arch_try_cmpxchg, __VA_ARGS__)
 228:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg)
 229:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_release arch_try_cmpxchg
 230:./include/linux/atomic/atomic-arch-fallback.h **** #else
 231:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_release(_ptr, _oldp, _new) \
 232:./include/linux/atomic/atomic-arch-fallback.h **** ({ \
 233:./include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 234:./include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg_release((_ptr), ___o, (_new)); \
 235:./include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 236:./include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 237:./include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 238:./include/linux/atomic/atomic-arch-fallback.h **** })
 239:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 240:./include/linux/atomic/atomic-arch-fallback.h **** 
 241:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg_relaxed)
 242:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_relaxed arch_try_cmpxchg_relaxed
 243:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg)
 244:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_relaxed arch_try_cmpxchg
 245:./include/linux/atomic/atomic-arch-fallback.h **** #else
 246:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_relaxed(_ptr, _oldp, _new) \
 247:./include/linux/atomic/atomic-arch-fallback.h **** ({ \
 248:./include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 249:./include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg_relaxed((_ptr), ___o, (_new)); \
 250:./include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 251:./include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 252:./include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 253:./include/linux/atomic/atomic-arch-fallback.h **** })
 254:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 255:./include/linux/atomic/atomic-arch-fallback.h **** 
 256:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg64)
 257:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64 arch_try_cmpxchg64
 258:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg64_relaxed)
 259:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64(...) \
 260:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_fence(arch_try_cmpxchg64, __VA_ARGS__)
 261:./include/linux/atomic/atomic-arch-fallback.h **** #else
 262:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64(_ptr, _oldp, _new) \
 263:./include/linux/atomic/atomic-arch-fallback.h **** ({ \
 264:./include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 265:./include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg64((_ptr), ___o, (_new)); \
 266:./include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 267:./include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 268:./include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 269:./include/linux/atomic/atomic-arch-fallback.h **** })
 270:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 271:./include/linux/atomic/atomic-arch-fallback.h **** 
 272:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg64_acquire)
 273:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_acquire arch_try_cmpxchg64_acquire
 274:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg64_relaxed)
 275:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_acquire(...) \
 276:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_acquire(arch_try_cmpxchg64, __VA_ARGS__)
ARM GAS  /tmp/ccalvPdg.s 			page 17


 277:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg64)
 278:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_acquire arch_try_cmpxchg64
 279:./include/linux/atomic/atomic-arch-fallback.h **** #else
 280:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_acquire(_ptr, _oldp, _new) \
 281:./include/linux/atomic/atomic-arch-fallback.h **** ({ \
 282:./include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 283:./include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg64_acquire((_ptr), ___o, (_new)); \
 284:./include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 285:./include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 286:./include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 287:./include/linux/atomic/atomic-arch-fallback.h **** })
 288:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 289:./include/linux/atomic/atomic-arch-fallback.h **** 
 290:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg64_release)
 291:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_release arch_try_cmpxchg64_release
 292:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg64_relaxed)
 293:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_release(...) \
 294:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_release(arch_try_cmpxchg64, __VA_ARGS__)
 295:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg64)
 296:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_release arch_try_cmpxchg64
 297:./include/linux/atomic/atomic-arch-fallback.h **** #else
 298:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_release(_ptr, _oldp, _new) \
 299:./include/linux/atomic/atomic-arch-fallback.h **** ({ \
 300:./include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 301:./include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg64_release((_ptr), ___o, (_new)); \
 302:./include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 303:./include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 304:./include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 305:./include/linux/atomic/atomic-arch-fallback.h **** })
 306:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 307:./include/linux/atomic/atomic-arch-fallback.h **** 
 308:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg64_relaxed)
 309:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_relaxed arch_try_cmpxchg64_relaxed
 310:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg64)
 311:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_relaxed arch_try_cmpxchg64
 312:./include/linux/atomic/atomic-arch-fallback.h **** #else
 313:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_relaxed(_ptr, _oldp, _new) \
 314:./include/linux/atomic/atomic-arch-fallback.h **** ({ \
 315:./include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 316:./include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg64_relaxed((_ptr), ___o, (_new)); \
 317:./include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 318:./include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 319:./include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 320:./include/linux/atomic/atomic-arch-fallback.h **** })
 321:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 322:./include/linux/atomic/atomic-arch-fallback.h **** 
 323:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg128)
 324:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128 arch_try_cmpxchg128
 325:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg128_relaxed)
 326:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128(...) \
 327:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_fence(arch_try_cmpxchg128, __VA_ARGS__)
 328:./include/linux/atomic/atomic-arch-fallback.h **** #else
 329:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128(_ptr, _oldp, _new) \
 330:./include/linux/atomic/atomic-arch-fallback.h **** ({ \
 331:./include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 332:./include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg128((_ptr), ___o, (_new)); \
 333:./include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
ARM GAS  /tmp/ccalvPdg.s 			page 18


 334:./include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 335:./include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 336:./include/linux/atomic/atomic-arch-fallback.h **** })
 337:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 338:./include/linux/atomic/atomic-arch-fallback.h **** 
 339:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg128_acquire)
 340:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_acquire arch_try_cmpxchg128_acquire
 341:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg128_relaxed)
 342:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_acquire(...) \
 343:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_acquire(arch_try_cmpxchg128, __VA_ARGS__)
 344:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg128)
 345:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_acquire arch_try_cmpxchg128
 346:./include/linux/atomic/atomic-arch-fallback.h **** #else
 347:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_acquire(_ptr, _oldp, _new) \
 348:./include/linux/atomic/atomic-arch-fallback.h **** ({ \
 349:./include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 350:./include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg128_acquire((_ptr), ___o, (_new)); \
 351:./include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 352:./include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 353:./include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 354:./include/linux/atomic/atomic-arch-fallback.h **** })
 355:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 356:./include/linux/atomic/atomic-arch-fallback.h **** 
 357:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg128_release)
 358:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_release arch_try_cmpxchg128_release
 359:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg128_relaxed)
 360:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_release(...) \
 361:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_release(arch_try_cmpxchg128, __VA_ARGS__)
 362:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg128)
 363:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_release arch_try_cmpxchg128
 364:./include/linux/atomic/atomic-arch-fallback.h **** #else
 365:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_release(_ptr, _oldp, _new) \
 366:./include/linux/atomic/atomic-arch-fallback.h **** ({ \
 367:./include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 368:./include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg128_release((_ptr), ___o, (_new)); \
 369:./include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 370:./include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 371:./include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 372:./include/linux/atomic/atomic-arch-fallback.h **** })
 373:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 374:./include/linux/atomic/atomic-arch-fallback.h **** 
 375:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg128_relaxed)
 376:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_relaxed arch_try_cmpxchg128_relaxed
 377:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg128)
 378:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_relaxed arch_try_cmpxchg128
 379:./include/linux/atomic/atomic-arch-fallback.h **** #else
 380:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_relaxed(_ptr, _oldp, _new) \
 381:./include/linux/atomic/atomic-arch-fallback.h **** ({ \
 382:./include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 383:./include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg128_relaxed((_ptr), ___o, (_new)); \
 384:./include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 385:./include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 386:./include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 387:./include/linux/atomic/atomic-arch-fallback.h **** })
 388:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 389:./include/linux/atomic/atomic-arch-fallback.h **** 
 390:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_local arch_cmpxchg_local
ARM GAS  /tmp/ccalvPdg.s 			page 19


 391:./include/linux/atomic/atomic-arch-fallback.h **** 
 392:./include/linux/atomic/atomic-arch-fallback.h **** #ifdef arch_try_cmpxchg_local
 393:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_local arch_try_cmpxchg_local
 394:./include/linux/atomic/atomic-arch-fallback.h **** #else
 395:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_local(_ptr, _oldp, _new) \
 396:./include/linux/atomic/atomic-arch-fallback.h **** ({ \
 397:./include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 398:./include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg_local((_ptr), ___o, (_new)); \
 399:./include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 400:./include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 401:./include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 402:./include/linux/atomic/atomic-arch-fallback.h **** })
 403:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 404:./include/linux/atomic/atomic-arch-fallback.h **** 
 405:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_local arch_cmpxchg64_local
 406:./include/linux/atomic/atomic-arch-fallback.h **** 
 407:./include/linux/atomic/atomic-arch-fallback.h **** #ifdef arch_try_cmpxchg64_local
 408:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_local arch_try_cmpxchg64_local
 409:./include/linux/atomic/atomic-arch-fallback.h **** #else
 410:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_local(_ptr, _oldp, _new) \
 411:./include/linux/atomic/atomic-arch-fallback.h **** ({ \
 412:./include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 413:./include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg64_local((_ptr), ___o, (_new)); \
 414:./include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 415:./include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 416:./include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 417:./include/linux/atomic/atomic-arch-fallback.h **** })
 418:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 419:./include/linux/atomic/atomic-arch-fallback.h **** 
 420:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_local arch_cmpxchg128_local
 421:./include/linux/atomic/atomic-arch-fallback.h **** 
 422:./include/linux/atomic/atomic-arch-fallback.h **** #ifdef arch_try_cmpxchg128_local
 423:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_local arch_try_cmpxchg128_local
 424:./include/linux/atomic/atomic-arch-fallback.h **** #else
 425:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_local(_ptr, _oldp, _new) \
 426:./include/linux/atomic/atomic-arch-fallback.h **** ({ \
 427:./include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 428:./include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg128_local((_ptr), ___o, (_new)); \
 429:./include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 430:./include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 431:./include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 432:./include/linux/atomic/atomic-arch-fallback.h **** })
 433:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 434:./include/linux/atomic/atomic-arch-fallback.h **** 
 435:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_sync_cmpxchg arch_sync_cmpxchg
 436:./include/linux/atomic/atomic-arch-fallback.h **** 
 437:./include/linux/atomic/atomic-arch-fallback.h **** #ifdef arch_sync_try_cmpxchg
 438:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_sync_try_cmpxchg arch_sync_try_cmpxchg
 439:./include/linux/atomic/atomic-arch-fallback.h **** #else
 440:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_sync_try_cmpxchg(_ptr, _oldp, _new) \
 441:./include/linux/atomic/atomic-arch-fallback.h **** ({ \
 442:./include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 443:./include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_sync_cmpxchg((_ptr), ___o, (_new)); \
 444:./include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 445:./include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 446:./include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 447:./include/linux/atomic/atomic-arch-fallback.h **** })
ARM GAS  /tmp/ccalvPdg.s 			page 20


 448:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 449:./include/linux/atomic/atomic-arch-fallback.h **** 
 450:./include/linux/atomic/atomic-arch-fallback.h **** /**
 451:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_read() - atomic load with relaxed ordering
 452:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 453:./include/linux/atomic/atomic-arch-fallback.h ****  *
 454:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically loads the value of @v with relaxed ordering.
 455:./include/linux/atomic/atomic-arch-fallback.h ****  *
 456:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_read() elsewhere.
 457:./include/linux/atomic/atomic-arch-fallback.h ****  *
 458:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The value loaded from @v.
 459:./include/linux/atomic/atomic-arch-fallback.h ****  */
 460:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 461:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_read(const atomic_t *v)
 462:./include/linux/atomic/atomic-arch-fallback.h **** {
 463:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_read(v);
 464:./include/linux/atomic/atomic-arch-fallback.h **** }
 465:./include/linux/atomic/atomic-arch-fallback.h **** 
 466:./include/linux/atomic/atomic-arch-fallback.h **** /**
 467:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_read_acquire() - atomic load with acquire ordering
 468:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 469:./include/linux/atomic/atomic-arch-fallback.h ****  *
 470:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically loads the value of @v with acquire ordering.
 471:./include/linux/atomic/atomic-arch-fallback.h ****  *
 472:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_read_acquire() elsewhere.
 473:./include/linux/atomic/atomic-arch-fallback.h ****  *
 474:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The value loaded from @v.
 475:./include/linux/atomic/atomic-arch-fallback.h ****  */
 476:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 477:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_read_acquire(const atomic_t *v)
 478:./include/linux/atomic/atomic-arch-fallback.h **** {
 479:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_read_acquire)
 480:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_read_acquire(v);
 481:./include/linux/atomic/atomic-arch-fallback.h **** #else
 482:./include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
 483:./include/linux/atomic/atomic-arch-fallback.h **** 
 484:./include/linux/atomic/atomic-arch-fallback.h **** 	if (__native_word(atomic_t)) {
 485:./include/linux/atomic/atomic-arch-fallback.h **** 		ret = smp_load_acquire(&(v)->counter);
 486:./include/linux/atomic/atomic-arch-fallback.h **** 	} else {
 487:./include/linux/atomic/atomic-arch-fallback.h **** 		ret = raw_atomic_read(v);
 488:./include/linux/atomic/atomic-arch-fallback.h **** 		__atomic_acquire_fence();
 489:./include/linux/atomic/atomic-arch-fallback.h **** 	}
 490:./include/linux/atomic/atomic-arch-fallback.h **** 
 491:./include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
 492:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 493:./include/linux/atomic/atomic-arch-fallback.h **** }
 494:./include/linux/atomic/atomic-arch-fallback.h **** 
 495:./include/linux/atomic/atomic-arch-fallback.h **** /**
 496:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_set() - atomic set with relaxed ordering
 497:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 498:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to assign
 499:./include/linux/atomic/atomic-arch-fallback.h ****  *
 500:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically sets @v to @i with relaxed ordering.
 501:./include/linux/atomic/atomic-arch-fallback.h ****  *
 502:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_set() elsewhere.
 503:./include/linux/atomic/atomic-arch-fallback.h ****  *
 504:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: Nothing.
ARM GAS  /tmp/ccalvPdg.s 			page 21


 505:./include/linux/atomic/atomic-arch-fallback.h ****  */
 506:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline void
 507:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_set(atomic_t *v, int i)
 129              		.loc 5 507 1 view .LVU45
 130              	.LBB33:
 508:./include/linux/atomic/atomic-arch-fallback.h **** {
 509:./include/linux/atomic/atomic-arch-fallback.h **** 	arch_atomic_set(v, i);
 131              		.loc 5 509 2 view .LVU46
 132              		.loc 5 509 2 view .LVU47
 133              	.LBB34:
 134              		.loc 5 509 2 view .LVU48
 135              		.loc 5 509 2 view .LVU49
 136              	.LBE34:
 137              		.loc 5 509 2 discriminator 2 view .LVU50
 138              		.loc 5 509 2 discriminator 2 view .LVU51
 139              		.loc 5 509 2 discriminator 2 view .LVU52
 140 0024 0123     		movs	r3, #1
 141 0026 2364     		str	r3, [r4, #64]
 142              		.loc 5 509 2 discriminator 2 view .LVU53
 143              		.loc 5 509 2 discriminator 2 view .LVU54
 144              	.LVL9:
 145              		.loc 5 509 2 is_stmt 0 discriminator 2 view .LVU55
 146              	.LBE33:
 147              	.LBE32:
 148              	.LBE31:
  24:./block/request.c ****     rq->state = MQ_RQ_IDLE;
 149              		.loc 1 24 5 is_stmt 1 view .LVU56
  25:./block/request.c ****     
  26:./block/request.c ****     /*  */
  27:./block/request.c ****     rq->start_time_ns = ktime_get_ns();
 150              		.loc 1 27 5 view .LVU57
 151              	.LBB35:
 152              	.LBI35:
 153              		.file 6 "./include/linux/time.h"
   1:./include/linux/time.h **** /* SPDX-License-Identifier: GPL-2.0 */
   2:./include/linux/time.h **** #ifndef _LINUX_TIME_H
   3:./include/linux/time.h **** #define _LINUX_TIME_H
   4:./include/linux/time.h **** 
   5:./include/linux/time.h **** # include <linux/cache.h>
   6:./include/linux/time.h **** # include <linux/math64.h>
   7:./include/linux/time.h **** # include <linux/time64.h>
   8:./include/linux/time.h **** 
   9:./include/linux/time.h **** extern time64_t ktime_get();
  10:./include/linux/time.h **** 
  11:./include/linux/time.h **** #define jiffies ktime_get()
  12:./include/linux/time.h **** 
  13:./include/linux/time.h **** extern unsigned int HZ;
  14:./include/linux/time.h **** 
  15:./include/linux/time.h **** static __always_inline timer_t ktime_get_ns(){
 154              		.loc 6 15 32 view .LVU58
 155              	.LBB36:
  16:./include/linux/time.h ****     return ktime_get();
 156              		.loc 6 16 5 view .LVU59
 157              		.loc 6 16 12 is_stmt 0 view .LVU60
 158 0028 FFF7FEFF 		bl	ktime_get
 159              	.LVL10:
 160              	.LBE36:
ARM GAS  /tmp/ccalvPdg.s 			page 22


 161              	.LBE35:
 162              		.loc 1 27 23 discriminator 1 view .LVU61
 163 002c 6063     		str	r0, [r4, #52]
  28:./block/request.c ****     rq->io_start_time_ns = 0;
 164              		.loc 1 28 5 is_stmt 1 view .LVU62
 165              		.loc 1 28 26 is_stmt 0 view .LVU63
 166 002e 0023     		movs	r3, #0
 167 0030 A363     		str	r3, [r4, #56]
  29:./block/request.c ****     
  30:./block/request.c ****     /* I/O  */
  31:./block/request.c ****     rq->part = NULL;
 168              		.loc 1 31 5 is_stmt 1 view .LVU64
 169              		.loc 1 31 14 is_stmt 0 view .LVU65
 170 0032 2363     		str	r3, [r4, #48]
  32:./block/request.c ****     rq->timeout = 1000;
 171              		.loc 1 32 5 is_stmt 1 view .LVU66
 172              		.loc 1 32 17 is_stmt 0 view .LVU67
 173 0034 4FF47A73 		mov	r3, #1000
 174 0038 6361     		str	r3, [r4, #20]
  33:./block/request.c ****     
  34:./block/request.c ****     return rq;
 175              		.loc 1 34 5 is_stmt 1 view .LVU68
  35:./block/request.c **** }
 176              		.loc 1 35 1 is_stmt 0 view .LVU69
 177 003a 2046     		mov	r0, r4
 178 003c 70BD     		pop	{r4, r5, r6, pc}
 179              		.loc 1 35 1 view .LVU70
 180              		.cfi_endproc
 181              	.LFE960:
 183              		.section	.text.__blk_insert_request,"ax",%progbits
 184              		.align	1
 185              		.global	__blk_insert_request
 186              		.syntax unified
 187              		.thumb
 188              		.thumb_func
 190              	__blk_insert_request:
 191              	.LVL11:
 192              	.LFB961:
  36:./block/request.c **** 
  37:./block/request.c **** 
  38:./block/request.c **** void __blk_insert_request(struct request *rq, struct bio *bio)
  39:./block/request.c **** {
 193              		.loc 1 39 1 is_stmt 1 view -0
 194              		.cfi_startproc
 195              		@ args = 0, pretend = 0, frame = 0
 196              		@ frame_needed = 0, uses_anonymous_args = 0
 197              		@ link register save eliminated.
  40:./block/request.c ****     
  41:./block/request.c ****     bio->bi_next = NULL;
 198              		.loc 1 41 5 view .LVU72
 199              		.loc 1 41 18 is_stmt 0 view .LVU73
 200 0000 0023     		movs	r3, #0
 201 0002 0B60     		str	r3, [r1]
  42:./block/request.c **** 
  43:./block/request.c ****     struct bio *head = rq->bio;
 202              		.loc 1 43 5 is_stmt 1 view .LVU74
 203              		.loc 1 43 17 is_stmt 0 view .LVU75
ARM GAS  /tmp/ccalvPdg.s 			page 23


 204 0004 036A     		ldr	r3, [r0, #32]
 205              	.LVL12:
  44:./block/request.c ****     if(head == NULL)
 206              		.loc 1 44 5 is_stmt 1 view .LVU76
 207              		.loc 1 44 7 is_stmt 0 view .LVU77
 208 0006 33B1     		cbz	r3, .L6
  45:./block/request.c ****     {
  46:./block/request.c ****         rq->bio = bio;
  47:./block/request.c ****         rq->biotail = bio;
  48:./block/request.c ****     }
  49:./block/request.c ****     else
  50:./block/request.c ****     {
  51:./block/request.c ****         rq->biotail->bi_next = bio;
 209              		.loc 1 51 9 is_stmt 1 view .LVU78
 210              		.loc 1 51 11 is_stmt 0 view .LVU79
 211 0008 436A     		ldr	r3, [r0, #36]
 212              	.LVL13:
 213              		.loc 1 51 30 view .LVU80
 214 000a 1960     		str	r1, [r3]
 215              	.LVL14:
  52:./block/request.c ****         rq->biotail = bio;
 216              		.loc 1 52 9 is_stmt 1 view .LVU81
 217              		.loc 1 52 21 is_stmt 0 view .LVU82
 218 000c 4162     		str	r1, [r0, #36]
 219              	.L5:
  53:./block/request.c ****     }
  54:./block/request.c **** 
  55:./block/request.c ****     rq->__data_len += 1;
 220              		.loc 1 55 5 is_stmt 1 view .LVU83
 221              		.loc 1 55 7 is_stmt 0 view .LVU84
 222 000e 8369     		ldr	r3, [r0, #24]
 223              		.loc 1 55 20 view .LVU85
 224 0010 0133     		adds	r3, r3, #1
 225 0012 8361     		str	r3, [r0, #24]
  56:./block/request.c ****     
  57:./block/request.c **** 
  58:./block/request.c **** }...
 226              		.loc 1 58 1 view .LVU86
 227 0014 7047     		bx	lr
 228              	.LVL15:
 229              	.L6:
  46:./block/request.c ****         rq->bio = bio;
 230              		.loc 1 46 9 is_stmt 1 view .LVU87
  46:./block/request.c ****         rq->bio = bio;
 231              		.loc 1 46 17 is_stmt 0 view .LVU88
 232 0016 0162     		str	r1, [r0, #32]
  47:./block/request.c ****         rq->biotail = bio;
 233              		.loc 1 47 9 is_stmt 1 view .LVU89
  47:./block/request.c ****         rq->biotail = bio;
 234              		.loc 1 47 21 is_stmt 0 view .LVU90
 235 0018 4162     		str	r1, [r0, #36]
 236 001a F8E7     		b	.L5
 237              		.cfi_endproc
 238              	.LFE961:
 240              		.text
 241              	.Letext0:
 242              		.file 7 "./include/asm-generic/int-l64.h"
ARM GAS  /tmp/ccalvPdg.s 			page 24


 243              		.file 8 "./include/asm-generic/posix_types.h"
 244              		.file 9 "./include/uapi/linux/types.h"
 245              		.file 10 "./include/linux/types.h"
 246              		.file 11 "./include/linux/time64.h"
 247              		.file 12 "./arch/arm_m/include/asm/spinlock.h"
 248              		.file 13 "./include/linux/spinlock_types_raw.h"
 249              		.file 14 "./include/linux/spinlock_types.h"
 250              		.file 15 "./include/linux/mutex.h"
 251              		.file 16 "./include/linux/errseq.h"
 252              		.file 17 "./include/linux/rbtree_types.h"
 253              		.file 18 "./include/linux/uidgid_types.h"
 254              		.file 19 "./include/linux/projid.h"
 255              		.file 20 "./include/linux/fs.h"
 256              		.file 21 "./include/linux/mnt_idmapping.h"
 257              		.file 22 "./include/linux/uio.h"
 258              		.file 23 "./include/linux/wait.h"
 259              		.file 24 "./include/linux/xarray.h"
 260              		.file 25 "./include/linux/lockref.h"
 261              		.file 26 "./include/linux/dcache.h"
 262              		.file 27 "./include/linux/migrate_mode.h"
 263              		.file 28 "./include/linux/path.h"
 264              		.file 29 "./include/linux/reciprocal_div.h"
 265              		.file 30 "./include/linux/mm_type.h"
 266              		.file 31 "./include/linux/statfs.h"
 267              		.file 32 "./include/linux/stat.h"
 268              		.file 33 "./include/linux/bvec.h"
 269              		.file 34 "./include/linux/blk_types.h"
 270              		.file 35 "./include/linux/rw_hint.h"
 271              		.file 36 "./include/linux/blkdev.h"
 272              		.file 37 "./include/linux/bio.h"
 273              		.file 38 "./include/linux/mempool_super_haper.h"
 274              		.file 39 "./include/linux/mempool.h"
 275              		.file 40 "./include/linux/lockdep_types.h"
 276              		.file 41 "./include/linux/workqueue_types.h"
 277              		.file 42 "./include/linux/blk-mq.h"
 278              		.file 43 "./include/uapi/linux/pr.h"
 279              		.file 44 "./include/linux/pr.h"
 280              		.file 45 "./include/linux/hdreg.h"
 281              		.file 46 "./arch/arm_m/include/asm/string.h"
 282              		.file 47 "./include/linux/instrumented.h"
 283              		.file 48 "./include/linux/kcsan-checks.h"
 284              		.file 49 "./include/linux/kasan-checks.h"
 285              		.file 50 "./include/linux/stddef.h"
 286              		.file 51 "<built-in>"
ARM GAS  /tmp/ccalvPdg.s 			page 25


DEFINED SYMBOLS
                            *ABS*:00000000 request.c
     /tmp/ccalvPdg.s:21     .text.request_alloc:00000000 $t
     /tmp/ccalvPdg.s:27     .text.request_alloc:00000000 request_alloc
     /tmp/ccalvPdg.s:184    .text.__blk_insert_request:00000000 $t
     /tmp/ccalvPdg.s:190    .text.__blk_insert_request:00000000 __blk_insert_request

UNDEFINED SYMBOLS
__smalloc__
memset
ktime_get
