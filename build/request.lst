ARM GAS  /tmp/cc68D0Lo.s 			page 1


   1              		.cpu cortex-m4
   2              		.arch armv7e-m
   3              		.fpu fpv4-sp-d16
   4              		.eabi_attribute 27, 1
   5              		.eabi_attribute 28, 1
   6              		.eabi_attribute 20, 1
   7              		.eabi_attribute 21, 1
   8              		.eabi_attribute 23, 3
   9              		.eabi_attribute 24, 1
  10              		.eabi_attribute 25, 1
  11              		.eabi_attribute 26, 1
  12              		.eabi_attribute 30, 1
  13              		.eabi_attribute 34, 1
  14              		.eabi_attribute 18, 4
  15              		.file	"request.c"
  16              		.text
  17              	.Ltext0:
  18              		.cfi_sections	.debug_frame
  19              		.file 1 "/mnt/c/Users/31740/Desktop/newcore/block/request.c"
  20              		.section	.text.__blk_insert_request,"ax",%progbits
  21              		.align	1
  22              		.global	__blk_insert_request
  23              		.syntax unified
  24              		.thumb
  25              		.thumb_func
  27              	__blk_insert_request:
  28              	.LVL0:
  29              	.LFB961:
   1:/mnt/c/Users/31740/Desktop/newcore/block/request.c **** #include <linux/blkdev.h>
   2:/mnt/c/Users/31740/Desktop/newcore/block/request.c **** #include <linux/slab.h>
   3:/mnt/c/Users/31740/Desktop/newcore/block/request.c **** #include <linux/errno.h>
   4:/mnt/c/Users/31740/Desktop/newcore/block/request.c **** #include <linux/string.h>
   5:/mnt/c/Users/31740/Desktop/newcore/block/request.c **** #include <linux/time.h>
   6:/mnt/c/Users/31740/Desktop/newcore/block/request.c **** #include <linux/list.h>
   7:/mnt/c/Users/31740/Desktop/newcore/block/request.c **** #include <linux/atomic.h>
   8:/mnt/c/Users/31740/Desktop/newcore/block/request.c **** #include <linux/module.h>
   9:/mnt/c/Users/31740/Desktop/newcore/block/request.c **** 
  10:/mnt/c/Users/31740/Desktop/newcore/block/request.c **** struct request *request_alloc(struct request_queue *q, blk_opf_t opf, gfp_t gfp_mask)
  11:/mnt/c/Users/31740/Desktop/newcore/block/request.c **** {
  12:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     struct request *rq = kmalloc(sizeof(struct request), gfp_mask);
  13:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     if (!rq)  -ENOMEM;
  14:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     memset(rq, 0, sizeof(struct request));
  15:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     rq->q = q;
  16:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     rq->cmd_flags = opf;
  17:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     rq->__data_len = 0;
  18:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     rq->__sector = 0;
  19:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     rq->bio = rq->biotail = NULL;
  20:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     INIT_LIST_HEAD(&rq->queuelist);
  21:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     atomic_set(&rq->ref, 1);
  22:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     rq->state = MQ_RQ_IDLE;
  23:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     rq->start_time_ns = ktime_get_ns();
  24:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     rq->io_start_time_ns = 0;
  25:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     rq->part = NULL;
  26:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     rq->timeout = 1000;
  27:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     return rq;
  28:/mnt/c/Users/31740/Desktop/newcore/block/request.c **** }
  29:/mnt/c/Users/31740/Desktop/newcore/block/request.c **** EXPORT_SYMBOL(request_alloc);
ARM GAS  /tmp/cc68D0Lo.s 			page 2


  30:/mnt/c/Users/31740/Desktop/newcore/block/request.c **** 
  31:/mnt/c/Users/31740/Desktop/newcore/block/request.c **** 
  32:/mnt/c/Users/31740/Desktop/newcore/block/request.c **** void __blk_insert_request(struct request *rq, struct bio *bio)
  33:/mnt/c/Users/31740/Desktop/newcore/block/request.c **** {
  30              		.loc 1 33 1 view -0
  31              		.cfi_startproc
  32              		@ args = 0, pretend = 0, frame = 0
  33              		@ frame_needed = 0, uses_anonymous_args = 0
  34              		@ link register save eliminated.
  34:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     bio->bi_next = NULL;
  35              		.loc 1 34 5 view .LVU1
  36              		.loc 1 34 18 is_stmt 0 view .LVU2
  37 0000 0023     		movs	r3, #0
  38 0002 0B60     		str	r3, [r1]
  35:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     struct bio *head = rq->bio;
  39              		.loc 1 35 5 is_stmt 1 view .LVU3
  40              		.loc 1 35 17 is_stmt 0 view .LVU4
  41 0004 036A     		ldr	r3, [r0, #32]
  42              	.LVL1:
  36:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     if(head == NULL){
  43              		.loc 1 36 5 is_stmt 1 view .LVU5
  44              		.loc 1 36 7 is_stmt 0 view .LVU6
  45 0006 33B1     		cbz	r3, .L4
  37:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****         rq->bio = bio;
  38:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****         rq->biotail = bio;
  39:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     }
  40:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     else{
  41:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****         rq->biotail->bi_next = bio;
  46              		.loc 1 41 9 is_stmt 1 view .LVU7
  47              		.loc 1 41 11 is_stmt 0 view .LVU8
  48 0008 436A     		ldr	r3, [r0, #36]
  49              	.LVL2:
  50              		.loc 1 41 30 view .LVU9
  51 000a 1960     		str	r1, [r3]
  52              	.LVL3:
  42:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****         rq->biotail = bio;
  53              		.loc 1 42 9 is_stmt 1 view .LVU10
  54              		.loc 1 42 21 is_stmt 0 view .LVU11
  55 000c 4162     		str	r1, [r0, #36]
  56              	.L3:
  43:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     }
  44:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     rq->__data_len += 1;
  57              		.loc 1 44 5 is_stmt 1 view .LVU12
  58              		.loc 1 44 7 is_stmt 0 view .LVU13
  59 000e 8369     		ldr	r3, [r0, #24]
  60              		.loc 1 44 20 view .LVU14
  61 0010 0133     		adds	r3, r3, #1
  62 0012 8361     		str	r3, [r0, #24]
  45:/mnt/c/Users/31740/Desktop/newcore/block/request.c **** }
  63              		.loc 1 45 1 view .LVU15
  64 0014 7047     		bx	lr
  65              	.LVL4:
  66              	.L4:
  37:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****         rq->biotail = bio;
  67              		.loc 1 37 9 is_stmt 1 view .LVU16
  37:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****         rq->biotail = bio;
  68              		.loc 1 37 17 is_stmt 0 view .LVU17
ARM GAS  /tmp/cc68D0Lo.s 			page 3


  69 0016 0162     		str	r1, [r0, #32]
  38:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     }
  70              		.loc 1 38 9 is_stmt 1 view .LVU18
  38:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     }
  71              		.loc 1 38 21 is_stmt 0 view .LVU19
  72 0018 4162     		str	r1, [r0, #36]
  73 001a F8E7     		b	.L3
  74              		.cfi_endproc
  75              	.LFE961:
  77              		.section	.text.request_alloc,"ax",%progbits
  78              		.align	1
  79              		.global	request_alloc
  80              		.syntax unified
  81              		.thumb
  82              		.thumb_func
  84              	request_alloc:
  85              	.LVL5:
  86              	.LFB960:
  11:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     struct request *rq = kmalloc(sizeof(struct request), gfp_mask);
  87              		.loc 1 11 1 is_stmt 1 view -0
  88              		.cfi_startproc
  89              		@ args = 0, pretend = 0, frame = 0
  90              		@ frame_needed = 0, uses_anonymous_args = 0
  11:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     struct request *rq = kmalloc(sizeof(struct request), gfp_mask);
  91              		.loc 1 11 1 is_stmt 0 view .LVU21
  92 0000 70B5     		push	{r4, r5, r6, lr}
  93              	.LCFI0:
  94              		.cfi_def_cfa_offset 16
  95              		.cfi_offset 4, -16
  96              		.cfi_offset 5, -12
  97              		.cfi_offset 6, -8
  98              		.cfi_offset 14, -4
  99 0002 0646     		mov	r6, r0
 100 0004 0D46     		mov	r5, r1
  12:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     if (!rq)  -ENOMEM;
 101              		.loc 1 12 5 is_stmt 1 view .LVU22
 102              	.LVL6:
 103              	.LBB25:
 104              	.LBI25:
 105              		.file 2 "/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h"
   1:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* SPDX-License-Identifier: GPL-2.0 */
   2:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /*
   3:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Written by Mark Hemment, 1996 (markhe@nextd.demon.co.uk).
   4:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
   5:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * (C) SGI 2006, Christoph Lameter
   6:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * 	Cleaned up and restructured to ease the addition of alternative
   7:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * 	implementations of SLAB allocators.
   8:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * (C) Linux Foundation 2008-2013
   9:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *      Unified interface for all slab allocators
  10:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
  11:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
  12:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifndef _LINUX_SLAB_H
  13:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define	_LINUX_SLAB_H
  14:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
  15:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #include <linux/cache.h>
  16:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #include <linux/overflow.h>
  17:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #include <linux/types.h>
ARM GAS  /tmp/cc68D0Lo.s 			page 4


  18:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #include <linux/raid/pq.h>
  19:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #include <linux/gfp_types.h>
  20:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #include <linux/numa.h>
  21:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #include <linux/reciprocal_div.h>
  22:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #include <linux/spinlock.h>
  23:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
  24:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** enum _slab_flag_bits {
  25:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_CONSISTENCY_CHECKS,
  26:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_RED_ZONE,
  27:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_POISON,
  28:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_KMALLOC,
  29:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_HWCACHE_ALIGN,
  30:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_CACHE_DMA,
  31:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_CACHE_DMA32,
  32:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_STORE_USER,
  33:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_PANIC,
  34:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_TYPESAFE_BY_RCU,
  35:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_TRACE,
  36:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_DEBUG_OBJECTS
  37:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_DEBUG_OBJECTS,
  38:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
  39:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_NOLEAKTRACE,
  40:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_NO_MERGE,
  41:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_FAILSLAB
  42:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_FAILSLAB,
  43:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
  44:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_MEMCG
  45:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_ACCOUNT,
  46:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
  47:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_KASAN_GENERIC
  48:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_KASAN,
  49:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
  50:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_NO_USER_FLAGS,
  51:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_KFENCE
  52:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_SKIP_KFENCE,
  53:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
  54:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifndef CONFIG_SLUB_TINY
  55:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_RECLAIM_ACCOUNT,
  56:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
  57:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_OBJECT_POISON,
  58:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_CMPXCHG_DOUBLE,
  59:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_SLAB_OBJ_EXT
  60:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_NO_OBJ_EXT,
  61:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
  62:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_FLAGS_LAST_BIT
  63:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** };
  64:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
  65:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
  66:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
  67:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define __SLAB_FLAG_BIT(nr)	((slab_flags_t __force)(1U << (nr)))
  68:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define __SLAB_FLAG_UNUSED	((slab_flags_t __force)(0U))
  69:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
  70:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /*
  71:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Flags to pass to kmem_cache_create().
  72:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * The ones marked DEBUG need CONFIG_SLUB_DEBUG enabled, otherwise are no-op
  73:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
  74:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* DEBUG: Perform (expensive) checks on alloc/free */
ARM GAS  /tmp/cc68D0Lo.s 			page 5


  75:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_CONSISTENCY_CHECKS	__SLAB_FLAG_BIT(_SLAB_CONSISTENCY_CHECKS)
  76:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* DEBUG: Red zone objs in a cache */
  77:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_RED_ZONE		__SLAB_FLAG_BIT(_SLAB_RED_ZONE)
  78:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* DEBUG: Poison objects */
  79:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_POISON		__SLAB_FLAG_BIT(_SLAB_POISON)
  80:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* Indicate a kmalloc slab */
  81:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_KMALLOC		__SLAB_FLAG_BIT(_SLAB_KMALLOC)
  82:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /**
  83:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * define SLAB_HWCACHE_ALIGN - Align objects on cache line boundaries.
  84:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
  85:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Sufficiently large objects are aligned on cache line boundary. For object
  86:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * size smaller than a half of cache line size, the alignment is on the half of
  87:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * cache line size. In general, if object size is smaller than 1/2^n of cache
  88:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * line size, the alignment is adjusted to 1/2^n.
  89:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
  90:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * If explicit alignment is also requested by the respective
  91:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * &struct kmem_cache_args field, the greater of both is alignments is applied.
  92:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
  93:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_HWCACHE_ALIGN	__SLAB_FLAG_BIT(_SLAB_HWCACHE_ALIGN)
  94:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* Use GFP_DMA memory */
  95:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_CACHE_DMA		__SLAB_FLAG_BIT(_SLAB_CACHE_DMA)
  96:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* Use GFP_DMA32 memory */
  97:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_CACHE_DMA32	__SLAB_FLAG_BIT(_SLAB_CACHE_DMA32)
  98:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* DEBUG: Store the last owner for bug hunting */
  99:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_STORE_USER		__SLAB_FLAG_BIT(_SLAB_STORE_USER)
 100:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* Panic if kmem_cache_create() fails */
 101:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_PANIC		__SLAB_FLAG_BIT(_SLAB_PANIC)
 102:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /**
 103:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * define SLAB_TYPESAFE_BY_RCU - **WARNING** READ THIS!
 104:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 105:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * This delays freeing the SLAB page by a grace period, it does _NOT_
 106:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * delay object freeing. This means that if you do kmem_cache_free()
 107:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * that memory location is free to be reused at any time. Thus it may
 108:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * be possible to see another object there in the same RCU grace period.
 109:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 110:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * This feature only ensures the memory location backing the object
 111:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * stays valid, the trick to using this is relying on an independent
 112:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * object validation pass. Something like:
 113:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 114:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * ::
 115:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 116:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *  begin:
 117:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *   rcu_read_lock();
 118:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *   obj = lockless_lookup(key);
 119:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *   if (obj) {
 120:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *     if (!try_get_ref(obj)) // might fail for free objects
 121:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *       rcu_read_unlock();
 122:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *       goto begin;
 123:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 124:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *     if (obj->key != key) { // not the object we expected
 125:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *       put_ref(obj);
 126:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *       rcu_read_unlock();
 127:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *       goto begin;
 128:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *     }
 129:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *   }
 130:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *  rcu_read_unlock();
 131:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
ARM GAS  /tmp/cc68D0Lo.s 			page 6


 132:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * This is useful if we need to approach a kernel structure obliquely,
 133:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * from its address obtained without the usual locking. We can lock
 134:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * the structure to stabilize it and check it's still at the given address,
 135:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * only if we can be sure that the memory has not been meanwhile reused
 136:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * for some other kind of object (which our subsystem's lock might corrupt).
 137:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 138:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * rcu_read_lock before reading the address, then rcu_read_unlock after
 139:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * taking the spinlock within the structure expected at that address.
 140:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 141:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Note that it is not possible to acquire a lock within a structure
 142:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * allocated with SLAB_TYPESAFE_BY_RCU without first acquiring a reference
 143:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * as described above.  The reason is that SLAB_TYPESAFE_BY_RCU pages
 144:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * are not zeroed before being given to the slab, which means that any
 145:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * locks must be initialized after each and every kmem_struct_alloc().
 146:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Alternatively, make the ctor passed to kmem_cache_create() initialize
 147:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * the locks at page-allocation time, as is done in __i915_request_ctor(),
 148:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * sighand_ctor(), and anon_vma_ctor().  Such a ctor permits readers
 149:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * to safely acquire those ctor-initialized locks under rcu_read_lock()
 150:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * protection.
 151:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 152:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Note that SLAB_TYPESAFE_BY_RCU was originally named SLAB_DESTROY_BY_RCU.
 153:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
 154:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_TYPESAFE_BY_RCU	__SLAB_FLAG_BIT(_SLAB_TYPESAFE_BY_RCU)
 155:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* Trace allocations and frees */
 156:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_TRACE		__SLAB_FLAG_BIT(_SLAB_TRACE)
 157:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 158:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* Flag to prevent checks on free */
 159:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_DEBUG_OBJECTS
 160:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** # define SLAB_DEBUG_OBJECTS	__SLAB_FLAG_BIT(_SLAB_DEBUG_OBJECTS)
 161:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #else
 162:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** # define SLAB_DEBUG_OBJECTS	__SLAB_FLAG_UNUSED
 163:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
 164:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 165:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* Avoid kmemleak tracing */
 166:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_NOLEAKTRACE	__SLAB_FLAG_BIT(_SLAB_NOLEAKTRACE)
 167:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 168:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /*
 169:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Prevent merging with compatible kmem caches. This flag should be used
 170:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * cautiously. Valid use cases:
 171:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 172:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * - caches created for self-tests (e.g. kunit)
 173:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * - general caches created and used by a subsystem, only when a
 174:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *   (subsystem-specific) debug option is enabled
 175:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * - performance critical caches, should be very rare and consulted with slab
 176:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *   maintainers, and not used together with CONFIG_SLUB_TINY
 177:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
 178:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_NO_MERGE		__SLAB_FLAG_BIT(_SLAB_NO_MERGE)
 179:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 180:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* Fault injection mark */
 181:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_FAILSLAB
 182:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** # define SLAB_FAILSLAB		__SLAB_FLAG_BIT(_SLAB_FAILSLAB)
 183:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #else
 184:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** # define SLAB_FAILSLAB		__SLAB_FLAG_UNUSED
 185:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
 186:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /**
 187:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * define SLAB_ACCOUNT - Account allocations to memcg.
 188:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
ARM GAS  /tmp/cc68D0Lo.s 			page 7


 189:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * All object allocations from this cache will be memcg accounted, regardless of
 190:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * __GFP_ACCOUNT being or not being passed to individual allocations.
 191:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
 192:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_MEMCG
 193:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** # define SLAB_ACCOUNT		__SLAB_FLAG_BIT(_SLAB_ACCOUNT)
 194:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #else
 195:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** # define SLAB_ACCOUNT		__SLAB_FLAG_UNUSED
 196:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
 197:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 198:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_KASAN_GENERIC
 199:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_KASAN		__SLAB_FLAG_BIT(_SLAB_KASAN)
 200:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #else
 201:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_KASAN		__SLAB_FLAG_UNUSED
 202:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
 203:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 204:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /*
 205:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Ignore user specified debugging flags.
 206:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Intended for caches created for self-tests so they have only flags
 207:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * specified in the code and other flags are ignored.
 208:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
 209:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_NO_USER_FLAGS	__SLAB_FLAG_BIT(_SLAB_NO_USER_FLAGS)
 210:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 211:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_KFENCE
 212:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_SKIP_KFENCE	__SLAB_FLAG_BIT(_SLAB_SKIP_KFENCE)
 213:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #else
 214:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_SKIP_KFENCE	__SLAB_FLAG_UNUSED
 215:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
 216:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 217:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* The following flags affect the page allocator grouping pages by mobility */
 218:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /**
 219:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * define SLAB_RECLAIM_ACCOUNT - Objects are reclaimable.
 220:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 221:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Use this flag for caches that have an associated shrinker. As a result, slab
 222:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * pages are allocated with __GFP_RECLAIMABLE, which affects grouping pages by
 223:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * mobility, and are accounted in SReclaimable counter in /proc/meminfo
 224:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
 225:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifndef CONFIG_SLUB_TINY
 226:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_RECLAIM_ACCOUNT	__SLAB_FLAG_BIT(_SLAB_RECLAIM_ACCOUNT)
 227:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #else
 228:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_RECLAIM_ACCOUNT	__SLAB_FLAG_UNUSED
 229:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
 230:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_TEMPORARY		SLAB_RECLAIM_ACCOUNT	/* Objects are short-lived */
 231:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 232:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* Slab created using create_boot_cache */
 233:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_SLAB_OBJ_EXT
 234:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_NO_OBJ_EXT		__SLAB_FLAG_BIT(_SLAB_NO_OBJ_EXT)
 235:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #else
 236:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_NO_OBJ_EXT		__SLAB_FLAG_UNUSED
 237:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
 238:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 239:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /*
 240:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * freeptr_t represents a SLUB freelist pointer, which might be encoded
 241:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * and not dereferenceable if CONFIG_SLAB_FREELIST_HARDENED is enabled.
 242:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
 243:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** typedef struct { unsigned long v; } freeptr_t;
 244:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 245:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /*
ARM GAS  /tmp/cc68D0Lo.s 			page 8


 246:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * ZERO_SIZE_PTR will be returned for zero sized kmalloc requests.
 247:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 248:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Dereferencing ZERO_SIZE_PTR will lead to a distinct access fault.
 249:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 250:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * ZERO_SIZE_PTR can be passed to kfree though in the same way that NULL can.
 251:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Both make kfree a no-op.
 252:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
 253:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define ZERO_SIZE_PTR ((void *)16)
 254:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 255:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define ZERO_OR_NULL_PTR(x) ((unsigned long)(x) <= \
 256:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 				(unsigned long)ZERO_SIZE_PTR)
 257:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 258:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 259:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 260:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 261:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 262:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_SLUB_CPU_PARTIAL
 263:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define slub_percpu_partial(c)			((c)->partial)
 264:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 265:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define slub_set_percpu_partial(c, p)		\
 266:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** ({						\
 267:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	slub_percpu_partial(c) = (p)->next;	\
 268:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** })
 269:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 270:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define slub_percpu_partial_read_once(c)	READ_ONCE(slub_percpu_partial(c))
 271:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #else
 272:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define slub_percpu_partial(c)			NULL
 273:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 274:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define slub_set_percpu_partial(c, p)
 275:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 276:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define slub_percpu_partial_read_once(c)	NULL
 277:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 278:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 279:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif // CONFIG_SLUB_CPU_PARTIAL
 280:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 281:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /*
 282:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	* Word size structure that can be atomically updated or read and that
 283:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	* contains both the order and the number of objects that a slab of the
 284:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	* given order would contain.
 285:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	*/				
 286:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** struct kmem_cache_order_objects {
 287:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	unsigned int x;
 288:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** };
 289:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 290:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** struct kmem_cache_node {
 291:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	spinlock_t list_lock;
 292:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	unsigned long nr_partial;
 293:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	struct list_head partial;
 294:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_SLUB_DEBUG
 295:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	atomic_long_t nr_slabs;
 296:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	atomic_long_t total_objects;
 297:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	struct list_head full;
 298:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
 299:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** };
 300:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 301:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** struct kmem_cache {
 302:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#ifndef CONFIG_SLUB_TINY
ARM GAS  /tmp/cc68D0Lo.s 			page 9


 303:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	//	struct kmem_cache_cpu __percpu *cpu_slab;
 304:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#endif
 305:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		/* Used for retrieving partial slabs, etc. */
 306:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		slab_flags_t flags;
 307:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned long min_partial;
 308:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int size;		/* Object size including metadata */
 309:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int object_size;	/* Object size without metadata */
 310:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		struct reciprocal_value reciprocal_size;
 311:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int offset;		/* Free pointer offset */
 312:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#ifdef CONFIG_SLUB_CPU_PARTIAL
 313:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		/* Number of per cpu partial objects to keep around */
 314:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int cpu_partial;
 315:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		/* Number of per cpu partial slabs to keep around */
 316:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int cpu_partial_slabs;
 317:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#endif
 318:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		struct kmem_cache_order_objects oo;
 319:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	
 320:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		/* Allocation and freeing of slabs */
 321:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		struct kmem_cache_order_objects min;
 322:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		gfp_t allocflags;		/* gfp flags to use on each alloc */
 323:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		int refcount;			/* Refcount for slab cache destroy */
 324:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		void (*ctor)(void *object);	/* Object constructor */
 325:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int inuse;		/* Offset to metadata */
 326:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int align;		/* Alignment */
 327:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int red_left_pad;	/* Left redzone padding size */
 328:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		const char *name;		/* Name (only for display!) */
 329:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		struct list_head list;		/* List of slab caches */
 330:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#ifdef CONFIG_SYSFS
 331:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		struct kobject kobj;		/* For sysfs */
 332:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#endif
 333:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#ifdef CONFIG_SLAB_FREELIST_HARDENED
 334:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned long random;
 335:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#endif
 336:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	
 337:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#ifdef CONFIG_NUMA
 338:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		/*
 339:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 			* Defragmentation by allocating from a remote node.
 340:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 			*/
 341:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int remote_node_defrag_ratio;
 342:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#endif
 343:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	
 344:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#ifdef CONFIG_SLAB_FREELIST_RANDOM
 345:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int *random_seq;
 346:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#endif
 347:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	
 348:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#ifdef CONFIG_KASAN_GENERIC
 349:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		struct kasan_cache kasan_info;
 350:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#endif
 351:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	
 352:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#ifdef CONFIG_HARDENED_USERCOPY
 353:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int useroffset;	/* Usercopy region offset */
 354:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int usersize;		/* Usercopy region size */
 355:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#endif
 356:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	
 357:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		struct kmem_cache_node *node[MAX_NUMNODES];
 358:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	};
 359:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 					
ARM GAS  /tmp/cc68D0Lo.s 			page 10


 360:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 361:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 362:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 363:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 364:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define KMALLOC_WAIT 1
 365:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 366:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 367:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** extern void* __smalloc__(u32 size, gfp_t flags);
 368:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** extern void  __sfree__(void* addr);
 369:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 370:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 371:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** static void inline *vmalloc(unsigned long size){
 372:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	return __smalloc__(size,GFP_TRANSHUGE_LIGHT);
 373:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** }
 374:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 375:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** static void inline vfree(void *addr){
 376:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	__sfree__(addr);
 377:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** }
 378:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 379:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** static void inline *kmalloc(size_t size, gfp_t flags){
 106              		.loc 2 379 21 view .LVU23
 107              	.LBB26:
 380:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	return __smalloc__((u32)size,flags);
 108              		.loc 2 380 2 view .LVU24
 109              		.loc 2 380 9 is_stmt 0 view .LVU25
 110 0006 1146     		mov	r1, r2
 111              	.LVL7:
 112              		.loc 2 380 9 view .LVU26
 113 0008 5C20     		movs	r0, #92
 114              	.LVL8:
 115              		.loc 2 380 9 view .LVU27
 116 000a FFF7FEFF 		bl	__smalloc__
 117              	.LVL9:
 118              		.loc 2 380 9 view .LVU28
 119 000e 0446     		mov	r4, r0
 120              	.LVL10:
 121              		.loc 2 380 9 view .LVU29
 122              	.LBE26:
 123              	.LBE25:
  13:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     memset(rq, 0, sizeof(struct request));
 124              		.loc 1 13 5 is_stmt 1 view .LVU30
  13:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     memset(rq, 0, sizeof(struct request));
 125              		.loc 1 13 15 discriminator 1 view .LVU31
  14:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     rq->q = q;
 126              		.loc 1 14 5 view .LVU32
 127 0010 5C22     		movs	r2, #92
 128 0012 0021     		movs	r1, #0
 129 0014 FFF7FEFF 		bl	memset
 130              	.LVL11:
  15:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     rq->cmd_flags = opf;
 131              		.loc 1 15 5 view .LVU33
  15:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     rq->cmd_flags = opf;
 132              		.loc 1 15 11 is_stmt 0 view .LVU34
 133 0018 2660     		str	r6, [r4]
  16:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     rq->__data_len = 0;
 134              		.loc 1 16 5 is_stmt 1 view .LVU35
  16:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     rq->__data_len = 0;
ARM GAS  /tmp/cc68D0Lo.s 			page 11


 135              		.loc 1 16 19 is_stmt 0 view .LVU36
 136 001a 6560     		str	r5, [r4, #4]
  17:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     rq->__sector = 0;
 137              		.loc 1 17 5 is_stmt 1 view .LVU37
  18:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     rq->bio = rq->biotail = NULL;
 138              		.loc 1 18 5 view .LVU38
  19:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     INIT_LIST_HEAD(&rq->queuelist);
 139              		.loc 1 19 5 view .LVU39
  20:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     atomic_set(&rq->ref, 1);
 140              		.loc 1 20 5 view .LVU40
 141 001c 04F12803 		add	r3, r4, #40
 142              	.LVL12:
 143              	.LBB27:
 144              	.LBI27:
 145              		.file 3 "/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h"
   1:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** /* SPDX-License-Identifier: GPL-2.0 */
   2:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** #ifndef _LINUX_LIST_H
   3:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** #define _LINUX_LIST_H
   4:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 
   5:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** #include <linux/container_of.h>
   6:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** #include <linux/types.h>
   7:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** #include <linux/stddef.h>
   8:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** #include <linux/poison.h>
   9:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** #include <linux/const.h>
  10:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 
  11:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** #include <asm/barrier.h>
  12:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** #include <linux/rwonce.h>
  13:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** /*
  14:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * Circular doubly linked list implementation.
  15:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  *
  16:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * Some of the internal functions ("__xxx") are useful when
  17:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * manipulating whole lists rather than single entries, as
  18:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * sometimes we already know the next/prev entries and we can
  19:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * generate better code by using them directly rather than
  20:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * using the generic single-entry routines.
  21:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  */
  22:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 
  23:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** #define LIST_HEAD_INIT(name) { &(name), &(name) }
  24:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 
  25:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** #define LIST_HEAD(name) \
  26:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	struct list_head name = LIST_HEAD_INIT(name)
  27:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 
  28:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** /**
  29:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * INIT_LIST_HEAD - Initialize a list_head structure
  30:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * @list: list_head structure to be initialized.
  31:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  *
  32:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * Initializes the list_head to point to itself.  If it is a list header,
  33:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * the result is an empty list.
  34:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  */
  35:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** static inline void INIT_LIST_HEAD(struct list_head *list)
 146              		.loc 3 35 20 view .LVU41
 147              	.LBB28:
  36:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** {
  37:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	WRITE_ONCE(list->next, list);
 148              		.loc 3 37 2 view .LVU42
 149              		.loc 3 37 2 view .LVU43
 150              	.LBB29:
ARM GAS  /tmp/cc68D0Lo.s 			page 12


 151              		.loc 3 37 2 view .LVU44
 152              		.loc 3 37 2 view .LVU45
 153              	.LBE29:
 154              		.loc 3 37 2 discriminator 2 view .LVU46
 155              		.loc 3 37 2 discriminator 2 view .LVU47
 156              		.loc 3 37 2 discriminator 2 view .LVU48
 157 0020 A362     		str	r3, [r4, #40]
 158              		.loc 3 37 2 discriminator 2 view .LVU49
 159              		.loc 3 37 2 discriminator 2 view .LVU50
  38:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	WRITE_ONCE(list->prev, list);
 160              		.loc 3 38 2 view .LVU51
 161              		.loc 3 38 2 view .LVU52
 162              	.LBB30:
 163              		.loc 3 38 2 view .LVU53
 164              		.loc 3 38 2 view .LVU54
 165              	.LBE30:
 166              		.loc 3 38 2 discriminator 2 view .LVU55
 167              		.loc 3 38 2 discriminator 2 view .LVU56
 168              		.loc 3 38 2 discriminator 2 view .LVU57
 169 0022 E362     		str	r3, [r4, #44]
 170              		.loc 3 38 2 discriminator 2 view .LVU58
 171              		.loc 3 38 2 discriminator 2 view .LVU59
 172              	.LVL13:
 173              		.loc 3 38 2 is_stmt 0 discriminator 2 view .LVU60
 174              	.LBE28:
 175              	.LBE27:
  21:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     rq->state = MQ_RQ_IDLE;
 176              		.loc 1 21 5 is_stmt 1 view .LVU61
 177              	.LBB31:
 178              	.LBI31:
 179              		.file 4 "/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h"
   1:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** // SPDX-License-Identifier: GPL-2.0
   2:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
   3:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** // Generated by scripts/atomic/gen-atomic-instrumented.sh 
   4:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** // DO NOT MODIFY THIS FILE DIRECTLY
   5:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
   6:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /*
   7:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * This file provoides atomic operations with explicit instrumentation (e.g.
   8:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * KASAN, KCSAN), which should be used unless it is necessary to avoid
   9:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * instrumentation. Where it is necessary to aovid instrumenation, the
  10:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * raw_atomic*() operations should be used.
  11:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
  12:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** #ifndef _LINUX_ATOMIC_INSTRUMENTED_H
  13:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** #define _LINUX_ATOMIC_INSTRUMENTED_H
  14:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
  15:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** #include <linux/build_bug.h>
  16:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** #include <linux/compiler.h>
  17:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** #include <linux/instrumented.h>
  18:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
  19:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
  20:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_read() - atomic load with relaxed ordering
  21:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
  22:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
  23:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically loads the value of @v with relaxed ordering.
  24:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
  25:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_read() there.
  26:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
ARM GAS  /tmp/cc68D0Lo.s 			page 13


  27:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The value loaded from @v.
  28:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
  29:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
  30:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_read(const atomic_t *v)
  31:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
  32:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read(v, sizeof(*v));
  33:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_read(v);
  34:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
  35:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
  36:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
  37:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_read_acquire() - atomic load with acquire ordering
  38:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
  39:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
  40:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically loads the value of @v with acquire ordering.
  41:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
  42:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_read_acquire() there.
  43:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
  44:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The value loaded from @v.
  45:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
  46:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
  47:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_read_acquire(const atomic_t *v)
  48:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
  49:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read(v, sizeof(*v));
  50:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_read_acquire(v);
  51:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
  52:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
  53:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
  54:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_set() - atomic set with relaxed ordering
  55:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
  56:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to assign
  57:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
  58:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically sets @v to @i with relaxed ordering.
  59:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
  60:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_set() there.
  61:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
  62:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: Nothing.
  63:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
  64:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline void
  65:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_set(atomic_t *v, int i)
 180              		.loc 4 65 1 view .LVU62
  66:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
  67:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_write(v, sizeof(*v));
 181              		.loc 4 67 2 view .LVU63
  68:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	raw_atomic_set(v, i);
 182              		.loc 4 68 2 view .LVU64
 183              	.LBB32:
 184              	.LBI32:
 185              		.file 5 "/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h"
   1:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** // SPDX-License-Identifier: GPL-2.0
   2:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
   3:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** // Generated by scripts/atomic/gen-atomic-fallback.sh
   4:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** // DO NOT MODIFY THIS FILE DIRECTLY
   5:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
   6:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #ifndef _LINUX_ATOMIC_FALLBACK_H
   7:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define _LINUX_ATOMIC_FALLBACK_H
   8:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
   9:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #include <linux/compiler.h>
ARM GAS  /tmp/cc68D0Lo.s 			page 14


  10:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
  11:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_xchg)
  12:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg arch_xchg
  13:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_xchg_relaxed)
  14:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg(...) \
  15:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_fence(arch_xchg, __VA_ARGS__)
  16:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
  17:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_xchg_not_implemented(void);
  18:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg(...) raw_xchg_not_implemented()
  19:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
  20:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
  21:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_xchg_acquire)
  22:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_acquire arch_xchg_acquire
  23:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_xchg_relaxed)
  24:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_acquire(...) \
  25:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_acquire(arch_xchg, __VA_ARGS__)
  26:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_xchg)
  27:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_acquire arch_xchg
  28:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
  29:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_xchg_acquire_not_implemented(void);
  30:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_acquire(...) raw_xchg_acquire_not_implemented()
  31:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
  32:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
  33:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_xchg_release)
  34:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_release arch_xchg_release
  35:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_xchg_relaxed)
  36:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_release(...) \
  37:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_release(arch_xchg, __VA_ARGS__)
  38:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_xchg)
  39:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_release arch_xchg
  40:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
  41:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_xchg_release_not_implemented(void);
  42:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_release(...) raw_xchg_release_not_implemented()
  43:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
  44:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
  45:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_xchg_relaxed)
  46:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_relaxed arch_xchg_relaxed
  47:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_xchg)
  48:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_relaxed arch_xchg
  49:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
  50:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_xchg_relaxed_not_implemented(void);
  51:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_relaxed(...) raw_xchg_relaxed_not_implemented()
  52:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
  53:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
  54:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg)
  55:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg arch_cmpxchg
  56:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg_relaxed)
  57:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg(...) \
  58:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_fence(arch_cmpxchg, __VA_ARGS__)
  59:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
  60:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg_not_implemented(void);
  61:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg(...) raw_cmpxchg_not_implemented()
  62:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
  63:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
  64:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg_acquire)
  65:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_acquire arch_cmpxchg_acquire
  66:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg_relaxed)
ARM GAS  /tmp/cc68D0Lo.s 			page 15


  67:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_acquire(...) \
  68:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_acquire(arch_cmpxchg, __VA_ARGS__)
  69:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg)
  70:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_acquire arch_cmpxchg
  71:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
  72:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg_acquire_not_implemented(void);
  73:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_acquire(...) raw_cmpxchg_acquire_not_implemented()
  74:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
  75:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
  76:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg_release)
  77:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_release arch_cmpxchg_release
  78:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg_relaxed)
  79:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_release(...) \
  80:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_release(arch_cmpxchg, __VA_ARGS__)
  81:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg)
  82:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_release arch_cmpxchg
  83:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
  84:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg_release_not_implemented(void);
  85:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_release(...) raw_cmpxchg_release_not_implemented()
  86:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
  87:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
  88:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg_relaxed)
  89:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_relaxed arch_cmpxchg_relaxed
  90:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg)
  91:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_relaxed arch_cmpxchg
  92:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
  93:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg_relaxed_not_implemented(void);
  94:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_relaxed(...) raw_cmpxchg_relaxed_not_implemented()
  95:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
  96:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
  97:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg64)
  98:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64 arch_cmpxchg64
  99:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg64_relaxed)
 100:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64(...) \
 101:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_fence(arch_cmpxchg64, __VA_ARGS__)
 102:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 103:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg64_not_implemented(void);
 104:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64(...) raw_cmpxchg64_not_implemented()
 105:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 106:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 107:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg64_acquire)
 108:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_acquire arch_cmpxchg64_acquire
 109:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg64_relaxed)
 110:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_acquire(...) \
 111:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_acquire(arch_cmpxchg64, __VA_ARGS__)
 112:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg64)
 113:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_acquire arch_cmpxchg64
 114:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 115:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg64_acquire_not_implemented(void);
 116:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_acquire(...) raw_cmpxchg64_acquire_not_implemented()
 117:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 118:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 119:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg64_release)
 120:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_release arch_cmpxchg64_release
 121:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg64_relaxed)
 122:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_release(...) \
 123:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_release(arch_cmpxchg64, __VA_ARGS__)
ARM GAS  /tmp/cc68D0Lo.s 			page 16


 124:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg64)
 125:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_release arch_cmpxchg64
 126:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 127:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg64_release_not_implemented(void);
 128:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_release(...) raw_cmpxchg64_release_not_implemented()
 129:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 130:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 131:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg64_relaxed)
 132:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_relaxed arch_cmpxchg64_relaxed
 133:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg64)
 134:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_relaxed arch_cmpxchg64
 135:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 136:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg64_relaxed_not_implemented(void);
 137:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_relaxed(...) raw_cmpxchg64_relaxed_not_implemented()
 138:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 139:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 140:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg128)
 141:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128 arch_cmpxchg128
 142:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg128_relaxed)
 143:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128(...) \
 144:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_fence(arch_cmpxchg128, __VA_ARGS__)
 145:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 146:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg128_not_implemented(void);
 147:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128(...) raw_cmpxchg128_not_implemented()
 148:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 149:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 150:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg128_acquire)
 151:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_acquire arch_cmpxchg128_acquire
 152:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg128_relaxed)
 153:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_acquire(...) \
 154:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_acquire(arch_cmpxchg128, __VA_ARGS__)
 155:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg128)
 156:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_acquire arch_cmpxchg128
 157:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 158:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg128_acquire_not_implemented(void);
 159:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_acquire(...) raw_cmpxchg128_acquire_not_implemented()
 160:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 161:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 162:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg128_release)
 163:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_release arch_cmpxchg128_release
 164:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg128_relaxed)
 165:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_release(...) \
 166:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_release(arch_cmpxchg128, __VA_ARGS__)
 167:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg128)
 168:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_release arch_cmpxchg128
 169:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 170:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg128_release_not_implemented(void);
 171:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_release(...) raw_cmpxchg128_release_not_implemented()
 172:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 173:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 174:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg128_relaxed)
 175:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_relaxed arch_cmpxchg128_relaxed
 176:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg128)
 177:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_relaxed arch_cmpxchg128
 178:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 179:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg128_relaxed_not_implemented(void);
 180:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_relaxed(...) raw_cmpxchg128_relaxed_not_implemented()
ARM GAS  /tmp/cc68D0Lo.s 			page 17


 181:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 182:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 183:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 184:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 185:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 186:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 187:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 188:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 189:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg)
 190:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg arch_try_cmpxchg
 191:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg_relaxed)
 192:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg(...) \
 193:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_fence(arch_try_cmpxchg, __VA_ARGS__)
 194:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 195:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg(_ptr, _oldp, _new) \
 196:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 197:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 198:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg((_ptr), ___o, (_new)); \
 199:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 200:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 201:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 202:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 203:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 204:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 205:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg_acquire)
 206:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_acquire arch_try_cmpxchg_acquire
 207:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg_relaxed)
 208:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_acquire(...) \
 209:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_acquire(arch_try_cmpxchg, __VA_ARGS__)
 210:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg)
 211:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_acquire arch_try_cmpxchg
 212:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 213:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_acquire(_ptr, _oldp, _new) \
 214:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 215:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 216:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg_acquire((_ptr), ___o, (_new)); \
 217:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 218:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 219:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 220:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 221:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 222:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 223:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg_release)
 224:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_release arch_try_cmpxchg_release
 225:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg_relaxed)
 226:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_release(...) \
 227:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_release(arch_try_cmpxchg, __VA_ARGS__)
 228:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg)
 229:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_release arch_try_cmpxchg
 230:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 231:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_release(_ptr, _oldp, _new) \
 232:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 233:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 234:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg_release((_ptr), ___o, (_new)); \
 235:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 236:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 237:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
ARM GAS  /tmp/cc68D0Lo.s 			page 18


 238:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 239:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 240:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 241:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg_relaxed)
 242:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_relaxed arch_try_cmpxchg_relaxed
 243:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg)
 244:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_relaxed arch_try_cmpxchg
 245:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 246:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_relaxed(_ptr, _oldp, _new) \
 247:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 248:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 249:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg_relaxed((_ptr), ___o, (_new)); \
 250:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 251:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 252:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 253:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 254:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 255:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 256:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg64)
 257:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64 arch_try_cmpxchg64
 258:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg64_relaxed)
 259:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64(...) \
 260:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_fence(arch_try_cmpxchg64, __VA_ARGS__)
 261:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 262:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64(_ptr, _oldp, _new) \
 263:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 264:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 265:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg64((_ptr), ___o, (_new)); \
 266:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 267:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 268:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 269:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 270:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 271:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 272:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg64_acquire)
 273:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_acquire arch_try_cmpxchg64_acquire
 274:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg64_relaxed)
 275:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_acquire(...) \
 276:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_acquire(arch_try_cmpxchg64, __VA_ARGS__)
 277:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg64)
 278:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_acquire arch_try_cmpxchg64
 279:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 280:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_acquire(_ptr, _oldp, _new) \
 281:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 282:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 283:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg64_acquire((_ptr), ___o, (_new)); \
 284:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 285:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 286:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 287:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 288:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 289:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 290:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg64_release)
 291:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_release arch_try_cmpxchg64_release
 292:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg64_relaxed)
 293:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_release(...) \
 294:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_release(arch_try_cmpxchg64, __VA_ARGS__)
ARM GAS  /tmp/cc68D0Lo.s 			page 19


 295:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg64)
 296:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_release arch_try_cmpxchg64
 297:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 298:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_release(_ptr, _oldp, _new) \
 299:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 300:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 301:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg64_release((_ptr), ___o, (_new)); \
 302:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 303:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 304:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 305:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 306:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 307:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 308:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg64_relaxed)
 309:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_relaxed arch_try_cmpxchg64_relaxed
 310:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg64)
 311:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_relaxed arch_try_cmpxchg64
 312:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 313:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_relaxed(_ptr, _oldp, _new) \
 314:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 315:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 316:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg64_relaxed((_ptr), ___o, (_new)); \
 317:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 318:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 319:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 320:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 321:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 322:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 323:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg128)
 324:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128 arch_try_cmpxchg128
 325:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg128_relaxed)
 326:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128(...) \
 327:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_fence(arch_try_cmpxchg128, __VA_ARGS__)
 328:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 329:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128(_ptr, _oldp, _new) \
 330:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 331:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 332:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg128((_ptr), ___o, (_new)); \
 333:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 334:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 335:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 336:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 337:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 338:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 339:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg128_acquire)
 340:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_acquire arch_try_cmpxchg128_acquire
 341:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg128_relaxed)
 342:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_acquire(...) \
 343:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_acquire(arch_try_cmpxchg128, __VA_ARGS__)
 344:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg128)
 345:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_acquire arch_try_cmpxchg128
 346:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 347:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_acquire(_ptr, _oldp, _new) \
 348:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 349:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 350:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg128_acquire((_ptr), ___o, (_new)); \
 351:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
ARM GAS  /tmp/cc68D0Lo.s 			page 20


 352:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 353:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 354:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 355:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 356:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 357:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg128_release)
 358:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_release arch_try_cmpxchg128_release
 359:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg128_relaxed)
 360:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_release(...) \
 361:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_release(arch_try_cmpxchg128, __VA_ARGS__)
 362:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg128)
 363:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_release arch_try_cmpxchg128
 364:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 365:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_release(_ptr, _oldp, _new) \
 366:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 367:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 368:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg128_release((_ptr), ___o, (_new)); \
 369:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 370:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 371:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 372:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 373:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 374:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 375:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg128_relaxed)
 376:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_relaxed arch_try_cmpxchg128_relaxed
 377:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg128)
 378:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_relaxed arch_try_cmpxchg128
 379:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 380:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_relaxed(_ptr, _oldp, _new) \
 381:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 382:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 383:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg128_relaxed((_ptr), ___o, (_new)); \
 384:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 385:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 386:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 387:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 388:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 389:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 390:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_local arch_cmpxchg_local
 391:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 392:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #ifdef arch_try_cmpxchg_local
 393:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_local arch_try_cmpxchg_local
 394:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 395:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_local(_ptr, _oldp, _new) \
 396:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 397:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 398:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg_local((_ptr), ___o, (_new)); \
 399:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 400:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 401:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 402:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 403:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 404:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 405:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_local arch_cmpxchg64_local
 406:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 407:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #ifdef arch_try_cmpxchg64_local
 408:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_local arch_try_cmpxchg64_local
ARM GAS  /tmp/cc68D0Lo.s 			page 21


 409:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 410:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_local(_ptr, _oldp, _new) \
 411:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 412:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 413:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg64_local((_ptr), ___o, (_new)); \
 414:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 415:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 416:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 417:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 418:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 419:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 420:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_local arch_cmpxchg128_local
 421:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 422:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #ifdef arch_try_cmpxchg128_local
 423:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_local arch_try_cmpxchg128_local
 424:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 425:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_local(_ptr, _oldp, _new) \
 426:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 427:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 428:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg128_local((_ptr), ___o, (_new)); \
 429:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 430:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 431:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 432:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 433:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 434:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 435:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_sync_cmpxchg arch_sync_cmpxchg
 436:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 437:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #ifdef arch_sync_try_cmpxchg
 438:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_sync_try_cmpxchg arch_sync_try_cmpxchg
 439:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 440:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_sync_try_cmpxchg(_ptr, _oldp, _new) \
 441:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 442:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 443:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_sync_cmpxchg((_ptr), ___o, (_new)); \
 444:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 445:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 446:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 447:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 448:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 449:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 450:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 451:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_read() - atomic load with relaxed ordering
 452:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 453:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 454:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically loads the value of @v with relaxed ordering.
 455:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 456:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_read() elsewhere.
 457:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 458:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The value loaded from @v.
 459:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 460:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 461:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_read(const atomic_t *v)
 462:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 463:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_read(v);
 464:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 465:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
ARM GAS  /tmp/cc68D0Lo.s 			page 22


 466:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 467:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_read_acquire() - atomic load with acquire ordering
 468:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 469:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 470:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically loads the value of @v with acquire ordering.
 471:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 472:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_read_acquire() elsewhere.
 473:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 474:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The value loaded from @v.
 475:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 476:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 477:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_read_acquire(const atomic_t *v)
 478:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 479:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_read_acquire)
 480:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_read_acquire(v);
 481:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 482:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
 483:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 484:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (__native_word(atomic_t)) {
 485:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		ret = smp_load_acquire(&(v)->counter);
 486:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	} else {
 487:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		ret = raw_atomic_read(v);
 488:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		__atomic_acquire_fence();
 489:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	}
 490:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 491:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
 492:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 493:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 494:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 495:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 496:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_set() - atomic set with relaxed ordering
 497:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 498:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to assign
 499:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 500:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically sets @v to @i with relaxed ordering.
 501:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 502:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_set() elsewhere.
 503:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 504:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: Nothing.
 505:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 506:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline void
 507:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_set(atomic_t *v, int i)
 186              		.loc 5 507 1 view .LVU65
 187              	.LBB33:
 508:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 509:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	arch_atomic_set(v, i);
 188              		.loc 5 509 2 view .LVU66
 189              		.loc 5 509 2 view .LVU67
 190              	.LBB34:
 191              		.loc 5 509 2 view .LVU68
 192              		.loc 5 509 2 view .LVU69
 193              	.LBE34:
 194              		.loc 5 509 2 discriminator 2 view .LVU70
 195              		.loc 5 509 2 discriminator 2 view .LVU71
 196              		.loc 5 509 2 discriminator 2 view .LVU72
 197 0024 0123     		movs	r3, #1
 198 0026 2364     		str	r3, [r4, #64]
ARM GAS  /tmp/cc68D0Lo.s 			page 23


 199              		.loc 5 509 2 discriminator 2 view .LVU73
 200              		.loc 5 509 2 discriminator 2 view .LVU74
 201              	.LVL14:
 202              		.loc 5 509 2 is_stmt 0 discriminator 2 view .LVU75
 203              	.LBE33:
 204              	.LBE32:
 205              	.LBE31:
  22:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     rq->start_time_ns = ktime_get_ns();
 206              		.loc 1 22 5 is_stmt 1 view .LVU76
  23:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     rq->io_start_time_ns = 0;
 207              		.loc 1 23 5 view .LVU77
 208              	.LBB35:
 209              	.LBI35:
 210              		.file 6 "/mnt/c/Users/31740/Desktop/newcore/include/linux/time.h"
   1:/mnt/c/Users/31740/Desktop/newcore/include/linux/time.h **** /* SPDX-License-Identifier: GPL-2.0 */
   2:/mnt/c/Users/31740/Desktop/newcore/include/linux/time.h **** #ifndef _LINUX_TIME_H
   3:/mnt/c/Users/31740/Desktop/newcore/include/linux/time.h **** #define _LINUX_TIME_H
   4:/mnt/c/Users/31740/Desktop/newcore/include/linux/time.h **** 
   5:/mnt/c/Users/31740/Desktop/newcore/include/linux/time.h **** # include <linux/cache.h>
   6:/mnt/c/Users/31740/Desktop/newcore/include/linux/time.h **** # include <linux/math64.h>
   7:/mnt/c/Users/31740/Desktop/newcore/include/linux/time.h **** # include <linux/time64.h>
   8:/mnt/c/Users/31740/Desktop/newcore/include/linux/time.h **** 
   9:/mnt/c/Users/31740/Desktop/newcore/include/linux/time.h **** extern time64_t ktime_get();
  10:/mnt/c/Users/31740/Desktop/newcore/include/linux/time.h **** 
  11:/mnt/c/Users/31740/Desktop/newcore/include/linux/time.h **** #define jiffies ktime_get()
  12:/mnt/c/Users/31740/Desktop/newcore/include/linux/time.h **** 
  13:/mnt/c/Users/31740/Desktop/newcore/include/linux/time.h **** extern unsigned int HZ;
  14:/mnt/c/Users/31740/Desktop/newcore/include/linux/time.h **** 
  15:/mnt/c/Users/31740/Desktop/newcore/include/linux/time.h **** static __always_inline timer_t ktime_get_ns(){
 211              		.loc 6 15 32 view .LVU78
 212              	.LBB36:
  16:/mnt/c/Users/31740/Desktop/newcore/include/linux/time.h ****     return ktime_get();
 213              		.loc 6 16 5 view .LVU79
 214              		.loc 6 16 12 is_stmt 0 view .LVU80
 215 0028 FFF7FEFF 		bl	ktime_get
 216              	.LVL15:
 217              	.LBE36:
 218              	.LBE35:
  23:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     rq->io_start_time_ns = 0;
 219              		.loc 1 23 23 discriminator 1 view .LVU81
 220 002c 6063     		str	r0, [r4, #52]
  24:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     rq->part = NULL;
 221              		.loc 1 24 5 is_stmt 1 view .LVU82
  24:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     rq->part = NULL;
 222              		.loc 1 24 26 is_stmt 0 view .LVU83
 223 002e 0023     		movs	r3, #0
 224 0030 A363     		str	r3, [r4, #56]
  25:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     rq->timeout = 1000;
 225              		.loc 1 25 5 is_stmt 1 view .LVU84
  25:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     rq->timeout = 1000;
 226              		.loc 1 25 14 is_stmt 0 view .LVU85
 227 0032 2363     		str	r3, [r4, #48]
  26:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     return rq;
 228              		.loc 1 26 5 is_stmt 1 view .LVU86
  26:/mnt/c/Users/31740/Desktop/newcore/block/request.c ****     return rq;
 229              		.loc 1 26 17 is_stmt 0 view .LVU87
 230 0034 4FF47A73 		mov	r3, #1000
ARM GAS  /tmp/cc68D0Lo.s 			page 24


 231 0038 6361     		str	r3, [r4, #20]
  27:/mnt/c/Users/31740/Desktop/newcore/block/request.c **** }
 232              		.loc 1 27 5 is_stmt 1 view .LVU88
  28:/mnt/c/Users/31740/Desktop/newcore/block/request.c **** EXPORT_SYMBOL(request_alloc);
 233              		.loc 1 28 1 is_stmt 0 view .LVU89
 234 003a 2046     		mov	r0, r4
 235 003c 70BD     		pop	{r4, r5, r6, pc}
  28:/mnt/c/Users/31740/Desktop/newcore/block/request.c **** EXPORT_SYMBOL(request_alloc);
 236              		.loc 1 28 1 view .LVU90
 237              		.cfi_endproc
 238              	.LFE960:
 240              		.section	.rodata.str1.4,"aMS",%progbits,1
 241              		.align	2
 242              	.LC0:
 243 0000 5F5F626C 		.ascii	"__blk_insert_request\000"
 243      6B5F696E 
 243      73657274 
 243      5F726571 
 243      75657374 
 244 0015 000000   		.align	2
 245              	.LC1:
 246 0018 00       		.ascii	"\000"
 247              		.section	.export_table,"aw"
 248              		.align	2
 251              	__blk_insert_request_export_struct:
 252 0000 00000000 		.word	.LC0
 253 0004 18000000 		.word	.LC1
 254 0008 00000000 		.word	__blk_insert_request
 255              		.section	.rodata.str1.4
 256 0019 000000   		.align	2
 257              	.LC2:
 258 001c 72657175 		.ascii	"request_alloc\000"
 258      6573745F 
 258      616C6C6F 
 258      6300
 259              		.section	.export_table
 260              		.align	2
 263              	request_alloc_export_struct:
 264 000c 1C000000 		.word	.LC2
 265 0010 18000000 		.word	.LC1
 266 0014 00000000 		.word	request_alloc
 267              		.text
 268              	.Letext0:
 269              		.file 7 "/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/int-l64.h"
 270              		.file 8 "/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/posix_types.h"
 271              		.file 9 "/mnt/c/Users/31740/Desktop/newcore/include/uapi/linux/types.h"
 272              		.file 10 "/mnt/c/Users/31740/Desktop/newcore/include/linux/types.h"
 273              		.file 11 "/mnt/c/Users/31740/Desktop/newcore/include/linux/time64.h"
 274              		.file 12 "/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h"
 275              		.file 13 "/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock_types_raw.h"
 276              		.file 14 "/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock_types.h"
 277              		.file 15 "/mnt/c/Users/31740/Desktop/newcore/include/linux/mutex.h"
 278              		.file 16 "/mnt/c/Users/31740/Desktop/newcore/include/linux/errseq.h"
 279              		.file 17 "/mnt/c/Users/31740/Desktop/newcore/include/linux/rbtree_types.h"
 280              		.file 18 "/mnt/c/Users/31740/Desktop/newcore/include/linux/uidgid_types.h"
 281              		.file 19 "/mnt/c/Users/31740/Desktop/newcore/include/linux/projid.h"
 282              		.file 20 "/mnt/c/Users/31740/Desktop/newcore/include/linux/fs.h"
ARM GAS  /tmp/cc68D0Lo.s 			page 25


 283              		.file 21 "/mnt/c/Users/31740/Desktop/newcore/include/linux/mnt_idmapping.h"
 284              		.file 22 "/mnt/c/Users/31740/Desktop/newcore/include/linux/uio.h"
 285              		.file 23 "/mnt/c/Users/31740/Desktop/newcore/include/linux/wait.h"
 286              		.file 24 "/mnt/c/Users/31740/Desktop/newcore/include/linux/xarray.h"
 287              		.file 25 "/mnt/c/Users/31740/Desktop/newcore/include/linux/lockref.h"
 288              		.file 26 "/mnt/c/Users/31740/Desktop/newcore/include/linux/dcache.h"
 289              		.file 27 "/mnt/c/Users/31740/Desktop/newcore/include/linux/migrate_mode.h"
 290              		.file 28 "/mnt/c/Users/31740/Desktop/newcore/include/linux/path.h"
 291              		.file 29 "/mnt/c/Users/31740/Desktop/newcore/include/linux/reciprocal_div.h"
 292              		.file 30 "/mnt/c/Users/31740/Desktop/newcore/include/linux/mm_type.h"
 293              		.file 31 "/mnt/c/Users/31740/Desktop/newcore/include/linux/statfs.h"
 294              		.file 32 "/mnt/c/Users/31740/Desktop/newcore/include/linux/stat.h"
 295              		.file 33 "/mnt/c/Users/31740/Desktop/newcore/include/linux/bvec.h"
 296              		.file 34 "/mnt/c/Users/31740/Desktop/newcore/include/linux/stddef.h"
 297              		.file 35 "/mnt/c/Users/31740/Desktop/newcore/include/linux/blk_types.h"
 298              		.file 36 "/mnt/c/Users/31740/Desktop/newcore/include/linux/rw_hint.h"
 299              		.file 37 "/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h"
 300              		.file 38 "/mnt/c/Users/31740/Desktop/newcore/include/linux/bio.h"
 301              		.file 39 "/mnt/c/Users/31740/Desktop/newcore/include/linux/mempool_super_haper.h"
 302              		.file 40 "/mnt/c/Users/31740/Desktop/newcore/include/linux/mempool.h"
 303              		.file 41 "/mnt/c/Users/31740/Desktop/newcore/include/linux/lockdep_types.h"
 304              		.file 42 "/mnt/c/Users/31740/Desktop/newcore/include/linux/workqueue_types.h"
 305              		.file 43 "/mnt/c/Users/31740/Desktop/newcore/include/linux/blk-mq.h"
 306              		.file 44 "/mnt/c/Users/31740/Desktop/newcore/include/uapi/linux/pr.h"
 307              		.file 45 "/mnt/c/Users/31740/Desktop/newcore/include/linux/pr.h"
 308              		.file 46 "/mnt/c/Users/31740/Desktop/newcore/include/linux/hdreg.h"
 309              		.file 47 "/mnt/c/Users/31740/Desktop/newcore/include/linux/export.h"
 310              		.file 48 "/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/string.h"
 311              		.file 49 "/mnt/c/Users/31740/Desktop/newcore/include/linux/instrumented.h"
 312              		.file 50 "/mnt/c/Users/31740/Desktop/newcore/include/linux/kcsan-checks.h"
 313              		.file 51 "/mnt/c/Users/31740/Desktop/newcore/include/linux/kasan-checks.h"
 314              		.file 52 "<built-in>"
ARM GAS  /tmp/cc68D0Lo.s 			page 26


DEFINED SYMBOLS
                            *ABS*:00000000 request.c
     /tmp/cc68D0Lo.s:21     .text.__blk_insert_request:00000000 $t
     /tmp/cc68D0Lo.s:27     .text.__blk_insert_request:00000000 __blk_insert_request
     /tmp/cc68D0Lo.s:78     .text.request_alloc:00000000 $t
     /tmp/cc68D0Lo.s:84     .text.request_alloc:00000000 request_alloc
     /tmp/cc68D0Lo.s:241    .rodata.str1.4:00000000 $d
     /tmp/cc68D0Lo.s:248    .export_table:00000000 $d
     /tmp/cc68D0Lo.s:251    .export_table:00000000 __blk_insert_request_export_struct
     /tmp/cc68D0Lo.s:263    .export_table:0000000c request_alloc_export_struct

UNDEFINED SYMBOLS
__smalloc__
memset
ktime_get
