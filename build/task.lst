ARM GAS  /tmp/cc6nMSng.s 			page 1


   1              		.cpu cortex-m4
   2              		.arch armv7e-m
   3              		.fpu fpv4-sp-d16
   4              		.eabi_attribute 27, 1
   5              		.eabi_attribute 28, 1
   6              		.eabi_attribute 20, 1
   7              		.eabi_attribute 21, 1
   8              		.eabi_attribute 23, 3
   9              		.eabi_attribute 24, 1
  10              		.eabi_attribute 25, 1
  11              		.eabi_attribute 26, 1
  12              		.eabi_attribute 30, 1
  13              		.eabi_attribute 34, 1
  14              		.eabi_attribute 18, 4
  15              		.file	"task.c"
  16              		.text
  17              	.Ltext0:
  18              		.cfi_sections	.debug_frame
  19              		.file 1 "./kernel/sched/task.c"
  20              		.section	.text.init_task_context,"ax",%progbits
  21              		.align	1
  22              		.syntax unified
  23              		.thumb
  24              		.thumb_func
  26              	init_task_context:
  27              	.LVL0:
  28              	.LFB221:
  29              		.file 2 "./arch/arm_m/include/asm/context.h"
   1:./arch/arm_m/include/asm/context.h **** #ifndef __CONTEXT_H__
   2:./arch/arm_m/include/asm/context.h **** #define __CONTEXT_H__                
   3:./arch/arm_m/include/asm/context.h **** 
   4:./arch/arm_m/include/asm/context.h **** 
   5:./arch/arm_m/include/asm/context.h **** extern void __init_Taskcontext(struct task_struct* task_data);
   6:./arch/arm_m/include/asm/context.h **** static void init_task_context(struct task_struct* task_data){
  30              		.loc 2 6 61 view -0
  31              		.cfi_startproc
  32              		@ args = 0, pretend = 0, frame = 0
  33              		@ frame_needed = 0, uses_anonymous_args = 0
  34              		.loc 2 6 61 is_stmt 0 view .LVU1
  35 0000 08B5     		push	{r3, lr}
  36              	.LCFI0:
  37              		.cfi_def_cfa_offset 8
  38              		.cfi_offset 3, -8
  39              		.cfi_offset 14, -4
   7:./arch/arm_m/include/asm/context.h ****     __init_Taskcontext(task_data);
  40              		.loc 2 7 5 is_stmt 1 view .LVU2
  41 0002 FFF7FEFF 		bl	__init_Taskcontext
  42              	.LVL1:
   8:./arch/arm_m/include/asm/context.h **** }
  43              		.loc 2 8 1 is_stmt 0 view .LVU3
  44 0006 08BD     		pop	{r3, pc}
  45              		.cfi_endproc
  46              	.LFE221:
  48              		.section	.rodata.__new_task_create.str1.4,"aMS",%progbits,1
  49              		.align	2
  50              	.LC0:
  51 0000 63616E20 		.ascii	"can not create t\012\000"
ARM GAS  /tmp/cc6nMSng.s 			page 2


  51      6E6F7420 
  51      63726561 
  51      74652074 
  51      0A00
  52 0012 0000     		.align	2
  53              	.LC1:
  54 0014 63616E20 		.ascii	"can not alloc memory1\012\015\000"
  54      6E6F7420 
  54      616C6C6F 
  54      63206D65 
  54      6D6F7279 
  55              		.section	.text.__new_task_create,"ax",%progbits
  56              		.align	1
  57              		.global	__new_task_create
  58              		.syntax unified
  59              		.thumb
  60              		.thumb_func
  62              	__new_task_create:
  63              	.LVL2:
  64              	.LFB284:
   1:./kernel/sched/task.c **** #include <linux/kernel.h>
   2:./kernel/sched/task.c **** #include <linux/sched.h>
   3:./kernel/sched/task.c **** #include <linux/slab.h>
   4:./kernel/sched/task.c **** #include <linux/error.h>
   5:./kernel/sched/task.c **** #include <linux/string.h>
   6:./kernel/sched/task.c **** 
   7:./kernel/sched/task.c **** static uint32_t id_count = 9;
   8:./kernel/sched/task.c **** struct task_struct* __new_task_create(
   9:./kernel/sched/task.c ****             int (*entry)(void*), 
  10:./kernel/sched/task.c ****             int stack_size,
  11:./kernel/sched/task.c ****             void *argv,
  12:./kernel/sched/task.c ****             int priority,
  13:./kernel/sched/task.c ****             char *name
  14:./kernel/sched/task.c ****             )
  15:./kernel/sched/task.c **** {
  65              		.loc 1 15 1 is_stmt 1 view -0
  66              		.cfi_startproc
  67              		@ args = 4, pretend = 0, frame = 0
  68              		@ frame_needed = 0, uses_anonymous_args = 0
  69              		.loc 1 15 1 is_stmt 0 view .LVU5
  70 0000 2DE9F843 		push	{r3, r4, r5, r6, r7, r8, r9, lr}
  71              	.LCFI1:
  72              		.cfi_def_cfa_offset 32
  73              		.cfi_offset 3, -32
  74              		.cfi_offset 4, -28
  75              		.cfi_offset 5, -24
  76              		.cfi_offset 6, -20
  77              		.cfi_offset 7, -16
  78              		.cfi_offset 8, -12
  79              		.cfi_offset 9, -8
  80              		.cfi_offset 14, -4
  81 0004 089E     		ldr	r6, [sp, #32]
  16:./kernel/sched/task.c ****     if(entry == NULL || name == NULL){
  82              		.loc 1 16 5 is_stmt 1 view .LVU6
  83              		.loc 1 16 7 is_stmt 0 view .LVU7
  84 0006 60B3     		cbz	r0, .L4
  85 0008 9046     		mov	r8, r2
ARM GAS  /tmp/cc6nMSng.s 			page 3


  86 000a 1F46     		mov	r7, r3
  87 000c 8146     		mov	r9, r0
  88              		.loc 1 16 22 discriminator 1 view .LVU8
  89 000e 46B3     		cbz	r6, .L4
  17:./kernel/sched/task.c ****         pr_info(KERN_INFO "can not create t\n");
  18:./kernel/sched/task.c ****         return -1;
  19:./kernel/sched/task.c ****     }
  20:./kernel/sched/task.c ****     stack_size += 64;
  90              		.loc 1 20 5 is_stmt 1 view .LVU9
  91              	.LVL3:
  21:./kernel/sched/task.c ****     stack_size += sizeof(struct task_struct);
  92              		.loc 1 21 5 view .LVU10
  22:./kernel/sched/task.c ****     stack_size = (stack_size + 127) & ~127; 
  93              		.loc 1 22 5 view .LVU11
  94 0010 01F23311 		addw	r1, r1, #307
  95              	.LVL4:
  96              		.loc 1 22 5 is_stmt 0 view .LVU12
  97 0014 21F07F05 		bic	r5, r1, #127
  98              	.LVL5:
  23:./kernel/sched/task.c ****     struct task_struct *new_task = kmalloc(stack_size, GFP_NOWAIT);
  99              		.loc 1 23 5 is_stmt 1 view .LVU13
 100              	.LBB8:
 101              	.LBI8:
 102              		.file 3 "./include/linux/slab.h"
   1:./include/linux/slab.h **** /* SPDX-License-Identifier: GPL-2.0 */
   2:./include/linux/slab.h **** /*
   3:./include/linux/slab.h ****  * Written by Mark Hemment, 1996 (markhe@nextd.demon.co.uk).
   4:./include/linux/slab.h ****  *
   5:./include/linux/slab.h ****  * (C) SGI 2006, Christoph Lameter
   6:./include/linux/slab.h ****  * 	Cleaned up and restructured to ease the addition of alternative
   7:./include/linux/slab.h ****  * 	implementations of SLAB allocators.
   8:./include/linux/slab.h ****  * (C) Linux Foundation 2008-2013
   9:./include/linux/slab.h ****  *      Unified interface for all slab allocators
  10:./include/linux/slab.h ****  */
  11:./include/linux/slab.h **** 
  12:./include/linux/slab.h **** #ifndef _LINUX_SLAB_H
  13:./include/linux/slab.h **** #define	_LINUX_SLAB_H
  14:./include/linux/slab.h **** 
  15:./include/linux/slab.h **** #include <linux/cache.h>
  16:./include/linux/slab.h **** #include <linux/overflow.h>
  17:./include/linux/slab.h **** #include <linux/types.h>
  18:./include/linux/slab.h **** #include <linux/raid/pq.h>
  19:./include/linux/slab.h **** #include <linux/gfp_types.h>
  20:./include/linux/slab.h **** #include <linux/numa.h>
  21:./include/linux/slab.h **** #include <linux/reciprocal_div.h>
  22:./include/linux/slab.h **** #include <linux/spinlock.h>
  23:./include/linux/slab.h **** 
  24:./include/linux/slab.h **** enum _slab_flag_bits {
  25:./include/linux/slab.h **** 	_SLAB_CONSISTENCY_CHECKS,
  26:./include/linux/slab.h **** 	_SLAB_RED_ZONE,
  27:./include/linux/slab.h **** 	_SLAB_POISON,
  28:./include/linux/slab.h **** 	_SLAB_KMALLOC,
  29:./include/linux/slab.h **** 	_SLAB_HWCACHE_ALIGN,
  30:./include/linux/slab.h **** 	_SLAB_CACHE_DMA,
  31:./include/linux/slab.h **** 	_SLAB_CACHE_DMA32,
  32:./include/linux/slab.h **** 	_SLAB_STORE_USER,
  33:./include/linux/slab.h **** 	_SLAB_PANIC,
ARM GAS  /tmp/cc6nMSng.s 			page 4


  34:./include/linux/slab.h **** 	_SLAB_TYPESAFE_BY_RCU,
  35:./include/linux/slab.h **** 	_SLAB_TRACE,
  36:./include/linux/slab.h **** #ifdef CONFIG_DEBUG_OBJECTS
  37:./include/linux/slab.h **** 	_SLAB_DEBUG_OBJECTS,
  38:./include/linux/slab.h **** #endif
  39:./include/linux/slab.h **** 	_SLAB_NOLEAKTRACE,
  40:./include/linux/slab.h **** 	_SLAB_NO_MERGE,
  41:./include/linux/slab.h **** #ifdef CONFIG_FAILSLAB
  42:./include/linux/slab.h **** 	_SLAB_FAILSLAB,
  43:./include/linux/slab.h **** #endif
  44:./include/linux/slab.h **** #ifdef CONFIG_MEMCG
  45:./include/linux/slab.h **** 	_SLAB_ACCOUNT,
  46:./include/linux/slab.h **** #endif
  47:./include/linux/slab.h **** #ifdef CONFIG_KASAN_GENERIC
  48:./include/linux/slab.h **** 	_SLAB_KASAN,
  49:./include/linux/slab.h **** #endif
  50:./include/linux/slab.h **** 	_SLAB_NO_USER_FLAGS,
  51:./include/linux/slab.h **** #ifdef CONFIG_KFENCE
  52:./include/linux/slab.h **** 	_SLAB_SKIP_KFENCE,
  53:./include/linux/slab.h **** #endif
  54:./include/linux/slab.h **** #ifndef CONFIG_SLUB_TINY
  55:./include/linux/slab.h **** 	_SLAB_RECLAIM_ACCOUNT,
  56:./include/linux/slab.h **** #endif
  57:./include/linux/slab.h **** 	_SLAB_OBJECT_POISON,
  58:./include/linux/slab.h **** 	_SLAB_CMPXCHG_DOUBLE,
  59:./include/linux/slab.h **** #ifdef CONFIG_SLAB_OBJ_EXT
  60:./include/linux/slab.h **** 	_SLAB_NO_OBJ_EXT,
  61:./include/linux/slab.h **** #endif
  62:./include/linux/slab.h **** 	_SLAB_FLAGS_LAST_BIT
  63:./include/linux/slab.h **** };
  64:./include/linux/slab.h **** 
  65:./include/linux/slab.h **** 
  66:./include/linux/slab.h **** 
  67:./include/linux/slab.h **** #define __SLAB_FLAG_BIT(nr)	((slab_flags_t __force)(1U << (nr)))
  68:./include/linux/slab.h **** #define __SLAB_FLAG_UNUSED	((slab_flags_t __force)(0U))
  69:./include/linux/slab.h **** 
  70:./include/linux/slab.h **** /*
  71:./include/linux/slab.h ****  * Flags to pass to kmem_cache_create().
  72:./include/linux/slab.h ****  * The ones marked DEBUG need CONFIG_SLUB_DEBUG enabled, otherwise are no-op
  73:./include/linux/slab.h ****  */
  74:./include/linux/slab.h **** /* DEBUG: Perform (expensive) checks on alloc/free */
  75:./include/linux/slab.h **** #define SLAB_CONSISTENCY_CHECKS	__SLAB_FLAG_BIT(_SLAB_CONSISTENCY_CHECKS)
  76:./include/linux/slab.h **** /* DEBUG: Red zone objs in a cache */
  77:./include/linux/slab.h **** #define SLAB_RED_ZONE		__SLAB_FLAG_BIT(_SLAB_RED_ZONE)
  78:./include/linux/slab.h **** /* DEBUG: Poison objects */
  79:./include/linux/slab.h **** #define SLAB_POISON		__SLAB_FLAG_BIT(_SLAB_POISON)
  80:./include/linux/slab.h **** /* Indicate a kmalloc slab */
  81:./include/linux/slab.h **** #define SLAB_KMALLOC		__SLAB_FLAG_BIT(_SLAB_KMALLOC)
  82:./include/linux/slab.h **** /**
  83:./include/linux/slab.h ****  * define SLAB_HWCACHE_ALIGN - Align objects on cache line boundaries.
  84:./include/linux/slab.h ****  *
  85:./include/linux/slab.h ****  * Sufficiently large objects are aligned on cache line boundary. For object
  86:./include/linux/slab.h ****  * size smaller than a half of cache line size, the alignment is on the half of
  87:./include/linux/slab.h ****  * cache line size. In general, if object size is smaller than 1/2^n of cache
  88:./include/linux/slab.h ****  * line size, the alignment is adjusted to 1/2^n.
  89:./include/linux/slab.h ****  *
  90:./include/linux/slab.h ****  * If explicit alignment is also requested by the respective
ARM GAS  /tmp/cc6nMSng.s 			page 5


  91:./include/linux/slab.h ****  * &struct kmem_cache_args field, the greater of both is alignments is applied.
  92:./include/linux/slab.h ****  */
  93:./include/linux/slab.h **** #define SLAB_HWCACHE_ALIGN	__SLAB_FLAG_BIT(_SLAB_HWCACHE_ALIGN)
  94:./include/linux/slab.h **** /* Use GFP_DMA memory */
  95:./include/linux/slab.h **** #define SLAB_CACHE_DMA		__SLAB_FLAG_BIT(_SLAB_CACHE_DMA)
  96:./include/linux/slab.h **** /* Use GFP_DMA32 memory */
  97:./include/linux/slab.h **** #define SLAB_CACHE_DMA32	__SLAB_FLAG_BIT(_SLAB_CACHE_DMA32)
  98:./include/linux/slab.h **** /* DEBUG: Store the last owner for bug hunting */
  99:./include/linux/slab.h **** #define SLAB_STORE_USER		__SLAB_FLAG_BIT(_SLAB_STORE_USER)
 100:./include/linux/slab.h **** /* Panic if kmem_cache_create() fails */
 101:./include/linux/slab.h **** #define SLAB_PANIC		__SLAB_FLAG_BIT(_SLAB_PANIC)
 102:./include/linux/slab.h **** /**
 103:./include/linux/slab.h ****  * define SLAB_TYPESAFE_BY_RCU - **WARNING** READ THIS!
 104:./include/linux/slab.h ****  *
 105:./include/linux/slab.h ****  * This delays freeing the SLAB page by a grace period, it does _NOT_
 106:./include/linux/slab.h ****  * delay object freeing. This means that if you do kmem_cache_free()
 107:./include/linux/slab.h ****  * that memory location is free to be reused at any time. Thus it may
 108:./include/linux/slab.h ****  * be possible to see another object there in the same RCU grace period.
 109:./include/linux/slab.h ****  *
 110:./include/linux/slab.h ****  * This feature only ensures the memory location backing the object
 111:./include/linux/slab.h ****  * stays valid, the trick to using this is relying on an independent
 112:./include/linux/slab.h ****  * object validation pass. Something like:
 113:./include/linux/slab.h ****  *
 114:./include/linux/slab.h ****  * ::
 115:./include/linux/slab.h ****  *
 116:./include/linux/slab.h ****  *  begin:
 117:./include/linux/slab.h ****  *   rcu_read_lock();
 118:./include/linux/slab.h ****  *   obj = lockless_lookup(key);
 119:./include/linux/slab.h ****  *   if (obj) {
 120:./include/linux/slab.h ****  *     if (!try_get_ref(obj)) // might fail for free objects
 121:./include/linux/slab.h ****  *       rcu_read_unlock();
 122:./include/linux/slab.h ****  *       goto begin;
 123:./include/linux/slab.h ****  *
 124:./include/linux/slab.h ****  *     if (obj->key != key) { // not the object we expected
 125:./include/linux/slab.h ****  *       put_ref(obj);
 126:./include/linux/slab.h ****  *       rcu_read_unlock();
 127:./include/linux/slab.h ****  *       goto begin;
 128:./include/linux/slab.h ****  *     }
 129:./include/linux/slab.h ****  *   }
 130:./include/linux/slab.h ****  *  rcu_read_unlock();
 131:./include/linux/slab.h ****  *
 132:./include/linux/slab.h ****  * This is useful if we need to approach a kernel structure obliquely,
 133:./include/linux/slab.h ****  * from its address obtained without the usual locking. We can lock
 134:./include/linux/slab.h ****  * the structure to stabilize it and check it's still at the given address,
 135:./include/linux/slab.h ****  * only if we can be sure that the memory has not been meanwhile reused
 136:./include/linux/slab.h ****  * for some other kind of object (which our subsystem's lock might corrupt).
 137:./include/linux/slab.h ****  *
 138:./include/linux/slab.h ****  * rcu_read_lock before reading the address, then rcu_read_unlock after
 139:./include/linux/slab.h ****  * taking the spinlock within the structure expected at that address.
 140:./include/linux/slab.h ****  *
 141:./include/linux/slab.h ****  * Note that it is not possible to acquire a lock within a structure
 142:./include/linux/slab.h ****  * allocated with SLAB_TYPESAFE_BY_RCU without first acquiring a reference
 143:./include/linux/slab.h ****  * as described above.  The reason is that SLAB_TYPESAFE_BY_RCU pages
 144:./include/linux/slab.h ****  * are not zeroed before being given to the slab, which means that any
 145:./include/linux/slab.h ****  * locks must be initialized after each and every kmem_struct_alloc().
 146:./include/linux/slab.h ****  * Alternatively, make the ctor passed to kmem_cache_create() initialize
 147:./include/linux/slab.h ****  * the locks at page-allocation time, as is done in __i915_request_ctor(),
ARM GAS  /tmp/cc6nMSng.s 			page 6


 148:./include/linux/slab.h ****  * sighand_ctor(), and anon_vma_ctor().  Such a ctor permits readers
 149:./include/linux/slab.h ****  * to safely acquire those ctor-initialized locks under rcu_read_lock()
 150:./include/linux/slab.h ****  * protection.
 151:./include/linux/slab.h ****  *
 152:./include/linux/slab.h ****  * Note that SLAB_TYPESAFE_BY_RCU was originally named SLAB_DESTROY_BY_RCU.
 153:./include/linux/slab.h ****  */
 154:./include/linux/slab.h **** #define SLAB_TYPESAFE_BY_RCU	__SLAB_FLAG_BIT(_SLAB_TYPESAFE_BY_RCU)
 155:./include/linux/slab.h **** /* Trace allocations and frees */
 156:./include/linux/slab.h **** #define SLAB_TRACE		__SLAB_FLAG_BIT(_SLAB_TRACE)
 157:./include/linux/slab.h **** 
 158:./include/linux/slab.h **** /* Flag to prevent checks on free */
 159:./include/linux/slab.h **** #ifdef CONFIG_DEBUG_OBJECTS
 160:./include/linux/slab.h **** # define SLAB_DEBUG_OBJECTS	__SLAB_FLAG_BIT(_SLAB_DEBUG_OBJECTS)
 161:./include/linux/slab.h **** #else
 162:./include/linux/slab.h **** # define SLAB_DEBUG_OBJECTS	__SLAB_FLAG_UNUSED
 163:./include/linux/slab.h **** #endif
 164:./include/linux/slab.h **** 
 165:./include/linux/slab.h **** /* Avoid kmemleak tracing */
 166:./include/linux/slab.h **** #define SLAB_NOLEAKTRACE	__SLAB_FLAG_BIT(_SLAB_NOLEAKTRACE)
 167:./include/linux/slab.h **** 
 168:./include/linux/slab.h **** /*
 169:./include/linux/slab.h ****  * Prevent merging with compatible kmem caches. This flag should be used
 170:./include/linux/slab.h ****  * cautiously. Valid use cases:
 171:./include/linux/slab.h ****  *
 172:./include/linux/slab.h ****  * - caches created for self-tests (e.g. kunit)
 173:./include/linux/slab.h ****  * - general caches created and used by a subsystem, only when a
 174:./include/linux/slab.h ****  *   (subsystem-specific) debug option is enabled
 175:./include/linux/slab.h ****  * - performance critical caches, should be very rare and consulted with slab
 176:./include/linux/slab.h ****  *   maintainers, and not used together with CONFIG_SLUB_TINY
 177:./include/linux/slab.h ****  */
 178:./include/linux/slab.h **** #define SLAB_NO_MERGE		__SLAB_FLAG_BIT(_SLAB_NO_MERGE)
 179:./include/linux/slab.h **** 
 180:./include/linux/slab.h **** /* Fault injection mark */
 181:./include/linux/slab.h **** #ifdef CONFIG_FAILSLAB
 182:./include/linux/slab.h **** # define SLAB_FAILSLAB		__SLAB_FLAG_BIT(_SLAB_FAILSLAB)
 183:./include/linux/slab.h **** #else
 184:./include/linux/slab.h **** # define SLAB_FAILSLAB		__SLAB_FLAG_UNUSED
 185:./include/linux/slab.h **** #endif
 186:./include/linux/slab.h **** /**
 187:./include/linux/slab.h ****  * define SLAB_ACCOUNT - Account allocations to memcg.
 188:./include/linux/slab.h ****  *
 189:./include/linux/slab.h ****  * All object allocations from this cache will be memcg accounted, regardless of
 190:./include/linux/slab.h ****  * __GFP_ACCOUNT being or not being passed to individual allocations.
 191:./include/linux/slab.h ****  */
 192:./include/linux/slab.h **** #ifdef CONFIG_MEMCG
 193:./include/linux/slab.h **** # define SLAB_ACCOUNT		__SLAB_FLAG_BIT(_SLAB_ACCOUNT)
 194:./include/linux/slab.h **** #else
 195:./include/linux/slab.h **** # define SLAB_ACCOUNT		__SLAB_FLAG_UNUSED
 196:./include/linux/slab.h **** #endif
 197:./include/linux/slab.h **** 
 198:./include/linux/slab.h **** #ifdef CONFIG_KASAN_GENERIC
 199:./include/linux/slab.h **** #define SLAB_KASAN		__SLAB_FLAG_BIT(_SLAB_KASAN)
 200:./include/linux/slab.h **** #else
 201:./include/linux/slab.h **** #define SLAB_KASAN		__SLAB_FLAG_UNUSED
 202:./include/linux/slab.h **** #endif
 203:./include/linux/slab.h **** 
 204:./include/linux/slab.h **** /*
ARM GAS  /tmp/cc6nMSng.s 			page 7


 205:./include/linux/slab.h ****  * Ignore user specified debugging flags.
 206:./include/linux/slab.h ****  * Intended for caches created for self-tests so they have only flags
 207:./include/linux/slab.h ****  * specified in the code and other flags are ignored.
 208:./include/linux/slab.h ****  */
 209:./include/linux/slab.h **** #define SLAB_NO_USER_FLAGS	__SLAB_FLAG_BIT(_SLAB_NO_USER_FLAGS)
 210:./include/linux/slab.h **** 
 211:./include/linux/slab.h **** #ifdef CONFIG_KFENCE
 212:./include/linux/slab.h **** #define SLAB_SKIP_KFENCE	__SLAB_FLAG_BIT(_SLAB_SKIP_KFENCE)
 213:./include/linux/slab.h **** #else
 214:./include/linux/slab.h **** #define SLAB_SKIP_KFENCE	__SLAB_FLAG_UNUSED
 215:./include/linux/slab.h **** #endif
 216:./include/linux/slab.h **** 
 217:./include/linux/slab.h **** /* The following flags affect the page allocator grouping pages by mobility */
 218:./include/linux/slab.h **** /**
 219:./include/linux/slab.h ****  * define SLAB_RECLAIM_ACCOUNT - Objects are reclaimable.
 220:./include/linux/slab.h ****  *
 221:./include/linux/slab.h ****  * Use this flag for caches that have an associated shrinker. As a result, slab
 222:./include/linux/slab.h ****  * pages are allocated with __GFP_RECLAIMABLE, which affects grouping pages by
 223:./include/linux/slab.h ****  * mobility, and are accounted in SReclaimable counter in /proc/meminfo
 224:./include/linux/slab.h ****  */
 225:./include/linux/slab.h **** #ifndef CONFIG_SLUB_TINY
 226:./include/linux/slab.h **** #define SLAB_RECLAIM_ACCOUNT	__SLAB_FLAG_BIT(_SLAB_RECLAIM_ACCOUNT)
 227:./include/linux/slab.h **** #else
 228:./include/linux/slab.h **** #define SLAB_RECLAIM_ACCOUNT	__SLAB_FLAG_UNUSED
 229:./include/linux/slab.h **** #endif
 230:./include/linux/slab.h **** #define SLAB_TEMPORARY		SLAB_RECLAIM_ACCOUNT	/* Objects are short-lived */
 231:./include/linux/slab.h **** 
 232:./include/linux/slab.h **** /* Slab created using create_boot_cache */
 233:./include/linux/slab.h **** #ifdef CONFIG_SLAB_OBJ_EXT
 234:./include/linux/slab.h **** #define SLAB_NO_OBJ_EXT		__SLAB_FLAG_BIT(_SLAB_NO_OBJ_EXT)
 235:./include/linux/slab.h **** #else
 236:./include/linux/slab.h **** #define SLAB_NO_OBJ_EXT		__SLAB_FLAG_UNUSED
 237:./include/linux/slab.h **** #endif
 238:./include/linux/slab.h **** 
 239:./include/linux/slab.h **** /*
 240:./include/linux/slab.h ****  * freeptr_t represents a SLUB freelist pointer, which might be encoded
 241:./include/linux/slab.h ****  * and not dereferenceable if CONFIG_SLAB_FREELIST_HARDENED is enabled.
 242:./include/linux/slab.h ****  */
 243:./include/linux/slab.h **** typedef struct { unsigned long v; } freeptr_t;
 244:./include/linux/slab.h **** 
 245:./include/linux/slab.h **** /*
 246:./include/linux/slab.h ****  * ZERO_SIZE_PTR will be returned for zero sized kmalloc requests.
 247:./include/linux/slab.h ****  *
 248:./include/linux/slab.h ****  * Dereferencing ZERO_SIZE_PTR will lead to a distinct access fault.
 249:./include/linux/slab.h ****  *
 250:./include/linux/slab.h ****  * ZERO_SIZE_PTR can be passed to kfree though in the same way that NULL can.
 251:./include/linux/slab.h ****  * Both make kfree a no-op.
 252:./include/linux/slab.h ****  */
 253:./include/linux/slab.h **** #define ZERO_SIZE_PTR ((void *)16)
 254:./include/linux/slab.h **** 
 255:./include/linux/slab.h **** #define ZERO_OR_NULL_PTR(x) ((unsigned long)(x) <= \
 256:./include/linux/slab.h **** 				(unsigned long)ZERO_SIZE_PTR)
 257:./include/linux/slab.h **** 
 258:./include/linux/slab.h **** 
 259:./include/linux/slab.h **** 
 260:./include/linux/slab.h **** 
 261:./include/linux/slab.h **** 
ARM GAS  /tmp/cc6nMSng.s 			page 8


 262:./include/linux/slab.h **** #ifdef CONFIG_SLUB_CPU_PARTIAL
 263:./include/linux/slab.h **** #define slub_percpu_partial(c)			((c)->partial)
 264:./include/linux/slab.h **** 
 265:./include/linux/slab.h **** #define slub_set_percpu_partial(c, p)		\
 266:./include/linux/slab.h **** ({						\
 267:./include/linux/slab.h **** 	slub_percpu_partial(c) = (p)->next;	\
 268:./include/linux/slab.h **** })
 269:./include/linux/slab.h **** 
 270:./include/linux/slab.h **** #define slub_percpu_partial_read_once(c)	READ_ONCE(slub_percpu_partial(c))
 271:./include/linux/slab.h **** #else
 272:./include/linux/slab.h **** #define slub_percpu_partial(c)			NULL
 273:./include/linux/slab.h **** 
 274:./include/linux/slab.h **** #define slub_set_percpu_partial(c, p)
 275:./include/linux/slab.h **** 
 276:./include/linux/slab.h **** #define slub_percpu_partial_read_once(c)	NULL
 277:./include/linux/slab.h **** 
 278:./include/linux/slab.h **** 
 279:./include/linux/slab.h **** #endif // CONFIG_SLUB_CPU_PARTIAL
 280:./include/linux/slab.h **** 
 281:./include/linux/slab.h **** /*
 282:./include/linux/slab.h **** 	* Word size structure that can be atomically updated or read and that
 283:./include/linux/slab.h **** 	* contains both the order and the number of objects that a slab of the
 284:./include/linux/slab.h **** 	* given order would contain.
 285:./include/linux/slab.h **** 	*/				
 286:./include/linux/slab.h **** struct kmem_cache_order_objects {
 287:./include/linux/slab.h **** 	unsigned int x;
 288:./include/linux/slab.h **** };
 289:./include/linux/slab.h **** 
 290:./include/linux/slab.h **** struct kmem_cache_node {
 291:./include/linux/slab.h **** 	spinlock_t list_lock;
 292:./include/linux/slab.h **** 	unsigned long nr_partial;
 293:./include/linux/slab.h **** 	struct list_head partial;
 294:./include/linux/slab.h **** #ifdef CONFIG_SLUB_DEBUG
 295:./include/linux/slab.h **** 	atomic_long_t nr_slabs;
 296:./include/linux/slab.h **** 	atomic_long_t total_objects;
 297:./include/linux/slab.h **** 	struct list_head full;
 298:./include/linux/slab.h **** #endif
 299:./include/linux/slab.h **** };
 300:./include/linux/slab.h **** 
 301:./include/linux/slab.h **** struct kmem_cache {
 302:./include/linux/slab.h **** 	#ifndef CONFIG_SLUB_TINY
 303:./include/linux/slab.h **** 	//	struct kmem_cache_cpu __percpu *cpu_slab;
 304:./include/linux/slab.h **** 	#endif
 305:./include/linux/slab.h **** 		/* Used for retrieving partial slabs, etc. */
 306:./include/linux/slab.h **** 		slab_flags_t flags;
 307:./include/linux/slab.h **** 		unsigned long min_partial;
 308:./include/linux/slab.h **** 		unsigned int size;		/* Object size including metadata */
 309:./include/linux/slab.h **** 		unsigned int object_size;	/* Object size without metadata */
 310:./include/linux/slab.h **** 		struct reciprocal_value reciprocal_size;
 311:./include/linux/slab.h **** 		unsigned int offset;		/* Free pointer offset */
 312:./include/linux/slab.h **** 	#ifdef CONFIG_SLUB_CPU_PARTIAL
 313:./include/linux/slab.h **** 		/* Number of per cpu partial objects to keep around */
 314:./include/linux/slab.h **** 		unsigned int cpu_partial;
 315:./include/linux/slab.h **** 		/* Number of per cpu partial slabs to keep around */
 316:./include/linux/slab.h **** 		unsigned int cpu_partial_slabs;
 317:./include/linux/slab.h **** 	#endif
 318:./include/linux/slab.h **** 		struct kmem_cache_order_objects oo;
ARM GAS  /tmp/cc6nMSng.s 			page 9


 319:./include/linux/slab.h **** 	
 320:./include/linux/slab.h **** 		/* Allocation and freeing of slabs */
 321:./include/linux/slab.h **** 		struct kmem_cache_order_objects min;
 322:./include/linux/slab.h **** 		gfp_t allocflags;		/* gfp flags to use on each alloc */
 323:./include/linux/slab.h **** 		int refcount;			/* Refcount for slab cache destroy */
 324:./include/linux/slab.h **** 		void (*ctor)(void *object);	/* Object constructor */
 325:./include/linux/slab.h **** 		unsigned int inuse;		/* Offset to metadata */
 326:./include/linux/slab.h **** 		unsigned int align;		/* Alignment */
 327:./include/linux/slab.h **** 		unsigned int red_left_pad;	/* Left redzone padding size */
 328:./include/linux/slab.h **** 		const char *name;		/* Name (only for display!) */
 329:./include/linux/slab.h **** 		struct list_head list;		/* List of slab caches */
 330:./include/linux/slab.h **** 	#ifdef CONFIG_SYSFS
 331:./include/linux/slab.h **** 		struct kobject kobj;		/* For sysfs */
 332:./include/linux/slab.h **** 	#endif
 333:./include/linux/slab.h **** 	#ifdef CONFIG_SLAB_FREELIST_HARDENED
 334:./include/linux/slab.h **** 		unsigned long random;
 335:./include/linux/slab.h **** 	#endif
 336:./include/linux/slab.h **** 	
 337:./include/linux/slab.h **** 	#ifdef CONFIG_NUMA
 338:./include/linux/slab.h **** 		/*
 339:./include/linux/slab.h **** 			* Defragmentation by allocating from a remote node.
 340:./include/linux/slab.h **** 			*/
 341:./include/linux/slab.h **** 		unsigned int remote_node_defrag_ratio;
 342:./include/linux/slab.h **** 	#endif
 343:./include/linux/slab.h **** 	
 344:./include/linux/slab.h **** 	#ifdef CONFIG_SLAB_FREELIST_RANDOM
 345:./include/linux/slab.h **** 		unsigned int *random_seq;
 346:./include/linux/slab.h **** 	#endif
 347:./include/linux/slab.h **** 	
 348:./include/linux/slab.h **** 	#ifdef CONFIG_KASAN_GENERIC
 349:./include/linux/slab.h **** 		struct kasan_cache kasan_info;
 350:./include/linux/slab.h **** 	#endif
 351:./include/linux/slab.h **** 	
 352:./include/linux/slab.h **** 	#ifdef CONFIG_HARDENED_USERCOPY
 353:./include/linux/slab.h **** 		unsigned int useroffset;	/* Usercopy region offset */
 354:./include/linux/slab.h **** 		unsigned int usersize;		/* Usercopy region size */
 355:./include/linux/slab.h **** 	#endif
 356:./include/linux/slab.h **** 	
 357:./include/linux/slab.h **** 		struct kmem_cache_node *node[MAX_NUMNODES];
 358:./include/linux/slab.h **** 	};
 359:./include/linux/slab.h **** 					
 360:./include/linux/slab.h **** 
 361:./include/linux/slab.h **** 
 362:./include/linux/slab.h **** 
 363:./include/linux/slab.h **** 
 364:./include/linux/slab.h **** #define KMALLOC_WAIT 1
 365:./include/linux/slab.h **** 
 366:./include/linux/slab.h **** 
 367:./include/linux/slab.h **** extern void* __smalloc__(u32 size, gfp_t flags);
 368:./include/linux/slab.h **** extern void  __sfree__(void* addr);
 369:./include/linux/slab.h **** 
 370:./include/linux/slab.h **** 
 371:./include/linux/slab.h **** static void inline *vmalloc(unsigned long size){
 372:./include/linux/slab.h **** 	return __smalloc__(size,GFP_TRANSHUGE_LIGHT);
 373:./include/linux/slab.h **** }
 374:./include/linux/slab.h **** 
 375:./include/linux/slab.h **** static void inline vfree(void *addr){
ARM GAS  /tmp/cc6nMSng.s 			page 10


 376:./include/linux/slab.h **** 	__sfree__(addr);
 377:./include/linux/slab.h **** }
 378:./include/linux/slab.h **** 
 379:./include/linux/slab.h **** static void inline *kmalloc(size_t size, gfp_t flags){
 103              		.loc 3 379 21 view .LVU14
 104              	.LBB9:
 380:./include/linux/slab.h **** 	return __smalloc__((u32)size,flags);
 105              		.loc 3 380 2 view .LVU15
 106              		.loc 3 380 9 is_stmt 0 view .LVU16
 107 0018 4FF42051 		mov	r1, #10240
 108 001c 2846     		mov	r0, r5
 109              	.LVL6:
 110              		.loc 3 380 9 view .LVU17
 111 001e FFF7FEFF 		bl	__smalloc__
 112              	.LVL7:
 113              		.loc 3 380 9 view .LVU18
 114              	.LBE9:
 115              	.LBE8:
  24:./kernel/sched/task.c ****     if (new_task == NULL){
 116              		.loc 1 24 5 is_stmt 1 view .LVU19
 117              		.loc 1 24 8 is_stmt 0 view .LVU20
 118 0022 0446     		mov	r4, r0
 119 0024 18B3     		cbz	r0, .L14
  25:./kernel/sched/task.c ****         printk("can not alloc memory1\n\r");
  26:./kernel/sched/task.c ****         return -ENOMEM;
  27:./kernel/sched/task.c ****     } 
  28:./kernel/sched/task.c ****     if(priority == 0)
 120              		.loc 1 28 5 is_stmt 1 view .LVU21
 121              		.loc 1 28 7 is_stmt 0 view .LVU22
 122 0026 07B9     		cbnz	r7, .L8
  29:./kernel/sched/task.c ****         priority = defauld_thread_priority;
 123              		.loc 1 29 18 view .LVU23
 124 0028 0827     		movs	r7, #8
 125              	.LVL8:
 126              	.L8:
  30:./kernel/sched/task.c ****     
  31:./kernel/sched/task.c ****     new_task->stack_ptr = (void*)new_task + sizeof(struct task_struct);
 127              		.loc 1 31 5 is_stmt 1 view .LVU24
 128              		.loc 1 31 43 is_stmt 0 view .LVU25
 129 002a 04F17403 		add	r3, r4, #116
 130              		.loc 1 31 25 view .LVU26
 131 002e E364     		str	r3, [r4, #76]
  32:./kernel/sched/task.c ****     new_task->magic  = task_struct_magic;
 132              		.loc 1 32 5 is_stmt 1 view .LVU27
 133              		.loc 1 32 22 is_stmt 0 view .LVU28
 134 0030 7B23     		movs	r3, #123
 135 0032 2370     		strb	r3, [r4]
  33:./kernel/sched/task.c ****     new_task->id     = id_count++;
 136              		.loc 1 33 5 is_stmt 1 view .LVU29
 137              		.loc 1 33 32 is_stmt 0 view .LVU30
 138 0034 244A     		ldr	r2, .L15
 139 0036 1368     		ldr	r3, [r2]
 140 0038 591C     		adds	r1, r3, #1
 141 003a 1160     		str	r1, [r2]
 142              		.loc 1 33 22 view .LVU31
 143 003c 6360     		str	r3, [r4, #4]
  34:./kernel/sched/task.c ****     new_task->entry  = entry;
ARM GAS  /tmp/cc6nMSng.s 			page 11


 144              		.loc 1 34 5 is_stmt 1 view .LVU32
 145              		.loc 1 34 22 is_stmt 0 view .LVU33
 146 003e C4F85490 		str	r9, [r4, #84]
  35:./kernel/sched/task.c ****     new_task->arg    = argv;
 147              		.loc 1 35 5 is_stmt 1 view .LVU34
 148              		.loc 1 35 22 is_stmt 0 view .LVU35
 149 0042 C4F85880 		str	r8, [r4, #88]
  36:./kernel/sched/task.c ****     new_task->priority = priority;
 150              		.loc 1 36 5 is_stmt 1 view .LVU36
 151              		.loc 1 36 24 is_stmt 0 view .LVU37
 152 0046 6766     		str	r7, [r4, #100]
  37:./kernel/sched/task.c ****     new_task->stack_Top = (void*)new_task + stack_size;
 153              		.loc 1 37 5 is_stmt 1 view .LVU38
 154              		.loc 1 37 43 is_stmt 0 view .LVU39
 155 0048 2544     		add	r5, r5, r4
 156              	.LVL9:
 157              		.loc 1 37 25 view .LVU40
 158 004a 2565     		str	r5, [r4, #80]
  38:./kernel/sched/task.c **** 
  39:./kernel/sched/task.c ****     if(strlen(name) < task_name_max_len){
 159              		.loc 1 39 5 is_stmt 1 view .LVU41
 160              		.loc 1 39 8 is_stmt 0 view .LVU42
 161 004c 3046     		mov	r0, r6
 162              	.LVL10:
 163              		.loc 1 39 8 view .LVU43
 164 004e FFF7FEFF 		bl	strlen
 165              	.LVL11:
 166              		.loc 1 39 7 discriminator 1 view .LVU44
 167 0052 3F28     		cmp	r0, #63
 168 0054 11D8     		bhi	.L9
  40:./kernel/sched/task.c ****         strcpy(new_task->task_name,name);
 169              		.loc 1 40 9 is_stmt 1 view .LVU45
 170 0056 3146     		mov	r1, r6
 171 0058 04F10800 		add	r0, r4, #8
 172 005c FFF7FEFF 		bl	strcpy
 173              	.LVL12:
 174 0060 28E0     		b	.L10
 175              	.LVL13:
 176              	.L4:
  17:./kernel/sched/task.c ****         return -1;
 177              		.loc 1 17 9 view .LVU46
 178 0062 1A48     		ldr	r0, .L15+4
 179              	.LVL14:
  17:./kernel/sched/task.c ****         return -1;
 180              		.loc 1 17 9 is_stmt 0 view .LVU47
 181 0064 FFF7FEFF 		bl	printk
 182              	.LVL15:
  18:./kernel/sched/task.c ****     }
 183              		.loc 1 18 9 is_stmt 1 view .LVU48
  18:./kernel/sched/task.c ****     }
 184              		.loc 1 18 16 is_stmt 0 view .LVU49
 185 0068 4FF0FF34 		mov	r4, #-1
 186 006c 28E0     		b	.L3
 187              	.LVL16:
 188              	.L14:
  25:./kernel/sched/task.c ****         return -ENOMEM;
 189              		.loc 1 25 9 is_stmt 1 view .LVU50
ARM GAS  /tmp/cc6nMSng.s 			page 12


 190 006e 1848     		ldr	r0, .L15+8
 191              	.LVL17:
  25:./kernel/sched/task.c ****         return -ENOMEM;
 192              		.loc 1 25 9 is_stmt 0 view .LVU51
 193 0070 FFF7FEFF 		bl	printk
 194              	.LVL18:
  26:./kernel/sched/task.c ****     } 
 195              		.loc 1 26 9 is_stmt 1 view .LVU52
  26:./kernel/sched/task.c ****     } 
 196              		.loc 1 26 16 is_stmt 0 view .LVU53
 197 0074 6FF00B04 		mvn	r4, #11
 198              	.LVL19:
  26:./kernel/sched/task.c ****     } 
 199              		.loc 1 26 16 view .LVU54
 200 0078 22E0     		b	.L3
 201              	.LVL20:
 202              	.L9:
  41:./kernel/sched/task.c ****     }
  42:./kernel/sched/task.c ****     else{
  43:./kernel/sched/task.c ****         memcpy(new_task->task_name,name,task_name_max_len -1);
 203              		.loc 1 43 9 is_stmt 1 view .LVU55
 204 007a 3346     		mov	r3, r6
 205 007c 04F10802 		add	r2, r4, #8
 206 0080 3036     		adds	r6, r6, #48
 207              	.LVL21:
 208              	.L11:
 209              		.loc 1 43 9 is_stmt 0 view .LVU56
 210 0082 1F68     		ldr	r7, [r3]	@ unaligned
 211 0084 5D68     		ldr	r5, [r3, #4]	@ unaligned
 212 0086 9868     		ldr	r0, [r3, #8]	@ unaligned
 213 0088 D968     		ldr	r1, [r3, #12]	@ unaligned
 214 008a 1760     		str	r7, [r2]	@ unaligned
 215 008c 5560     		str	r5, [r2, #4]	@ unaligned
 216 008e 9060     		str	r0, [r2, #8]	@ unaligned
 217 0090 D160     		str	r1, [r2, #12]	@ unaligned
 218 0092 1033     		adds	r3, r3, #16
 219 0094 1032     		adds	r2, r2, #16
 220 0096 B342     		cmp	r3, r6
 221 0098 F3D1     		bne	.L11
 222 009a 1D68     		ldr	r5, [r3]	@ unaligned
 223 009c 5868     		ldr	r0, [r3, #4]	@ unaligned
 224 009e 9968     		ldr	r1, [r3, #8]	@ unaligned
 225 00a0 1560     		str	r5, [r2]	@ unaligned
 226 00a2 5060     		str	r0, [r2, #4]	@ unaligned
 227 00a4 9160     		str	r1, [r2, #8]	@ unaligned
 228 00a6 9989     		ldrh	r1, [r3, #12]	@ unaligned
 229 00a8 9B7B     		ldrb	r3, [r3, #14]	@ zero_extendqisi2
 230 00aa 9181     		strh	r1, [r2, #12]	@ unaligned
 231 00ac 9373     		strb	r3, [r2, #14]
  44:./kernel/sched/task.c ****         new_task->task_name[task_name_max_len -1] = '\0';
 232              		.loc 1 44 9 is_stmt 1 view .LVU57
 233              		.loc 1 44 51 is_stmt 0 view .LVU58
 234 00ae 0023     		movs	r3, #0
 235 00b0 84F84730 		strb	r3, [r4, #71]
 236              	.L10:
  45:./kernel/sched/task.c ****     }
  46:./kernel/sched/task.c ****     init_task_context(new_task);
ARM GAS  /tmp/cc6nMSng.s 			page 13


 237              		.loc 1 46 5 is_stmt 1 view .LVU59
 238 00b4 2046     		mov	r0, r4
 239 00b6 FFF7FEFF 		bl	init_task_context
 240              	.LVL22:
  47:./kernel/sched/task.c ****     new_task->state = TASK_READY;
 241              		.loc 1 47 5 view .LVU60
 242              		.loc 1 47 21 is_stmt 0 view .LVU61
 243 00ba 0223     		movs	r3, #2
 244 00bc 84F85C30 		strb	r3, [r4, #92]
  48:./kernel/sched/task.c ****     return new_task;
 245              		.loc 1 48 5 is_stmt 1 view .LVU62
 246              	.LVL23:
 247              	.L3:
  49:./kernel/sched/task.c **** }
 248              		.loc 1 49 1 is_stmt 0 view .LVU63
 249 00c0 2046     		mov	r0, r4
 250 00c2 BDE8F883 		pop	{r3, r4, r5, r6, r7, r8, r9, pc}
 251              	.L16:
 252 00c6 00BF     		.align	2
 253              	.L15:
 254 00c8 00000000 		.word	id_count
 255 00cc 00000000 		.word	.LC0
 256 00d0 14000000 		.word	.LC1
 257              		.cfi_endproc
 258              	.LFE284:
 260              		.section	.text.__destory_task,"ax",%progbits
 261              		.align	1
 262              		.global	__destory_task
 263              		.syntax unified
 264              		.thumb
 265              		.thumb_func
 267              	__destory_task:
 268              	.LVL24:
 269              	.LFB285:
  50:./kernel/sched/task.c **** 
  51:./kernel/sched/task.c **** void __destory_task(struct task_struct *t) 
  52:./kernel/sched/task.c **** {
 270              		.loc 1 52 1 is_stmt 1 view -0
 271              		.cfi_startproc
 272              		@ args = 0, pretend = 0, frame = 0
 273              		@ frame_needed = 0, uses_anonymous_args = 0
  53:./kernel/sched/task.c ****     if(t == NULL) return;
 274              		.loc 1 53 5 view .LVU65
 275              		.loc 1 53 7 is_stmt 0 view .LVU66
 276 0000 18B1     		cbz	r0, .L20
  52:./kernel/sched/task.c ****     if(t == NULL) return;
 277              		.loc 1 52 1 view .LVU67
 278 0002 08B5     		push	{r3, lr}
 279              	.LCFI2:
 280              		.cfi_def_cfa_offset 8
 281              		.cfi_offset 3, -8
 282              		.cfi_offset 14, -4
  54:./kernel/sched/task.c ****     kfree(t);
 283              		.loc 1 54 5 is_stmt 1 view .LVU68
 284              	.LVL25:
 285              	.LBB10:
 286              	.LBI10:
ARM GAS  /tmp/cc6nMSng.s 			page 14


 381:./include/linux/slab.h **** }
 382:./include/linux/slab.h **** 
 383:./include/linux/slab.h **** static void inline kfree(const void *ptr){
 287              		.loc 3 383 20 view .LVU69
 288              	.LBB11:
 384:./include/linux/slab.h **** 	__sfree__((void*)ptr);
 289              		.loc 3 384 2 view .LVU70
 290 0004 FFF7FEFF 		bl	__sfree__
 291              	.LVL26:
 292              		.loc 3 384 2 is_stmt 0 view .LVU71
 293              	.LBE11:
 294              	.LBE10:
  55:./kernel/sched/task.c **** }
 295              		.loc 1 55 1 view .LVU72
 296 0008 08BD     		pop	{r3, pc}
 297              	.LVL27:
 298              	.L20:
 299              	.LCFI3:
 300              		.cfi_def_cfa_offset 0
 301              		.cfi_restore 3
 302              		.cfi_restore 14
 303              		.loc 1 55 1 view .LVU73
 304 000a 7047     		bx	lr
 305              		.cfi_endproc
 306              	.LFE285:
 308              		.section	.text.__register_task,"ax",%progbits
 309              		.align	1
 310              		.global	__register_task
 311              		.syntax unified
 312              		.thumb
 313              		.thumb_func
 315              	__register_task:
 316              	.LVL28:
 317              	.LFB286:
  56:./kernel/sched/task.c **** 
  57:./kernel/sched/task.c **** 
  58:./kernel/sched/task.c **** int __register_task(struct task_struct* new_task ,struct scheduler* scheduler){
 318              		.loc 1 58 79 is_stmt 1 view -0
 319              		.cfi_startproc
 320              		@ args = 0, pretend = 0, frame = 0
 321              		@ frame_needed = 0, uses_anonymous_args = 0
 322              		.loc 1 58 79 is_stmt 0 view .LVU75
 323 0000 08B5     		push	{r3, lr}
 324              	.LCFI4:
 325              		.cfi_def_cfa_offset 8
 326              		.cfi_offset 3, -8
 327              		.cfi_offset 14, -4
  59:./kernel/sched/task.c ****    return scheduler->t_pop->add_task(new_task,scheduler);
 328              		.loc 1 59 4 is_stmt 1 view .LVU76
 329              		.loc 1 59 20 is_stmt 0 view .LVU77
 330 0002 8B68     		ldr	r3, [r1, #8]
 331              		.loc 1 59 27 view .LVU78
 332 0004 5B68     		ldr	r3, [r3, #4]
 333              		.loc 1 59 11 view .LVU79
 334 0006 9847     		blx	r3
 335              	.LVL29:
  60:./kernel/sched/task.c **** }
ARM GAS  /tmp/cc6nMSng.s 			page 15


 336              		.loc 1 60 1 view .LVU80
 337 0008 08BD     		pop	{r3, pc}
 338              		.cfi_endproc
 339              	.LFE286:
 341              		.section	.rodata.__default_Task_return_function.str1.4,"aMS",%progbits,1
 342              		.align	2
 343              	.LC2:
 344 0000 7461736B 		.ascii	"task :%s has return\012\000"
 344      203A2573 
 344      20686173 
 344      20726574 
 344      75726E0A 
 345              		.section	.text.__default_Task_return_function,"ax",%progbits
 346              		.align	1
 347              		.global	__default_Task_return_function
 348              		.syntax unified
 349              		.thumb
 350              		.thumb_func
 352              	__default_Task_return_function:
 353              	.LFB287:
  61:./kernel/sched/task.c **** 
  62:./kernel/sched/task.c **** void __default_Task_return_function(void){
 354              		.loc 1 62 42 is_stmt 1 view -0
 355              		.cfi_startproc
 356              		@ args = 0, pretend = 0, frame = 0
 357              		@ frame_needed = 0, uses_anonymous_args = 0
 358 0000 10B5     		push	{r4, lr}
 359              	.LCFI5:
 360              		.cfi_def_cfa_offset 8
 361              		.cfi_offset 4, -8
 362              		.cfi_offset 14, -4
  63:./kernel/sched/task.c ****     struct task_struct* cutrrent_task = get_current_task();
 363              		.loc 1 63 5 view .LVU82
 364              		.loc 1 63 41 is_stmt 0 view .LVU83
 365 0002 FFF7FEFF 		bl	get_current_task
 366              	.LVL30:
 367 0006 0446     		mov	r4, r0
 368              	.LVL31:
  64:./kernel/sched/task.c ****     pr_info("task :%s has return\n" ,cutrrent_task->task_name);
 369              		.loc 1 64 5 is_stmt 1 view .LVU84
 370 0008 00F10801 		add	r1, r0, #8
 371 000c 0648     		ldr	r0, .L28
 372              	.LVL32:
 373              		.loc 1 64 5 is_stmt 0 view .LVU85
 374 000e FFF7FEFF 		bl	printk
 375              	.LVL33:
  65:./kernel/sched/task.c ****     cutrrent_task->state = TASK_DEAD;
 376              		.loc 1 65 5 is_stmt 1 view .LVU86
 377              		.loc 1 65 26 is_stmt 0 view .LVU87
 378 0012 0623     		movs	r3, #6
 379 0014 84F85C30 		strb	r3, [r4, #92]
 380              	.L26:
  66:./kernel/sched/task.c ****     while (1)
 381              		.loc 1 66 5 is_stmt 1 view .LVU88
  67:./kernel/sched/task.c ****     {
  68:./kernel/sched/task.c ****         __delay(10);
 382              		.loc 1 68 9 view .LVU89
ARM GAS  /tmp/cc6nMSng.s 			page 16


 383 0018 0A20     		movs	r0, #10
 384 001a FFF7FEFF 		bl	__delay
 385              	.LVL34:
  69:./kernel/sched/task.c ****         cutrrent_task->state = TASK_DEAD;
 386              		.loc 1 69 9 discriminator 1 view .LVU90
 387              		.loc 1 69 30 is_stmt 0 discriminator 1 view .LVU91
 388 001e 0623     		movs	r3, #6
 389 0020 84F85C30 		strb	r3, [r4, #92]
  66:./kernel/sched/task.c ****     while (1)
 390              		.loc 1 66 11 is_stmt 1 view .LVU92
 391 0024 F8E7     		b	.L26
 392              	.L29:
 393 0026 00BF     		.align	2
 394              	.L28:
 395 0028 00000000 		.word	.LC2
 396              		.cfi_endproc
 397              	.LFE287:
 399              		.section	.rodata.task_run.str1.4,"aMS",%progbits,1
 400              		.align	2
 401              	.LC3:
 402 0000 63707520 		.ascii	"cpu number err\000"
 402      6E756D62 
 402      65722065 
 402      727200
 403              		.section	.text.task_run,"ax",%progbits
 404              		.align	1
 405              		.global	task_run
 406              		.syntax unified
 407              		.thumb
 408              		.thumb_func
 410              	task_run:
 411              	.LVL35:
 412              	.LFB288:
  70:./kernel/sched/task.c ****     }
  71:./kernel/sched/task.c **** } 
  72:./kernel/sched/task.c **** 
  73:./kernel/sched/task.c **** 
  74:./kernel/sched/task.c **** struct task_struct* task_run(       
  75:./kernel/sched/task.c **** int (*entry)(void*), 
  76:./kernel/sched/task.c **** int stack_size,
  77:./kernel/sched/task.c **** void *argv,
  78:./kernel/sched/task.c **** int priority,
  79:./kernel/sched/task.c **** char *name,
  80:./kernel/sched/task.c **** uint32_t core_id)
  81:./kernel/sched/task.c **** {
 413              		.loc 1 81 1 view -0
 414              		.cfi_startproc
 415              		@ args = 8, pretend = 0, frame = 0
 416              		@ frame_needed = 0, uses_anonymous_args = 0
 417              		.loc 1 81 1 is_stmt 0 view .LVU94
 418 0000 2DE9F041 		push	{r4, r5, r6, r7, r8, lr}
 419              	.LCFI6:
 420              		.cfi_def_cfa_offset 24
 421              		.cfi_offset 4, -24
 422              		.cfi_offset 5, -20
 423              		.cfi_offset 6, -16
 424              		.cfi_offset 7, -12
ARM GAS  /tmp/cc6nMSng.s 			page 17


 425              		.cfi_offset 8, -8
 426              		.cfi_offset 14, -4
 427 0004 82B0     		sub	sp, sp, #8
 428              	.LCFI7:
 429              		.cfi_def_cfa_offset 32
 430 0006 0746     		mov	r7, r0
 431 0008 0E46     		mov	r6, r1
 432 000a 1446     		mov	r4, r2
 433 000c 1D46     		mov	r5, r3
  82:./kernel/sched/task.c ****     struct scheduler * schedule = 
 434              		.loc 1 82 5 is_stmt 1 view .LVU95
  83:./kernel/sched/task.c ****     get_scheduler_by_cpu_core_id(core_id);
 435              		.loc 1 83 5 is_stmt 0 view .LVU96
 436 000e 0998     		ldr	r0, [sp, #36]
 437              	.LVL36:
 438              		.loc 1 83 5 view .LVU97
 439 0010 FFF7FEFF 		bl	get_scheduler_by_cpu_core_id
 440              	.LVL37:
  84:./kernel/sched/task.c ****     if(schedule == NULL){
 441              		.loc 1 84 5 is_stmt 1 view .LVU98
 442              		.loc 1 84 7 is_stmt 0 view .LVU99
 443 0014 8046     		mov	r8, r0
 444 0016 A0B1     		cbz	r0, .L35
  85:./kernel/sched/task.c ****         pr_err("cpu number err");
  86:./kernel/sched/task.c ****         return NULL;
  87:./kernel/sched/task.c ****     }
  88:./kernel/sched/task.c ****     struct task_struct* task =
 445              		.loc 1 88 5 is_stmt 1 view .LVU100
  89:./kernel/sched/task.c ****     __new_task_create(entry,stack_size,argv,priority,name);
 446              		.loc 1 89 5 is_stmt 0 view .LVU101
 447 0018 089B     		ldr	r3, [sp, #32]
 448 001a 0093     		str	r3, [sp]
 449 001c 2B46     		mov	r3, r5
 450 001e 2246     		mov	r2, r4
 451 0020 3146     		mov	r1, r6
 452 0022 3846     		mov	r0, r7
 453              	.LVL38:
 454              		.loc 1 89 5 view .LVU102
 455 0024 FFF7FEFF 		bl	__new_task_create
 456              	.LVL39:
 457 0028 0446     		mov	r4, r0
 458              	.LVL40:
  90:./kernel/sched/task.c ****     if(IS_ERR(task)){
 459              		.loc 1 90 5 is_stmt 1 view .LVU103
 460              	.LBB12:
 461              	.LBI12:
 462              		.file 4 "./include/linux/err.h"
   1:./include/linux/err.h **** /* SPDX-License-Identifier: GPL-2.0 */
   2:./include/linux/err.h **** #ifndef _LINUX_ERR_H
   3:./include/linux/err.h **** #define _LINUX_ERR_H
   4:./include/linux/err.h **** 
   5:./include/linux/err.h **** #include <linux/compiler_attributes.h>
   6:./include/linux/err.h **** #include <linux/compiler.h>
   7:./include/linux/err.h **** #include <linux/types.h>
   8:./include/linux/err.h **** 
   9:./include/linux/err.h **** #include <asm/errno.h>
  10:./include/linux/err.h **** 
ARM GAS  /tmp/cc6nMSng.s 			page 18


  11:./include/linux/err.h **** /*
  12:./include/linux/err.h ****  * Kernel pointers have redundant information, so we can use a
  13:./include/linux/err.h ****  * scheme where we can return either an error code or a normal
  14:./include/linux/err.h ****  * pointer with the same return value.
  15:./include/linux/err.h ****  *
  16:./include/linux/err.h ****  * This should be a per-architecture thing, to allow different
  17:./include/linux/err.h ****  * error and pointer decisions.
  18:./include/linux/err.h ****  */
  19:./include/linux/err.h **** #define MAX_ERRNO	4095
  20:./include/linux/err.h **** 
  21:./include/linux/err.h **** #ifndef __ASSEMBLY__
  22:./include/linux/err.h **** 
  23:./include/linux/err.h **** /**
  24:./include/linux/err.h ****  * IS_ERR_VALUE - Detect an error pointer.
  25:./include/linux/err.h ****  * @x: The pointer to check.
  26:./include/linux/err.h ****  *
  27:./include/linux/err.h ****  * Like IS_ERR(), but does not generate a compiler warning if result is unused.
  28:./include/linux/err.h ****  */
  29:./include/linux/err.h **** 
  30:./include/linux/err.h **** #ifndef unlikely
  31:./include/linux/err.h **** #  define unlikely(x) __builtin_expect(!!(x), 0)
  32:./include/linux/err.h **** #endif
  33:./include/linux/err.h **** 
  34:./include/linux/err.h **** #ifndef likely
  35:./include/linux/err.h **** #  define likely(x) __builtin_expect(!!(x), 1)
  36:./include/linux/err.h **** #endif
  37:./include/linux/err.h **** 
  38:./include/linux/err.h **** #define IS_ERR_VALUE(x) unlikely((unsigned long)(void *)(x) >= (unsigned long)-MAX_ERRNO)
  39:./include/linux/err.h **** 
  40:./include/linux/err.h **** /**
  41:./include/linux/err.h ****  * ERR_PTR - Create an error pointer.
  42:./include/linux/err.h ****  * @error: A negative error code.
  43:./include/linux/err.h ****  *
  44:./include/linux/err.h ****  * Encodes @error into a pointer value. Users should consider the result
  45:./include/linux/err.h ****  * opaque and not assume anything about how the error is encoded.
  46:./include/linux/err.h ****  *
  47:./include/linux/err.h ****  * Return: A pointer with @error encoded within its value.
  48:./include/linux/err.h ****  */
  49:./include/linux/err.h **** static inline void * __must_check ERR_PTR(long error)
  50:./include/linux/err.h **** {
  51:./include/linux/err.h **** 	return (void *) error;
  52:./include/linux/err.h **** }
  53:./include/linux/err.h **** 
  54:./include/linux/err.h **** /* Return the pointer in the percpu address space. */
  55:./include/linux/err.h **** #define ERR_PTR_PCPU(error) ((void __percpu *)(unsigned long)ERR_PTR(error))
  56:./include/linux/err.h **** 
  57:./include/linux/err.h **** /**
  58:./include/linux/err.h ****  * PTR_ERR - Extract the error code from an error pointer.
  59:./include/linux/err.h ****  * @ptr: An error pointer.
  60:./include/linux/err.h ****  * Return: The error code within @ptr.
  61:./include/linux/err.h ****  */
  62:./include/linux/err.h **** static inline long __must_check PTR_ERR(__force const void *ptr)
  63:./include/linux/err.h **** {
  64:./include/linux/err.h **** 	return (long) ptr;
  65:./include/linux/err.h **** }
  66:./include/linux/err.h **** 
  67:./include/linux/err.h **** /* Read an error pointer from the percpu address space. */
ARM GAS  /tmp/cc6nMSng.s 			page 19


  68:./include/linux/err.h **** #define PTR_ERR_PCPU(ptr) (PTR_ERR((const void *)(__force const unsigned long)(ptr)))
  69:./include/linux/err.h **** 
  70:./include/linux/err.h **** /**
  71:./include/linux/err.h ****  * IS_ERR - Detect an error pointer.
  72:./include/linux/err.h ****  * @ptr: The pointer to check.
  73:./include/linux/err.h ****  * Return: true if @ptr is an error pointer, false otherwise.
  74:./include/linux/err.h ****  */
  75:./include/linux/err.h **** static inline bool __must_check IS_ERR(__force const void *ptr)
 463              		.loc 4 75 33 view .LVU104
 464              	.LBB13:
  76:./include/linux/err.h **** {
  77:./include/linux/err.h **** 	return IS_ERR_VALUE((unsigned long)ptr);
 465              		.loc 4 77 2 view .LVU105
 466              		.loc 4 77 2 is_stmt 0 view .LVU106
 467              	.LBE13:
 468              	.LBE12:
 469              		.loc 1 90 7 discriminator 1 view .LVU107
 470 002a 10F5805F 		cmn	r0, #4096
 471 002e 12D8     		bhi	.L33
  91:./kernel/sched/task.c ****         return NULL;   
  92:./kernel/sched/task.c ****     }
  93:./kernel/sched/task.c ****     if( __register_task(task,schedule) < 0)
 472              		.loc 1 93 5 is_stmt 1 view .LVU108
 473              		.loc 1 93 9 is_stmt 0 view .LVU109
 474 0030 4146     		mov	r1, r8
 475 0032 FFF7FEFF 		bl	__register_task
 476              	.LVL41:
 477              		.loc 1 93 7 discriminator 1 view .LVU110
 478 0036 0028     		cmp	r0, #0
 479 0038 08DB     		blt	.L36
 480              	.LVL42:
 481              	.L30:
  94:./kernel/sched/task.c ****     {
  95:./kernel/sched/task.c ****         __destory_task(task);
  96:./kernel/sched/task.c ****         return NULL;
  97:./kernel/sched/task.c ****     }
  98:./kernel/sched/task.c ****     return task;
  99:./kernel/sched/task.c **** }
 482              		.loc 1 99 1 view .LVU111
 483 003a 2046     		mov	r0, r4
 484 003c 02B0     		add	sp, sp, #8
 485              	.LCFI8:
 486              		.cfi_remember_state
 487              		.cfi_def_cfa_offset 24
 488              		@ sp needed
 489 003e BDE8F081 		pop	{r4, r5, r6, r7, r8, pc}
 490              	.LVL43:
 491              	.L35:
 492              	.LCFI9:
 493              		.cfi_restore_state
  85:./kernel/sched/task.c ****         return NULL;
 494              		.loc 1 85 9 is_stmt 1 view .LVU112
 495 0042 0648     		ldr	r0, .L37
 496              	.LVL44:
  85:./kernel/sched/task.c ****         return NULL;
 497              		.loc 1 85 9 is_stmt 0 view .LVU113
 498 0044 FFF7FEFF 		bl	printk
ARM GAS  /tmp/cc6nMSng.s 			page 20


 499              	.LVL45:
  86:./kernel/sched/task.c ****     }
 500              		.loc 1 86 9 is_stmt 1 view .LVU114
  86:./kernel/sched/task.c ****     }
 501              		.loc 1 86 16 is_stmt 0 view .LVU115
 502 0048 4446     		mov	r4, r8
 503              	.LVL46:
  86:./kernel/sched/task.c ****     }
 504              		.loc 1 86 16 view .LVU116
 505 004a F6E7     		b	.L30
 506              	.LVL47:
 507              	.L36:
  95:./kernel/sched/task.c ****         return NULL;
 508              		.loc 1 95 9 is_stmt 1 view .LVU117
 509 004c 2046     		mov	r0, r4
 510 004e FFF7FEFF 		bl	__destory_task
 511              	.LVL48:
  96:./kernel/sched/task.c ****     }
 512              		.loc 1 96 9 view .LVU118
  96:./kernel/sched/task.c ****     }
 513              		.loc 1 96 16 is_stmt 0 view .LVU119
 514 0052 0024     		movs	r4, #0
 515              	.LVL49:
  96:./kernel/sched/task.c ****     }
 516              		.loc 1 96 16 view .LVU120
 517 0054 F1E7     		b	.L30
 518              	.LVL50:
 519              	.L33:
  91:./kernel/sched/task.c ****     }
 520              		.loc 1 91 16 view .LVU121
 521 0056 0024     		movs	r4, #0
 522 0058 EFE7     		b	.L30
 523              	.L38:
 524 005a 00BF     		.align	2
 525              	.L37:
 526 005c 00000000 		.word	.LC3
 527              		.cfi_endproc
 528              	.LFE288:
 530              		.section	.data.id_count,"aw"
 531              		.align	2
 534              	id_count:
 535 0000 09000000 		.word	9
 536              		.text
 537              	.Letext0:
 538              		.file 5 "./include/asm-generic/int-l64.h"
 539              		.file 6 "./include/asm-generic/posix_types.h"
 540              		.file 7 "./include/linux/types.h"
 541              		.file 8 "./include/linux/time64.h"
 542              		.file 9 "./arch/arm_m/include/asm/sched.h"
 543              		.file 10 "./include/linux/sched.h"
 544              		.file 11 "./arch/arm_m/include/asm/spinlock.h"
 545              		.file 12 "./include/linux/spinlock_types_raw.h"
 546              		.file 13 "./include/linux/spinlock_types.h"
 547              		.file 14 "./include/linux/mutex.h"
 548              		.file 15 "./include/linux/error.h"
 549              		.file 16 "./arch/arm_m/include/asm/string.h"
 550              		.file 17 "./include/linux/string.h"
ARM GAS  /tmp/cc6nMSng.s 			page 21


 551              		.file 18 "./include/linux/printk.h"
 552              		.file 19 "./include/linux/gfp_types.h"
ARM GAS  /tmp/cc6nMSng.s 			page 22


DEFINED SYMBOLS
                            *ABS*:00000000 task.c
     /tmp/cc6nMSng.s:21     .text.init_task_context:00000000 $t
     /tmp/cc6nMSng.s:26     .text.init_task_context:00000000 init_task_context
     /tmp/cc6nMSng.s:49     .rodata.__new_task_create.str1.4:00000000 $d
     /tmp/cc6nMSng.s:56     .text.__new_task_create:00000000 $t
     /tmp/cc6nMSng.s:62     .text.__new_task_create:00000000 __new_task_create
     /tmp/cc6nMSng.s:254    .text.__new_task_create:000000c8 $d
     /tmp/cc6nMSng.s:534    .data.id_count:00000000 id_count
     /tmp/cc6nMSng.s:261    .text.__destory_task:00000000 $t
     /tmp/cc6nMSng.s:267    .text.__destory_task:00000000 __destory_task
     /tmp/cc6nMSng.s:309    .text.__register_task:00000000 $t
     /tmp/cc6nMSng.s:315    .text.__register_task:00000000 __register_task
     /tmp/cc6nMSng.s:342    .rodata.__default_Task_return_function.str1.4:00000000 $d
     /tmp/cc6nMSng.s:346    .text.__default_Task_return_function:00000000 $t
     /tmp/cc6nMSng.s:352    .text.__default_Task_return_function:00000000 __default_Task_return_function
     /tmp/cc6nMSng.s:395    .text.__default_Task_return_function:00000028 $d
     /tmp/cc6nMSng.s:400    .rodata.task_run.str1.4:00000000 $d
     /tmp/cc6nMSng.s:404    .text.task_run:00000000 $t
     /tmp/cc6nMSng.s:410    .text.task_run:00000000 task_run
     /tmp/cc6nMSng.s:526    .text.task_run:0000005c $d
     /tmp/cc6nMSng.s:531    .data.id_count:00000000 $d

UNDEFINED SYMBOLS
__init_Taskcontext
__smalloc__
strlen
strcpy
printk
__sfree__
get_current_task
__delay
get_scheduler_by_cpu_core_id
