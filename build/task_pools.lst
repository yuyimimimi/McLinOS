ARM GAS  /tmp/ccJeHFgp.s 			page 1


   1              		.cpu cortex-m4
   2              		.arch armv7e-m
   3              		.fpu fpv4-sp-d16
   4              		.eabi_attribute 27, 1
   5              		.eabi_attribute 28, 1
   6              		.eabi_attribute 20, 1
   7              		.eabi_attribute 21, 1
   8              		.eabi_attribute 23, 3
   9              		.eabi_attribute 24, 1
  10              		.eabi_attribute 25, 1
  11              		.eabi_attribute 26, 1
  12              		.eabi_attribute 30, 1
  13              		.eabi_attribute 34, 1
  14              		.eabi_attribute 18, 4
  15              		.file	"task_pools.c"
  16              		.text
  17              	.Ltext0:
  18              		.cfi_sections	.debug_frame
  19              		.file 1 "/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c"
  20              		.section	.rodata.register_task_pool.str1.4,"aMS",%progbits,1
  21              		.align	2
  22              	.LC0:
  23 0000 7461736B 		.ascii	"task pool %s already registered\012\000"
  23      20706F6F 
  23      6C202573 
  23      20616C72 
  23      65616479 
  24 0021 000000   		.align	2
  25              	.LC1:
  26 0024 52656769 		.ascii	"Registered task pool: %s\012\000"
  26      73746572 
  26      65642074 
  26      61736B20 
  26      706F6F6C 
  27              		.section	.text.register_task_pool,"ax",%progbits
  28              		.align	1
  29              		.global	register_task_pool
  30              		.syntax unified
  31              		.thumb
  32              		.thumb_func
  34              	register_task_pool:
  35              	.LVL0:
  36              	.LFB270:
   1:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c **** #include <linux/kernel.h> 
   2:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c **** #include <linux/list.h>
   3:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c **** #include <linux/slab.h>
   4:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c **** #include <linux/string.h>
   5:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c **** 
   6:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c **** static LIST_HEAD(task_pool_list);
   7:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c **** 
   8:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c **** int register_task_pool(struct task_pool_types *new_pool){
  37              		.loc 1 8 57 view -0
  38              		.cfi_startproc
  39              		@ args = 0, pretend = 0, frame = 0
  40              		@ frame_needed = 0, uses_anonymous_args = 0
  41              		.loc 1 8 57 is_stmt 0 view .LVU1
  42 0000 70B5     		push	{r4, r5, r6, lr}
ARM GAS  /tmp/ccJeHFgp.s 			page 2


  43              	.LCFI0:
  44              		.cfi_def_cfa_offset 16
  45              		.cfi_offset 4, -16
  46              		.cfi_offset 5, -12
  47              		.cfi_offset 6, -8
  48              		.cfi_offset 14, -4
  49 0002 0646     		mov	r6, r0
   9:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c ****     struct task_pool_types *entry;
  50              		.loc 1 9 5 is_stmt 1 view .LVU2
  10:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c ****     list_for_each_entry(entry, &task_pool_list, node) {
  51              		.loc 1 10 5 view .LVU3
  52              	.LBB47:
  53              		.loc 1 10 5 view .LVU4
  54 0004 104B     		ldr	r3, .L8
  55 0006 1C68     		ldr	r4, [r3]
  56              	.LVL1:
  57              		.loc 1 10 5 view .LVU5
  58              		.loc 1 10 5 view .LVU6
  59              		.loc 1 10 5 is_stmt 0 view .LVU7
  60              	.LBE47:
  61 0008 00E0     		b	.L2
  62              	.LVL2:
  63              	.L3:
  64              		.loc 1 10 5 is_stmt 1 discriminator 2 view .LVU8
  65              	.LBB48:
  66              		.loc 1 10 5 discriminator 2 view .LVU9
  67 000a 2468     		ldr	r4, [r4]
  68              	.LVL3:
  69              		.loc 1 10 5 discriminator 2 view .LVU10
  70              		.loc 1 10 5 discriminator 2 view .LVU11
  71              	.L2:
  72              		.loc 1 10 5 is_stmt 0 discriminator 2 view .LVU12
  73              	.LBE48:
  74              		.loc 1 10 5 is_stmt 1 discriminator 1 view .LVU13
  75 000c 0E4B     		ldr	r3, .L8
  76 000e 9C42     		cmp	r4, r3
  77 0010 0ED0     		beq	.L7
  11:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c ****         if (strcmp(entry->name, new_pool->name) == 0) {
  78              		.loc 1 11 9 view .LVU14
  79              		.loc 1 11 41 is_stmt 0 view .LVU15
  80 0012 B568     		ldr	r5, [r6, #8]
  81              		.loc 1 11 13 view .LVU16
  82 0014 2946     		mov	r1, r5
  83 0016 A068     		ldr	r0, [r4, #8]
  84 0018 FFF7FEFF 		bl	strcmp
  85              	.LVL4:
  86              		.loc 1 11 12 discriminator 1 view .LVU17
  87 001c 0028     		cmp	r0, #0
  88 001e F4D1     		bne	.L3
  12:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c ****             pr_warn("task pool %s already registered\n", new_pool->name);
  89              		.loc 1 12 13 is_stmt 1 view .LVU18
  90 0020 2A46     		mov	r2, r5
  91 0022 0A49     		ldr	r1, .L8+4
  92 0024 0420     		movs	r0, #4
  93 0026 FFF7FEFF 		bl	printk
  94              	.LVL5:
  13:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c ****             return -EEXIST;
ARM GAS  /tmp/ccJeHFgp.s 			page 3


  95              		.loc 1 13 13 view .LVU19
  96              		.loc 1 13 20 is_stmt 0 view .LVU20
  97 002a 6FF01000 		mvn	r0, #16
  98 002e 0AE0     		b	.L1
  99              	.L7:
  14:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c ****         }
  15:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c ****     }
  16:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c ****     list_add_tail(&new_pool->node, &task_pool_list);
 100              		.loc 1 16 5 is_stmt 1 view .LVU21
 101              	.LVL6:
 102              	.LBB49:
 103              	.LBI49:
 104              		.file 2 "/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h"
   1:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** /* SPDX-License-Identifier: GPL-2.0 */
   2:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** #ifndef _LINUX_LIST_H
   3:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** #define _LINUX_LIST_H
   4:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 
   5:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** #include <linux/container_of.h>
   6:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** #include <linux/types.h>
   7:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** #include <linux/stddef.h>
   8:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** #include <linux/poison.h>
   9:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** #include <linux/const.h>
  10:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 
  11:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** #include <asm/barrier.h>
  12:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** #include <linux/rwonce.h>
  13:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** /*
  14:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * Circular doubly linked list implementation.
  15:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  *
  16:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * Some of the internal functions ("__xxx") are useful when
  17:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * manipulating whole lists rather than single entries, as
  18:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * sometimes we already know the next/prev entries and we can
  19:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * generate better code by using them directly rather than
  20:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * using the generic single-entry routines.
  21:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  */
  22:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 
  23:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** #define LIST_HEAD_INIT(name) { &(name), &(name) }
  24:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 
  25:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** #define LIST_HEAD(name) \
  26:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	struct list_head name = LIST_HEAD_INIT(name)
  27:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 
  28:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** /**
  29:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * INIT_LIST_HEAD - Initialize a list_head structure
  30:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * @list: list_head structure to be initialized.
  31:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  *
  32:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * Initializes the list_head to point to itself.  If it is a list header,
  33:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * the result is an empty list.
  34:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  */
  35:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** static inline void INIT_LIST_HEAD(struct list_head *list)
  36:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** {
  37:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	WRITE_ONCE(list->next, list);
  38:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	WRITE_ONCE(list->prev, list);
  39:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** }
  40:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 
  41:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** #ifdef CONFIG_LIST_HARDENED
  42:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 
  43:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** #ifdef CONFIG_DEBUG_LIST
  44:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** # define __list_valid_slowpath
ARM GAS  /tmp/ccJeHFgp.s 			page 4


  45:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** #else
  46:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** # define __list_valid_slowpath __cold __preserve_most
  47:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** #endif
  48:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 
  49:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** /*
  50:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * Performs the full set of list corruption checks before __list_add().
  51:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * On list corruption reports a warning, and returns false.
  52:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  */
  53:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** extern bool __list_valid_slowpath __list_add_valid_or_report(struct list_head *new,
  54:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 							     struct list_head *prev,
  55:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 							     struct list_head *next);
  56:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 
  57:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** /*
  58:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * Performs list corruption checks before __list_add(). Returns false if a
  59:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * corruption is detected, true otherwise.
  60:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  *
  61:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * With CONFIG_LIST_HARDENED only, performs minimal list integrity checking
  62:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * inline to catch non-faulting corruptions, and only if a corruption is
  63:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * detected calls the reporting function __list_add_valid_or_report().
  64:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  */
  65:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** static __always_inline bool __list_add_valid(struct list_head *new,
  66:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 					     struct list_head *prev,
  67:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 					     struct list_head *next)
  68:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** {
  69:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	bool ret = true;
  70:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 
  71:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	if (!IS_ENABLED(CONFIG_DEBUG_LIST)) {
  72:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 		/*
  73:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 		 * With the hardening version, elide checking if next and prev
  74:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 		 * are NULL, since the immediate dereference of them below would
  75:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 		 * result in a fault if NULL.
  76:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 		 *
  77:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 		 * With the reduced set of checks, we can afford to inline the
  78:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 		 * checks, which also gives the compiler a chance to elide some
  79:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 		 * of them completely if they can be proven at compile-time. If
  80:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 		 * one of the pre-conditions does not hold, the slow-path will
  81:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 		 * show a report which pre-condition failed.
  82:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 		 */
  83:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 		if (likely(next->prev == prev && prev->next == next && new != prev && new != next))
  84:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 			return true;
  85:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 		ret = false;
  86:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	}
  87:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 
  88:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	ret &= __list_add_valid_or_report(new, prev, next);
  89:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	return ret;
  90:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** }
  91:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 
  92:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** /*
  93:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * Performs the full set of list corruption checks before __list_del_entry().
  94:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * On list corruption reports a warning, and returns false.
  95:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  */
  96:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** extern bool __list_valid_slowpath __list_del_entry_valid_or_report(struct list_head *entry);
  97:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 
  98:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** /*
  99:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * Performs list corruption checks before __list_del_entry(). Returns false if a
 100:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * corruption is detected, true otherwise.
 101:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  *
ARM GAS  /tmp/ccJeHFgp.s 			page 5


 102:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * With CONFIG_LIST_HARDENED only, performs minimal list integrity checking
 103:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * inline to catch non-faulting corruptions, and only if a corruption is
 104:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * detected calls the reporting function __list_del_entry_valid_or_report().
 105:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  */
 106:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** static __always_inline bool __list_del_entry_valid(struct list_head *entry)
 107:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** {
 108:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	bool ret = true;
 109:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 
 110:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	if (!IS_ENABLED(CONFIG_DEBUG_LIST)) {
 111:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 		struct list_head *prev = entry->prev;
 112:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 		struct list_head *next = entry->next;
 113:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 
 114:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 		/*
 115:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 		 * With the hardening version, elide checking if next and prev
 116:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 		 * are NULL, LIST_POISON1 or LIST_POISON2, since the immediate
 117:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 		 * dereference of them below would result in a fault.
 118:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 		 */
 119:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 		if (likely(prev->next == entry && next->prev == entry))
 120:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 			return true;
 121:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 		ret = false;
 122:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	}
 123:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 
 124:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	ret &= __list_del_entry_valid_or_report(entry);
 125:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	return ret;
 126:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** }
 127:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** #else
 128:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** static inline bool __list_add_valid(struct list_head *new,
 129:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 				struct list_head *prev,
 130:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 				struct list_head *next)
 131:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** {
 132:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	return true;
 133:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** }
 134:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** static inline bool __list_del_entry_valid(struct list_head *entry)
 135:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** {
 136:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	return true;
 137:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** }
 138:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** #endif
 139:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 
 140:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** /*
 141:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * Insert a new entry between two known consecutive entries.
 142:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  *
 143:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * This is only for internal list manipulation where we know
 144:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * the prev/next entries already!
 145:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  */
 146:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** static inline void __list_add(struct list_head *new,
 147:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 			      struct list_head *prev,
 148:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 			      struct list_head *next)
 149:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** {
 150:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	if (!__list_add_valid(new, prev, next))
 151:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 		return;
 152:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 
 153:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	next->prev = new;
 154:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	new->next = next;
 155:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	new->prev = prev;
 156:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	WRITE_ONCE(prev->next, new);
 157:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** }
 158:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 
ARM GAS  /tmp/ccJeHFgp.s 			page 6


 159:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** /**
 160:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * list_add - add a new entry
 161:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * @new: new entry to be added
 162:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * @head: list head to add it after
 163:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  *
 164:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * Insert a new entry after the specified head.
 165:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * This is good for implementing stacks.
 166:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  */
 167:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** static inline void list_add(struct list_head *new, struct list_head *head)
 168:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** {
 169:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	__list_add(new, head, head->next);
 170:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** }
 171:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 
 172:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 
 173:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** /**
 174:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * list_add_tail - add a new entry
 175:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * @new: new entry to be added
 176:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * @head: list head to add it before
 177:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  *
 178:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * Insert a new entry before the specified head.
 179:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * This is useful for implementing queues.
 180:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  */
 181:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** static inline void list_add_tail(struct list_head *new, struct list_head *head)
 105              		.loc 2 181 20 view .LVU22
 106              	.LBB50:
 182:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** {
 183:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	__list_add(new, head->prev, head);
 107              		.loc 2 183 2 view .LVU23
 108 0030 5A68     		ldr	r2, [r3, #4]
 109              	.LVL7:
 110              	.LBB51:
 111              	.LBI51:
 146:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 			      struct list_head *prev,
 112              		.loc 2 146 20 view .LVU24
 113              	.LBB52:
 150:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 		return;
 114              		.loc 2 150 2 view .LVU25
 153:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	new->next = next;
 115              		.loc 2 153 2 view .LVU26
 153:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	new->next = next;
 116              		.loc 2 153 13 is_stmt 0 view .LVU27
 117 0032 5E60     		str	r6, [r3, #4]
 154:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	new->prev = prev;
 118              		.loc 2 154 2 is_stmt 1 view .LVU28
 154:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	new->prev = prev;
 119              		.loc 2 154 12 is_stmt 0 view .LVU29
 120 0034 3360     		str	r3, [r6]
 155:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	WRITE_ONCE(prev->next, new);
 121              		.loc 2 155 2 is_stmt 1 view .LVU30
 155:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	WRITE_ONCE(prev->next, new);
 122              		.loc 2 155 12 is_stmt 0 view .LVU31
 123 0036 7260     		str	r2, [r6, #4]
 156:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** }
 124              		.loc 2 156 2 is_stmt 1 view .LVU32
 156:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** }
 125              		.loc 2 156 2 view .LVU33
 126              	.LBB53:
ARM GAS  /tmp/ccJeHFgp.s 			page 7


 156:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** }
 127              		.loc 2 156 2 view .LVU34
 156:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** }
 128              		.loc 2 156 2 view .LVU35
 129              	.LBE53:
 156:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** }
 130              		.loc 2 156 2 discriminator 2 view .LVU36
 156:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** }
 131              		.loc 2 156 2 discriminator 2 view .LVU37
 156:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** }
 132              		.loc 2 156 2 discriminator 2 view .LVU38
 133 0038 1660     		str	r6, [r2]
 156:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** }
 134              		.loc 2 156 2 discriminator 3 view .LVU39
 156:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** }
 135              		.loc 2 156 2 discriminator 3 view .LVU40
 136              	.LVL8:
 156:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** }
 137              		.loc 2 156 2 is_stmt 0 discriminator 3 view .LVU41
 138              	.LBE52:
 139              	.LBE51:
 140              	.LBE50:
 141              	.LBE49:
  17:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c ****     pr_info("Registered task pool: %s\n", new_pool->name);
 142              		.loc 1 17 5 is_stmt 1 view .LVU42
 143 003a B268     		ldr	r2, [r6, #8]
 144 003c 0449     		ldr	r1, .L8+8
 145 003e 0620     		movs	r0, #6
 146 0040 FFF7FEFF 		bl	printk
 147              	.LVL9:
  18:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c ****     return 0;
 148              		.loc 1 18 5 view .LVU43
 149              		.loc 1 18 12 is_stmt 0 view .LVU44
 150 0044 0020     		movs	r0, #0
 151              	.L1:
  19:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c **** }
 152              		.loc 1 19 1 view .LVU45
 153 0046 70BD     		pop	{r4, r5, r6, pc}
 154              	.LVL10:
 155              	.L9:
 156              		.loc 1 19 1 view .LVU46
 157              		.align	2
 158              	.L8:
 159 0048 00000000 		.word	task_pool_list
 160 004c 00000000 		.word	.LC0
 161 0050 24000000 		.word	.LC1
 162              		.cfi_endproc
 163              	.LFE270:
 165              		.section	.text.find_task_pool,"ax",%progbits
 166              		.align	1
 167              		.global	find_task_pool
 168              		.syntax unified
 169              		.thumb
 170              		.thumb_func
 172              	find_task_pool:
 173              	.LVL11:
 174              	.LFB271:
ARM GAS  /tmp/ccJeHFgp.s 			page 8


  20:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c **** 
  21:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c **** struct task_pool_types *find_task_pool(const char *name){
 175              		.loc 1 21 57 is_stmt 1 view -0
 176              		.cfi_startproc
 177              		@ args = 0, pretend = 0, frame = 0
 178              		@ frame_needed = 0, uses_anonymous_args = 0
 179              		.loc 1 21 57 is_stmt 0 view .LVU48
 180 0000 38B5     		push	{r3, r4, r5, lr}
 181              	.LCFI1:
 182              		.cfi_def_cfa_offset 16
 183              		.cfi_offset 3, -16
 184              		.cfi_offset 4, -12
 185              		.cfi_offset 5, -8
 186              		.cfi_offset 14, -4
 187 0002 0546     		mov	r5, r0
  22:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c ****     struct task_pool_types *entry;
 188              		.loc 1 22 5 is_stmt 1 view .LVU49
  23:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c ****     list_for_each_entry(entry, &task_pool_list, node) {
 189              		.loc 1 23 5 view .LVU50
 190              	.LBB54:
 191              		.loc 1 23 5 view .LVU51
 192 0004 084B     		ldr	r3, .L17
 193 0006 1C68     		ldr	r4, [r3]
 194              	.LVL12:
 195              		.loc 1 23 5 view .LVU52
 196              		.loc 1 23 5 view .LVU53
 197              		.loc 1 23 5 is_stmt 0 view .LVU54
 198              	.LBE54:
 199 0008 00E0     		b	.L11
 200              	.LVL13:
 201              	.L16:
 202              		.loc 1 23 5 is_stmt 1 discriminator 2 view .LVU55
 203              	.LBB55:
 204              		.loc 1 23 5 discriminator 2 view .LVU56
 205 000a 2468     		ldr	r4, [r4]
 206              	.LVL14:
 207              		.loc 1 23 5 discriminator 2 view .LVU57
 208              		.loc 1 23 5 discriminator 2 view .LVU58
 209              	.L11:
 210              		.loc 1 23 5 is_stmt 0 discriminator 2 view .LVU59
 211              	.LBE55:
 212              		.loc 1 23 5 is_stmt 1 discriminator 1 view .LVU60
 213 000c 064B     		ldr	r3, .L17
 214 000e 9C42     		cmp	r4, r3
 215 0010 06D0     		beq	.L15
  24:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c ****         if (strcmp(entry->name, name) == 0)
 216              		.loc 1 24 9 view .LVU61
 217              		.loc 1 24 13 is_stmt 0 view .LVU62
 218 0012 2946     		mov	r1, r5
 219 0014 A068     		ldr	r0, [r4, #8]
 220 0016 FFF7FEFF 		bl	strcmp
 221              	.LVL15:
 222              		.loc 1 24 12 discriminator 1 view .LVU63
 223 001a 0028     		cmp	r0, #0
 224 001c F5D1     		bne	.L16
 225 001e 00E0     		b	.L10
 226              	.L15:
ARM GAS  /tmp/ccJeHFgp.s 			page 9


  25:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c ****             return entry;
  26:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c ****     }
  27:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c ****     return NULL; 
 227              		.loc 1 27 12 view .LVU64
 228 0020 0024     		movs	r4, #0
 229              	.LVL16:
 230              	.L10:
  28:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c **** }
 231              		.loc 1 28 1 view .LVU65
 232 0022 2046     		mov	r0, r4
 233 0024 38BD     		pop	{r3, r4, r5, pc}
 234              	.LVL17:
 235              	.L18:
 236              		.loc 1 28 1 view .LVU66
 237 0026 00BF     		.align	2
 238              	.L17:
 239 0028 00000000 		.word	task_pool_list
 240              		.cfi_endproc
 241              	.LFE271:
 243              		.section	.rodata.unregister_task_pool.str1.4,"aMS",%progbits,1
 244              		.align	2
 245              	.LC2:
 246 0000 556E7265 		.ascii	"Unregistered task pool: %s\012\000"
 246      67697374 
 246      65726564 
 246      20746173 
 246      6B20706F 
 247              		.section	.text.unregister_task_pool,"ax",%progbits
 248              		.align	1
 249              		.global	unregister_task_pool
 250              		.syntax unified
 251              		.thumb
 252              		.thumb_func
 254              	unregister_task_pool:
 255              	.LVL18:
 256              	.LFB272:
  29:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c **** 
  30:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c **** int unregister_task_pool(const char *name){
 257              		.loc 1 30 43 is_stmt 1 view -0
 258              		.cfi_startproc
 259              		@ args = 0, pretend = 0, frame = 0
 260              		@ frame_needed = 0, uses_anonymous_args = 0
 261              		.loc 1 30 43 is_stmt 0 view .LVU68
 262 0000 F8B5     		push	{r3, r4, r5, r6, r7, lr}
 263              	.LCFI2:
 264              		.cfi_def_cfa_offset 24
 265              		.cfi_offset 3, -24
 266              		.cfi_offset 4, -20
 267              		.cfi_offset 5, -16
 268              		.cfi_offset 6, -12
 269              		.cfi_offset 7, -8
 270              		.cfi_offset 14, -4
 271 0002 0646     		mov	r6, r0
  31:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c ****     struct task_pool_types *entry, *tmp;
 272              		.loc 1 31 5 is_stmt 1 view .LVU69
  32:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c ****     list_for_each_entry_safe(entry, tmp, &task_pool_list, node) {
 273              		.loc 1 32 5 view .LVU70
ARM GAS  /tmp/ccJeHFgp.s 			page 10


 274              	.LBB56:
 275              		.loc 1 32 5 view .LVU71
 276 0004 144B     		ldr	r3, .L26
 277 0006 1C68     		ldr	r4, [r3]
 278              	.LVL19:
 279              		.loc 1 32 5 view .LVU72
 280              		.loc 1 32 5 view .LVU73
 281              		.loc 1 32 5 is_stmt 0 view .LVU74
 282              	.LBE56:
 283              	.LBB57:
 284              		.loc 1 32 5 is_stmt 1 view .LVU75
 285 0008 2568     		ldr	r5, [r4]
 286              	.LVL20:
 287              		.loc 1 32 5 view .LVU76
 288              		.loc 1 32 5 view .LVU77
 289              		.loc 1 32 5 is_stmt 0 view .LVU78
 290              	.LBE57:
 291 000a 01E0     		b	.L20
 292              	.LVL21:
 293              	.L21:
 294              		.loc 1 32 5 is_stmt 1 discriminator 2 view .LVU79
 295              	.LBB58:
 296              		.loc 1 32 5 discriminator 2 view .LVU80
 297              		.loc 1 32 5 discriminator 2 view .LVU81
 298              		.loc 1 32 5 discriminator 2 view .LVU82
 299              		.loc 1 32 5 is_stmt 0 discriminator 2 view .LVU83
 300              	.LBE58:
 301 000c 2C46     		mov	r4, r5
 302 000e 2D68     		ldr	r5, [r5]
 303              	.LVL22:
 304              	.L20:
 305              		.loc 1 32 5 is_stmt 1 discriminator 1 view .LVU84
 306 0010 114B     		ldr	r3, .L26
 307 0012 9C42     		cmp	r4, r3
 308 0014 1CD0     		beq	.L25
  33:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c ****         if (strcmp(entry->name, name) == 0) {
 309              		.loc 1 33 9 view .LVU85
 310              		.loc 1 33 13 is_stmt 0 view .LVU86
 311 0016 3146     		mov	r1, r6
 312 0018 A068     		ldr	r0, [r4, #8]
 313 001a FFF7FEFF 		bl	strcmp
 314              	.LVL23:
 315              		.loc 1 33 12 discriminator 1 view .LVU87
 316 001e 0746     		mov	r7, r0
 317 0020 0028     		cmp	r0, #0
 318 0022 F3D1     		bne	.L21
  34:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c ****             list_del(&entry->node);
 319              		.loc 1 34 13 is_stmt 1 view .LVU88
 320              	.LVL24:
 321              	.LBB59:
 322              	.LBI59:
 184:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** }
 185:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 
 186:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** /*
 187:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * Delete a list entry by making the prev/next entries
 188:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * point to each other.
 189:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  *
ARM GAS  /tmp/ccJeHFgp.s 			page 11


 190:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * This is only for internal list manipulation where we know
 191:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * the prev/next entries already!
 192:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  */
 193:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** static inline void __list_del(struct list_head * prev, struct list_head * next)
 194:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** {
 195:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	next->prev = prev;
 196:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	WRITE_ONCE(prev->next, next);
 197:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** }
 198:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 
 199:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** /*
 200:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * Delete a list entry and clear the 'prev' pointer.
 201:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  *
 202:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * This is a special-purpose list clearing method used in the networking code
 203:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * for lists allocated as per-cpu, where we don't want to incur the extra
 204:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * WRITE_ONCE() overhead of a regular list_del_init(). The code that uses this
 205:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * needs to check the node 'prev' pointer instead of calling list_empty().
 206:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  */
 207:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** static inline void __list_del_clearprev(struct list_head *entry)
 208:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** {
 209:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	__list_del(entry->prev, entry->next);
 210:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	entry->prev = NULL;
 211:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** }
 212:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 
 213:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** static inline void __list_del_entry(struct list_head *entry)
 214:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** {
 215:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	if (!__list_del_entry_valid(entry))
 216:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 		return;
 217:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 
 218:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	__list_del(entry->prev, entry->next);
 219:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** }
 220:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 
 221:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** /**
 222:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * list_del - deletes entry from list.
 223:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * @entry: the element to delete from the list.
 224:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * Note: list_empty() on entry does not return true after this, the entry is
 225:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  * in an undefined state.
 226:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h ****  */
 227:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** static inline void list_del(struct list_head *entry)
 323              		.loc 2 227 20 view .LVU89
 324              	.LBB60:
 228:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** {
 229:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	__list_del_entry(entry);
 325              		.loc 2 229 2 view .LVU90
 326              	.LBB61:
 327              	.LBI61:
 213:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** {
 328              		.loc 2 213 20 view .LVU91
 329              	.LBB62:
 215:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 		return;
 330              		.loc 2 215 2 view .LVU92
 218:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** }
 331              		.loc 2 218 2 view .LVU93
 332 0024 6368     		ldr	r3, [r4, #4]
 333 0026 2268     		ldr	r2, [r4]
 334              	.LVL25:
 335              	.LBB63:
 336              	.LBI63:
ARM GAS  /tmp/ccJeHFgp.s 			page 12


 193:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** {
 337              		.loc 2 193 20 view .LVU94
 338              	.LBB64:
 195:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	WRITE_ONCE(prev->next, next);
 339              		.loc 2 195 2 view .LVU95
 195:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	WRITE_ONCE(prev->next, next);
 340              		.loc 2 195 13 is_stmt 0 view .LVU96
 341 0028 5360     		str	r3, [r2, #4]
 196:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** }
 342              		.loc 2 196 2 is_stmt 1 view .LVU97
 196:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** }
 343              		.loc 2 196 2 view .LVU98
 344              	.LBB65:
 196:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** }
 345              		.loc 2 196 2 view .LVU99
 196:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** }
 346              		.loc 2 196 2 view .LVU100
 347              	.LBE65:
 196:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** }
 348              		.loc 2 196 2 discriminator 2 view .LVU101
 196:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** }
 349              		.loc 2 196 2 discriminator 2 view .LVU102
 196:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** }
 350              		.loc 2 196 2 discriminator 2 view .LVU103
 351 002a 1A60     		str	r2, [r3]
 196:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** }
 352              		.loc 2 196 2 discriminator 2 view .LVU104
 196:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** }
 353              		.loc 2 196 2 discriminator 2 view .LVU105
 354              	.LVL26:
 196:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** }
 355              		.loc 2 196 2 is_stmt 0 discriminator 2 view .LVU106
 356              	.LBE64:
 357              	.LBE63:
 358              	.LBE62:
 359              	.LBE61:
 230:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	entry->next = LIST_POISON1;
 360              		.loc 2 230 2 is_stmt 1 view .LVU107
 361              		.loc 2 230 14 is_stmt 0 view .LVU108
 362 002c 4FF48073 		mov	r3, #256
 363 0030 2360     		str	r3, [r4]
 231:/mnt/c/Users/31740/Desktop/newcore/include/linux/list.h **** 	entry->prev = LIST_POISON2;
 364              		.loc 2 231 2 is_stmt 1 view .LVU109
 365              		.loc 2 231 14 is_stmt 0 view .LVU110
 366 0032 4FF49173 		mov	r3, #290
 367 0036 6360     		str	r3, [r4, #4]
 368              	.LVL27:
 369              		.loc 2 231 14 view .LVU111
 370              	.LBE60:
 371              	.LBE59:
  35:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c ****             pr_info("Unregistered task pool: %s\n", name);
 372              		.loc 1 35 13 is_stmt 1 view .LVU112
 373 0038 3246     		mov	r2, r6
 374 003a 0849     		ldr	r1, .L26+4
 375 003c 0620     		movs	r0, #6
 376 003e FFF7FEFF 		bl	printk
 377              	.LVL28:
ARM GAS  /tmp/ccJeHFgp.s 			page 13


  36:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c ****             kfree(entry->name);
 378              		.loc 1 36 13 view .LVU113
 379              	.LBB66:
 380              	.LBI66:
 381              		.file 3 "/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h"
   1:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* SPDX-License-Identifier: GPL-2.0 */
   2:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /*
   3:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Written by Mark Hemment, 1996 (markhe@nextd.demon.co.uk).
   4:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
   5:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * (C) SGI 2006, Christoph Lameter
   6:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * 	Cleaned up and restructured to ease the addition of alternative
   7:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * 	implementations of SLAB allocators.
   8:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * (C) Linux Foundation 2008-2013
   9:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *      Unified interface for all slab allocators
  10:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
  11:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
  12:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifndef _LINUX_SLAB_H
  13:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define	_LINUX_SLAB_H
  14:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
  15:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #include <linux/cache.h>
  16:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #include <linux/overflow.h>
  17:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #include <linux/types.h>
  18:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #include <linux/raid/pq.h>
  19:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #include <linux/gfp_types.h>
  20:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #include <linux/numa.h>
  21:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #include <linux/reciprocal_div.h>
  22:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #include <linux/spinlock.h>
  23:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
  24:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** enum _slab_flag_bits {
  25:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_CONSISTENCY_CHECKS,
  26:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_RED_ZONE,
  27:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_POISON,
  28:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_KMALLOC,
  29:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_HWCACHE_ALIGN,
  30:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_CACHE_DMA,
  31:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_CACHE_DMA32,
  32:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_STORE_USER,
  33:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_PANIC,
  34:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_TYPESAFE_BY_RCU,
  35:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_TRACE,
  36:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_DEBUG_OBJECTS
  37:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_DEBUG_OBJECTS,
  38:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
  39:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_NOLEAKTRACE,
  40:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_NO_MERGE,
  41:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_FAILSLAB
  42:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_FAILSLAB,
  43:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
  44:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_MEMCG
  45:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_ACCOUNT,
  46:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
  47:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_KASAN_GENERIC
  48:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_KASAN,
  49:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
  50:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_NO_USER_FLAGS,
  51:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_KFENCE
  52:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_SKIP_KFENCE,
ARM GAS  /tmp/ccJeHFgp.s 			page 14


  53:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
  54:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifndef CONFIG_SLUB_TINY
  55:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_RECLAIM_ACCOUNT,
  56:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
  57:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_OBJECT_POISON,
  58:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_CMPXCHG_DOUBLE,
  59:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_SLAB_OBJ_EXT
  60:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_NO_OBJ_EXT,
  61:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
  62:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_FLAGS_LAST_BIT
  63:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** };
  64:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
  65:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
  66:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
  67:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define __SLAB_FLAG_BIT(nr)	((slab_flags_t __force)(1U << (nr)))
  68:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define __SLAB_FLAG_UNUSED	((slab_flags_t __force)(0U))
  69:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
  70:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /*
  71:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Flags to pass to kmem_cache_create().
  72:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * The ones marked DEBUG need CONFIG_SLUB_DEBUG enabled, otherwise are no-op
  73:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
  74:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* DEBUG: Perform (expensive) checks on alloc/free */
  75:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_CONSISTENCY_CHECKS	__SLAB_FLAG_BIT(_SLAB_CONSISTENCY_CHECKS)
  76:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* DEBUG: Red zone objs in a cache */
  77:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_RED_ZONE		__SLAB_FLAG_BIT(_SLAB_RED_ZONE)
  78:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* DEBUG: Poison objects */
  79:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_POISON		__SLAB_FLAG_BIT(_SLAB_POISON)
  80:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* Indicate a kmalloc slab */
  81:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_KMALLOC		__SLAB_FLAG_BIT(_SLAB_KMALLOC)
  82:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /**
  83:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * define SLAB_HWCACHE_ALIGN - Align objects on cache line boundaries.
  84:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
  85:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Sufficiently large objects are aligned on cache line boundary. For object
  86:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * size smaller than a half of cache line size, the alignment is on the half of
  87:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * cache line size. In general, if object size is smaller than 1/2^n of cache
  88:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * line size, the alignment is adjusted to 1/2^n.
  89:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
  90:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * If explicit alignment is also requested by the respective
  91:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * &struct kmem_cache_args field, the greater of both is alignments is applied.
  92:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
  93:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_HWCACHE_ALIGN	__SLAB_FLAG_BIT(_SLAB_HWCACHE_ALIGN)
  94:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* Use GFP_DMA memory */
  95:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_CACHE_DMA		__SLAB_FLAG_BIT(_SLAB_CACHE_DMA)
  96:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* Use GFP_DMA32 memory */
  97:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_CACHE_DMA32	__SLAB_FLAG_BIT(_SLAB_CACHE_DMA32)
  98:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* DEBUG: Store the last owner for bug hunting */
  99:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_STORE_USER		__SLAB_FLAG_BIT(_SLAB_STORE_USER)
 100:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* Panic if kmem_cache_create() fails */
 101:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_PANIC		__SLAB_FLAG_BIT(_SLAB_PANIC)
 102:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /**
 103:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * define SLAB_TYPESAFE_BY_RCU - **WARNING** READ THIS!
 104:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 105:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * This delays freeing the SLAB page by a grace period, it does _NOT_
 106:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * delay object freeing. This means that if you do kmem_cache_free()
 107:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * that memory location is free to be reused at any time. Thus it may
 108:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * be possible to see another object there in the same RCU grace period.
 109:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
ARM GAS  /tmp/ccJeHFgp.s 			page 15


 110:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * This feature only ensures the memory location backing the object
 111:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * stays valid, the trick to using this is relying on an independent
 112:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * object validation pass. Something like:
 113:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 114:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * ::
 115:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 116:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *  begin:
 117:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *   rcu_read_lock();
 118:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *   obj = lockless_lookup(key);
 119:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *   if (obj) {
 120:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *     if (!try_get_ref(obj)) // might fail for free objects
 121:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *       rcu_read_unlock();
 122:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *       goto begin;
 123:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 124:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *     if (obj->key != key) { // not the object we expected
 125:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *       put_ref(obj);
 126:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *       rcu_read_unlock();
 127:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *       goto begin;
 128:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *     }
 129:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *   }
 130:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *  rcu_read_unlock();
 131:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 132:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * This is useful if we need to approach a kernel structure obliquely,
 133:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * from its address obtained without the usual locking. We can lock
 134:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * the structure to stabilize it and check it's still at the given address,
 135:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * only if we can be sure that the memory has not been meanwhile reused
 136:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * for some other kind of object (which our subsystem's lock might corrupt).
 137:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 138:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * rcu_read_lock before reading the address, then rcu_read_unlock after
 139:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * taking the spinlock within the structure expected at that address.
 140:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 141:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Note that it is not possible to acquire a lock within a structure
 142:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * allocated with SLAB_TYPESAFE_BY_RCU without first acquiring a reference
 143:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * as described above.  The reason is that SLAB_TYPESAFE_BY_RCU pages
 144:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * are not zeroed before being given to the slab, which means that any
 145:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * locks must be initialized after each and every kmem_struct_alloc().
 146:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Alternatively, make the ctor passed to kmem_cache_create() initialize
 147:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * the locks at page-allocation time, as is done in __i915_request_ctor(),
 148:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * sighand_ctor(), and anon_vma_ctor().  Such a ctor permits readers
 149:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * to safely acquire those ctor-initialized locks under rcu_read_lock()
 150:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * protection.
 151:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 152:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Note that SLAB_TYPESAFE_BY_RCU was originally named SLAB_DESTROY_BY_RCU.
 153:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
 154:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_TYPESAFE_BY_RCU	__SLAB_FLAG_BIT(_SLAB_TYPESAFE_BY_RCU)
 155:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* Trace allocations and frees */
 156:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_TRACE		__SLAB_FLAG_BIT(_SLAB_TRACE)
 157:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 158:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* Flag to prevent checks on free */
 159:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_DEBUG_OBJECTS
 160:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** # define SLAB_DEBUG_OBJECTS	__SLAB_FLAG_BIT(_SLAB_DEBUG_OBJECTS)
 161:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #else
 162:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** # define SLAB_DEBUG_OBJECTS	__SLAB_FLAG_UNUSED
 163:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
 164:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 165:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* Avoid kmemleak tracing */
 166:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_NOLEAKTRACE	__SLAB_FLAG_BIT(_SLAB_NOLEAKTRACE)
ARM GAS  /tmp/ccJeHFgp.s 			page 16


 167:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 168:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /*
 169:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Prevent merging with compatible kmem caches. This flag should be used
 170:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * cautiously. Valid use cases:
 171:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 172:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * - caches created for self-tests (e.g. kunit)
 173:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * - general caches created and used by a subsystem, only when a
 174:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *   (subsystem-specific) debug option is enabled
 175:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * - performance critical caches, should be very rare and consulted with slab
 176:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *   maintainers, and not used together with CONFIG_SLUB_TINY
 177:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
 178:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_NO_MERGE		__SLAB_FLAG_BIT(_SLAB_NO_MERGE)
 179:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 180:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* Fault injection mark */
 181:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_FAILSLAB
 182:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** # define SLAB_FAILSLAB		__SLAB_FLAG_BIT(_SLAB_FAILSLAB)
 183:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #else
 184:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** # define SLAB_FAILSLAB		__SLAB_FLAG_UNUSED
 185:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
 186:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /**
 187:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * define SLAB_ACCOUNT - Account allocations to memcg.
 188:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 189:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * All object allocations from this cache will be memcg accounted, regardless of
 190:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * __GFP_ACCOUNT being or not being passed to individual allocations.
 191:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
 192:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_MEMCG
 193:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** # define SLAB_ACCOUNT		__SLAB_FLAG_BIT(_SLAB_ACCOUNT)
 194:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #else
 195:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** # define SLAB_ACCOUNT		__SLAB_FLAG_UNUSED
 196:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
 197:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 198:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_KASAN_GENERIC
 199:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_KASAN		__SLAB_FLAG_BIT(_SLAB_KASAN)
 200:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #else
 201:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_KASAN		__SLAB_FLAG_UNUSED
 202:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
 203:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 204:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /*
 205:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Ignore user specified debugging flags.
 206:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Intended for caches created for self-tests so they have only flags
 207:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * specified in the code and other flags are ignored.
 208:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
 209:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_NO_USER_FLAGS	__SLAB_FLAG_BIT(_SLAB_NO_USER_FLAGS)
 210:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 211:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_KFENCE
 212:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_SKIP_KFENCE	__SLAB_FLAG_BIT(_SLAB_SKIP_KFENCE)
 213:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #else
 214:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_SKIP_KFENCE	__SLAB_FLAG_UNUSED
 215:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
 216:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 217:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* The following flags affect the page allocator grouping pages by mobility */
 218:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /**
 219:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * define SLAB_RECLAIM_ACCOUNT - Objects are reclaimable.
 220:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 221:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Use this flag for caches that have an associated shrinker. As a result, slab
 222:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * pages are allocated with __GFP_RECLAIMABLE, which affects grouping pages by
 223:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * mobility, and are accounted in SReclaimable counter in /proc/meminfo
ARM GAS  /tmp/ccJeHFgp.s 			page 17


 224:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
 225:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifndef CONFIG_SLUB_TINY
 226:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_RECLAIM_ACCOUNT	__SLAB_FLAG_BIT(_SLAB_RECLAIM_ACCOUNT)
 227:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #else
 228:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_RECLAIM_ACCOUNT	__SLAB_FLAG_UNUSED
 229:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
 230:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_TEMPORARY		SLAB_RECLAIM_ACCOUNT	/* Objects are short-lived */
 231:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 232:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* Slab created using create_boot_cache */
 233:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_SLAB_OBJ_EXT
 234:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_NO_OBJ_EXT		__SLAB_FLAG_BIT(_SLAB_NO_OBJ_EXT)
 235:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #else
 236:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_NO_OBJ_EXT		__SLAB_FLAG_UNUSED
 237:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
 238:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 239:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /*
 240:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * freeptr_t represents a SLUB freelist pointer, which might be encoded
 241:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * and not dereferenceable if CONFIG_SLAB_FREELIST_HARDENED is enabled.
 242:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
 243:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** typedef struct { unsigned long v; } freeptr_t;
 244:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 245:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /*
 246:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * ZERO_SIZE_PTR will be returned for zero sized kmalloc requests.
 247:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 248:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Dereferencing ZERO_SIZE_PTR will lead to a distinct access fault.
 249:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 250:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * ZERO_SIZE_PTR can be passed to kfree though in the same way that NULL can.
 251:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Both make kfree a no-op.
 252:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
 253:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define ZERO_SIZE_PTR ((void *)16)
 254:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 255:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define ZERO_OR_NULL_PTR(x) ((unsigned long)(x) <= \
 256:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 				(unsigned long)ZERO_SIZE_PTR)
 257:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 258:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 259:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 260:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 261:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 262:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_SLUB_CPU_PARTIAL
 263:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define slub_percpu_partial(c)			((c)->partial)
 264:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 265:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define slub_set_percpu_partial(c, p)		\
 266:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** ({						\
 267:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	slub_percpu_partial(c) = (p)->next;	\
 268:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** })
 269:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 270:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define slub_percpu_partial_read_once(c)	READ_ONCE(slub_percpu_partial(c))
 271:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #else
 272:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define slub_percpu_partial(c)			NULL
 273:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 274:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define slub_set_percpu_partial(c, p)
 275:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 276:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define slub_percpu_partial_read_once(c)	NULL
 277:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 278:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 279:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif // CONFIG_SLUB_CPU_PARTIAL
 280:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
ARM GAS  /tmp/ccJeHFgp.s 			page 18


 281:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /*
 282:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	* Word size structure that can be atomically updated or read and that
 283:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	* contains both the order and the number of objects that a slab of the
 284:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	* given order would contain.
 285:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	*/				
 286:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** struct kmem_cache_order_objects {
 287:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	unsigned int x;
 288:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** };
 289:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 290:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** struct kmem_cache_node {
 291:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	spinlock_t list_lock;
 292:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	unsigned long nr_partial;
 293:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	struct list_head partial;
 294:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_SLUB_DEBUG
 295:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	atomic_long_t nr_slabs;
 296:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	atomic_long_t total_objects;
 297:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	struct list_head full;
 298:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
 299:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** };
 300:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 301:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** struct kmem_cache {
 302:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#ifndef CONFIG_SLUB_TINY
 303:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	//	struct kmem_cache_cpu __percpu *cpu_slab;
 304:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#endif
 305:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		/* Used for retrieving partial slabs, etc. */
 306:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		slab_flags_t flags;
 307:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned long min_partial;
 308:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int size;		/* Object size including metadata */
 309:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int object_size;	/* Object size without metadata */
 310:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		struct reciprocal_value reciprocal_size;
 311:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int offset;		/* Free pointer offset */
 312:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#ifdef CONFIG_SLUB_CPU_PARTIAL
 313:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		/* Number of per cpu partial objects to keep around */
 314:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int cpu_partial;
 315:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		/* Number of per cpu partial slabs to keep around */
 316:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int cpu_partial_slabs;
 317:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#endif
 318:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		struct kmem_cache_order_objects oo;
 319:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	
 320:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		/* Allocation and freeing of slabs */
 321:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		struct kmem_cache_order_objects min;
 322:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		gfp_t allocflags;		/* gfp flags to use on each alloc */
 323:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		int refcount;			/* Refcount for slab cache destroy */
 324:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		void (*ctor)(void *object);	/* Object constructor */
 325:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int inuse;		/* Offset to metadata */
 326:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int align;		/* Alignment */
 327:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int red_left_pad;	/* Left redzone padding size */
 328:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		const char *name;		/* Name (only for display!) */
 329:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		struct list_head list;		/* List of slab caches */
 330:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#ifdef CONFIG_SYSFS
 331:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		struct kobject kobj;		/* For sysfs */
 332:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#endif
 333:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#ifdef CONFIG_SLAB_FREELIST_HARDENED
 334:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned long random;
 335:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#endif
 336:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	
 337:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#ifdef CONFIG_NUMA
ARM GAS  /tmp/ccJeHFgp.s 			page 19


 338:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		/*
 339:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 			* Defragmentation by allocating from a remote node.
 340:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 			*/
 341:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int remote_node_defrag_ratio;
 342:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#endif
 343:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	
 344:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#ifdef CONFIG_SLAB_FREELIST_RANDOM
 345:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int *random_seq;
 346:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#endif
 347:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	
 348:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#ifdef CONFIG_KASAN_GENERIC
 349:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		struct kasan_cache kasan_info;
 350:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#endif
 351:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	
 352:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#ifdef CONFIG_HARDENED_USERCOPY
 353:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int useroffset;	/* Usercopy region offset */
 354:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int usersize;		/* Usercopy region size */
 355:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#endif
 356:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	
 357:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		struct kmem_cache_node *node[MAX_NUMNODES];
 358:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	};
 359:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 					
 360:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 361:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 362:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 363:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 364:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define KMALLOC_WAIT 1
 365:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 366:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 367:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** extern void* __smalloc__(u32 size, gfp_t flags);
 368:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** extern void  __sfree__(void* addr);
 369:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 370:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 371:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** static void inline *vmalloc(unsigned long size){
 372:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	return __smalloc__(size,GFP_TRANSHUGE_LIGHT);
 373:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** }
 374:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 375:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** static void inline vfree(void *addr){
 376:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	__sfree__(addr);
 377:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** }
 378:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 379:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** static void inline *kmalloc(size_t size, gfp_t flags){
 380:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	return __smalloc__((u32)size,flags);
 381:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** }
 382:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 383:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** static void inline kfree(const void *ptr){
 382              		.loc 3 383 20 view .LVU114
 383              	.LBB67:
 384:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	__sfree__((void*)ptr);
 384              		.loc 3 384 2 view .LVU115
 385 0042 A068     		ldr	r0, [r4, #8]
 386 0044 FFF7FEFF 		bl	__sfree__
 387              	.LVL29:
 388              		.loc 3 384 2 is_stmt 0 view .LVU116
 389              	.LBE67:
 390              	.LBE66:
  37:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c ****             kfree(entry);
ARM GAS  /tmp/ccJeHFgp.s 			page 20


 391              		.loc 1 37 13 is_stmt 1 view .LVU117
 392              	.LBB68:
 393              	.LBI68:
 383:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	__sfree__((void*)ptr);
 394              		.loc 3 383 20 view .LVU118
 395              	.LBB69:
 396              		.loc 3 384 2 view .LVU119
 397 0048 2046     		mov	r0, r4
 398 004a FFF7FEFF 		bl	__sfree__
 399              	.LVL30:
 400              		.loc 3 384 2 is_stmt 0 view .LVU120
 401              	.LBE69:
 402              	.LBE68:
  38:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c ****             return 0;
 403              		.loc 1 38 13 is_stmt 1 view .LVU121
 404              		.loc 1 38 20 is_stmt 0 view .LVU122
 405 004e 01E0     		b	.L19
 406              	.L25:
  39:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c ****         }
  40:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c ****     }
  41:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c ****     return -ENOENT;
 407              		.loc 1 41 12 view .LVU123
 408 0050 6FF00107 		mvn	r7, #1
 409              	.L19:
  42:/mnt/c/Users/31740/Desktop/newcore/kernel/sched/task_pools.c **** }
 410              		.loc 1 42 1 view .LVU124
 411 0054 3846     		mov	r0, r7
 412 0056 F8BD     		pop	{r3, r4, r5, r6, r7, pc}
 413              	.LVL31:
 414              	.L27:
 415              		.loc 1 42 1 view .LVU125
 416              		.align	2
 417              	.L26:
 418 0058 00000000 		.word	task_pool_list
 419 005c 00000000 		.word	.LC2
 420              		.cfi_endproc
 421              	.LFE272:
 423              		.section	.data.task_pool_list,"aw"
 424              		.align	2
 427              	task_pool_list:
 428 0000 00000000 		.word	task_pool_list
 429 0004 00000000 		.word	task_pool_list
 430              		.text
 431              	.Letext0:
 432              		.file 4 "/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/int-l64.h"
 433              		.file 5 "/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/posix_types.h"
 434              		.file 6 "/mnt/c/Users/31740/Desktop/newcore/include/linux/types.h"
 435              		.file 7 "/mnt/c/Users/31740/Desktop/newcore/include/linux/time64.h"
 436              		.file 8 "/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/sched.h"
 437              		.file 9 "/mnt/c/Users/31740/Desktop/newcore/include/linux/sched.h"
 438              		.file 10 "/mnt/c/Users/31740/Desktop/newcore/include/linux/printk.h"
 439              		.file 11 "/mnt/c/Users/31740/Desktop/newcore/include/linux/stddef.h"
 440              		.file 12 "/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/string.h"
ARM GAS  /tmp/ccJeHFgp.s 			page 21


DEFINED SYMBOLS
                            *ABS*:00000000 task_pools.c
     /tmp/ccJeHFgp.s:21     .rodata.register_task_pool.str1.4:00000000 $d
     /tmp/ccJeHFgp.s:28     .text.register_task_pool:00000000 $t
     /tmp/ccJeHFgp.s:34     .text.register_task_pool:00000000 register_task_pool
     /tmp/ccJeHFgp.s:159    .text.register_task_pool:00000048 $d
     /tmp/ccJeHFgp.s:427    .data.task_pool_list:00000000 task_pool_list
     /tmp/ccJeHFgp.s:166    .text.find_task_pool:00000000 $t
     /tmp/ccJeHFgp.s:172    .text.find_task_pool:00000000 find_task_pool
     /tmp/ccJeHFgp.s:239    .text.find_task_pool:00000028 $d
     /tmp/ccJeHFgp.s:244    .rodata.unregister_task_pool.str1.4:00000000 $d
     /tmp/ccJeHFgp.s:248    .text.unregister_task_pool:00000000 $t
     /tmp/ccJeHFgp.s:254    .text.unregister_task_pool:00000000 unregister_task_pool
     /tmp/ccJeHFgp.s:418    .text.unregister_task_pool:00000058 $d
     /tmp/ccJeHFgp.s:424    .data.task_pool_list:00000000 $d

UNDEFINED SYMBOLS
strcmp
printk
__sfree__
