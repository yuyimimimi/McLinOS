ARM GAS  /tmp/ccKJN8PY.s 			page 1


   1              		.cpu cortex-m4
   2              		.arch armv7e-m
   3              		.fpu fpv4-sp-d16
   4              		.eabi_attribute 27, 1
   5              		.eabi_attribute 28, 1
   6              		.eabi_attribute 20, 1
   7              		.eabi_attribute 21, 1
   8              		.eabi_attribute 23, 3
   9              		.eabi_attribute 24, 1
  10              		.eabi_attribute 25, 1
  11              		.eabi_attribute 26, 1
  12              		.eabi_attribute 30, 1
  13              		.eabi_attribute 34, 1
  14              		.eabi_attribute 18, 4
  15              		.file	"fs_inode.c"
  16              		.text
  17              	.Ltext0:
  18              		.cfi_sections	.debug_frame
  19              		.file 1 "./fs/fs_inode.c"
  20              		.section	.text.inode_get,"ax",%progbits
  21              		.align	1
  22              		.global	inode_get
  23              		.syntax unified
  24              		.thumb
  25              		.thumb_func
  27              	inode_get:
  28              	.LVL0:
  29              	.LFB1037:
   1:./fs/fs_inode.c **** #include <linux/kernel.h>
   2:./fs/fs_inode.c **** #include <linux/fs.h>
   3:./fs/fs_inode.c **** #include <linux/spinlock.h>
   4:./fs/fs_inode.c **** #include <linux/string.h>
   5:./fs/fs_inode.c **** #include <linux/slab.h>
   6:./fs/fs_inode.c **** #include <linux/dcache.h>
   7:./fs/fs_inode.c **** #include <linux/export.h>
   8:./fs/fs_inode.c **** #include <linux/list.h>
   9:./fs/fs_inode.c **** #include <linux/fs.h>
  10:./fs/fs_inode.c **** #include <linux/stat.h>
  11:./fs/fs_inode.c **** #include <linux/time.h>
  12:./fs/fs_inode.c **** #include <linux/atomic.h>
  13:./fs/fs_inode.c **** 
  14:./fs/fs_inode.c **** 
  15:./fs/fs_inode.c **** struct inode* new_inode(struct super_block *sb){
  16:./fs/fs_inode.c ****     struct inode *inode = (struct inode *)kmalloc(sizeof(struct inode), GFP_KERNEL);
  17:./fs/fs_inode.c ****     if (inode == NULL) return NULL;
  18:./fs/fs_inode.c **** 	memset(inode,0,sizeof(struct inode));
  19:./fs/fs_inode.c ****     inode->i_mode    = S_IFCHR | 0777;
  20:./fs/fs_inode.c ****     time64_t now        = jiffies;
  21:./fs/fs_inode.c ****     inode->i_sb       = sb;
  22:./fs/fs_inode.c **** 	atomic_set(&inode->i_count,1);
  23:./fs/fs_inode.c ****     return inode;
  24:./fs/fs_inode.c **** }
  25:./fs/fs_inode.c **** EXPORT_SYMBOL(new_inode);
  26:./fs/fs_inode.c **** 
  27:./fs/fs_inode.c **** void destroy_inode(struct inode *node){
  28:./fs/fs_inode.c **** 	if(node != NULL)
  29:./fs/fs_inode.c **** 	kfree(node);
ARM GAS  /tmp/ccKJN8PY.s 			page 2


  30:./fs/fs_inode.c **** }
  31:./fs/fs_inode.c **** EXPORT_SYMBOL(destroy_inode);
  32:./fs/fs_inode.c **** 
  33:./fs/fs_inode.c **** void inode_get(struct inode *inode){
  30              		.loc 1 33 36 view -0
  31              		.cfi_startproc
  32              		@ args = 0, pretend = 0, frame = 0
  33              		@ frame_needed = 0, uses_anonymous_args = 0
  34              		@ link register save eliminated.
  34:./fs/fs_inode.c ****     atomic_inc(&inode->i_count);  
  35              		.loc 1 34 5 view .LVU1
  36 0000 4C30     		adds	r0, r0, #76
  37              	.LVL1:
  38              	.LBB74:
  39              	.LBI74:
  40              		.file 2 "./include/linux/atomic/atomic-instrumented.h"
   1:./include/linux/atomic/atomic-instrumented.h **** // SPDX-License-Identifier: GPL-2.0
   2:./include/linux/atomic/atomic-instrumented.h **** 
   3:./include/linux/atomic/atomic-instrumented.h **** // Generated by scripts/atomic/gen-atomic-instrumented.sh 
   4:./include/linux/atomic/atomic-instrumented.h **** // DO NOT MODIFY THIS FILE DIRECTLY
   5:./include/linux/atomic/atomic-instrumented.h **** 
   6:./include/linux/atomic/atomic-instrumented.h **** /*
   7:./include/linux/atomic/atomic-instrumented.h ****  * This file provoides atomic operations with explicit instrumentation (e.g.
   8:./include/linux/atomic/atomic-instrumented.h ****  * KASAN, KCSAN), which should be used unless it is necessary to avoid
   9:./include/linux/atomic/atomic-instrumented.h ****  * instrumentation. Where it is necessary to aovid instrumenation, the
  10:./include/linux/atomic/atomic-instrumented.h ****  * raw_atomic*() operations should be used.
  11:./include/linux/atomic/atomic-instrumented.h ****  */
  12:./include/linux/atomic/atomic-instrumented.h **** #ifndef _LINUX_ATOMIC_INSTRUMENTED_H
  13:./include/linux/atomic/atomic-instrumented.h **** #define _LINUX_ATOMIC_INSTRUMENTED_H
  14:./include/linux/atomic/atomic-instrumented.h **** 
  15:./include/linux/atomic/atomic-instrumented.h **** #include <linux/build_bug.h>
  16:./include/linux/atomic/atomic-instrumented.h **** #include <linux/compiler.h>
  17:./include/linux/atomic/atomic-instrumented.h **** #include <linux/instrumented.h>
  18:./include/linux/atomic/atomic-instrumented.h **** 
  19:./include/linux/atomic/atomic-instrumented.h **** /**
  20:./include/linux/atomic/atomic-instrumented.h ****  * atomic_read() - atomic load with relaxed ordering
  21:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
  22:./include/linux/atomic/atomic-instrumented.h ****  *
  23:./include/linux/atomic/atomic-instrumented.h ****  * Atomically loads the value of @v with relaxed ordering.
  24:./include/linux/atomic/atomic-instrumented.h ****  *
  25:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_read() there.
  26:./include/linux/atomic/atomic-instrumented.h ****  *
  27:./include/linux/atomic/atomic-instrumented.h ****  * Return: The value loaded from @v.
  28:./include/linux/atomic/atomic-instrumented.h ****  */
  29:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
  30:./include/linux/atomic/atomic-instrumented.h **** atomic_read(const atomic_t *v)
  31:./include/linux/atomic/atomic-instrumented.h **** {
  32:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read(v, sizeof(*v));
  33:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_read(v);
  34:./include/linux/atomic/atomic-instrumented.h **** }
  35:./include/linux/atomic/atomic-instrumented.h **** 
  36:./include/linux/atomic/atomic-instrumented.h **** /**
  37:./include/linux/atomic/atomic-instrumented.h ****  * atomic_read_acquire() - atomic load with acquire ordering
  38:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
  39:./include/linux/atomic/atomic-instrumented.h ****  *
  40:./include/linux/atomic/atomic-instrumented.h ****  * Atomically loads the value of @v with acquire ordering.
  41:./include/linux/atomic/atomic-instrumented.h ****  *
ARM GAS  /tmp/ccKJN8PY.s 			page 3


  42:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_read_acquire() there.
  43:./include/linux/atomic/atomic-instrumented.h ****  *
  44:./include/linux/atomic/atomic-instrumented.h ****  * Return: The value loaded from @v.
  45:./include/linux/atomic/atomic-instrumented.h ****  */
  46:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
  47:./include/linux/atomic/atomic-instrumented.h **** atomic_read_acquire(const atomic_t *v)
  48:./include/linux/atomic/atomic-instrumented.h **** {
  49:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read(v, sizeof(*v));
  50:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_read_acquire(v);
  51:./include/linux/atomic/atomic-instrumented.h **** }
  52:./include/linux/atomic/atomic-instrumented.h **** 
  53:./include/linux/atomic/atomic-instrumented.h **** /**
  54:./include/linux/atomic/atomic-instrumented.h ****  * atomic_set() - atomic set with relaxed ordering
  55:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
  56:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value to assign
  57:./include/linux/atomic/atomic-instrumented.h ****  *
  58:./include/linux/atomic/atomic-instrumented.h ****  * Atomically sets @v to @i with relaxed ordering.
  59:./include/linux/atomic/atomic-instrumented.h ****  *
  60:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_set() there.
  61:./include/linux/atomic/atomic-instrumented.h ****  *
  62:./include/linux/atomic/atomic-instrumented.h ****  * Return: Nothing.
  63:./include/linux/atomic/atomic-instrumented.h ****  */
  64:./include/linux/atomic/atomic-instrumented.h **** static __always_inline void
  65:./include/linux/atomic/atomic-instrumented.h **** atomic_set(atomic_t *v, int i)
  66:./include/linux/atomic/atomic-instrumented.h **** {
  67:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_write(v, sizeof(*v));
  68:./include/linux/atomic/atomic-instrumented.h **** 	raw_atomic_set(v, i);
  69:./include/linux/atomic/atomic-instrumented.h **** }
  70:./include/linux/atomic/atomic-instrumented.h **** 
  71:./include/linux/atomic/atomic-instrumented.h **** /**
  72:./include/linux/atomic/atomic-instrumented.h ****  * atomic_set_release() - atomic set with release ordering
  73:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
  74:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value to assign
  75:./include/linux/atomic/atomic-instrumented.h ****  *
  76:./include/linux/atomic/atomic-instrumented.h ****  * Atomically sets @v to @i with release ordering.
  77:./include/linux/atomic/atomic-instrumented.h ****  *
  78:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_set_release() there.
  79:./include/linux/atomic/atomic-instrumented.h ****  *
  80:./include/linux/atomic/atomic-instrumented.h ****  * Return: Nothing.
  81:./include/linux/atomic/atomic-instrumented.h ****  */
  82:./include/linux/atomic/atomic-instrumented.h **** static __always_inline void
  83:./include/linux/atomic/atomic-instrumented.h **** atomic_set_release(atomic_t *v, int i)
  84:./include/linux/atomic/atomic-instrumented.h **** {
  85:./include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
  86:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_write(v, sizeof(*v));
  87:./include/linux/atomic/atomic-instrumented.h **** 	raw_atomic_set_release(v, i);
  88:./include/linux/atomic/atomic-instrumented.h **** }
  89:./include/linux/atomic/atomic-instrumented.h **** 
  90:./include/linux/atomic/atomic-instrumented.h **** /**
  91:./include/linux/atomic/atomic-instrumented.h ****  * atomic_add() - atomic add with relaxed ordering
  92:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value to add
  93:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
  94:./include/linux/atomic/atomic-instrumented.h ****  *
  95:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + @i) with relaxed ordering.
  96:./include/linux/atomic/atomic-instrumented.h ****  *
  97:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_add() there.
  98:./include/linux/atomic/atomic-instrumented.h ****  *
ARM GAS  /tmp/ccKJN8PY.s 			page 4


  99:./include/linux/atomic/atomic-instrumented.h ****  * Return: Nothing.
 100:./include/linux/atomic/atomic-instrumented.h ****  */
 101:./include/linux/atomic/atomic-instrumented.h **** static __always_inline void
 102:./include/linux/atomic/atomic-instrumented.h **** atomic_add(int i, atomic_t *v)
 103:./include/linux/atomic/atomic-instrumented.h **** {
 104:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 105:./include/linux/atomic/atomic-instrumented.h **** 	raw_atomic_add(i, v);
 106:./include/linux/atomic/atomic-instrumented.h **** }
 107:./include/linux/atomic/atomic-instrumented.h **** 
 108:./include/linux/atomic/atomic-instrumented.h **** /**
 109:./include/linux/atomic/atomic-instrumented.h ****  * atomic_add_return() - atomic add with full ordering
 110:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value to add
 111:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 112:./include/linux/atomic/atomic-instrumented.h ****  *
 113:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + @i) with full ordering.
 114:./include/linux/atomic/atomic-instrumented.h ****  *
 115:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_add_return() there.
 116:./include/linux/atomic/atomic-instrumented.h ****  *
 117:./include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 118:./include/linux/atomic/atomic-instrumented.h ****  */
 119:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 120:./include/linux/atomic/atomic-instrumented.h **** atomic_add_return(int i, atomic_t *v)
 121:./include/linux/atomic/atomic-instrumented.h **** {
 122:./include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
 123:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 124:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_add_return(i, v);
 125:./include/linux/atomic/atomic-instrumented.h **** }
 126:./include/linux/atomic/atomic-instrumented.h **** 
 127:./include/linux/atomic/atomic-instrumented.h **** /**
 128:./include/linux/atomic/atomic-instrumented.h ****  * atomic_add_return_acquire() - atomic add with acquire ordering
 129:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value to add
 130:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 131:./include/linux/atomic/atomic-instrumented.h ****  *
 132:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + @i) with acquire ordering.
 133:./include/linux/atomic/atomic-instrumented.h ****  *
 134:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_add_return_acquire() there.
 135:./include/linux/atomic/atomic-instrumented.h ****  *
 136:./include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 137:./include/linux/atomic/atomic-instrumented.h ****  */
 138:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 139:./include/linux/atomic/atomic-instrumented.h **** atomic_add_return_acquire(int i, atomic_t *v)
 140:./include/linux/atomic/atomic-instrumented.h **** {
 141:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 142:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_add_return_acquire(i, v);
 143:./include/linux/atomic/atomic-instrumented.h **** }
 144:./include/linux/atomic/atomic-instrumented.h **** 
 145:./include/linux/atomic/atomic-instrumented.h **** /**
 146:./include/linux/atomic/atomic-instrumented.h ****  * atomic_add_return_release() - atomic add with release ordering
 147:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value to add
 148:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 149:./include/linux/atomic/atomic-instrumented.h ****  *
 150:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + @i) with release ordering.
 151:./include/linux/atomic/atomic-instrumented.h ****  *
 152:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_add_return_release() there.
 153:./include/linux/atomic/atomic-instrumented.h ****  *
 154:./include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 155:./include/linux/atomic/atomic-instrumented.h ****  */
ARM GAS  /tmp/ccKJN8PY.s 			page 5


 156:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 157:./include/linux/atomic/atomic-instrumented.h **** atomic_add_return_release(int i, atomic_t *v)
 158:./include/linux/atomic/atomic-instrumented.h **** {
 159:./include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
 160:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 161:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_add_return_release(i, v);
 162:./include/linux/atomic/atomic-instrumented.h **** }
 163:./include/linux/atomic/atomic-instrumented.h **** 
 164:./include/linux/atomic/atomic-instrumented.h **** /**
 165:./include/linux/atomic/atomic-instrumented.h ****  * atomic_add_return_relaxed() - atomic add with relaxed ordering
 166:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value to add
 167:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 168:./include/linux/atomic/atomic-instrumented.h ****  *
 169:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + @i) with relaxed ordering.
 170:./include/linux/atomic/atomic-instrumented.h ****  *
 171:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_add_return_relaxed() there.
 172:./include/linux/atomic/atomic-instrumented.h ****  *
 173:./include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 174:./include/linux/atomic/atomic-instrumented.h ****  */
 175:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 176:./include/linux/atomic/atomic-instrumented.h **** atomic_add_return_relaxed(int i, atomic_t *v)
 177:./include/linux/atomic/atomic-instrumented.h **** {
 178:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 179:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_add_return_relaxed(i, v);
 180:./include/linux/atomic/atomic-instrumented.h **** }
 181:./include/linux/atomic/atomic-instrumented.h **** 
 182:./include/linux/atomic/atomic-instrumented.h **** /**
 183:./include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_add() - atomic add with full ordering
 184:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value to add
 185:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 186:./include/linux/atomic/atomic-instrumented.h ****  *
 187:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + @i) with full ordering.
 188:./include/linux/atomic/atomic-instrumented.h ****  *
 189:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_add() there.
 190:./include/linux/atomic/atomic-instrumented.h ****  *
 191:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 192:./include/linux/atomic/atomic-instrumented.h ****  */
 193:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 194:./include/linux/atomic/atomic-instrumented.h **** atomic_fetch_add(int i, atomic_t *v)
 195:./include/linux/atomic/atomic-instrumented.h **** {
 196:./include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
 197:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 198:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_add(i, v);
 199:./include/linux/atomic/atomic-instrumented.h **** }
 200:./include/linux/atomic/atomic-instrumented.h **** 
 201:./include/linux/atomic/atomic-instrumented.h **** /**
 202:./include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_add_acquire() - atomic add with acquire ordering
 203:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value to add
 204:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 205:./include/linux/atomic/atomic-instrumented.h ****  *
 206:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + @i) with acquire ordering.
 207:./include/linux/atomic/atomic-instrumented.h ****  *
 208:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_add_acquire() there.
 209:./include/linux/atomic/atomic-instrumented.h ****  *
 210:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 211:./include/linux/atomic/atomic-instrumented.h ****  */
 212:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
ARM GAS  /tmp/ccKJN8PY.s 			page 6


 213:./include/linux/atomic/atomic-instrumented.h **** atomic_fetch_add_acquire(int i, atomic_t *v)
 214:./include/linux/atomic/atomic-instrumented.h **** {
 215:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 216:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_add_acquire(i, v);
 217:./include/linux/atomic/atomic-instrumented.h **** }
 218:./include/linux/atomic/atomic-instrumented.h **** 
 219:./include/linux/atomic/atomic-instrumented.h **** /**
 220:./include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_add_release() - atomic add with release ordering
 221:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value to add
 222:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 223:./include/linux/atomic/atomic-instrumented.h ****  *
 224:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + @i) with release ordering.
 225:./include/linux/atomic/atomic-instrumented.h ****  *
 226:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_add_release() there.
 227:./include/linux/atomic/atomic-instrumented.h ****  *
 228:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 229:./include/linux/atomic/atomic-instrumented.h ****  */
 230:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 231:./include/linux/atomic/atomic-instrumented.h **** atomic_fetch_add_release(int i, atomic_t *v)
 232:./include/linux/atomic/atomic-instrumented.h **** {
 233:./include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
 234:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 235:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_add_release(i, v);
 236:./include/linux/atomic/atomic-instrumented.h **** }
 237:./include/linux/atomic/atomic-instrumented.h **** 
 238:./include/linux/atomic/atomic-instrumented.h **** /**
 239:./include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_add_relaxed() - atomic add with relaxed ordering
 240:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value to add
 241:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 242:./include/linux/atomic/atomic-instrumented.h ****  *
 243:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + @i) with relaxed ordering.
 244:./include/linux/atomic/atomic-instrumented.h ****  *
 245:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_add_relaxed() there.
 246:./include/linux/atomic/atomic-instrumented.h ****  *
 247:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 248:./include/linux/atomic/atomic-instrumented.h ****  */
 249:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 250:./include/linux/atomic/atomic-instrumented.h **** atomic_fetch_add_relaxed(int i, atomic_t *v)
 251:./include/linux/atomic/atomic-instrumented.h **** {
 252:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 253:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_add_relaxed(i, v);
 254:./include/linux/atomic/atomic-instrumented.h **** }
 255:./include/linux/atomic/atomic-instrumented.h **** 
 256:./include/linux/atomic/atomic-instrumented.h **** /**
 257:./include/linux/atomic/atomic-instrumented.h ****  * atomic_sub() - atomic subtract with relaxed ordering
 258:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value to subtract
 259:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 260:./include/linux/atomic/atomic-instrumented.h ****  *
 261:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - @i) with relaxed ordering.
 262:./include/linux/atomic/atomic-instrumented.h ****  *
 263:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_sub() there.
 264:./include/linux/atomic/atomic-instrumented.h ****  *
 265:./include/linux/atomic/atomic-instrumented.h ****  * Return: Nothing.
 266:./include/linux/atomic/atomic-instrumented.h ****  */
 267:./include/linux/atomic/atomic-instrumented.h **** static __always_inline void
 268:./include/linux/atomic/atomic-instrumented.h **** atomic_sub(int i, atomic_t *v)
 269:./include/linux/atomic/atomic-instrumented.h **** {
ARM GAS  /tmp/ccKJN8PY.s 			page 7


 270:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 271:./include/linux/atomic/atomic-instrumented.h **** 	raw_atomic_sub(i, v);
 272:./include/linux/atomic/atomic-instrumented.h **** }
 273:./include/linux/atomic/atomic-instrumented.h **** 
 274:./include/linux/atomic/atomic-instrumented.h **** /**
 275:./include/linux/atomic/atomic-instrumented.h ****  * atomic_sub_return() - atomic subtract with full ordering
 276:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value to subtract
 277:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 278:./include/linux/atomic/atomic-instrumented.h ****  *
 279:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - @i) with full ordering.
 280:./include/linux/atomic/atomic-instrumented.h ****  *
 281:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_sub_return() there.
 282:./include/linux/atomic/atomic-instrumented.h ****  *
 283:./include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 284:./include/linux/atomic/atomic-instrumented.h ****  */
 285:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 286:./include/linux/atomic/atomic-instrumented.h **** atomic_sub_return(int i, atomic_t *v)
 287:./include/linux/atomic/atomic-instrumented.h **** {
 288:./include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
 289:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 290:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_sub_return(i, v);
 291:./include/linux/atomic/atomic-instrumented.h **** }
 292:./include/linux/atomic/atomic-instrumented.h **** 
 293:./include/linux/atomic/atomic-instrumented.h **** /**
 294:./include/linux/atomic/atomic-instrumented.h ****  * atomic_sub_return_acquire() - atomic subtract with acquire ordering
 295:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value to subtract
 296:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 297:./include/linux/atomic/atomic-instrumented.h ****  *
 298:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - @i) with acquire ordering.
 299:./include/linux/atomic/atomic-instrumented.h ****  *
 300:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_sub_return_acquire() there.
 301:./include/linux/atomic/atomic-instrumented.h ****  *
 302:./include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 303:./include/linux/atomic/atomic-instrumented.h ****  */
 304:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 305:./include/linux/atomic/atomic-instrumented.h **** atomic_sub_return_acquire(int i, atomic_t *v)
 306:./include/linux/atomic/atomic-instrumented.h **** {
 307:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 308:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_sub_return_acquire(i, v);
 309:./include/linux/atomic/atomic-instrumented.h **** }
 310:./include/linux/atomic/atomic-instrumented.h **** 
 311:./include/linux/atomic/atomic-instrumented.h **** /**
 312:./include/linux/atomic/atomic-instrumented.h ****  * atomic_sub_return_release() - atomic subtract with release ordering
 313:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value to subtract
 314:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 315:./include/linux/atomic/atomic-instrumented.h ****  *
 316:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - @i) with release ordering.
 317:./include/linux/atomic/atomic-instrumented.h ****  *
 318:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_sub_return_release() there.
 319:./include/linux/atomic/atomic-instrumented.h ****  *
 320:./include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 321:./include/linux/atomic/atomic-instrumented.h ****  */
 322:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 323:./include/linux/atomic/atomic-instrumented.h **** atomic_sub_return_release(int i, atomic_t *v)
 324:./include/linux/atomic/atomic-instrumented.h **** {
 325:./include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
 326:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
ARM GAS  /tmp/ccKJN8PY.s 			page 8


 327:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_sub_return_release(i, v);
 328:./include/linux/atomic/atomic-instrumented.h **** }
 329:./include/linux/atomic/atomic-instrumented.h **** 
 330:./include/linux/atomic/atomic-instrumented.h **** /**
 331:./include/linux/atomic/atomic-instrumented.h ****  * atomic_sub_return_relaxed() - atomic subtract with relaxed ordering
 332:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value to subtract
 333:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 334:./include/linux/atomic/atomic-instrumented.h ****  *
 335:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - @i) with relaxed ordering.
 336:./include/linux/atomic/atomic-instrumented.h ****  *
 337:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_sub_return_relaxed() there.
 338:./include/linux/atomic/atomic-instrumented.h ****  *
 339:./include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 340:./include/linux/atomic/atomic-instrumented.h ****  */
 341:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 342:./include/linux/atomic/atomic-instrumented.h **** atomic_sub_return_relaxed(int i, atomic_t *v)
 343:./include/linux/atomic/atomic-instrumented.h **** {
 344:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 345:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_sub_return_relaxed(i, v);
 346:./include/linux/atomic/atomic-instrumented.h **** }
 347:./include/linux/atomic/atomic-instrumented.h **** 
 348:./include/linux/atomic/atomic-instrumented.h **** /**
 349:./include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_sub() - atomic subtract with full ordering
 350:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value to subtract
 351:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 352:./include/linux/atomic/atomic-instrumented.h ****  *
 353:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - @i) with full ordering.
 354:./include/linux/atomic/atomic-instrumented.h ****  *
 355:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_sub() there.
 356:./include/linux/atomic/atomic-instrumented.h ****  *
 357:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 358:./include/linux/atomic/atomic-instrumented.h ****  */
 359:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 360:./include/linux/atomic/atomic-instrumented.h **** atomic_fetch_sub(int i, atomic_t *v)
 361:./include/linux/atomic/atomic-instrumented.h **** {
 362:./include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
 363:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 364:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_sub(i, v);
 365:./include/linux/atomic/atomic-instrumented.h **** }
 366:./include/linux/atomic/atomic-instrumented.h **** 
 367:./include/linux/atomic/atomic-instrumented.h **** /**
 368:./include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_sub_acquire() - atomic subtract with acquire ordering
 369:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value to subtract
 370:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 371:./include/linux/atomic/atomic-instrumented.h ****  *
 372:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - @i) with acquire ordering.
 373:./include/linux/atomic/atomic-instrumented.h ****  *
 374:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_sub_acquire() there.
 375:./include/linux/atomic/atomic-instrumented.h ****  *
 376:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 377:./include/linux/atomic/atomic-instrumented.h ****  */
 378:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 379:./include/linux/atomic/atomic-instrumented.h **** atomic_fetch_sub_acquire(int i, atomic_t *v)
 380:./include/linux/atomic/atomic-instrumented.h **** {
 381:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 382:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_sub_acquire(i, v);
 383:./include/linux/atomic/atomic-instrumented.h **** }
ARM GAS  /tmp/ccKJN8PY.s 			page 9


 384:./include/linux/atomic/atomic-instrumented.h **** 
 385:./include/linux/atomic/atomic-instrumented.h **** /**
 386:./include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_sub_release() - atomic subtract with release ordering
 387:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value to subtract
 388:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 389:./include/linux/atomic/atomic-instrumented.h ****  *
 390:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - @i) with release ordering.
 391:./include/linux/atomic/atomic-instrumented.h ****  *
 392:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_sub_release() there.
 393:./include/linux/atomic/atomic-instrumented.h ****  *
 394:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 395:./include/linux/atomic/atomic-instrumented.h ****  */
 396:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 397:./include/linux/atomic/atomic-instrumented.h **** atomic_fetch_sub_release(int i, atomic_t *v)
 398:./include/linux/atomic/atomic-instrumented.h **** {
 399:./include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
 400:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 401:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_sub_release(i, v);
 402:./include/linux/atomic/atomic-instrumented.h **** }
 403:./include/linux/atomic/atomic-instrumented.h **** 
 404:./include/linux/atomic/atomic-instrumented.h **** /**
 405:./include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_sub_relaxed() - atomic subtract with relaxed ordering
 406:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value to subtract
 407:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 408:./include/linux/atomic/atomic-instrumented.h ****  *
 409:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - @i) with relaxed ordering.
 410:./include/linux/atomic/atomic-instrumented.h ****  *
 411:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_sub_relaxed() there.
 412:./include/linux/atomic/atomic-instrumented.h ****  *
 413:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 414:./include/linux/atomic/atomic-instrumented.h ****  */
 415:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 416:./include/linux/atomic/atomic-instrumented.h **** atomic_fetch_sub_relaxed(int i, atomic_t *v)
 417:./include/linux/atomic/atomic-instrumented.h **** {
 418:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 419:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_sub_relaxed(i, v);
 420:./include/linux/atomic/atomic-instrumented.h **** }
 421:./include/linux/atomic/atomic-instrumented.h **** 
 422:./include/linux/atomic/atomic-instrumented.h **** /**
 423:./include/linux/atomic/atomic-instrumented.h ****  * atomic_inc() - atomic increment with relaxed ordering
 424:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 425:./include/linux/atomic/atomic-instrumented.h ****  *
 426:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + 1) with relaxed ordering.
 427:./include/linux/atomic/atomic-instrumented.h ****  *
 428:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_inc() there.
 429:./include/linux/atomic/atomic-instrumented.h ****  *
 430:./include/linux/atomic/atomic-instrumented.h ****  * Return: Nothing.
 431:./include/linux/atomic/atomic-instrumented.h ****  */
 432:./include/linux/atomic/atomic-instrumented.h **** static __always_inline void
 433:./include/linux/atomic/atomic-instrumented.h **** atomic_inc(atomic_t *v)
  41              		.loc 2 433 1 view .LVU2
 434:./include/linux/atomic/atomic-instrumented.h **** {
 435:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
  42              		.loc 2 435 2 view .LVU3
 436:./include/linux/atomic/atomic-instrumented.h **** 	raw_atomic_inc(v);
  43              		.loc 2 436 2 view .LVU4
  44              	.LBB75:
ARM GAS  /tmp/ccKJN8PY.s 			page 10


  45              	.LBI75:
  46              		.file 3 "./include/linux/atomic/atomic-arch-fallback.h"
   1:./include/linux/atomic/atomic-arch-fallback.h **** // SPDX-License-Identifier: GPL-2.0
   2:./include/linux/atomic/atomic-arch-fallback.h **** 
   3:./include/linux/atomic/atomic-arch-fallback.h **** // Generated by scripts/atomic/gen-atomic-fallback.sh
   4:./include/linux/atomic/atomic-arch-fallback.h **** // DO NOT MODIFY THIS FILE DIRECTLY
   5:./include/linux/atomic/atomic-arch-fallback.h **** 
   6:./include/linux/atomic/atomic-arch-fallback.h **** #ifndef _LINUX_ATOMIC_FALLBACK_H
   7:./include/linux/atomic/atomic-arch-fallback.h **** #define _LINUX_ATOMIC_FALLBACK_H
   8:./include/linux/atomic/atomic-arch-fallback.h **** 
   9:./include/linux/atomic/atomic-arch-fallback.h **** #include <linux/compiler.h>
  10:./include/linux/atomic/atomic-arch-fallback.h **** 
  11:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_xchg)
  12:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg arch_xchg
  13:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_xchg_relaxed)
  14:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg(...) \
  15:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_fence(arch_xchg, __VA_ARGS__)
  16:./include/linux/atomic/atomic-arch-fallback.h **** #else
  17:./include/linux/atomic/atomic-arch-fallback.h **** extern void raw_xchg_not_implemented(void);
  18:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg(...) raw_xchg_not_implemented()
  19:./include/linux/atomic/atomic-arch-fallback.h **** #endif
  20:./include/linux/atomic/atomic-arch-fallback.h **** 
  21:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_xchg_acquire)
  22:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_acquire arch_xchg_acquire
  23:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_xchg_relaxed)
  24:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_acquire(...) \
  25:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_acquire(arch_xchg, __VA_ARGS__)
  26:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_xchg)
  27:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_acquire arch_xchg
  28:./include/linux/atomic/atomic-arch-fallback.h **** #else
  29:./include/linux/atomic/atomic-arch-fallback.h **** extern void raw_xchg_acquire_not_implemented(void);
  30:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_acquire(...) raw_xchg_acquire_not_implemented()
  31:./include/linux/atomic/atomic-arch-fallback.h **** #endif
  32:./include/linux/atomic/atomic-arch-fallback.h **** 
  33:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_xchg_release)
  34:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_release arch_xchg_release
  35:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_xchg_relaxed)
  36:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_release(...) \
  37:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_release(arch_xchg, __VA_ARGS__)
  38:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_xchg)
  39:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_release arch_xchg
  40:./include/linux/atomic/atomic-arch-fallback.h **** #else
  41:./include/linux/atomic/atomic-arch-fallback.h **** extern void raw_xchg_release_not_implemented(void);
  42:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_release(...) raw_xchg_release_not_implemented()
  43:./include/linux/atomic/atomic-arch-fallback.h **** #endif
  44:./include/linux/atomic/atomic-arch-fallback.h **** 
  45:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_xchg_relaxed)
  46:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_relaxed arch_xchg_relaxed
  47:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_xchg)
  48:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_relaxed arch_xchg
  49:./include/linux/atomic/atomic-arch-fallback.h **** #else
  50:./include/linux/atomic/atomic-arch-fallback.h **** extern void raw_xchg_relaxed_not_implemented(void);
  51:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_relaxed(...) raw_xchg_relaxed_not_implemented()
  52:./include/linux/atomic/atomic-arch-fallback.h **** #endif
  53:./include/linux/atomic/atomic-arch-fallback.h **** 
  54:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg)
  55:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg arch_cmpxchg
ARM GAS  /tmp/ccKJN8PY.s 			page 11


  56:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg_relaxed)
  57:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg(...) \
  58:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_fence(arch_cmpxchg, __VA_ARGS__)
  59:./include/linux/atomic/atomic-arch-fallback.h **** #else
  60:./include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg_not_implemented(void);
  61:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg(...) raw_cmpxchg_not_implemented()
  62:./include/linux/atomic/atomic-arch-fallback.h **** #endif
  63:./include/linux/atomic/atomic-arch-fallback.h **** 
  64:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg_acquire)
  65:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_acquire arch_cmpxchg_acquire
  66:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg_relaxed)
  67:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_acquire(...) \
  68:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_acquire(arch_cmpxchg, __VA_ARGS__)
  69:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg)
  70:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_acquire arch_cmpxchg
  71:./include/linux/atomic/atomic-arch-fallback.h **** #else
  72:./include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg_acquire_not_implemented(void);
  73:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_acquire(...) raw_cmpxchg_acquire_not_implemented()
  74:./include/linux/atomic/atomic-arch-fallback.h **** #endif
  75:./include/linux/atomic/atomic-arch-fallback.h **** 
  76:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg_release)
  77:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_release arch_cmpxchg_release
  78:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg_relaxed)
  79:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_release(...) \
  80:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_release(arch_cmpxchg, __VA_ARGS__)
  81:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg)
  82:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_release arch_cmpxchg
  83:./include/linux/atomic/atomic-arch-fallback.h **** #else
  84:./include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg_release_not_implemented(void);
  85:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_release(...) raw_cmpxchg_release_not_implemented()
  86:./include/linux/atomic/atomic-arch-fallback.h **** #endif
  87:./include/linux/atomic/atomic-arch-fallback.h **** 
  88:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg_relaxed)
  89:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_relaxed arch_cmpxchg_relaxed
  90:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg)
  91:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_relaxed arch_cmpxchg
  92:./include/linux/atomic/atomic-arch-fallback.h **** #else
  93:./include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg_relaxed_not_implemented(void);
  94:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_relaxed(...) raw_cmpxchg_relaxed_not_implemented()
  95:./include/linux/atomic/atomic-arch-fallback.h **** #endif
  96:./include/linux/atomic/atomic-arch-fallback.h **** 
  97:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg64)
  98:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64 arch_cmpxchg64
  99:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg64_relaxed)
 100:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64(...) \
 101:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_fence(arch_cmpxchg64, __VA_ARGS__)
 102:./include/linux/atomic/atomic-arch-fallback.h **** #else
 103:./include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg64_not_implemented(void);
 104:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64(...) raw_cmpxchg64_not_implemented()
 105:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 106:./include/linux/atomic/atomic-arch-fallback.h **** 
 107:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg64_acquire)
 108:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_acquire arch_cmpxchg64_acquire
 109:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg64_relaxed)
 110:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_acquire(...) \
 111:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_acquire(arch_cmpxchg64, __VA_ARGS__)
 112:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg64)
ARM GAS  /tmp/ccKJN8PY.s 			page 12


 113:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_acquire arch_cmpxchg64
 114:./include/linux/atomic/atomic-arch-fallback.h **** #else
 115:./include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg64_acquire_not_implemented(void);
 116:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_acquire(...) raw_cmpxchg64_acquire_not_implemented()
 117:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 118:./include/linux/atomic/atomic-arch-fallback.h **** 
 119:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg64_release)
 120:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_release arch_cmpxchg64_release
 121:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg64_relaxed)
 122:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_release(...) \
 123:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_release(arch_cmpxchg64, __VA_ARGS__)
 124:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg64)
 125:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_release arch_cmpxchg64
 126:./include/linux/atomic/atomic-arch-fallback.h **** #else
 127:./include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg64_release_not_implemented(void);
 128:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_release(...) raw_cmpxchg64_release_not_implemented()
 129:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 130:./include/linux/atomic/atomic-arch-fallback.h **** 
 131:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg64_relaxed)
 132:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_relaxed arch_cmpxchg64_relaxed
 133:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg64)
 134:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_relaxed arch_cmpxchg64
 135:./include/linux/atomic/atomic-arch-fallback.h **** #else
 136:./include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg64_relaxed_not_implemented(void);
 137:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_relaxed(...) raw_cmpxchg64_relaxed_not_implemented()
 138:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 139:./include/linux/atomic/atomic-arch-fallback.h **** 
 140:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg128)
 141:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128 arch_cmpxchg128
 142:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg128_relaxed)
 143:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128(...) \
 144:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_fence(arch_cmpxchg128, __VA_ARGS__)
 145:./include/linux/atomic/atomic-arch-fallback.h **** #else
 146:./include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg128_not_implemented(void);
 147:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128(...) raw_cmpxchg128_not_implemented()
 148:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 149:./include/linux/atomic/atomic-arch-fallback.h **** 
 150:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg128_acquire)
 151:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_acquire arch_cmpxchg128_acquire
 152:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg128_relaxed)
 153:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_acquire(...) \
 154:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_acquire(arch_cmpxchg128, __VA_ARGS__)
 155:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg128)
 156:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_acquire arch_cmpxchg128
 157:./include/linux/atomic/atomic-arch-fallback.h **** #else
 158:./include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg128_acquire_not_implemented(void);
 159:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_acquire(...) raw_cmpxchg128_acquire_not_implemented()
 160:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 161:./include/linux/atomic/atomic-arch-fallback.h **** 
 162:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg128_release)
 163:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_release arch_cmpxchg128_release
 164:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg128_relaxed)
 165:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_release(...) \
 166:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_release(arch_cmpxchg128, __VA_ARGS__)
 167:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg128)
 168:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_release arch_cmpxchg128
 169:./include/linux/atomic/atomic-arch-fallback.h **** #else
ARM GAS  /tmp/ccKJN8PY.s 			page 13


 170:./include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg128_release_not_implemented(void);
 171:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_release(...) raw_cmpxchg128_release_not_implemented()
 172:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 173:./include/linux/atomic/atomic-arch-fallback.h **** 
 174:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg128_relaxed)
 175:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_relaxed arch_cmpxchg128_relaxed
 176:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg128)
 177:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_relaxed arch_cmpxchg128
 178:./include/linux/atomic/atomic-arch-fallback.h **** #else
 179:./include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg128_relaxed_not_implemented(void);
 180:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_relaxed(...) raw_cmpxchg128_relaxed_not_implemented()
 181:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 182:./include/linux/atomic/atomic-arch-fallback.h **** 
 183:./include/linux/atomic/atomic-arch-fallback.h **** 
 184:./include/linux/atomic/atomic-arch-fallback.h **** 
 185:./include/linux/atomic/atomic-arch-fallback.h **** 
 186:./include/linux/atomic/atomic-arch-fallback.h **** 
 187:./include/linux/atomic/atomic-arch-fallback.h **** 
 188:./include/linux/atomic/atomic-arch-fallback.h **** 
 189:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg)
 190:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg arch_try_cmpxchg
 191:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg_relaxed)
 192:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg(...) \
 193:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_fence(arch_try_cmpxchg, __VA_ARGS__)
 194:./include/linux/atomic/atomic-arch-fallback.h **** #else
 195:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg(_ptr, _oldp, _new) \
 196:./include/linux/atomic/atomic-arch-fallback.h **** ({ \
 197:./include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 198:./include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg((_ptr), ___o, (_new)); \
 199:./include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 200:./include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 201:./include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 202:./include/linux/atomic/atomic-arch-fallback.h **** })
 203:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 204:./include/linux/atomic/atomic-arch-fallback.h **** 
 205:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg_acquire)
 206:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_acquire arch_try_cmpxchg_acquire
 207:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg_relaxed)
 208:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_acquire(...) \
 209:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_acquire(arch_try_cmpxchg, __VA_ARGS__)
 210:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg)
 211:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_acquire arch_try_cmpxchg
 212:./include/linux/atomic/atomic-arch-fallback.h **** #else
 213:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_acquire(_ptr, _oldp, _new) \
 214:./include/linux/atomic/atomic-arch-fallback.h **** ({ \
 215:./include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 216:./include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg_acquire((_ptr), ___o, (_new)); \
 217:./include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 218:./include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 219:./include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 220:./include/linux/atomic/atomic-arch-fallback.h **** })
 221:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 222:./include/linux/atomic/atomic-arch-fallback.h **** 
 223:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg_release)
 224:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_release arch_try_cmpxchg_release
 225:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg_relaxed)
 226:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_release(...) \
ARM GAS  /tmp/ccKJN8PY.s 			page 14


 227:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_release(arch_try_cmpxchg, __VA_ARGS__)
 228:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg)
 229:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_release arch_try_cmpxchg
 230:./include/linux/atomic/atomic-arch-fallback.h **** #else
 231:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_release(_ptr, _oldp, _new) \
 232:./include/linux/atomic/atomic-arch-fallback.h **** ({ \
 233:./include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 234:./include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg_release((_ptr), ___o, (_new)); \
 235:./include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 236:./include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 237:./include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 238:./include/linux/atomic/atomic-arch-fallback.h **** })
 239:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 240:./include/linux/atomic/atomic-arch-fallback.h **** 
 241:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg_relaxed)
 242:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_relaxed arch_try_cmpxchg_relaxed
 243:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg)
 244:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_relaxed arch_try_cmpxchg
 245:./include/linux/atomic/atomic-arch-fallback.h **** #else
 246:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_relaxed(_ptr, _oldp, _new) \
 247:./include/linux/atomic/atomic-arch-fallback.h **** ({ \
 248:./include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 249:./include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg_relaxed((_ptr), ___o, (_new)); \
 250:./include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 251:./include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 252:./include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 253:./include/linux/atomic/atomic-arch-fallback.h **** })
 254:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 255:./include/linux/atomic/atomic-arch-fallback.h **** 
 256:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg64)
 257:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64 arch_try_cmpxchg64
 258:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg64_relaxed)
 259:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64(...) \
 260:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_fence(arch_try_cmpxchg64, __VA_ARGS__)
 261:./include/linux/atomic/atomic-arch-fallback.h **** #else
 262:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64(_ptr, _oldp, _new) \
 263:./include/linux/atomic/atomic-arch-fallback.h **** ({ \
 264:./include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 265:./include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg64((_ptr), ___o, (_new)); \
 266:./include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 267:./include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 268:./include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 269:./include/linux/atomic/atomic-arch-fallback.h **** })
 270:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 271:./include/linux/atomic/atomic-arch-fallback.h **** 
 272:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg64_acquire)
 273:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_acquire arch_try_cmpxchg64_acquire
 274:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg64_relaxed)
 275:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_acquire(...) \
 276:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_acquire(arch_try_cmpxchg64, __VA_ARGS__)
 277:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg64)
 278:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_acquire arch_try_cmpxchg64
 279:./include/linux/atomic/atomic-arch-fallback.h **** #else
 280:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_acquire(_ptr, _oldp, _new) \
 281:./include/linux/atomic/atomic-arch-fallback.h **** ({ \
 282:./include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 283:./include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg64_acquire((_ptr), ___o, (_new)); \
ARM GAS  /tmp/ccKJN8PY.s 			page 15


 284:./include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 285:./include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 286:./include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 287:./include/linux/atomic/atomic-arch-fallback.h **** })
 288:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 289:./include/linux/atomic/atomic-arch-fallback.h **** 
 290:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg64_release)
 291:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_release arch_try_cmpxchg64_release
 292:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg64_relaxed)
 293:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_release(...) \
 294:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_release(arch_try_cmpxchg64, __VA_ARGS__)
 295:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg64)
 296:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_release arch_try_cmpxchg64
 297:./include/linux/atomic/atomic-arch-fallback.h **** #else
 298:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_release(_ptr, _oldp, _new) \
 299:./include/linux/atomic/atomic-arch-fallback.h **** ({ \
 300:./include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 301:./include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg64_release((_ptr), ___o, (_new)); \
 302:./include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 303:./include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 304:./include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 305:./include/linux/atomic/atomic-arch-fallback.h **** })
 306:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 307:./include/linux/atomic/atomic-arch-fallback.h **** 
 308:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg64_relaxed)
 309:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_relaxed arch_try_cmpxchg64_relaxed
 310:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg64)
 311:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_relaxed arch_try_cmpxchg64
 312:./include/linux/atomic/atomic-arch-fallback.h **** #else
 313:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_relaxed(_ptr, _oldp, _new) \
 314:./include/linux/atomic/atomic-arch-fallback.h **** ({ \
 315:./include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 316:./include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg64_relaxed((_ptr), ___o, (_new)); \
 317:./include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 318:./include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 319:./include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 320:./include/linux/atomic/atomic-arch-fallback.h **** })
 321:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 322:./include/linux/atomic/atomic-arch-fallback.h **** 
 323:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg128)
 324:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128 arch_try_cmpxchg128
 325:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg128_relaxed)
 326:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128(...) \
 327:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_fence(arch_try_cmpxchg128, __VA_ARGS__)
 328:./include/linux/atomic/atomic-arch-fallback.h **** #else
 329:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128(_ptr, _oldp, _new) \
 330:./include/linux/atomic/atomic-arch-fallback.h **** ({ \
 331:./include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 332:./include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg128((_ptr), ___o, (_new)); \
 333:./include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 334:./include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 335:./include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 336:./include/linux/atomic/atomic-arch-fallback.h **** })
 337:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 338:./include/linux/atomic/atomic-arch-fallback.h **** 
 339:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg128_acquire)
 340:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_acquire arch_try_cmpxchg128_acquire
ARM GAS  /tmp/ccKJN8PY.s 			page 16


 341:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg128_relaxed)
 342:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_acquire(...) \
 343:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_acquire(arch_try_cmpxchg128, __VA_ARGS__)
 344:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg128)
 345:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_acquire arch_try_cmpxchg128
 346:./include/linux/atomic/atomic-arch-fallback.h **** #else
 347:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_acquire(_ptr, _oldp, _new) \
 348:./include/linux/atomic/atomic-arch-fallback.h **** ({ \
 349:./include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 350:./include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg128_acquire((_ptr), ___o, (_new)); \
 351:./include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 352:./include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 353:./include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 354:./include/linux/atomic/atomic-arch-fallback.h **** })
 355:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 356:./include/linux/atomic/atomic-arch-fallback.h **** 
 357:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg128_release)
 358:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_release arch_try_cmpxchg128_release
 359:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg128_relaxed)
 360:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_release(...) \
 361:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_release(arch_try_cmpxchg128, __VA_ARGS__)
 362:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg128)
 363:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_release arch_try_cmpxchg128
 364:./include/linux/atomic/atomic-arch-fallback.h **** #else
 365:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_release(_ptr, _oldp, _new) \
 366:./include/linux/atomic/atomic-arch-fallback.h **** ({ \
 367:./include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 368:./include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg128_release((_ptr), ___o, (_new)); \
 369:./include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 370:./include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 371:./include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 372:./include/linux/atomic/atomic-arch-fallback.h **** })
 373:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 374:./include/linux/atomic/atomic-arch-fallback.h **** 
 375:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg128_relaxed)
 376:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_relaxed arch_try_cmpxchg128_relaxed
 377:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg128)
 378:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_relaxed arch_try_cmpxchg128
 379:./include/linux/atomic/atomic-arch-fallback.h **** #else
 380:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_relaxed(_ptr, _oldp, _new) \
 381:./include/linux/atomic/atomic-arch-fallback.h **** ({ \
 382:./include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 383:./include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg128_relaxed((_ptr), ___o, (_new)); \
 384:./include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 385:./include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 386:./include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 387:./include/linux/atomic/atomic-arch-fallback.h **** })
 388:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 389:./include/linux/atomic/atomic-arch-fallback.h **** 
 390:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_local arch_cmpxchg_local
 391:./include/linux/atomic/atomic-arch-fallback.h **** 
 392:./include/linux/atomic/atomic-arch-fallback.h **** #ifdef arch_try_cmpxchg_local
 393:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_local arch_try_cmpxchg_local
 394:./include/linux/atomic/atomic-arch-fallback.h **** #else
 395:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_local(_ptr, _oldp, _new) \
 396:./include/linux/atomic/atomic-arch-fallback.h **** ({ \
 397:./include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
ARM GAS  /tmp/ccKJN8PY.s 			page 17


 398:./include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg_local((_ptr), ___o, (_new)); \
 399:./include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 400:./include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 401:./include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 402:./include/linux/atomic/atomic-arch-fallback.h **** })
 403:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 404:./include/linux/atomic/atomic-arch-fallback.h **** 
 405:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_local arch_cmpxchg64_local
 406:./include/linux/atomic/atomic-arch-fallback.h **** 
 407:./include/linux/atomic/atomic-arch-fallback.h **** #ifdef arch_try_cmpxchg64_local
 408:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_local arch_try_cmpxchg64_local
 409:./include/linux/atomic/atomic-arch-fallback.h **** #else
 410:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_local(_ptr, _oldp, _new) \
 411:./include/linux/atomic/atomic-arch-fallback.h **** ({ \
 412:./include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 413:./include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg64_local((_ptr), ___o, (_new)); \
 414:./include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 415:./include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 416:./include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 417:./include/linux/atomic/atomic-arch-fallback.h **** })
 418:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 419:./include/linux/atomic/atomic-arch-fallback.h **** 
 420:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_local arch_cmpxchg128_local
 421:./include/linux/atomic/atomic-arch-fallback.h **** 
 422:./include/linux/atomic/atomic-arch-fallback.h **** #ifdef arch_try_cmpxchg128_local
 423:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_local arch_try_cmpxchg128_local
 424:./include/linux/atomic/atomic-arch-fallback.h **** #else
 425:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_local(_ptr, _oldp, _new) \
 426:./include/linux/atomic/atomic-arch-fallback.h **** ({ \
 427:./include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 428:./include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg128_local((_ptr), ___o, (_new)); \
 429:./include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 430:./include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 431:./include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 432:./include/linux/atomic/atomic-arch-fallback.h **** })
 433:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 434:./include/linux/atomic/atomic-arch-fallback.h **** 
 435:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_sync_cmpxchg arch_sync_cmpxchg
 436:./include/linux/atomic/atomic-arch-fallback.h **** 
 437:./include/linux/atomic/atomic-arch-fallback.h **** #ifdef arch_sync_try_cmpxchg
 438:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_sync_try_cmpxchg arch_sync_try_cmpxchg
 439:./include/linux/atomic/atomic-arch-fallback.h **** #else
 440:./include/linux/atomic/atomic-arch-fallback.h **** #define raw_sync_try_cmpxchg(_ptr, _oldp, _new) \
 441:./include/linux/atomic/atomic-arch-fallback.h **** ({ \
 442:./include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 443:./include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_sync_cmpxchg((_ptr), ___o, (_new)); \
 444:./include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 445:./include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 446:./include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 447:./include/linux/atomic/atomic-arch-fallback.h **** })
 448:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 449:./include/linux/atomic/atomic-arch-fallback.h **** 
 450:./include/linux/atomic/atomic-arch-fallback.h **** /**
 451:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_read() - atomic load with relaxed ordering
 452:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 453:./include/linux/atomic/atomic-arch-fallback.h ****  *
 454:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically loads the value of @v with relaxed ordering.
ARM GAS  /tmp/ccKJN8PY.s 			page 18


 455:./include/linux/atomic/atomic-arch-fallback.h ****  *
 456:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_read() elsewhere.
 457:./include/linux/atomic/atomic-arch-fallback.h ****  *
 458:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The value loaded from @v.
 459:./include/linux/atomic/atomic-arch-fallback.h ****  */
 460:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 461:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_read(const atomic_t *v)
 462:./include/linux/atomic/atomic-arch-fallback.h **** {
 463:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_read(v);
 464:./include/linux/atomic/atomic-arch-fallback.h **** }
 465:./include/linux/atomic/atomic-arch-fallback.h **** 
 466:./include/linux/atomic/atomic-arch-fallback.h **** /**
 467:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_read_acquire() - atomic load with acquire ordering
 468:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 469:./include/linux/atomic/atomic-arch-fallback.h ****  *
 470:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically loads the value of @v with acquire ordering.
 471:./include/linux/atomic/atomic-arch-fallback.h ****  *
 472:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_read_acquire() elsewhere.
 473:./include/linux/atomic/atomic-arch-fallback.h ****  *
 474:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The value loaded from @v.
 475:./include/linux/atomic/atomic-arch-fallback.h ****  */
 476:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 477:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_read_acquire(const atomic_t *v)
 478:./include/linux/atomic/atomic-arch-fallback.h **** {
 479:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_read_acquire)
 480:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_read_acquire(v);
 481:./include/linux/atomic/atomic-arch-fallback.h **** #else
 482:./include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
 483:./include/linux/atomic/atomic-arch-fallback.h **** 
 484:./include/linux/atomic/atomic-arch-fallback.h **** 	if (__native_word(atomic_t)) {
 485:./include/linux/atomic/atomic-arch-fallback.h **** 		ret = smp_load_acquire(&(v)->counter);
 486:./include/linux/atomic/atomic-arch-fallback.h **** 	} else {
 487:./include/linux/atomic/atomic-arch-fallback.h **** 		ret = raw_atomic_read(v);
 488:./include/linux/atomic/atomic-arch-fallback.h **** 		__atomic_acquire_fence();
 489:./include/linux/atomic/atomic-arch-fallback.h **** 	}
 490:./include/linux/atomic/atomic-arch-fallback.h **** 
 491:./include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
 492:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 493:./include/linux/atomic/atomic-arch-fallback.h **** }
 494:./include/linux/atomic/atomic-arch-fallback.h **** 
 495:./include/linux/atomic/atomic-arch-fallback.h **** /**
 496:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_set() - atomic set with relaxed ordering
 497:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 498:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to assign
 499:./include/linux/atomic/atomic-arch-fallback.h ****  *
 500:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically sets @v to @i with relaxed ordering.
 501:./include/linux/atomic/atomic-arch-fallback.h ****  *
 502:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_set() elsewhere.
 503:./include/linux/atomic/atomic-arch-fallback.h ****  *
 504:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: Nothing.
 505:./include/linux/atomic/atomic-arch-fallback.h ****  */
 506:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline void
 507:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_set(atomic_t *v, int i)
 508:./include/linux/atomic/atomic-arch-fallback.h **** {
 509:./include/linux/atomic/atomic-arch-fallback.h **** 	arch_atomic_set(v, i);
 510:./include/linux/atomic/atomic-arch-fallback.h **** }
 511:./include/linux/atomic/atomic-arch-fallback.h **** 
ARM GAS  /tmp/ccKJN8PY.s 			page 19


 512:./include/linux/atomic/atomic-arch-fallback.h **** /**
 513:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_set_release() - atomic set with release ordering
 514:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 515:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to assign
 516:./include/linux/atomic/atomic-arch-fallback.h ****  *
 517:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically sets @v to @i with release ordering.
 518:./include/linux/atomic/atomic-arch-fallback.h ****  *
 519:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_set_release() elsewhere.
 520:./include/linux/atomic/atomic-arch-fallback.h ****  *
 521:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: Nothing.
 522:./include/linux/atomic/atomic-arch-fallback.h ****  */
 523:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline void
 524:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_set_release(atomic_t *v, int i)
 525:./include/linux/atomic/atomic-arch-fallback.h **** {
 526:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_set_release)
 527:./include/linux/atomic/atomic-arch-fallback.h **** 	arch_atomic_set_release(v, i);
 528:./include/linux/atomic/atomic-arch-fallback.h **** #else
 529:./include/linux/atomic/atomic-arch-fallback.h **** 	if (__native_word(atomic_t)) {
 530:./include/linux/atomic/atomic-arch-fallback.h **** 		smp_store_release(&(v)->counter, i);
 531:./include/linux/atomic/atomic-arch-fallback.h **** 	} else {
 532:./include/linux/atomic/atomic-arch-fallback.h **** 		__atomic_release_fence();
 533:./include/linux/atomic/atomic-arch-fallback.h **** 		raw_atomic_set(v, i);
 534:./include/linux/atomic/atomic-arch-fallback.h **** 	}
 535:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 536:./include/linux/atomic/atomic-arch-fallback.h **** }
 537:./include/linux/atomic/atomic-arch-fallback.h **** 
 538:./include/linux/atomic/atomic-arch-fallback.h **** /**
 539:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_add() - atomic add with relaxed ordering
 540:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to add
 541:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 542:./include/linux/atomic/atomic-arch-fallback.h ****  *
 543:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + @i) with relaxed ordering.
 544:./include/linux/atomic/atomic-arch-fallback.h ****  *
 545:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_add() elsewhere.
 546:./include/linux/atomic/atomic-arch-fallback.h ****  *
 547:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: Nothing.
 548:./include/linux/atomic/atomic-arch-fallback.h ****  */
 549:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline void
 550:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_add(int i, atomic_t *v)
 551:./include/linux/atomic/atomic-arch-fallback.h **** {
 552:./include/linux/atomic/atomic-arch-fallback.h **** 	arch_atomic_add(i, v);
 553:./include/linux/atomic/atomic-arch-fallback.h **** }
 554:./include/linux/atomic/atomic-arch-fallback.h **** 
 555:./include/linux/atomic/atomic-arch-fallback.h **** /**
 556:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_add_return() - atomic add with full ordering
 557:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to add
 558:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 559:./include/linux/atomic/atomic-arch-fallback.h ****  *
 560:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + @i) with full ordering.
 561:./include/linux/atomic/atomic-arch-fallback.h ****  *
 562:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_add_return() elsewhere.
 563:./include/linux/atomic/atomic-arch-fallback.h ****  *
 564:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
 565:./include/linux/atomic/atomic-arch-fallback.h ****  */
 566:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 567:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_add_return(int i, atomic_t *v)
 568:./include/linux/atomic/atomic-arch-fallback.h **** {
ARM GAS  /tmp/ccKJN8PY.s 			page 20


 569:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_add_return)
 570:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_add_return(i, v);
 571:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_add_return_relaxed)
 572:./include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
 573:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
 574:./include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_add_return_relaxed(i, v);
 575:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
 576:./include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
 577:./include/linux/atomic/atomic-arch-fallback.h **** #else
 578:./include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_add_return"
 579:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 580:./include/linux/atomic/atomic-arch-fallback.h **** }
 581:./include/linux/atomic/atomic-arch-fallback.h **** 
 582:./include/linux/atomic/atomic-arch-fallback.h **** /**
 583:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_add_return_acquire() - atomic add with acquire ordering
 584:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to add
 585:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 586:./include/linux/atomic/atomic-arch-fallback.h ****  *
 587:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + @i) with acquire ordering.
 588:./include/linux/atomic/atomic-arch-fallback.h ****  *
 589:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_add_return_acquire() elsewhere.
 590:./include/linux/atomic/atomic-arch-fallback.h ****  *
 591:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
 592:./include/linux/atomic/atomic-arch-fallback.h ****  */
 593:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 594:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_add_return_acquire(int i, atomic_t *v)
 595:./include/linux/atomic/atomic-arch-fallback.h **** {
 596:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_add_return_acquire)
 597:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_add_return_acquire(i, v);
 598:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_add_return_relaxed)
 599:./include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_add_return_relaxed(i, v);
 600:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
 601:./include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
 602:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_add_return)
 603:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_add_return(i, v);
 604:./include/linux/atomic/atomic-arch-fallback.h **** #else
 605:./include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_add_return_acquire"
 606:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 607:./include/linux/atomic/atomic-arch-fallback.h **** }
 608:./include/linux/atomic/atomic-arch-fallback.h **** 
 609:./include/linux/atomic/atomic-arch-fallback.h **** /**
 610:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_add_return_release() - atomic add with release ordering
 611:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to add
 612:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 613:./include/linux/atomic/atomic-arch-fallback.h ****  *
 614:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + @i) with release ordering.
 615:./include/linux/atomic/atomic-arch-fallback.h ****  *
 616:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_add_return_release() elsewhere.
 617:./include/linux/atomic/atomic-arch-fallback.h ****  *
 618:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
 619:./include/linux/atomic/atomic-arch-fallback.h ****  */
 620:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 621:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_add_return_release(int i, atomic_t *v)
 622:./include/linux/atomic/atomic-arch-fallback.h **** {
 623:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_add_return_release)
 624:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_add_return_release(i, v);
 625:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_add_return_relaxed)
ARM GAS  /tmp/ccKJN8PY.s 			page 21


 626:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
 627:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_add_return_relaxed(i, v);
 628:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_add_return)
 629:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_add_return(i, v);
 630:./include/linux/atomic/atomic-arch-fallback.h **** #else
 631:./include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_add_return_release"
 632:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 633:./include/linux/atomic/atomic-arch-fallback.h **** }
 634:./include/linux/atomic/atomic-arch-fallback.h **** 
 635:./include/linux/atomic/atomic-arch-fallback.h **** /**
 636:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_add_return_relaxed() - atomic add with relaxed ordering
 637:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to add
 638:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 639:./include/linux/atomic/atomic-arch-fallback.h ****  *
 640:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + @i) with relaxed ordering.
 641:./include/linux/atomic/atomic-arch-fallback.h ****  *
 642:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_add_return_relaxed() elsewhere.
 643:./include/linux/atomic/atomic-arch-fallback.h ****  *
 644:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
 645:./include/linux/atomic/atomic-arch-fallback.h ****  */
 646:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 647:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_add_return_relaxed(int i, atomic_t *v)
 648:./include/linux/atomic/atomic-arch-fallback.h **** {
 649:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_add_return_relaxed)
 650:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_add_return_relaxed(i, v);
 651:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_add_return)
 652:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_add_return(i, v);
 653:./include/linux/atomic/atomic-arch-fallback.h **** #else
 654:./include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_add_return_relaxed"
 655:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 656:./include/linux/atomic/atomic-arch-fallback.h **** }
 657:./include/linux/atomic/atomic-arch-fallback.h **** 
 658:./include/linux/atomic/atomic-arch-fallback.h **** /**
 659:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_add() - atomic add with full ordering
 660:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to add
 661:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 662:./include/linux/atomic/atomic-arch-fallback.h ****  *
 663:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + @i) with full ordering.
 664:./include/linux/atomic/atomic-arch-fallback.h ****  *
 665:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_add() elsewhere.
 666:./include/linux/atomic/atomic-arch-fallback.h ****  *
 667:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
 668:./include/linux/atomic/atomic-arch-fallback.h ****  */
 669:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 670:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_add(int i, atomic_t *v)
 671:./include/linux/atomic/atomic-arch-fallback.h **** {
 672:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_add)
 673:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_add(i, v);
 674:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_add_relaxed)
 675:./include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
 676:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
 677:./include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_fetch_add_relaxed(i, v);
 678:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
 679:./include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
 680:./include/linux/atomic/atomic-arch-fallback.h **** #else
 681:./include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_add"
 682:./include/linux/atomic/atomic-arch-fallback.h **** #endif
ARM GAS  /tmp/ccKJN8PY.s 			page 22


 683:./include/linux/atomic/atomic-arch-fallback.h **** }
 684:./include/linux/atomic/atomic-arch-fallback.h **** 
 685:./include/linux/atomic/atomic-arch-fallback.h **** /**
 686:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_add_acquire() - atomic add with acquire ordering
 687:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to add
 688:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 689:./include/linux/atomic/atomic-arch-fallback.h ****  *
 690:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + @i) with acquire ordering.
 691:./include/linux/atomic/atomic-arch-fallback.h ****  *
 692:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_add_acquire() elsewhere.
 693:./include/linux/atomic/atomic-arch-fallback.h ****  *
 694:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
 695:./include/linux/atomic/atomic-arch-fallback.h ****  */
 696:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 697:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_add_acquire(int i, atomic_t *v)
 698:./include/linux/atomic/atomic-arch-fallback.h **** {
 699:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_add_acquire)
 700:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_add_acquire(i, v);
 701:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_add_relaxed)
 702:./include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_fetch_add_relaxed(i, v);
 703:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
 704:./include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
 705:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_add)
 706:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_add(i, v);
 707:./include/linux/atomic/atomic-arch-fallback.h **** #else
 708:./include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_add_acquire"
 709:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 710:./include/linux/atomic/atomic-arch-fallback.h **** }
 711:./include/linux/atomic/atomic-arch-fallback.h **** 
 712:./include/linux/atomic/atomic-arch-fallback.h **** /**
 713:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_add_release() - atomic add with release ordering
 714:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to add
 715:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 716:./include/linux/atomic/atomic-arch-fallback.h ****  *
 717:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + @i) with release ordering.
 718:./include/linux/atomic/atomic-arch-fallback.h ****  *
 719:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_add_release() elsewhere.
 720:./include/linux/atomic/atomic-arch-fallback.h ****  *
 721:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
 722:./include/linux/atomic/atomic-arch-fallback.h ****  */
 723:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 724:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_add_release(int i, atomic_t *v)
 725:./include/linux/atomic/atomic-arch-fallback.h **** {
 726:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_add_release)
 727:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_add_release(i, v);
 728:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_add_relaxed)
 729:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
 730:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_add_relaxed(i, v);
 731:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_add)
 732:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_add(i, v);
 733:./include/linux/atomic/atomic-arch-fallback.h **** #else
 734:./include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_add_release"
 735:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 736:./include/linux/atomic/atomic-arch-fallback.h **** }
 737:./include/linux/atomic/atomic-arch-fallback.h **** 
 738:./include/linux/atomic/atomic-arch-fallback.h **** /**
 739:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_add_relaxed() - atomic add with relaxed ordering
ARM GAS  /tmp/ccKJN8PY.s 			page 23


 740:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to add
 741:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 742:./include/linux/atomic/atomic-arch-fallback.h ****  *
 743:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + @i) with relaxed ordering.
 744:./include/linux/atomic/atomic-arch-fallback.h ****  *
 745:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_add_relaxed() elsewhere.
 746:./include/linux/atomic/atomic-arch-fallback.h ****  *
 747:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
 748:./include/linux/atomic/atomic-arch-fallback.h ****  */
 749:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 750:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_add_relaxed(int i, atomic_t *v)
 751:./include/linux/atomic/atomic-arch-fallback.h **** {
 752:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_add_relaxed)
 753:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_add_relaxed(i, v);
 754:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_add)
 755:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_add(i, v);
 756:./include/linux/atomic/atomic-arch-fallback.h **** #else
 757:./include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_add_relaxed"
 758:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 759:./include/linux/atomic/atomic-arch-fallback.h **** }
 760:./include/linux/atomic/atomic-arch-fallback.h **** 
 761:./include/linux/atomic/atomic-arch-fallback.h **** /**
 762:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_sub() - atomic subtract with relaxed ordering
 763:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to subtract
 764:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 765:./include/linux/atomic/atomic-arch-fallback.h ****  *
 766:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - @i) with relaxed ordering.
 767:./include/linux/atomic/atomic-arch-fallback.h ****  *
 768:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_sub() elsewhere.
 769:./include/linux/atomic/atomic-arch-fallback.h ****  *
 770:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: Nothing.
 771:./include/linux/atomic/atomic-arch-fallback.h ****  */
 772:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline void
 773:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_sub(int i, atomic_t *v)
 774:./include/linux/atomic/atomic-arch-fallback.h **** {
 775:./include/linux/atomic/atomic-arch-fallback.h **** 	arch_atomic_sub(i, v);
 776:./include/linux/atomic/atomic-arch-fallback.h **** }
 777:./include/linux/atomic/atomic-arch-fallback.h **** 
 778:./include/linux/atomic/atomic-arch-fallback.h **** /**
 779:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_sub_return() - atomic subtract with full ordering
 780:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to subtract
 781:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 782:./include/linux/atomic/atomic-arch-fallback.h ****  *
 783:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - @i) with full ordering.
 784:./include/linux/atomic/atomic-arch-fallback.h ****  *
 785:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_sub_return() elsewhere.
 786:./include/linux/atomic/atomic-arch-fallback.h ****  *
 787:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
 788:./include/linux/atomic/atomic-arch-fallback.h ****  */
 789:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 790:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_sub_return(int i, atomic_t *v)
 791:./include/linux/atomic/atomic-arch-fallback.h **** {
 792:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_sub_return)
 793:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_sub_return(i, v);
 794:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_sub_return_relaxed)
 795:./include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
 796:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
ARM GAS  /tmp/ccKJN8PY.s 			page 24


 797:./include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_sub_return_relaxed(i, v);
 798:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
 799:./include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
 800:./include/linux/atomic/atomic-arch-fallback.h **** #else
 801:./include/linux/atomic/atomic-arch-fallback.h **** 	volatile int *p = (volatile int *)&v->counter;
 802:./include/linux/atomic/atomic-arch-fallback.h **** 	int ret = *p;
 803:./include/linux/atomic/atomic-arch-fallback.h **** 	*p -= i;
 804:./include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
 805:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 806:./include/linux/atomic/atomic-arch-fallback.h **** }
 807:./include/linux/atomic/atomic-arch-fallback.h **** 
 808:./include/linux/atomic/atomic-arch-fallback.h **** 
 809:./include/linux/atomic/atomic-arch-fallback.h **** /**
 810:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_sub_return_acquire() - atomic subtract with acquire ordering
 811:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to subtract
 812:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 813:./include/linux/atomic/atomic-arch-fallback.h ****  *
 814:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - @i) with acquire ordering.
 815:./include/linux/atomic/atomic-arch-fallback.h ****  *
 816:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_sub_return_acquire() elsewhere.
 817:./include/linux/atomic/atomic-arch-fallback.h ****  *
 818:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
 819:./include/linux/atomic/atomic-arch-fallback.h ****  */
 820:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 821:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_sub_return_acquire(int i, atomic_t *v)
 822:./include/linux/atomic/atomic-arch-fallback.h **** {
 823:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_sub_return_acquire)
 824:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_sub_return_acquire(i, v);
 825:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_sub_return_relaxed)
 826:./include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_sub_return_relaxed(i, v);
 827:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
 828:./include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
 829:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_sub_return)
 830:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_sub_return(i, v);
 831:./include/linux/atomic/atomic-arch-fallback.h **** #else
 832:./include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_sub_return_acquire"
 833:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 834:./include/linux/atomic/atomic-arch-fallback.h **** }
 835:./include/linux/atomic/atomic-arch-fallback.h **** 
 836:./include/linux/atomic/atomic-arch-fallback.h **** /**
 837:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_sub_return_release() - atomic subtract with release ordering
 838:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to subtract
 839:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 840:./include/linux/atomic/atomic-arch-fallback.h ****  *
 841:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - @i) with release ordering.
 842:./include/linux/atomic/atomic-arch-fallback.h ****  *
 843:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_sub_return_release() elsewhere.
 844:./include/linux/atomic/atomic-arch-fallback.h ****  *
 845:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
 846:./include/linux/atomic/atomic-arch-fallback.h ****  */
 847:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 848:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_sub_return_release(int i, atomic_t *v)
 849:./include/linux/atomic/atomic-arch-fallback.h **** {
 850:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_sub_return_release)
 851:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_sub_return_release(i, v);
 852:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_sub_return_relaxed)
 853:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
ARM GAS  /tmp/ccKJN8PY.s 			page 25


 854:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_sub_return_relaxed(i, v);
 855:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_sub_return)
 856:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_sub_return(i, v);
 857:./include/linux/atomic/atomic-arch-fallback.h **** #else
 858:./include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_sub_return_release"
 859:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 860:./include/linux/atomic/atomic-arch-fallback.h **** }
 861:./include/linux/atomic/atomic-arch-fallback.h **** 
 862:./include/linux/atomic/atomic-arch-fallback.h **** /**
 863:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_sub_return_relaxed() - atomic subtract with relaxed ordering
 864:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to subtract
 865:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 866:./include/linux/atomic/atomic-arch-fallback.h ****  *
 867:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - @i) with relaxed ordering.
 868:./include/linux/atomic/atomic-arch-fallback.h ****  *
 869:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_sub_return_relaxed() elsewhere.
 870:./include/linux/atomic/atomic-arch-fallback.h ****  *
 871:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
 872:./include/linux/atomic/atomic-arch-fallback.h ****  */
 873:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 874:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_sub_return_relaxed(int i, atomic_t *v)
 875:./include/linux/atomic/atomic-arch-fallback.h **** {
 876:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_sub_return_relaxed)
 877:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_sub_return_relaxed(i, v);
 878:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_sub_return)
 879:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_sub_return(i, v);
 880:./include/linux/atomic/atomic-arch-fallback.h **** #else
 881:./include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_sub_return_relaxed"
 882:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 883:./include/linux/atomic/atomic-arch-fallback.h **** }
 884:./include/linux/atomic/atomic-arch-fallback.h **** 
 885:./include/linux/atomic/atomic-arch-fallback.h **** /**
 886:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_sub() - atomic subtract with full ordering
 887:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to subtract
 888:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 889:./include/linux/atomic/atomic-arch-fallback.h ****  *
 890:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - @i) with full ordering.
 891:./include/linux/atomic/atomic-arch-fallback.h ****  *
 892:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_sub() elsewhere.
 893:./include/linux/atomic/atomic-arch-fallback.h ****  *
 894:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
 895:./include/linux/atomic/atomic-arch-fallback.h ****  */
 896:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 897:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_sub(int i, atomic_t *v)
 898:./include/linux/atomic/atomic-arch-fallback.h **** {
 899:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_sub)
 900:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_sub(i, v);
 901:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_sub_relaxed)
 902:./include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
 903:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
 904:./include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_fetch_sub_relaxed(i, v);
 905:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
 906:./include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
 907:./include/linux/atomic/atomic-arch-fallback.h **** #else
 908:./include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_sub"
 909:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 910:./include/linux/atomic/atomic-arch-fallback.h **** }
ARM GAS  /tmp/ccKJN8PY.s 			page 26


 911:./include/linux/atomic/atomic-arch-fallback.h **** 
 912:./include/linux/atomic/atomic-arch-fallback.h **** /**
 913:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_sub_acquire() - atomic subtract with acquire ordering
 914:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to subtract
 915:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 916:./include/linux/atomic/atomic-arch-fallback.h ****  *
 917:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - @i) with acquire ordering.
 918:./include/linux/atomic/atomic-arch-fallback.h ****  *
 919:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_sub_acquire() elsewhere.
 920:./include/linux/atomic/atomic-arch-fallback.h ****  *
 921:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
 922:./include/linux/atomic/atomic-arch-fallback.h ****  */
 923:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 924:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_sub_acquire(int i, atomic_t *v)
 925:./include/linux/atomic/atomic-arch-fallback.h **** {
 926:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_sub_acquire)
 927:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_sub_acquire(i, v);
 928:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_sub_relaxed)
 929:./include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_fetch_sub_relaxed(i, v);
 930:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
 931:./include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
 932:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_sub)
 933:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_sub(i, v);
 934:./include/linux/atomic/atomic-arch-fallback.h **** #else
 935:./include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_sub_acquire"
 936:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 937:./include/linux/atomic/atomic-arch-fallback.h **** }
 938:./include/linux/atomic/atomic-arch-fallback.h **** 
 939:./include/linux/atomic/atomic-arch-fallback.h **** /**
 940:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_sub_release() - atomic subtract with release ordering
 941:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to subtract
 942:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 943:./include/linux/atomic/atomic-arch-fallback.h ****  *
 944:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - @i) with release ordering.
 945:./include/linux/atomic/atomic-arch-fallback.h ****  *
 946:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_sub_release() elsewhere.
 947:./include/linux/atomic/atomic-arch-fallback.h ****  *
 948:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
 949:./include/linux/atomic/atomic-arch-fallback.h ****  */
 950:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 951:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_sub_release(int i, atomic_t *v)
 952:./include/linux/atomic/atomic-arch-fallback.h **** {
 953:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_sub_release)
 954:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_sub_release(i, v);
 955:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_sub_relaxed)
 956:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
 957:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_sub_relaxed(i, v);
 958:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_sub)
 959:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_sub(i, v);
 960:./include/linux/atomic/atomic-arch-fallback.h **** #else
 961:./include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_sub_release"
 962:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 963:./include/linux/atomic/atomic-arch-fallback.h **** }
 964:./include/linux/atomic/atomic-arch-fallback.h **** 
 965:./include/linux/atomic/atomic-arch-fallback.h **** /**
 966:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_sub_relaxed() - atomic subtract with relaxed ordering
 967:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to subtract
ARM GAS  /tmp/ccKJN8PY.s 			page 27


 968:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 969:./include/linux/atomic/atomic-arch-fallback.h ****  *
 970:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - @i) with relaxed ordering.
 971:./include/linux/atomic/atomic-arch-fallback.h ****  *
 972:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_sub_relaxed() elsewhere.
 973:./include/linux/atomic/atomic-arch-fallback.h ****  *
 974:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
 975:./include/linux/atomic/atomic-arch-fallback.h ****  */
 976:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 977:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_sub_relaxed(int i, atomic_t *v)
 978:./include/linux/atomic/atomic-arch-fallback.h **** {
 979:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_sub_relaxed)
 980:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_sub_relaxed(i, v);
 981:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_sub)
 982:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_sub(i, v);
 983:./include/linux/atomic/atomic-arch-fallback.h **** #else
 984:./include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_sub_relaxed"
 985:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 986:./include/linux/atomic/atomic-arch-fallback.h **** }
 987:./include/linux/atomic/atomic-arch-fallback.h **** 
 988:./include/linux/atomic/atomic-arch-fallback.h **** /**
 989:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_inc() - atomic increment with relaxed ordering
 990:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 991:./include/linux/atomic/atomic-arch-fallback.h ****  *
 992:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + 1) with relaxed ordering.
 993:./include/linux/atomic/atomic-arch-fallback.h ****  *
 994:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_inc() elsewhere.
 995:./include/linux/atomic/atomic-arch-fallback.h ****  *
 996:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: Nothing.
 997:./include/linux/atomic/atomic-arch-fallback.h ****  */
 998:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline void
 999:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_inc(atomic_t *v)
  47              		.loc 3 999 1 view .LVU5
1000:./include/linux/atomic/atomic-arch-fallback.h **** {
1001:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_inc)
1002:./include/linux/atomic/atomic-arch-fallback.h **** 	arch_atomic_inc(v);
1003:./include/linux/atomic/atomic-arch-fallback.h **** #else
1004:./include/linux/atomic/atomic-arch-fallback.h **** 	raw_atomic_add(1, v);
  48              		.loc 3 1004 2 view .LVU6
  49              	.LBB76:
  50              	.LBI76:
 550:./include/linux/atomic/atomic-arch-fallback.h **** {
  51              		.loc 3 550 1 view .LVU7
 552:./include/linux/atomic/atomic-arch-fallback.h **** }
  52              		.loc 3 552 2 view .LVU8
  53              	.LBB77:
  54              	.LBI77:
  55              		.file 4 "./arch/arm_m/include/asm/atomic.h"
   1:./arch/arm_m/include/asm/atomic.h **** /* SPDX-License-Identifier: GPL-2.0-only */
   2:./arch/arm_m/include/asm/atomic.h **** /*
   3:./arch/arm_m/include/asm/atomic.h ****  * arch/arm/include/asm/atomic.h
   4:./arch/arm_m/include/asm/atomic.h ****  *
   5:./arch/arm_m/include/asm/atomic.h ****  * Copyright (C) 1996 Russell King.
   6:./arch/arm_m/include/asm/atomic.h ****  * Copyright (C) 2002 Deep Blue Solutions Ltd.
   7:./arch/arm_m/include/asm/atomic.h ****  * Modified for uClinux on STM32F407
   8:./arch/arm_m/include/asm/atomic.h ****  */
   9:./arch/arm_m/include/asm/atomic.h **** #ifndef __ASM_ARM_ATOMIC_H
ARM GAS  /tmp/ccKJN8PY.s 			page 28


  10:./arch/arm_m/include/asm/atomic.h **** #define __ASM_ARM_ATOMIC_H
  11:./arch/arm_m/include/asm/atomic.h **** 
  12:./arch/arm_m/include/asm/atomic.h **** #include <linux/compiler.h> /* Available */
  13:./arch/arm_m/include/asm/atomic.h **** #include <linux/types.h>    /* Available */
  14:./arch/arm_m/include/asm/atomic.h **** #include <asm/barrier.h>    /* Available */
  15:./arch/arm_m/include/asm/atomic.h **** 
  16:./arch/arm_m/include/asm/atomic.h **** /* Include architecture-specific configuration */
  17:./arch/arm_m/include/asm/atomic.h **** 
  18:./arch/arm_m/include/asm/atomic.h **** 
  19:./arch/arm_m/include/asm/atomic.h **** #ifdef __KERNEL__
  20:./arch/arm_m/include/asm/atomic.h **** 
  21:./arch/arm_m/include/asm/atomic.h **** 
  22:./arch/arm_m/include/asm/atomic.h **** 
  23:./arch/arm_m/include/asm/atomic.h **** 
  24:./arch/arm_m/include/asm/atomic.h **** 
  25:./arch/arm_m/include/asm/atomic.h **** // typedef struct {
  26:./arch/arm_m/include/asm/atomic.h **** //     volatile int counter;
  27:./arch/arm_m/include/asm/atomic.h **** // } atomic_t;
  28:./arch/arm_m/include/asm/atomic.h **** 
  29:./arch/arm_m/include/asm/atomic.h **** #define ATOMIC_INIT(i) { (i) }
  30:./arch/arm_m/include/asm/atomic.h **** 
  31:./arch/arm_m/include/asm/atomic.h **** /*
  32:./arch/arm_m/include/asm/atomic.h ****  * On ARMv7-M, ordinary assignment (str instruction) doesn't clear the local
  33:./arch/arm_m/include/asm/atomic.h ****  * strex/ldrex monitor on some implementations. The reason we can use it for
  34:./arch/arm_m/include/asm/atomic.h ****  * atomic_set() is the clrex or dummy strex done on every exception return.
  35:./arch/arm_m/include/asm/atomic.h ****  */
  36:./arch/arm_m/include/asm/atomic.h **** #define arch_atomic_read(v) READ_ONCE((v)->counter)
  37:./arch/arm_m/include/asm/atomic.h **** #define arch_atomic_set(v,i)    WRITE_ONCE(((v)->counter), (i))
  38:./arch/arm_m/include/asm/atomic.h **** 
  39:./arch/arm_m/include/asm/atomic.h **** /*
  40:./arch/arm_m/include/asm/atomic.h ****  * ARMv6 UP and SMP safe atomic ops.  We use load exclusive and
  41:./arch/arm_m/include/asm/atomic.h ****  * store exclusive to ensure that these are atomic.  We may loop
  42:./arch/arm_m/include/asm/atomic.h ****  * to ensure that the update happens.
  43:./arch/arm_m/include/asm/atomic.h ****  *
  44:./arch/arm_m/include/asm/atomic.h ****  * For STM32F407 (Cortex-M4, ARMv7-M), these instructions are available.
  45:./arch/arm_m/include/asm/atomic.h ****  */
  46:./arch/arm_m/include/asm/atomic.h **** 
  47:./arch/arm_m/include/asm/atomic.h **** #define ATOMIC_OP(op, c_op, asm_op)                     \
  48:./arch/arm_m/include/asm/atomic.h **** static inline void arch_atomic_##op(int i, atomic_t *v)         \
  49:./arch/arm_m/include/asm/atomic.h **** {                                       \
  50:./arch/arm_m/include/asm/atomic.h ****     unsigned long tmp;                          \
  51:./arch/arm_m/include/asm/atomic.h ****     int result;                                 \
  52:./arch/arm_m/include/asm/atomic.h ****                                         \
  53:./arch/arm_m/include/asm/atomic.h ****     /* prefetchw(&v->counter); - prefetch not available */ \
  54:./arch/arm_m/include/asm/atomic.h ****     __asm__ __volatile__("@ atomic_" #op "\n"           \
  55:./arch/arm_m/include/asm/atomic.h **** "1: ldrex   %0, [%3]\n"                      \
  56:./arch/arm_m/include/asm/atomic.h **** "   " #asm_op " %0, %0, %4\n"                \
  57:./arch/arm_m/include/asm/atomic.h **** "   strex   %1, %0, [%3]\n"                      \
  58:./arch/arm_m/include/asm/atomic.h **** "   teq %1, #0\n"                         \
  59:./arch/arm_m/include/asm/atomic.h **** "   bne 1b"                                \
  60:./arch/arm_m/include/asm/atomic.h ****     : "=&r" (result), "=&r" (tmp), "+Qo" (v->counter)     \
  61:./arch/arm_m/include/asm/atomic.h ****     : "r" (&v->counter), "Ir" (i)                 \
  62:./arch/arm_m/include/asm/atomic.h ****     : "cc");                                   \
  63:./arch/arm_m/include/asm/atomic.h **** }
  64:./arch/arm_m/include/asm/atomic.h **** 
  65:./arch/arm_m/include/asm/atomic.h **** #define ATOMIC_OP_RETURN(op, c_op, asm_op)                  \
  66:./arch/arm_m/include/asm/atomic.h **** static inline int arch_atomic_##op##_return_relaxed(int i, atomic_t *v) \
ARM GAS  /tmp/ccKJN8PY.s 			page 29


  67:./arch/arm_m/include/asm/atomic.h **** {                                       \
  68:./arch/arm_m/include/asm/atomic.h ****     unsigned long tmp;                          \
  69:./arch/arm_m/include/asm/atomic.h ****     int result;                                 \
  70:./arch/arm_m/include/asm/atomic.h ****                                         \
  71:./arch/arm_m/include/asm/atomic.h ****     /* prefetchw(&v->counter); - prefetch not available */ \
  72:./arch/arm_m/include/asm/atomic.h ****     __asm__ __volatile__("@ atomic_" #op "_return\n"        \
  73:./arch/arm_m/include/asm/atomic.h **** "1: ldrex   %0, [%3]\n"                      \
  74:./arch/arm_m/include/asm/atomic.h **** "   " #asm_op " %0, %0, %4\n"                \
  75:./arch/arm_m/include/asm/atomic.h **** "   strex   %1, %0, [%3]\n"                      \
  76:./arch/arm_m/include/asm/atomic.h **** "   teq %1, #0\n"                         \
  77:./arch/arm_m/include/asm/atomic.h **** "   bne 1b"                                \
  78:./arch/arm_m/include/asm/atomic.h ****     : "=&r" (result), "=&r" (tmp), "+Qo" (v->counter)     \
  79:./arch/arm_m/include/asm/atomic.h ****     : "r" (&v->counter), "Ir" (i)                 \
  80:./arch/arm_m/include/asm/atomic.h ****     : "cc");                                   \
  81:./arch/arm_m/include/asm/atomic.h ****                                         \
  82:./arch/arm_m/include/asm/atomic.h ****     return result;                              \
  83:./arch/arm_m/include/asm/atomic.h **** }
  84:./arch/arm_m/include/asm/atomic.h **** 
  85:./arch/arm_m/include/asm/atomic.h **** #define ATOMIC_FETCH_OP(op, c_op, asm_op)                   \
  86:./arch/arm_m/include/asm/atomic.h **** static inline int arch_atomic_fetch_##op##_relaxed(int i, atomic_t *v)  \
  87:./arch/arm_m/include/asm/atomic.h **** {                                       \
  88:./arch/arm_m/include/asm/atomic.h ****     unsigned long tmp;                          \
  89:./arch/arm_m/include/asm/atomic.h ****     int result, val;                             \
  90:./arch/arm_m/include/asm/atomic.h ****                                         \
  91:./arch/arm_m/include/asm/atomic.h ****     /* prefetchw(&v->counter); - prefetch not available */ \
  92:./arch/arm_m/include/asm/atomic.h ****     __asm__ __volatile__("@ atomic_fetch_" #op "\n"       \
  93:./arch/arm_m/include/asm/atomic.h **** "1: ldrex   %0, [%4]\n"                      \
  94:./arch/arm_m/include/asm/atomic.h **** "   " #asm_op " %1, %0, %5\n"                \
  95:./arch/arm_m/include/asm/atomic.h **** "   strex   %2, %1, [%4]\n"                      \
  96:./arch/arm_m/include/asm/atomic.h **** "   teq %2, #0\n"                         \
  97:./arch/arm_m/include/asm/atomic.h **** "   bne 1b"                                \
  98:./arch/arm_m/include/asm/atomic.h ****     : "=&r" (result), "=&r" (val), "=&r" (tmp), "+Qo" (v->counter) \
  99:./arch/arm_m/include/asm/atomic.h ****     : "r" (&v->counter), "Ir" (i)                 \
 100:./arch/arm_m/include/asm/atomic.h ****     : "cc");                                   \
 101:./arch/arm_m/include/asm/atomic.h ****                                         \
 102:./arch/arm_m/include/asm/atomic.h ****     return result;                              \
 103:./arch/arm_m/include/asm/atomic.h **** }
 104:./arch/arm_m/include/asm/atomic.h **** 
 105:./arch/arm_m/include/asm/atomic.h **** #define arch_atomic_add_return_relaxed       arch_atomic_add_return_relaxed
 106:./arch/arm_m/include/asm/atomic.h **** #define arch_atomic_sub_return_relaxed       arch_atomic_sub_return_relaxed
 107:./arch/arm_m/include/asm/atomic.h **** #define arch_atomic_fetch_add_relaxed        arch_atomic_fetch_add_relaxed
 108:./arch/arm_m/include/asm/atomic.h **** #define arch_atomic_fetch_sub_relaxed        arch_atomic_fetch_sub_relaxed
 109:./arch/arm_m/include/asm/atomic.h **** 
 110:./arch/arm_m/include/asm/atomic.h **** #define arch_atomic_fetch_and_relaxed        arch_atomic_fetch_and_relaxed
 111:./arch/arm_m/include/asm/atomic.h **** #define arch_atomic_fetch_andnot_relaxed     arch_atomic_fetch_andnot_relaxed
 112:./arch/arm_m/include/asm/atomic.h **** #define arch_atomic_fetch_or_relaxed         arch_atomic_fetch_or_relaxed
 113:./arch/arm_m/include/asm/atomic.h **** #define arch_atomic_fetch_xor_relaxed        arch_atomic_fetch_xor_relaxed
 114:./arch/arm_m/include/asm/atomic.h **** 
 115:./arch/arm_m/include/asm/atomic.h **** static inline int arch_atomic_cmpxchg_relaxed(atomic_t *ptr, int old, int new)
 116:./arch/arm_m/include/asm/atomic.h **** {
 117:./arch/arm_m/include/asm/atomic.h ****     int oldval;
 118:./arch/arm_m/include/asm/atomic.h ****     unsigned long res;
 119:./arch/arm_m/include/asm/atomic.h **** 
 120:./arch/arm_m/include/asm/atomic.h ****     /* prefetchw(&ptr->counter); - prefetch not available */
 121:./arch/arm_m/include/asm/atomic.h **** 
 122:./arch/arm_m/include/asm/atomic.h ****     do {
 123:./arch/arm_m/include/asm/atomic.h ****         __asm__ __volatile__("@ atomic_cmpxchg\n"
ARM GAS  /tmp/ccKJN8PY.s 			page 30


 124:./arch/arm_m/include/asm/atomic.h **** "   ldrex   %1, [%3]\n"
 125:./arch/arm_m/include/asm/atomic.h **** "   mov     %0, #0\n"
 126:./arch/arm_m/include/asm/atomic.h **** "   teq     %1, %4\n"
 127:./arch/arm_m/include/asm/atomic.h **** "   strexeq %0, %5, [%3]\n"
 128:./arch/arm_m/include/asm/atomic.h ****         : "=&r" (res), "=&r" (oldval), "+Qo" (ptr->counter)
 129:./arch/arm_m/include/asm/atomic.h ****         : "r" (&ptr->counter), "Ir" (old), "r" (new)
 130:./arch/arm_m/include/asm/atomic.h ****         : "cc");
 131:./arch/arm_m/include/asm/atomic.h ****     } while (res);
 132:./arch/arm_m/include/asm/atomic.h **** 
 133:./arch/arm_m/include/asm/atomic.h ****     return oldval;
 134:./arch/arm_m/include/asm/atomic.h **** }
 135:./arch/arm_m/include/asm/atomic.h **** #define arch_atomic_cmpxchg_relaxed        arch_atomic_cmpxchg_relaxed
 136:./arch/arm_m/include/asm/atomic.h **** 
 137:./arch/arm_m/include/asm/atomic.h **** static inline int arch_atomic_fetch_add_unless(atomic_t *v, int a, int u)
 138:./arch/arm_m/include/asm/atomic.h **** {
 139:./arch/arm_m/include/asm/atomic.h ****     int oldval, newval;
 140:./arch/arm_m/include/asm/atomic.h ****     unsigned long tmp;
 141:./arch/arm_m/include/asm/atomic.h **** 
 142:./arch/arm_m/include/asm/atomic.h ****     /* smp_mb(); - Memory barriers might need specific implementation */
 143:./arch/arm_m/include/asm/atomic.h ****     /* prefetchw(&v->counter); - prefetch not available */
 144:./arch/arm_m/include/asm/atomic.h **** 
 145:./arch/arm_m/include/asm/atomic.h ****     __asm__ __volatile__ ("@ atomic_add_unless\n"
 146:./arch/arm_m/include/asm/atomic.h **** "1: ldrex   %0, [%4]\n"
 147:./arch/arm_m/include/asm/atomic.h **** "   teq %0, %5\n"
 148:./arch/arm_m/include/asm/atomic.h **** "   beq 2f\n"
 149:./arch/arm_m/include/asm/atomic.h **** "   add %1, %0, %6\n"
 150:./arch/arm_m/include/asm/atomic.h **** "   strex   %2, %1, [%4]\n"
 151:./arch/arm_m/include/asm/atomic.h **** "   teq %2, #0\n"
 152:./arch/arm_m/include/asm/atomic.h **** "   bne 1b\n"
 153:./arch/arm_m/include/asm/atomic.h **** "2:"
 154:./arch/arm_m/include/asm/atomic.h ****     : "=&r" (oldval), "=&r" (newval), "=&r" (tmp), "+Qo" (v->counter)
 155:./arch/arm_m/include/asm/atomic.h ****     : "r" (&v->counter), "r" (u), "r" (a)
 156:./arch/arm_m/include/asm/atomic.h ****     : "cc");
 157:./arch/arm_m/include/asm/atomic.h **** 
 158:./arch/arm_m/include/asm/atomic.h ****     if (oldval != u)
 159:./arch/arm_m/include/asm/atomic.h ****         ; /* smp_mb(); - Memory barriers might need specific implementation */
 160:./arch/arm_m/include/asm/atomic.h **** 
 161:./arch/arm_m/include/asm/atomic.h ****     return oldval;
 162:./arch/arm_m/include/asm/atomic.h **** }
 163:./arch/arm_m/include/asm/atomic.h **** #define arch_atomic_fetch_add_unless         arch_atomic_fetch_add_unless
 164:./arch/arm_m/include/asm/atomic.h **** 
 165:./arch/arm_m/include/asm/atomic.h **** #define ATOMIC_OPS(op, c_op, asm_op)                    \
 166:./arch/arm_m/include/asm/atomic.h ****     ATOMIC_OP(op, c_op, asm_op)                     \
 167:./arch/arm_m/include/asm/atomic.h ****     ATOMIC_OP_RETURN(op, c_op, asm_op)                  \
 168:./arch/arm_m/include/asm/atomic.h ****     ATOMIC_FETCH_OP(op, c_op, asm_op)
 169:./arch/arm_m/include/asm/atomic.h **** 
 170:./arch/arm_m/include/asm/atomic.h **** ATOMIC_OPS(add, +=, add)
  56              		.loc 4 170 1 view .LVU9
  57              	.LBB78:
  58              		.loc 4 170 1 view .LVU10
  59              		.loc 4 170 1 view .LVU11
  60              		.loc 4 170 1 view .LVU12
  61              		.syntax unified
  62              	@ 170 "./arch/arm_m/include/asm/atomic.h" 1
  63              		@ atomic_add
  64 0002 50E8003F 	1: ldrex   r3, [r0]
  65 0006 03F10103 	   add r3, r3, #1
ARM GAS  /tmp/ccKJN8PY.s 			page 31


  66 000a 40E80032 	   strex   r2, r3, [r0]
  67 000e 92F0000F 	   teq r2, #0
  68 0012 F6D1     	   bne 1b
  69              	@ 0 "" 2
  70              	.LVL2:
  71              		.loc 4 170 1 is_stmt 0 view .LVU13
  72              		.thumb
  73              		.syntax unified
  74              	.LBE78:
  75              	.LBE77:
  76              	.LBE76:
  77              	.LBE75:
  78              	.LBE74:
  35:./fs/fs_inode.c **** }
  79              		.loc 1 35 1 view .LVU14
  80 0014 7047     		bx	lr
  81              		.cfi_endproc
  82              	.LFE1037:
  84              		.section	.text.new_inode,"ax",%progbits
  85              		.align	1
  86              		.global	new_inode
  87              		.syntax unified
  88              		.thumb
  89              		.thumb_func
  91              	new_inode:
  92              	.LVL3:
  93              	.LFB1035:
  15:./fs/fs_inode.c ****     struct inode *inode = (struct inode *)kmalloc(sizeof(struct inode), GFP_KERNEL);
  94              		.loc 1 15 48 is_stmt 1 view -0
  95              		.cfi_startproc
  96              		@ args = 0, pretend = 0, frame = 0
  97              		@ frame_needed = 0, uses_anonymous_args = 0
  15:./fs/fs_inode.c ****     struct inode *inode = (struct inode *)kmalloc(sizeof(struct inode), GFP_KERNEL);
  98              		.loc 1 15 48 is_stmt 0 view .LVU16
  99 0000 38B5     		push	{r3, r4, r5, lr}
 100              	.LCFI0:
 101              		.cfi_def_cfa_offset 16
 102              		.cfi_offset 3, -16
 103              		.cfi_offset 4, -12
 104              		.cfi_offset 5, -8
 105              		.cfi_offset 14, -4
 106 0002 0546     		mov	r5, r0
  16:./fs/fs_inode.c ****     if (inode == NULL) return NULL;
 107              		.loc 1 16 5 is_stmt 1 view .LVU17
 108              	.LVL4:
 109              	.LBB79:
 110              	.LBI79:
 111              		.file 5 "./include/linux/slab.h"
   1:./include/linux/slab.h **** /* SPDX-License-Identifier: GPL-2.0 */
   2:./include/linux/slab.h **** /*
   3:./include/linux/slab.h ****  * Written by Mark Hemment, 1996 (markhe@nextd.demon.co.uk).
   4:./include/linux/slab.h ****  *
   5:./include/linux/slab.h ****  * (C) SGI 2006, Christoph Lameter
   6:./include/linux/slab.h ****  * 	Cleaned up and restructured to ease the addition of alternative
   7:./include/linux/slab.h ****  * 	implementations of SLAB allocators.
   8:./include/linux/slab.h ****  * (C) Linux Foundation 2008-2013
   9:./include/linux/slab.h ****  *      Unified interface for all slab allocators
ARM GAS  /tmp/ccKJN8PY.s 			page 32


  10:./include/linux/slab.h ****  */
  11:./include/linux/slab.h **** 
  12:./include/linux/slab.h **** #ifndef _LINUX_SLAB_H
  13:./include/linux/slab.h **** #define	_LINUX_SLAB_H
  14:./include/linux/slab.h **** 
  15:./include/linux/slab.h **** #include <linux/cache.h>
  16:./include/linux/slab.h **** #include <linux/overflow.h>
  17:./include/linux/slab.h **** #include <linux/types.h>
  18:./include/linux/slab.h **** #include <linux/raid/pq.h>
  19:./include/linux/slab.h **** #include <linux/gfp_types.h>
  20:./include/linux/slab.h **** #include <linux/numa.h>
  21:./include/linux/slab.h **** #include <linux/reciprocal_div.h>
  22:./include/linux/slab.h **** #include <linux/spinlock.h>
  23:./include/linux/slab.h **** 
  24:./include/linux/slab.h **** enum _slab_flag_bits {
  25:./include/linux/slab.h **** 	_SLAB_CONSISTENCY_CHECKS,
  26:./include/linux/slab.h **** 	_SLAB_RED_ZONE,
  27:./include/linux/slab.h **** 	_SLAB_POISON,
  28:./include/linux/slab.h **** 	_SLAB_KMALLOC,
  29:./include/linux/slab.h **** 	_SLAB_HWCACHE_ALIGN,
  30:./include/linux/slab.h **** 	_SLAB_CACHE_DMA,
  31:./include/linux/slab.h **** 	_SLAB_CACHE_DMA32,
  32:./include/linux/slab.h **** 	_SLAB_STORE_USER,
  33:./include/linux/slab.h **** 	_SLAB_PANIC,
  34:./include/linux/slab.h **** 	_SLAB_TYPESAFE_BY_RCU,
  35:./include/linux/slab.h **** 	_SLAB_TRACE,
  36:./include/linux/slab.h **** #ifdef CONFIG_DEBUG_OBJECTS
  37:./include/linux/slab.h **** 	_SLAB_DEBUG_OBJECTS,
  38:./include/linux/slab.h **** #endif
  39:./include/linux/slab.h **** 	_SLAB_NOLEAKTRACE,
  40:./include/linux/slab.h **** 	_SLAB_NO_MERGE,
  41:./include/linux/slab.h **** #ifdef CONFIG_FAILSLAB
  42:./include/linux/slab.h **** 	_SLAB_FAILSLAB,
  43:./include/linux/slab.h **** #endif
  44:./include/linux/slab.h **** #ifdef CONFIG_MEMCG
  45:./include/linux/slab.h **** 	_SLAB_ACCOUNT,
  46:./include/linux/slab.h **** #endif
  47:./include/linux/slab.h **** #ifdef CONFIG_KASAN_GENERIC
  48:./include/linux/slab.h **** 	_SLAB_KASAN,
  49:./include/linux/slab.h **** #endif
  50:./include/linux/slab.h **** 	_SLAB_NO_USER_FLAGS,
  51:./include/linux/slab.h **** #ifdef CONFIG_KFENCE
  52:./include/linux/slab.h **** 	_SLAB_SKIP_KFENCE,
  53:./include/linux/slab.h **** #endif
  54:./include/linux/slab.h **** #ifndef CONFIG_SLUB_TINY
  55:./include/linux/slab.h **** 	_SLAB_RECLAIM_ACCOUNT,
  56:./include/linux/slab.h **** #endif
  57:./include/linux/slab.h **** 	_SLAB_OBJECT_POISON,
  58:./include/linux/slab.h **** 	_SLAB_CMPXCHG_DOUBLE,
  59:./include/linux/slab.h **** #ifdef CONFIG_SLAB_OBJ_EXT
  60:./include/linux/slab.h **** 	_SLAB_NO_OBJ_EXT,
  61:./include/linux/slab.h **** #endif
  62:./include/linux/slab.h **** 	_SLAB_FLAGS_LAST_BIT
  63:./include/linux/slab.h **** };
  64:./include/linux/slab.h **** 
  65:./include/linux/slab.h **** 
  66:./include/linux/slab.h **** 
ARM GAS  /tmp/ccKJN8PY.s 			page 33


  67:./include/linux/slab.h **** #define __SLAB_FLAG_BIT(nr)	((slab_flags_t __force)(1U << (nr)))
  68:./include/linux/slab.h **** #define __SLAB_FLAG_UNUSED	((slab_flags_t __force)(0U))
  69:./include/linux/slab.h **** 
  70:./include/linux/slab.h **** /*
  71:./include/linux/slab.h ****  * Flags to pass to kmem_cache_create().
  72:./include/linux/slab.h ****  * The ones marked DEBUG need CONFIG_SLUB_DEBUG enabled, otherwise are no-op
  73:./include/linux/slab.h ****  */
  74:./include/linux/slab.h **** /* DEBUG: Perform (expensive) checks on alloc/free */
  75:./include/linux/slab.h **** #define SLAB_CONSISTENCY_CHECKS	__SLAB_FLAG_BIT(_SLAB_CONSISTENCY_CHECKS)
  76:./include/linux/slab.h **** /* DEBUG: Red zone objs in a cache */
  77:./include/linux/slab.h **** #define SLAB_RED_ZONE		__SLAB_FLAG_BIT(_SLAB_RED_ZONE)
  78:./include/linux/slab.h **** /* DEBUG: Poison objects */
  79:./include/linux/slab.h **** #define SLAB_POISON		__SLAB_FLAG_BIT(_SLAB_POISON)
  80:./include/linux/slab.h **** /* Indicate a kmalloc slab */
  81:./include/linux/slab.h **** #define SLAB_KMALLOC		__SLAB_FLAG_BIT(_SLAB_KMALLOC)
  82:./include/linux/slab.h **** /**
  83:./include/linux/slab.h ****  * define SLAB_HWCACHE_ALIGN - Align objects on cache line boundaries.
  84:./include/linux/slab.h ****  *
  85:./include/linux/slab.h ****  * Sufficiently large objects are aligned on cache line boundary. For object
  86:./include/linux/slab.h ****  * size smaller than a half of cache line size, the alignment is on the half of
  87:./include/linux/slab.h ****  * cache line size. In general, if object size is smaller than 1/2^n of cache
  88:./include/linux/slab.h ****  * line size, the alignment is adjusted to 1/2^n.
  89:./include/linux/slab.h ****  *
  90:./include/linux/slab.h ****  * If explicit alignment is also requested by the respective
  91:./include/linux/slab.h ****  * &struct kmem_cache_args field, the greater of both is alignments is applied.
  92:./include/linux/slab.h ****  */
  93:./include/linux/slab.h **** #define SLAB_HWCACHE_ALIGN	__SLAB_FLAG_BIT(_SLAB_HWCACHE_ALIGN)
  94:./include/linux/slab.h **** /* Use GFP_DMA memory */
  95:./include/linux/slab.h **** #define SLAB_CACHE_DMA		__SLAB_FLAG_BIT(_SLAB_CACHE_DMA)
  96:./include/linux/slab.h **** /* Use GFP_DMA32 memory */
  97:./include/linux/slab.h **** #define SLAB_CACHE_DMA32	__SLAB_FLAG_BIT(_SLAB_CACHE_DMA32)
  98:./include/linux/slab.h **** /* DEBUG: Store the last owner for bug hunting */
  99:./include/linux/slab.h **** #define SLAB_STORE_USER		__SLAB_FLAG_BIT(_SLAB_STORE_USER)
 100:./include/linux/slab.h **** /* Panic if kmem_cache_create() fails */
 101:./include/linux/slab.h **** #define SLAB_PANIC		__SLAB_FLAG_BIT(_SLAB_PANIC)
 102:./include/linux/slab.h **** /**
 103:./include/linux/slab.h ****  * define SLAB_TYPESAFE_BY_RCU - **WARNING** READ THIS!
 104:./include/linux/slab.h ****  *
 105:./include/linux/slab.h ****  * This delays freeing the SLAB page by a grace period, it does _NOT_
 106:./include/linux/slab.h ****  * delay object freeing. This means that if you do kmem_cache_free()
 107:./include/linux/slab.h ****  * that memory location is free to be reused at any time. Thus it may
 108:./include/linux/slab.h ****  * be possible to see another object there in the same RCU grace period.
 109:./include/linux/slab.h ****  *
 110:./include/linux/slab.h ****  * This feature only ensures the memory location backing the object
 111:./include/linux/slab.h ****  * stays valid, the trick to using this is relying on an independent
 112:./include/linux/slab.h ****  * object validation pass. Something like:
 113:./include/linux/slab.h ****  *
 114:./include/linux/slab.h ****  * ::
 115:./include/linux/slab.h ****  *
 116:./include/linux/slab.h ****  *  begin:
 117:./include/linux/slab.h ****  *   rcu_read_lock();
 118:./include/linux/slab.h ****  *   obj = lockless_lookup(key);
 119:./include/linux/slab.h ****  *   if (obj) {
 120:./include/linux/slab.h ****  *     if (!try_get_ref(obj)) // might fail for free objects
 121:./include/linux/slab.h ****  *       rcu_read_unlock();
 122:./include/linux/slab.h ****  *       goto begin;
 123:./include/linux/slab.h ****  *
ARM GAS  /tmp/ccKJN8PY.s 			page 34


 124:./include/linux/slab.h ****  *     if (obj->key != key) { // not the object we expected
 125:./include/linux/slab.h ****  *       put_ref(obj);
 126:./include/linux/slab.h ****  *       rcu_read_unlock();
 127:./include/linux/slab.h ****  *       goto begin;
 128:./include/linux/slab.h ****  *     }
 129:./include/linux/slab.h ****  *   }
 130:./include/linux/slab.h ****  *  rcu_read_unlock();
 131:./include/linux/slab.h ****  *
 132:./include/linux/slab.h ****  * This is useful if we need to approach a kernel structure obliquely,
 133:./include/linux/slab.h ****  * from its address obtained without the usual locking. We can lock
 134:./include/linux/slab.h ****  * the structure to stabilize it and check it's still at the given address,
 135:./include/linux/slab.h ****  * only if we can be sure that the memory has not been meanwhile reused
 136:./include/linux/slab.h ****  * for some other kind of object (which our subsystem's lock might corrupt).
 137:./include/linux/slab.h ****  *
 138:./include/linux/slab.h ****  * rcu_read_lock before reading the address, then rcu_read_unlock after
 139:./include/linux/slab.h ****  * taking the spinlock within the structure expected at that address.
 140:./include/linux/slab.h ****  *
 141:./include/linux/slab.h ****  * Note that it is not possible to acquire a lock within a structure
 142:./include/linux/slab.h ****  * allocated with SLAB_TYPESAFE_BY_RCU without first acquiring a reference
 143:./include/linux/slab.h ****  * as described above.  The reason is that SLAB_TYPESAFE_BY_RCU pages
 144:./include/linux/slab.h ****  * are not zeroed before being given to the slab, which means that any
 145:./include/linux/slab.h ****  * locks must be initialized after each and every kmem_struct_alloc().
 146:./include/linux/slab.h ****  * Alternatively, make the ctor passed to kmem_cache_create() initialize
 147:./include/linux/slab.h ****  * the locks at page-allocation time, as is done in __i915_request_ctor(),
 148:./include/linux/slab.h ****  * sighand_ctor(), and anon_vma_ctor().  Such a ctor permits readers
 149:./include/linux/slab.h ****  * to safely acquire those ctor-initialized locks under rcu_read_lock()
 150:./include/linux/slab.h ****  * protection.
 151:./include/linux/slab.h ****  *
 152:./include/linux/slab.h ****  * Note that SLAB_TYPESAFE_BY_RCU was originally named SLAB_DESTROY_BY_RCU.
 153:./include/linux/slab.h ****  */
 154:./include/linux/slab.h **** #define SLAB_TYPESAFE_BY_RCU	__SLAB_FLAG_BIT(_SLAB_TYPESAFE_BY_RCU)
 155:./include/linux/slab.h **** /* Trace allocations and frees */
 156:./include/linux/slab.h **** #define SLAB_TRACE		__SLAB_FLAG_BIT(_SLAB_TRACE)
 157:./include/linux/slab.h **** 
 158:./include/linux/slab.h **** /* Flag to prevent checks on free */
 159:./include/linux/slab.h **** #ifdef CONFIG_DEBUG_OBJECTS
 160:./include/linux/slab.h **** # define SLAB_DEBUG_OBJECTS	__SLAB_FLAG_BIT(_SLAB_DEBUG_OBJECTS)
 161:./include/linux/slab.h **** #else
 162:./include/linux/slab.h **** # define SLAB_DEBUG_OBJECTS	__SLAB_FLAG_UNUSED
 163:./include/linux/slab.h **** #endif
 164:./include/linux/slab.h **** 
 165:./include/linux/slab.h **** /* Avoid kmemleak tracing */
 166:./include/linux/slab.h **** #define SLAB_NOLEAKTRACE	__SLAB_FLAG_BIT(_SLAB_NOLEAKTRACE)
 167:./include/linux/slab.h **** 
 168:./include/linux/slab.h **** /*
 169:./include/linux/slab.h ****  * Prevent merging with compatible kmem caches. This flag should be used
 170:./include/linux/slab.h ****  * cautiously. Valid use cases:
 171:./include/linux/slab.h ****  *
 172:./include/linux/slab.h ****  * - caches created for self-tests (e.g. kunit)
 173:./include/linux/slab.h ****  * - general caches created and used by a subsystem, only when a
 174:./include/linux/slab.h ****  *   (subsystem-specific) debug option is enabled
 175:./include/linux/slab.h ****  * - performance critical caches, should be very rare and consulted with slab
 176:./include/linux/slab.h ****  *   maintainers, and not used together with CONFIG_SLUB_TINY
 177:./include/linux/slab.h ****  */
 178:./include/linux/slab.h **** #define SLAB_NO_MERGE		__SLAB_FLAG_BIT(_SLAB_NO_MERGE)
 179:./include/linux/slab.h **** 
 180:./include/linux/slab.h **** /* Fault injection mark */
ARM GAS  /tmp/ccKJN8PY.s 			page 35


 181:./include/linux/slab.h **** #ifdef CONFIG_FAILSLAB
 182:./include/linux/slab.h **** # define SLAB_FAILSLAB		__SLAB_FLAG_BIT(_SLAB_FAILSLAB)
 183:./include/linux/slab.h **** #else
 184:./include/linux/slab.h **** # define SLAB_FAILSLAB		__SLAB_FLAG_UNUSED
 185:./include/linux/slab.h **** #endif
 186:./include/linux/slab.h **** /**
 187:./include/linux/slab.h ****  * define SLAB_ACCOUNT - Account allocations to memcg.
 188:./include/linux/slab.h ****  *
 189:./include/linux/slab.h ****  * All object allocations from this cache will be memcg accounted, regardless of
 190:./include/linux/slab.h ****  * __GFP_ACCOUNT being or not being passed to individual allocations.
 191:./include/linux/slab.h ****  */
 192:./include/linux/slab.h **** #ifdef CONFIG_MEMCG
 193:./include/linux/slab.h **** # define SLAB_ACCOUNT		__SLAB_FLAG_BIT(_SLAB_ACCOUNT)
 194:./include/linux/slab.h **** #else
 195:./include/linux/slab.h **** # define SLAB_ACCOUNT		__SLAB_FLAG_UNUSED
 196:./include/linux/slab.h **** #endif
 197:./include/linux/slab.h **** 
 198:./include/linux/slab.h **** #ifdef CONFIG_KASAN_GENERIC
 199:./include/linux/slab.h **** #define SLAB_KASAN		__SLAB_FLAG_BIT(_SLAB_KASAN)
 200:./include/linux/slab.h **** #else
 201:./include/linux/slab.h **** #define SLAB_KASAN		__SLAB_FLAG_UNUSED
 202:./include/linux/slab.h **** #endif
 203:./include/linux/slab.h **** 
 204:./include/linux/slab.h **** /*
 205:./include/linux/slab.h ****  * Ignore user specified debugging flags.
 206:./include/linux/slab.h ****  * Intended for caches created for self-tests so they have only flags
 207:./include/linux/slab.h ****  * specified in the code and other flags are ignored.
 208:./include/linux/slab.h ****  */
 209:./include/linux/slab.h **** #define SLAB_NO_USER_FLAGS	__SLAB_FLAG_BIT(_SLAB_NO_USER_FLAGS)
 210:./include/linux/slab.h **** 
 211:./include/linux/slab.h **** #ifdef CONFIG_KFENCE
 212:./include/linux/slab.h **** #define SLAB_SKIP_KFENCE	__SLAB_FLAG_BIT(_SLAB_SKIP_KFENCE)
 213:./include/linux/slab.h **** #else
 214:./include/linux/slab.h **** #define SLAB_SKIP_KFENCE	__SLAB_FLAG_UNUSED
 215:./include/linux/slab.h **** #endif
 216:./include/linux/slab.h **** 
 217:./include/linux/slab.h **** /* The following flags affect the page allocator grouping pages by mobility */
 218:./include/linux/slab.h **** /**
 219:./include/linux/slab.h ****  * define SLAB_RECLAIM_ACCOUNT - Objects are reclaimable.
 220:./include/linux/slab.h ****  *
 221:./include/linux/slab.h ****  * Use this flag for caches that have an associated shrinker. As a result, slab
 222:./include/linux/slab.h ****  * pages are allocated with __GFP_RECLAIMABLE, which affects grouping pages by
 223:./include/linux/slab.h ****  * mobility, and are accounted in SReclaimable counter in /proc/meminfo
 224:./include/linux/slab.h ****  */
 225:./include/linux/slab.h **** #ifndef CONFIG_SLUB_TINY
 226:./include/linux/slab.h **** #define SLAB_RECLAIM_ACCOUNT	__SLAB_FLAG_BIT(_SLAB_RECLAIM_ACCOUNT)
 227:./include/linux/slab.h **** #else
 228:./include/linux/slab.h **** #define SLAB_RECLAIM_ACCOUNT	__SLAB_FLAG_UNUSED
 229:./include/linux/slab.h **** #endif
 230:./include/linux/slab.h **** #define SLAB_TEMPORARY		SLAB_RECLAIM_ACCOUNT	/* Objects are short-lived */
 231:./include/linux/slab.h **** 
 232:./include/linux/slab.h **** /* Slab created using create_boot_cache */
 233:./include/linux/slab.h **** #ifdef CONFIG_SLAB_OBJ_EXT
 234:./include/linux/slab.h **** #define SLAB_NO_OBJ_EXT		__SLAB_FLAG_BIT(_SLAB_NO_OBJ_EXT)
 235:./include/linux/slab.h **** #else
 236:./include/linux/slab.h **** #define SLAB_NO_OBJ_EXT		__SLAB_FLAG_UNUSED
 237:./include/linux/slab.h **** #endif
ARM GAS  /tmp/ccKJN8PY.s 			page 36


 238:./include/linux/slab.h **** 
 239:./include/linux/slab.h **** /*
 240:./include/linux/slab.h ****  * freeptr_t represents a SLUB freelist pointer, which might be encoded
 241:./include/linux/slab.h ****  * and not dereferenceable if CONFIG_SLAB_FREELIST_HARDENED is enabled.
 242:./include/linux/slab.h ****  */
 243:./include/linux/slab.h **** typedef struct { unsigned long v; } freeptr_t;
 244:./include/linux/slab.h **** 
 245:./include/linux/slab.h **** /*
 246:./include/linux/slab.h ****  * ZERO_SIZE_PTR will be returned for zero sized kmalloc requests.
 247:./include/linux/slab.h ****  *
 248:./include/linux/slab.h ****  * Dereferencing ZERO_SIZE_PTR will lead to a distinct access fault.
 249:./include/linux/slab.h ****  *
 250:./include/linux/slab.h ****  * ZERO_SIZE_PTR can be passed to kfree though in the same way that NULL can.
 251:./include/linux/slab.h ****  * Both make kfree a no-op.
 252:./include/linux/slab.h ****  */
 253:./include/linux/slab.h **** #define ZERO_SIZE_PTR ((void *)16)
 254:./include/linux/slab.h **** 
 255:./include/linux/slab.h **** #define ZERO_OR_NULL_PTR(x) ((unsigned long)(x) <= \
 256:./include/linux/slab.h **** 				(unsigned long)ZERO_SIZE_PTR)
 257:./include/linux/slab.h **** 
 258:./include/linux/slab.h **** 
 259:./include/linux/slab.h **** 
 260:./include/linux/slab.h **** 
 261:./include/linux/slab.h **** 
 262:./include/linux/slab.h **** #ifdef CONFIG_SLUB_CPU_PARTIAL
 263:./include/linux/slab.h **** #define slub_percpu_partial(c)			((c)->partial)
 264:./include/linux/slab.h **** 
 265:./include/linux/slab.h **** #define slub_set_percpu_partial(c, p)		\
 266:./include/linux/slab.h **** ({						\
 267:./include/linux/slab.h **** 	slub_percpu_partial(c) = (p)->next;	\
 268:./include/linux/slab.h **** })
 269:./include/linux/slab.h **** 
 270:./include/linux/slab.h **** #define slub_percpu_partial_read_once(c)	READ_ONCE(slub_percpu_partial(c))
 271:./include/linux/slab.h **** #else
 272:./include/linux/slab.h **** #define slub_percpu_partial(c)			NULL
 273:./include/linux/slab.h **** 
 274:./include/linux/slab.h **** #define slub_set_percpu_partial(c, p)
 275:./include/linux/slab.h **** 
 276:./include/linux/slab.h **** #define slub_percpu_partial_read_once(c)	NULL
 277:./include/linux/slab.h **** 
 278:./include/linux/slab.h **** 
 279:./include/linux/slab.h **** #endif // CONFIG_SLUB_CPU_PARTIAL
 280:./include/linux/slab.h **** 
 281:./include/linux/slab.h **** /*
 282:./include/linux/slab.h **** 	* Word size structure that can be atomically updated or read and that
 283:./include/linux/slab.h **** 	* contains both the order and the number of objects that a slab of the
 284:./include/linux/slab.h **** 	* given order would contain.
 285:./include/linux/slab.h **** 	*/				
 286:./include/linux/slab.h **** struct kmem_cache_order_objects {
 287:./include/linux/slab.h **** 	unsigned int x;
 288:./include/linux/slab.h **** };
 289:./include/linux/slab.h **** 
 290:./include/linux/slab.h **** struct kmem_cache_node {
 291:./include/linux/slab.h **** 	spinlock_t list_lock;
 292:./include/linux/slab.h **** 	unsigned long nr_partial;
 293:./include/linux/slab.h **** 	struct list_head partial;
 294:./include/linux/slab.h **** #ifdef CONFIG_SLUB_DEBUG
ARM GAS  /tmp/ccKJN8PY.s 			page 37


 295:./include/linux/slab.h **** 	atomic_long_t nr_slabs;
 296:./include/linux/slab.h **** 	atomic_long_t total_objects;
 297:./include/linux/slab.h **** 	struct list_head full;
 298:./include/linux/slab.h **** #endif
 299:./include/linux/slab.h **** };
 300:./include/linux/slab.h **** 
 301:./include/linux/slab.h **** struct kmem_cache {
 302:./include/linux/slab.h **** 	#ifndef CONFIG_SLUB_TINY
 303:./include/linux/slab.h **** 	//	struct kmem_cache_cpu __percpu *cpu_slab;
 304:./include/linux/slab.h **** 	#endif
 305:./include/linux/slab.h **** 		/* Used for retrieving partial slabs, etc. */
 306:./include/linux/slab.h **** 		slab_flags_t flags;
 307:./include/linux/slab.h **** 		unsigned long min_partial;
 308:./include/linux/slab.h **** 		unsigned int size;		/* Object size including metadata */
 309:./include/linux/slab.h **** 		unsigned int object_size;	/* Object size without metadata */
 310:./include/linux/slab.h **** 		struct reciprocal_value reciprocal_size;
 311:./include/linux/slab.h **** 		unsigned int offset;		/* Free pointer offset */
 312:./include/linux/slab.h **** 	#ifdef CONFIG_SLUB_CPU_PARTIAL
 313:./include/linux/slab.h **** 		/* Number of per cpu partial objects to keep around */
 314:./include/linux/slab.h **** 		unsigned int cpu_partial;
 315:./include/linux/slab.h **** 		/* Number of per cpu partial slabs to keep around */
 316:./include/linux/slab.h **** 		unsigned int cpu_partial_slabs;
 317:./include/linux/slab.h **** 	#endif
 318:./include/linux/slab.h **** 		struct kmem_cache_order_objects oo;
 319:./include/linux/slab.h **** 	
 320:./include/linux/slab.h **** 		/* Allocation and freeing of slabs */
 321:./include/linux/slab.h **** 		struct kmem_cache_order_objects min;
 322:./include/linux/slab.h **** 		gfp_t allocflags;		/* gfp flags to use on each alloc */
 323:./include/linux/slab.h **** 		int refcount;			/* Refcount for slab cache destroy */
 324:./include/linux/slab.h **** 		void (*ctor)(void *object);	/* Object constructor */
 325:./include/linux/slab.h **** 		unsigned int inuse;		/* Offset to metadata */
 326:./include/linux/slab.h **** 		unsigned int align;		/* Alignment */
 327:./include/linux/slab.h **** 		unsigned int red_left_pad;	/* Left redzone padding size */
 328:./include/linux/slab.h **** 		const char *name;		/* Name (only for display!) */
 329:./include/linux/slab.h **** 		struct list_head list;		/* List of slab caches */
 330:./include/linux/slab.h **** 	#ifdef CONFIG_SYSFS
 331:./include/linux/slab.h **** 		struct kobject kobj;		/* For sysfs */
 332:./include/linux/slab.h **** 	#endif
 333:./include/linux/slab.h **** 	#ifdef CONFIG_SLAB_FREELIST_HARDENED
 334:./include/linux/slab.h **** 		unsigned long random;
 335:./include/linux/slab.h **** 	#endif
 336:./include/linux/slab.h **** 	
 337:./include/linux/slab.h **** 	#ifdef CONFIG_NUMA
 338:./include/linux/slab.h **** 		/*
 339:./include/linux/slab.h **** 			* Defragmentation by allocating from a remote node.
 340:./include/linux/slab.h **** 			*/
 341:./include/linux/slab.h **** 		unsigned int remote_node_defrag_ratio;
 342:./include/linux/slab.h **** 	#endif
 343:./include/linux/slab.h **** 	
 344:./include/linux/slab.h **** 	#ifdef CONFIG_SLAB_FREELIST_RANDOM
 345:./include/linux/slab.h **** 		unsigned int *random_seq;
 346:./include/linux/slab.h **** 	#endif
 347:./include/linux/slab.h **** 	
 348:./include/linux/slab.h **** 	#ifdef CONFIG_KASAN_GENERIC
 349:./include/linux/slab.h **** 		struct kasan_cache kasan_info;
 350:./include/linux/slab.h **** 	#endif
 351:./include/linux/slab.h **** 	
ARM GAS  /tmp/ccKJN8PY.s 			page 38


 352:./include/linux/slab.h **** 	#ifdef CONFIG_HARDENED_USERCOPY
 353:./include/linux/slab.h **** 		unsigned int useroffset;	/* Usercopy region offset */
 354:./include/linux/slab.h **** 		unsigned int usersize;		/* Usercopy region size */
 355:./include/linux/slab.h **** 	#endif
 356:./include/linux/slab.h **** 	
 357:./include/linux/slab.h **** 		struct kmem_cache_node *node[MAX_NUMNODES];
 358:./include/linux/slab.h **** 	};
 359:./include/linux/slab.h **** 					
 360:./include/linux/slab.h **** 
 361:./include/linux/slab.h **** 
 362:./include/linux/slab.h **** 
 363:./include/linux/slab.h **** 
 364:./include/linux/slab.h **** #define KMALLOC_WAIT 1
 365:./include/linux/slab.h **** 
 366:./include/linux/slab.h **** 
 367:./include/linux/slab.h **** extern void* __smalloc__(u32 size, gfp_t flags);
 368:./include/linux/slab.h **** extern void  __sfree__(void* addr);
 369:./include/linux/slab.h **** 
 370:./include/linux/slab.h **** 
 371:./include/linux/slab.h **** static void inline *vmalloc(unsigned long size){
 372:./include/linux/slab.h **** 	return __smalloc__(size,GFP_TRANSHUGE_LIGHT);
 373:./include/linux/slab.h **** }
 374:./include/linux/slab.h **** 
 375:./include/linux/slab.h **** static void inline vfree(void *addr){
 376:./include/linux/slab.h **** 	__sfree__(addr);
 377:./include/linux/slab.h **** }
 378:./include/linux/slab.h **** 
 379:./include/linux/slab.h **** static void inline *kmalloc(size_t size, gfp_t flags){
 112              		.loc 5 379 21 view .LVU18
 113              	.LBB80:
 380:./include/linux/slab.h **** 	return __smalloc__((u32)size,flags);
 114              		.loc 5 380 2 view .LVU19
 115              		.loc 5 380 9 is_stmt 0 view .LVU20
 116 0004 4FF44C61 		mov	r1, #3264
 117 0008 5C20     		movs	r0, #92
 118              	.LVL5:
 119              		.loc 5 380 9 view .LVU21
 120 000a FFF7FEFF 		bl	__smalloc__
 121              	.LVL6:
 122              		.loc 5 380 9 view .LVU22
 123              	.LBE80:
 124              	.LBE79:
  17:./fs/fs_inode.c **** 	memset(inode,0,sizeof(struct inode));
 125              		.loc 1 17 5 is_stmt 1 view .LVU23
  17:./fs/fs_inode.c **** 	memset(inode,0,sizeof(struct inode));
 126              		.loc 1 17 8 is_stmt 0 view .LVU24
 127 000e 0446     		mov	r4, r0
 128 0010 58B1     		cbz	r0, .L2
  18:./fs/fs_inode.c ****     inode->i_mode    = S_IFCHR | 0777;
 129              		.loc 1 18 2 is_stmt 1 view .LVU25
 130 0012 5C22     		movs	r2, #92
 131 0014 0021     		movs	r1, #0
 132 0016 FFF7FEFF 		bl	memset
 133              	.LVL7:
  19:./fs/fs_inode.c ****     time64_t now        = jiffies;
 134              		.loc 1 19 5 view .LVU26
  19:./fs/fs_inode.c ****     time64_t now        = jiffies;
ARM GAS  /tmp/ccKJN8PY.s 			page 39


 135              		.loc 1 19 22 is_stmt 0 view .LVU27
 136 001a 42F2FF13 		movw	r3, #8703
 137 001e 2380     		strh	r3, [r4]	@ movhi
  20:./fs/fs_inode.c ****     inode->i_sb       = sb;
 138              		.loc 1 20 5 is_stmt 1 view .LVU28
  20:./fs/fs_inode.c ****     inode->i_sb       = sb;
 139              		.loc 1 20 27 is_stmt 0 view .LVU29
 140 0020 FFF7FEFF 		bl	ktime_get
 141              	.LVL8:
  21:./fs/fs_inode.c **** 	atomic_set(&inode->i_count,1);
 142              		.loc 1 21 5 is_stmt 1 view .LVU30
  21:./fs/fs_inode.c **** 	atomic_set(&inode->i_count,1);
 143              		.loc 1 21 23 is_stmt 0 view .LVU31
 144 0024 E560     		str	r5, [r4, #12]
  22:./fs/fs_inode.c ****     return inode;
 145              		.loc 1 22 2 is_stmt 1 view .LVU32
 146              	.LVL9:
 147              	.LBB81:
 148              	.LBI81:
  65:./include/linux/atomic/atomic-instrumented.h **** {
 149              		.loc 2 65 1 view .LVU33
  67:./include/linux/atomic/atomic-instrumented.h **** 	raw_atomic_set(v, i);
 150              		.loc 2 67 2 view .LVU34
  68:./include/linux/atomic/atomic-instrumented.h **** }
 151              		.loc 2 68 2 view .LVU35
 152              	.LBB82:
 153              	.LBI82:
 507:./include/linux/atomic/atomic-arch-fallback.h **** {
 154              		.loc 3 507 1 view .LVU36
 155              	.LBB83:
 509:./include/linux/atomic/atomic-arch-fallback.h **** }
 156              		.loc 3 509 2 view .LVU37
 509:./include/linux/atomic/atomic-arch-fallback.h **** }
 157              		.loc 3 509 2 view .LVU38
 158              	.LBB84:
 509:./include/linux/atomic/atomic-arch-fallback.h **** }
 159              		.loc 3 509 2 view .LVU39
 509:./include/linux/atomic/atomic-arch-fallback.h **** }
 160              		.loc 3 509 2 view .LVU40
 161              	.LBE84:
 509:./include/linux/atomic/atomic-arch-fallback.h **** }
 162              		.loc 3 509 2 discriminator 2 view .LVU41
 509:./include/linux/atomic/atomic-arch-fallback.h **** }
 163              		.loc 3 509 2 discriminator 2 view .LVU42
 509:./include/linux/atomic/atomic-arch-fallback.h **** }
 164              		.loc 3 509 2 discriminator 2 view .LVU43
 165 0026 0123     		movs	r3, #1
 166 0028 E364     		str	r3, [r4, #76]
 509:./include/linux/atomic/atomic-arch-fallback.h **** }
 167              		.loc 3 509 2 discriminator 2 view .LVU44
 509:./include/linux/atomic/atomic-arch-fallback.h **** }
 168              		.loc 3 509 2 discriminator 2 view .LVU45
 169              	.LVL10:
 509:./include/linux/atomic/atomic-arch-fallback.h **** }
 170              		.loc 3 509 2 is_stmt 0 discriminator 2 view .LVU46
 171              	.LBE83:
 172              	.LBE82:
ARM GAS  /tmp/ccKJN8PY.s 			page 40


 173              	.LBE81:
  23:./fs/fs_inode.c **** }
 174              		.loc 1 23 5 is_stmt 1 view .LVU47
 175              	.L2:
  24:./fs/fs_inode.c **** EXPORT_SYMBOL(new_inode);
 176              		.loc 1 24 1 is_stmt 0 view .LVU48
 177 002a 2046     		mov	r0, r4
 178 002c 38BD     		pop	{r3, r4, r5, pc}
  24:./fs/fs_inode.c **** EXPORT_SYMBOL(new_inode);
 179              		.loc 1 24 1 view .LVU49
 180              		.cfi_endproc
 181              	.LFE1035:
 183              		.section	.text.destroy_inode,"ax",%progbits
 184              		.align	1
 185              		.global	destroy_inode
 186              		.syntax unified
 187              		.thumb
 188              		.thumb_func
 190              	destroy_inode:
 191              	.LVL11:
 192              	.LFB1036:
  27:./fs/fs_inode.c **** 	if(node != NULL)
 193              		.loc 1 27 39 is_stmt 1 view -0
 194              		.cfi_startproc
 195              		@ args = 0, pretend = 0, frame = 0
 196              		@ frame_needed = 0, uses_anonymous_args = 0
  28:./fs/fs_inode.c **** 	kfree(node);
 197              		.loc 1 28 2 view .LVU51
  28:./fs/fs_inode.c **** 	kfree(node);
 198              		.loc 1 28 4 is_stmt 0 view .LVU52
 199 0000 18B1     		cbz	r0, .L8
  27:./fs/fs_inode.c **** 	if(node != NULL)
 200              		.loc 1 27 39 view .LVU53
 201 0002 08B5     		push	{r3, lr}
 202              	.LCFI1:
 203              		.cfi_def_cfa_offset 8
 204              		.cfi_offset 3, -8
 205              		.cfi_offset 14, -4
  29:./fs/fs_inode.c **** }
 206              		.loc 1 29 2 is_stmt 1 view .LVU54
 207              	.LVL12:
 208              	.LBB85:
 209              	.LBI85:
 381:./include/linux/slab.h **** }
 382:./include/linux/slab.h **** 
 383:./include/linux/slab.h **** static void inline kfree(const void *ptr){
 210              		.loc 5 383 20 view .LVU55
 211              	.LBB86:
 384:./include/linux/slab.h **** 	__sfree__((void*)ptr);
 212              		.loc 5 384 2 view .LVU56
 213 0004 FFF7FEFF 		bl	__sfree__
 214              	.LVL13:
 215              		.loc 5 384 2 is_stmt 0 view .LVU57
 216              	.LBE86:
 217              	.LBE85:
  30:./fs/fs_inode.c **** EXPORT_SYMBOL(destroy_inode);
 218              		.loc 1 30 1 view .LVU58
ARM GAS  /tmp/ccKJN8PY.s 			page 41


 219 0008 08BD     		pop	{r3, pc}
 220              	.LVL14:
 221              	.L8:
 222              	.LCFI2:
 223              		.cfi_def_cfa_offset 0
 224              		.cfi_restore 3
 225              		.cfi_restore 14
  30:./fs/fs_inode.c **** EXPORT_SYMBOL(destroy_inode);
 226              		.loc 1 30 1 view .LVU59
 227 000a 7047     		bx	lr
 228              		.cfi_endproc
 229              	.LFE1036:
 231              		.section	.text.inode_put,"ax",%progbits
 232              		.align	1
 233              		.global	inode_put
 234              		.syntax unified
 235              		.thumb
 236              		.thumb_func
 238              	inode_put:
 239              	.LVL15:
 240              	.LFB1038:
  36:./fs/fs_inode.c **** EXPORT_SYMBOL(inode_get);
  37:./fs/fs_inode.c **** 
  38:./fs/fs_inode.c **** void inode_put(struct inode *inode){
 241              		.loc 1 38 36 is_stmt 1 view -0
 242              		.cfi_startproc
 243              		@ args = 0, pretend = 0, frame = 0
 244              		@ frame_needed = 0, uses_anonymous_args = 0
 245              		.loc 1 38 36 is_stmt 0 view .LVU61
 246 0000 08B5     		push	{r3, lr}
 247              	.LCFI3:
 248              		.cfi_def_cfa_offset 8
 249              		.cfi_offset 3, -8
 250              		.cfi_offset 14, -4
  39:./fs/fs_inode.c ****     if (atomic_dec_and_test(&inode->i_count)) {  
 251              		.loc 1 39 5 is_stmt 1 view .LVU62
 252              		.loc 1 39 9 is_stmt 0 view .LVU63
 253 0002 00F14C03 		add	r3, r0, #76
 254              	.LVL16:
 255              	.LBB87:
 256              	.LBI87:
 437:./include/linux/atomic/atomic-instrumented.h **** }
 438:./include/linux/atomic/atomic-instrumented.h **** 
 439:./include/linux/atomic/atomic-instrumented.h **** /**
 440:./include/linux/atomic/atomic-instrumented.h ****  * atomic_inc_return() - atomic increment with full ordering
 441:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 442:./include/linux/atomic/atomic-instrumented.h ****  *
 443:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + 1) with full ordering.
 444:./include/linux/atomic/atomic-instrumented.h ****  *
 445:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_inc_return() there.
 446:./include/linux/atomic/atomic-instrumented.h ****  *
 447:./include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 448:./include/linux/atomic/atomic-instrumented.h ****  */
 449:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 450:./include/linux/atomic/atomic-instrumented.h **** atomic_inc_return(atomic_t *v)
 451:./include/linux/atomic/atomic-instrumented.h **** {
 452:./include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
ARM GAS  /tmp/ccKJN8PY.s 			page 42


 453:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 454:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_inc_return(v);
 455:./include/linux/atomic/atomic-instrumented.h **** }
 456:./include/linux/atomic/atomic-instrumented.h **** 
 457:./include/linux/atomic/atomic-instrumented.h **** /**
 458:./include/linux/atomic/atomic-instrumented.h ****  * atomic_inc_return_acquire() - atomic increment with acquire ordering
 459:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 460:./include/linux/atomic/atomic-instrumented.h ****  *
 461:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + 1) with acquire ordering.
 462:./include/linux/atomic/atomic-instrumented.h ****  *
 463:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_inc_return_acquire() there.
 464:./include/linux/atomic/atomic-instrumented.h ****  *
 465:./include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 466:./include/linux/atomic/atomic-instrumented.h ****  */
 467:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 468:./include/linux/atomic/atomic-instrumented.h **** atomic_inc_return_acquire(atomic_t *v)
 469:./include/linux/atomic/atomic-instrumented.h **** {
 470:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 471:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_inc_return_acquire(v);
 472:./include/linux/atomic/atomic-instrumented.h **** }
 473:./include/linux/atomic/atomic-instrumented.h **** 
 474:./include/linux/atomic/atomic-instrumented.h **** /**
 475:./include/linux/atomic/atomic-instrumented.h ****  * atomic_inc_return_release() - atomic increment with release ordering
 476:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 477:./include/linux/atomic/atomic-instrumented.h ****  *
 478:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + 1) with release ordering.
 479:./include/linux/atomic/atomic-instrumented.h ****  *
 480:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_inc_return_release() there.
 481:./include/linux/atomic/atomic-instrumented.h ****  *
 482:./include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 483:./include/linux/atomic/atomic-instrumented.h ****  */
 484:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 485:./include/linux/atomic/atomic-instrumented.h **** atomic_inc_return_release(atomic_t *v)
 486:./include/linux/atomic/atomic-instrumented.h **** {
 487:./include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
 488:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 489:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_inc_return_release(v);
 490:./include/linux/atomic/atomic-instrumented.h **** }
 491:./include/linux/atomic/atomic-instrumented.h **** 
 492:./include/linux/atomic/atomic-instrumented.h **** /**
 493:./include/linux/atomic/atomic-instrumented.h ****  * atomic_inc_return_relaxed() - atomic increment with relaxed ordering
 494:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 495:./include/linux/atomic/atomic-instrumented.h ****  *
 496:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + 1) with relaxed ordering.
 497:./include/linux/atomic/atomic-instrumented.h ****  *
 498:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_inc_return_relaxed() there.
 499:./include/linux/atomic/atomic-instrumented.h ****  *
 500:./include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 501:./include/linux/atomic/atomic-instrumented.h ****  */
 502:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 503:./include/linux/atomic/atomic-instrumented.h **** atomic_inc_return_relaxed(atomic_t *v)
 504:./include/linux/atomic/atomic-instrumented.h **** {
 505:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 506:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_inc_return_relaxed(v);
 507:./include/linux/atomic/atomic-instrumented.h **** }
 508:./include/linux/atomic/atomic-instrumented.h **** 
 509:./include/linux/atomic/atomic-instrumented.h **** /**
ARM GAS  /tmp/ccKJN8PY.s 			page 43


 510:./include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_inc() - atomic increment with full ordering
 511:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 512:./include/linux/atomic/atomic-instrumented.h ****  *
 513:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + 1) with full ordering.
 514:./include/linux/atomic/atomic-instrumented.h ****  *
 515:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_inc() there.
 516:./include/linux/atomic/atomic-instrumented.h ****  *
 517:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 518:./include/linux/atomic/atomic-instrumented.h ****  */
 519:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 520:./include/linux/atomic/atomic-instrumented.h **** atomic_fetch_inc(atomic_t *v)
 521:./include/linux/atomic/atomic-instrumented.h **** {
 522:./include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
 523:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 524:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_inc(v);
 525:./include/linux/atomic/atomic-instrumented.h **** }
 526:./include/linux/atomic/atomic-instrumented.h **** 
 527:./include/linux/atomic/atomic-instrumented.h **** /**
 528:./include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_inc_acquire() - atomic increment with acquire ordering
 529:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 530:./include/linux/atomic/atomic-instrumented.h ****  *
 531:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + 1) with acquire ordering.
 532:./include/linux/atomic/atomic-instrumented.h ****  *
 533:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_inc_acquire() there.
 534:./include/linux/atomic/atomic-instrumented.h ****  *
 535:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 536:./include/linux/atomic/atomic-instrumented.h ****  */
 537:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 538:./include/linux/atomic/atomic-instrumented.h **** atomic_fetch_inc_acquire(atomic_t *v)
 539:./include/linux/atomic/atomic-instrumented.h **** {
 540:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 541:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_inc_acquire(v);
 542:./include/linux/atomic/atomic-instrumented.h **** }
 543:./include/linux/atomic/atomic-instrumented.h **** 
 544:./include/linux/atomic/atomic-instrumented.h **** /**
 545:./include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_inc_release() - atomic increment with release ordering
 546:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 547:./include/linux/atomic/atomic-instrumented.h ****  *
 548:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + 1) with release ordering.
 549:./include/linux/atomic/atomic-instrumented.h ****  *
 550:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_inc_release() there.
 551:./include/linux/atomic/atomic-instrumented.h ****  *
 552:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 553:./include/linux/atomic/atomic-instrumented.h ****  */
 554:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 555:./include/linux/atomic/atomic-instrumented.h **** atomic_fetch_inc_release(atomic_t *v)
 556:./include/linux/atomic/atomic-instrumented.h **** {
 557:./include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
 558:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 559:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_inc_release(v);
 560:./include/linux/atomic/atomic-instrumented.h **** }
 561:./include/linux/atomic/atomic-instrumented.h **** 
 562:./include/linux/atomic/atomic-instrumented.h **** /**
 563:./include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_inc_relaxed() - atomic increment with relaxed ordering
 564:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 565:./include/linux/atomic/atomic-instrumented.h ****  *
 566:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + 1) with relaxed ordering.
ARM GAS  /tmp/ccKJN8PY.s 			page 44


 567:./include/linux/atomic/atomic-instrumented.h ****  *
 568:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_inc_relaxed() there.
 569:./include/linux/atomic/atomic-instrumented.h ****  *
 570:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 571:./include/linux/atomic/atomic-instrumented.h ****  */
 572:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 573:./include/linux/atomic/atomic-instrumented.h **** atomic_fetch_inc_relaxed(atomic_t *v)
 574:./include/linux/atomic/atomic-instrumented.h **** {
 575:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 576:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_inc_relaxed(v);
 577:./include/linux/atomic/atomic-instrumented.h **** }
 578:./include/linux/atomic/atomic-instrumented.h **** 
 579:./include/linux/atomic/atomic-instrumented.h **** /**
 580:./include/linux/atomic/atomic-instrumented.h ****  * atomic_dec() - atomic decrement with relaxed ordering
 581:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 582:./include/linux/atomic/atomic-instrumented.h ****  *
 583:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - 1) with relaxed ordering.
 584:./include/linux/atomic/atomic-instrumented.h ****  *
 585:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_dec() there.
 586:./include/linux/atomic/atomic-instrumented.h ****  *
 587:./include/linux/atomic/atomic-instrumented.h ****  * Return: Nothing.
 588:./include/linux/atomic/atomic-instrumented.h ****  */
 589:./include/linux/atomic/atomic-instrumented.h **** static __always_inline void
 590:./include/linux/atomic/atomic-instrumented.h **** atomic_dec(atomic_t *v)
 591:./include/linux/atomic/atomic-instrumented.h **** {
 592:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 593:./include/linux/atomic/atomic-instrumented.h **** 	raw_atomic_dec(v);
 594:./include/linux/atomic/atomic-instrumented.h **** }
 595:./include/linux/atomic/atomic-instrumented.h **** 
 596:./include/linux/atomic/atomic-instrumented.h **** /**
 597:./include/linux/atomic/atomic-instrumented.h ****  * atomic_dec_return() - atomic decrement with full ordering
 598:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 599:./include/linux/atomic/atomic-instrumented.h ****  *
 600:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - 1) with full ordering.
 601:./include/linux/atomic/atomic-instrumented.h ****  *
 602:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_dec_return() there.
 603:./include/linux/atomic/atomic-instrumented.h ****  *
 604:./include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 605:./include/linux/atomic/atomic-instrumented.h ****  */
 606:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 607:./include/linux/atomic/atomic-instrumented.h **** atomic_dec_return(atomic_t *v)
 608:./include/linux/atomic/atomic-instrumented.h **** {
 609:./include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
 610:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 611:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_dec_return(v);
 612:./include/linux/atomic/atomic-instrumented.h **** }
 613:./include/linux/atomic/atomic-instrumented.h **** 
 614:./include/linux/atomic/atomic-instrumented.h **** /**
 615:./include/linux/atomic/atomic-instrumented.h ****  * atomic_dec_return_acquire() - atomic decrement with acquire ordering
 616:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 617:./include/linux/atomic/atomic-instrumented.h ****  *
 618:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - 1) with acquire ordering.
 619:./include/linux/atomic/atomic-instrumented.h ****  *
 620:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_dec_return_acquire() there.
 621:./include/linux/atomic/atomic-instrumented.h ****  *
 622:./include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 623:./include/linux/atomic/atomic-instrumented.h ****  */
ARM GAS  /tmp/ccKJN8PY.s 			page 45


 624:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 625:./include/linux/atomic/atomic-instrumented.h **** atomic_dec_return_acquire(atomic_t *v)
 626:./include/linux/atomic/atomic-instrumented.h **** {
 627:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 628:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_dec_return_acquire(v);
 629:./include/linux/atomic/atomic-instrumented.h **** }
 630:./include/linux/atomic/atomic-instrumented.h **** 
 631:./include/linux/atomic/atomic-instrumented.h **** /**
 632:./include/linux/atomic/atomic-instrumented.h ****  * atomic_dec_return_release() - atomic decrement with release ordering
 633:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 634:./include/linux/atomic/atomic-instrumented.h ****  *
 635:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - 1) with release ordering.
 636:./include/linux/atomic/atomic-instrumented.h ****  *
 637:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_dec_return_release() there.
 638:./include/linux/atomic/atomic-instrumented.h ****  *
 639:./include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 640:./include/linux/atomic/atomic-instrumented.h ****  */
 641:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 642:./include/linux/atomic/atomic-instrumented.h **** atomic_dec_return_release(atomic_t *v)
 643:./include/linux/atomic/atomic-instrumented.h **** {
 644:./include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
 645:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 646:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_dec_return_release(v);
 647:./include/linux/atomic/atomic-instrumented.h **** }
 648:./include/linux/atomic/atomic-instrumented.h **** 
 649:./include/linux/atomic/atomic-instrumented.h **** /**
 650:./include/linux/atomic/atomic-instrumented.h ****  * atomic_dec_return_relaxed() - atomic decrement with relaxed ordering
 651:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 652:./include/linux/atomic/atomic-instrumented.h ****  *
 653:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - 1) with relaxed ordering.
 654:./include/linux/atomic/atomic-instrumented.h ****  *
 655:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_dec_return_relaxed() there.
 656:./include/linux/atomic/atomic-instrumented.h ****  *
 657:./include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 658:./include/linux/atomic/atomic-instrumented.h ****  */
 659:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 660:./include/linux/atomic/atomic-instrumented.h **** atomic_dec_return_relaxed(atomic_t *v)
 661:./include/linux/atomic/atomic-instrumented.h **** {
 662:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 663:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_dec_return_relaxed(v);
 664:./include/linux/atomic/atomic-instrumented.h **** }
 665:./include/linux/atomic/atomic-instrumented.h **** 
 666:./include/linux/atomic/atomic-instrumented.h **** /**
 667:./include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_dec() - atomic decrement with full ordering
 668:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 669:./include/linux/atomic/atomic-instrumented.h ****  *
 670:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - 1) with full ordering.
 671:./include/linux/atomic/atomic-instrumented.h ****  *
 672:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_dec() there.
 673:./include/linux/atomic/atomic-instrumented.h ****  *
 674:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 675:./include/linux/atomic/atomic-instrumented.h ****  */
 676:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 677:./include/linux/atomic/atomic-instrumented.h **** atomic_fetch_dec(atomic_t *v)
 678:./include/linux/atomic/atomic-instrumented.h **** {
 679:./include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
 680:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
ARM GAS  /tmp/ccKJN8PY.s 			page 46


 681:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_dec(v);
 682:./include/linux/atomic/atomic-instrumented.h **** }
 683:./include/linux/atomic/atomic-instrumented.h **** 
 684:./include/linux/atomic/atomic-instrumented.h **** /**
 685:./include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_dec_acquire() - atomic decrement with acquire ordering
 686:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 687:./include/linux/atomic/atomic-instrumented.h ****  *
 688:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - 1) with acquire ordering.
 689:./include/linux/atomic/atomic-instrumented.h ****  *
 690:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_dec_acquire() there.
 691:./include/linux/atomic/atomic-instrumented.h ****  *
 692:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 693:./include/linux/atomic/atomic-instrumented.h ****  */
 694:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 695:./include/linux/atomic/atomic-instrumented.h **** atomic_fetch_dec_acquire(atomic_t *v)
 696:./include/linux/atomic/atomic-instrumented.h **** {
 697:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 698:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_dec_acquire(v);
 699:./include/linux/atomic/atomic-instrumented.h **** }
 700:./include/linux/atomic/atomic-instrumented.h **** 
 701:./include/linux/atomic/atomic-instrumented.h **** /**
 702:./include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_dec_release() - atomic decrement with release ordering
 703:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 704:./include/linux/atomic/atomic-instrumented.h ****  *
 705:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - 1) with release ordering.
 706:./include/linux/atomic/atomic-instrumented.h ****  *
 707:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_dec_release() there.
 708:./include/linux/atomic/atomic-instrumented.h ****  *
 709:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 710:./include/linux/atomic/atomic-instrumented.h ****  */
 711:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 712:./include/linux/atomic/atomic-instrumented.h **** atomic_fetch_dec_release(atomic_t *v)
 713:./include/linux/atomic/atomic-instrumented.h **** {
 714:./include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
 715:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 716:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_dec_release(v);
 717:./include/linux/atomic/atomic-instrumented.h **** }
 718:./include/linux/atomic/atomic-instrumented.h **** 
 719:./include/linux/atomic/atomic-instrumented.h **** /**
 720:./include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_dec_relaxed() - atomic decrement with relaxed ordering
 721:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 722:./include/linux/atomic/atomic-instrumented.h ****  *
 723:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - 1) with relaxed ordering.
 724:./include/linux/atomic/atomic-instrumented.h ****  *
 725:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_dec_relaxed() there.
 726:./include/linux/atomic/atomic-instrumented.h ****  *
 727:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 728:./include/linux/atomic/atomic-instrumented.h ****  */
 729:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 730:./include/linux/atomic/atomic-instrumented.h **** atomic_fetch_dec_relaxed(atomic_t *v)
 731:./include/linux/atomic/atomic-instrumented.h **** {
 732:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 733:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_dec_relaxed(v);
 734:./include/linux/atomic/atomic-instrumented.h **** }
 735:./include/linux/atomic/atomic-instrumented.h **** 
 736:./include/linux/atomic/atomic-instrumented.h **** /**
 737:./include/linux/atomic/atomic-instrumented.h ****  * atomic_and() - atomic bitwise AND with relaxed ordering
ARM GAS  /tmp/ccKJN8PY.s 			page 47


 738:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 739:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 740:./include/linux/atomic/atomic-instrumented.h ****  *
 741:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v & @i) with relaxed ordering.
 742:./include/linux/atomic/atomic-instrumented.h ****  *
 743:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_and() there.
 744:./include/linux/atomic/atomic-instrumented.h ****  *
 745:./include/linux/atomic/atomic-instrumented.h ****  * Return: Nothing.
 746:./include/linux/atomic/atomic-instrumented.h ****  */
 747:./include/linux/atomic/atomic-instrumented.h **** static __always_inline void
 748:./include/linux/atomic/atomic-instrumented.h **** atomic_and(int i, atomic_t *v)
 749:./include/linux/atomic/atomic-instrumented.h **** {
 750:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 751:./include/linux/atomic/atomic-instrumented.h **** 	raw_atomic_and(i, v);
 752:./include/linux/atomic/atomic-instrumented.h **** }
 753:./include/linux/atomic/atomic-instrumented.h **** 
 754:./include/linux/atomic/atomic-instrumented.h **** /**
 755:./include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_and() - atomic bitwise AND with full ordering
 756:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 757:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 758:./include/linux/atomic/atomic-instrumented.h ****  *
 759:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v & @i) with full ordering.
 760:./include/linux/atomic/atomic-instrumented.h ****  *
 761:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_and() there.
 762:./include/linux/atomic/atomic-instrumented.h ****  *
 763:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 764:./include/linux/atomic/atomic-instrumented.h ****  */
 765:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 766:./include/linux/atomic/atomic-instrumented.h **** atomic_fetch_and(int i, atomic_t *v)
 767:./include/linux/atomic/atomic-instrumented.h **** {
 768:./include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
 769:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 770:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_and(i, v);
 771:./include/linux/atomic/atomic-instrumented.h **** }
 772:./include/linux/atomic/atomic-instrumented.h **** 
 773:./include/linux/atomic/atomic-instrumented.h **** /**
 774:./include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_and_acquire() - atomic bitwise AND with acquire ordering
 775:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 776:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 777:./include/linux/atomic/atomic-instrumented.h ****  *
 778:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v & @i) with acquire ordering.
 779:./include/linux/atomic/atomic-instrumented.h ****  *
 780:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_and_acquire() there.
 781:./include/linux/atomic/atomic-instrumented.h ****  *
 782:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 783:./include/linux/atomic/atomic-instrumented.h ****  */
 784:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 785:./include/linux/atomic/atomic-instrumented.h **** atomic_fetch_and_acquire(int i, atomic_t *v)
 786:./include/linux/atomic/atomic-instrumented.h **** {
 787:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 788:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_and_acquire(i, v);
 789:./include/linux/atomic/atomic-instrumented.h **** }
 790:./include/linux/atomic/atomic-instrumented.h **** 
 791:./include/linux/atomic/atomic-instrumented.h **** /**
 792:./include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_and_release() - atomic bitwise AND with release ordering
 793:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 794:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
ARM GAS  /tmp/ccKJN8PY.s 			page 48


 795:./include/linux/atomic/atomic-instrumented.h ****  *
 796:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v & @i) with release ordering.
 797:./include/linux/atomic/atomic-instrumented.h ****  *
 798:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_and_release() there.
 799:./include/linux/atomic/atomic-instrumented.h ****  *
 800:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 801:./include/linux/atomic/atomic-instrumented.h ****  */
 802:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 803:./include/linux/atomic/atomic-instrumented.h **** atomic_fetch_and_release(int i, atomic_t *v)
 804:./include/linux/atomic/atomic-instrumented.h **** {
 805:./include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
 806:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 807:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_and_release(i, v);
 808:./include/linux/atomic/atomic-instrumented.h **** }
 809:./include/linux/atomic/atomic-instrumented.h **** 
 810:./include/linux/atomic/atomic-instrumented.h **** /**
 811:./include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_and_relaxed() - atomic bitwise AND with relaxed ordering
 812:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 813:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 814:./include/linux/atomic/atomic-instrumented.h ****  *
 815:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v & @i) with relaxed ordering.
 816:./include/linux/atomic/atomic-instrumented.h ****  *
 817:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_and_relaxed() there.
 818:./include/linux/atomic/atomic-instrumented.h ****  *
 819:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 820:./include/linux/atomic/atomic-instrumented.h ****  */
 821:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 822:./include/linux/atomic/atomic-instrumented.h **** atomic_fetch_and_relaxed(int i, atomic_t *v)
 823:./include/linux/atomic/atomic-instrumented.h **** {
 824:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 825:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_and_relaxed(i, v);
 826:./include/linux/atomic/atomic-instrumented.h **** }
 827:./include/linux/atomic/atomic-instrumented.h **** 
 828:./include/linux/atomic/atomic-instrumented.h **** /**
 829:./include/linux/atomic/atomic-instrumented.h ****  * atomic_andnot() - atomic bitwise AND NOT with relaxed ordering
 830:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 831:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 832:./include/linux/atomic/atomic-instrumented.h ****  *
 833:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v & ~@i) with relaxed ordering.
 834:./include/linux/atomic/atomic-instrumented.h ****  *
 835:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_andnot() there.
 836:./include/linux/atomic/atomic-instrumented.h ****  *
 837:./include/linux/atomic/atomic-instrumented.h ****  * Return: Nothing.
 838:./include/linux/atomic/atomic-instrumented.h ****  */
 839:./include/linux/atomic/atomic-instrumented.h **** static __always_inline void
 840:./include/linux/atomic/atomic-instrumented.h **** atomic_andnot(int i, atomic_t *v)
 841:./include/linux/atomic/atomic-instrumented.h **** {
 842:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 843:./include/linux/atomic/atomic-instrumented.h **** 	raw_atomic_andnot(i, v);
 844:./include/linux/atomic/atomic-instrumented.h **** }
 845:./include/linux/atomic/atomic-instrumented.h **** 
 846:./include/linux/atomic/atomic-instrumented.h **** /**
 847:./include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_andnot() - atomic bitwise AND NOT with full ordering
 848:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 849:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 850:./include/linux/atomic/atomic-instrumented.h ****  *
 851:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v & ~@i) with full ordering.
ARM GAS  /tmp/ccKJN8PY.s 			page 49


 852:./include/linux/atomic/atomic-instrumented.h ****  *
 853:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_andnot() there.
 854:./include/linux/atomic/atomic-instrumented.h ****  *
 855:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 856:./include/linux/atomic/atomic-instrumented.h ****  */
 857:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 858:./include/linux/atomic/atomic-instrumented.h **** atomic_fetch_andnot(int i, atomic_t *v)
 859:./include/linux/atomic/atomic-instrumented.h **** {
 860:./include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
 861:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 862:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_andnot(i, v);
 863:./include/linux/atomic/atomic-instrumented.h **** }
 864:./include/linux/atomic/atomic-instrumented.h **** 
 865:./include/linux/atomic/atomic-instrumented.h **** /**
 866:./include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_andnot_acquire() - atomic bitwise AND NOT with acquire ordering
 867:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 868:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 869:./include/linux/atomic/atomic-instrumented.h ****  *
 870:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v & ~@i) with acquire ordering.
 871:./include/linux/atomic/atomic-instrumented.h ****  *
 872:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_andnot_acquire() there.
 873:./include/linux/atomic/atomic-instrumented.h ****  *
 874:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 875:./include/linux/atomic/atomic-instrumented.h ****  */
 876:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 877:./include/linux/atomic/atomic-instrumented.h **** atomic_fetch_andnot_acquire(int i, atomic_t *v)
 878:./include/linux/atomic/atomic-instrumented.h **** {
 879:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 880:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_andnot_acquire(i, v);
 881:./include/linux/atomic/atomic-instrumented.h **** }
 882:./include/linux/atomic/atomic-instrumented.h **** 
 883:./include/linux/atomic/atomic-instrumented.h **** /**
 884:./include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_andnot_release() - atomic bitwise AND NOT with release ordering
 885:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 886:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 887:./include/linux/atomic/atomic-instrumented.h ****  *
 888:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v & ~@i) with release ordering.
 889:./include/linux/atomic/atomic-instrumented.h ****  *
 890:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_andnot_release() there.
 891:./include/linux/atomic/atomic-instrumented.h ****  *
 892:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 893:./include/linux/atomic/atomic-instrumented.h ****  */
 894:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 895:./include/linux/atomic/atomic-instrumented.h **** atomic_fetch_andnot_release(int i, atomic_t *v)
 896:./include/linux/atomic/atomic-instrumented.h **** {
 897:./include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
 898:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 899:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_andnot_release(i, v);
 900:./include/linux/atomic/atomic-instrumented.h **** }
 901:./include/linux/atomic/atomic-instrumented.h **** 
 902:./include/linux/atomic/atomic-instrumented.h **** /**
 903:./include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_andnot_relaxed() - atomic bitwise AND NOT with relaxed ordering
 904:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 905:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 906:./include/linux/atomic/atomic-instrumented.h ****  *
 907:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v & ~@i) with relaxed ordering.
 908:./include/linux/atomic/atomic-instrumented.h ****  *
ARM GAS  /tmp/ccKJN8PY.s 			page 50


 909:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_andnot_relaxed() there.
 910:./include/linux/atomic/atomic-instrumented.h ****  *
 911:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 912:./include/linux/atomic/atomic-instrumented.h ****  */
 913:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 914:./include/linux/atomic/atomic-instrumented.h **** atomic_fetch_andnot_relaxed(int i, atomic_t *v)
 915:./include/linux/atomic/atomic-instrumented.h **** {
 916:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 917:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_andnot_relaxed(i, v);
 918:./include/linux/atomic/atomic-instrumented.h **** }
 919:./include/linux/atomic/atomic-instrumented.h **** 
 920:./include/linux/atomic/atomic-instrumented.h **** /**
 921:./include/linux/atomic/atomic-instrumented.h ****  * atomic_or() - atomic bitwise OR with relaxed ordering
 922:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 923:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 924:./include/linux/atomic/atomic-instrumented.h ****  *
 925:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v | @i) with relaxed ordering.
 926:./include/linux/atomic/atomic-instrumented.h ****  *
 927:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_or() there.
 928:./include/linux/atomic/atomic-instrumented.h ****  *
 929:./include/linux/atomic/atomic-instrumented.h ****  * Return: Nothing.
 930:./include/linux/atomic/atomic-instrumented.h ****  */
 931:./include/linux/atomic/atomic-instrumented.h **** static __always_inline void
 932:./include/linux/atomic/atomic-instrumented.h **** atomic_or(int i, atomic_t *v)
 933:./include/linux/atomic/atomic-instrumented.h **** {
 934:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 935:./include/linux/atomic/atomic-instrumented.h **** 	raw_atomic_or(i, v);
 936:./include/linux/atomic/atomic-instrumented.h **** }
 937:./include/linux/atomic/atomic-instrumented.h **** 
 938:./include/linux/atomic/atomic-instrumented.h **** /**
 939:./include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_or() - atomic bitwise OR with full ordering
 940:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 941:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 942:./include/linux/atomic/atomic-instrumented.h ****  *
 943:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v | @i) with full ordering.
 944:./include/linux/atomic/atomic-instrumented.h ****  *
 945:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_or() there.
 946:./include/linux/atomic/atomic-instrumented.h ****  *
 947:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 948:./include/linux/atomic/atomic-instrumented.h ****  */
 949:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 950:./include/linux/atomic/atomic-instrumented.h **** atomic_fetch_or(int i, atomic_t *v)
 951:./include/linux/atomic/atomic-instrumented.h **** {
 952:./include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
 953:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 954:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_or(i, v);
 955:./include/linux/atomic/atomic-instrumented.h **** }
 956:./include/linux/atomic/atomic-instrumented.h **** 
 957:./include/linux/atomic/atomic-instrumented.h **** /**
 958:./include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_or_acquire() - atomic bitwise OR with acquire ordering
 959:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 960:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 961:./include/linux/atomic/atomic-instrumented.h ****  *
 962:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v | @i) with acquire ordering.
 963:./include/linux/atomic/atomic-instrumented.h ****  *
 964:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_or_acquire() there.
 965:./include/linux/atomic/atomic-instrumented.h ****  *
ARM GAS  /tmp/ccKJN8PY.s 			page 51


 966:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 967:./include/linux/atomic/atomic-instrumented.h ****  */
 968:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 969:./include/linux/atomic/atomic-instrumented.h **** atomic_fetch_or_acquire(int i, atomic_t *v)
 970:./include/linux/atomic/atomic-instrumented.h **** {
 971:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 972:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_or_acquire(i, v);
 973:./include/linux/atomic/atomic-instrumented.h **** }
 974:./include/linux/atomic/atomic-instrumented.h **** 
 975:./include/linux/atomic/atomic-instrumented.h **** /**
 976:./include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_or_release() - atomic bitwise OR with release ordering
 977:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 978:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 979:./include/linux/atomic/atomic-instrumented.h ****  *
 980:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v | @i) with release ordering.
 981:./include/linux/atomic/atomic-instrumented.h ****  *
 982:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_or_release() there.
 983:./include/linux/atomic/atomic-instrumented.h ****  *
 984:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 985:./include/linux/atomic/atomic-instrumented.h ****  */
 986:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 987:./include/linux/atomic/atomic-instrumented.h **** atomic_fetch_or_release(int i, atomic_t *v)
 988:./include/linux/atomic/atomic-instrumented.h **** {
 989:./include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
 990:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 991:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_or_release(i, v);
 992:./include/linux/atomic/atomic-instrumented.h **** }
 993:./include/linux/atomic/atomic-instrumented.h **** 
 994:./include/linux/atomic/atomic-instrumented.h **** /**
 995:./include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_or_relaxed() - atomic bitwise OR with relaxed ordering
 996:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 997:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 998:./include/linux/atomic/atomic-instrumented.h ****  *
 999:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v | @i) with relaxed ordering.
1000:./include/linux/atomic/atomic-instrumented.h ****  *
1001:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_or_relaxed() there.
1002:./include/linux/atomic/atomic-instrumented.h ****  *
1003:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1004:./include/linux/atomic/atomic-instrumented.h ****  */
1005:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1006:./include/linux/atomic/atomic-instrumented.h **** atomic_fetch_or_relaxed(int i, atomic_t *v)
1007:./include/linux/atomic/atomic-instrumented.h **** {
1008:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1009:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_or_relaxed(i, v);
1010:./include/linux/atomic/atomic-instrumented.h **** }
1011:./include/linux/atomic/atomic-instrumented.h **** 
1012:./include/linux/atomic/atomic-instrumented.h **** /**
1013:./include/linux/atomic/atomic-instrumented.h ****  * atomic_xor() - atomic bitwise XOR with relaxed ordering
1014:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value
1015:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1016:./include/linux/atomic/atomic-instrumented.h ****  *
1017:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v ^ @i) with relaxed ordering.
1018:./include/linux/atomic/atomic-instrumented.h ****  *
1019:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_xor() there.
1020:./include/linux/atomic/atomic-instrumented.h ****  *
1021:./include/linux/atomic/atomic-instrumented.h ****  * Return: Nothing.
1022:./include/linux/atomic/atomic-instrumented.h ****  */
ARM GAS  /tmp/ccKJN8PY.s 			page 52


1023:./include/linux/atomic/atomic-instrumented.h **** static __always_inline void
1024:./include/linux/atomic/atomic-instrumented.h **** atomic_xor(int i, atomic_t *v)
1025:./include/linux/atomic/atomic-instrumented.h **** {
1026:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1027:./include/linux/atomic/atomic-instrumented.h **** 	raw_atomic_xor(i, v);
1028:./include/linux/atomic/atomic-instrumented.h **** }
1029:./include/linux/atomic/atomic-instrumented.h **** 
1030:./include/linux/atomic/atomic-instrumented.h **** /**
1031:./include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_xor() - atomic bitwise XOR with full ordering
1032:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value
1033:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1034:./include/linux/atomic/atomic-instrumented.h ****  *
1035:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v ^ @i) with full ordering.
1036:./include/linux/atomic/atomic-instrumented.h ****  *
1037:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_xor() there.
1038:./include/linux/atomic/atomic-instrumented.h ****  *
1039:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1040:./include/linux/atomic/atomic-instrumented.h ****  */
1041:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1042:./include/linux/atomic/atomic-instrumented.h **** atomic_fetch_xor(int i, atomic_t *v)
1043:./include/linux/atomic/atomic-instrumented.h **** {
1044:./include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
1045:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1046:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_xor(i, v);
1047:./include/linux/atomic/atomic-instrumented.h **** }
1048:./include/linux/atomic/atomic-instrumented.h **** 
1049:./include/linux/atomic/atomic-instrumented.h **** /**
1050:./include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_xor_acquire() - atomic bitwise XOR with acquire ordering
1051:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value
1052:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1053:./include/linux/atomic/atomic-instrumented.h ****  *
1054:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v ^ @i) with acquire ordering.
1055:./include/linux/atomic/atomic-instrumented.h ****  *
1056:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_xor_acquire() there.
1057:./include/linux/atomic/atomic-instrumented.h ****  *
1058:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1059:./include/linux/atomic/atomic-instrumented.h ****  */
1060:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1061:./include/linux/atomic/atomic-instrumented.h **** atomic_fetch_xor_acquire(int i, atomic_t *v)
1062:./include/linux/atomic/atomic-instrumented.h **** {
1063:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1064:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_xor_acquire(i, v);
1065:./include/linux/atomic/atomic-instrumented.h **** }
1066:./include/linux/atomic/atomic-instrumented.h **** 
1067:./include/linux/atomic/atomic-instrumented.h **** /**
1068:./include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_xor_release() - atomic bitwise XOR with release ordering
1069:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value
1070:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1071:./include/linux/atomic/atomic-instrumented.h ****  *
1072:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v ^ @i) with release ordering.
1073:./include/linux/atomic/atomic-instrumented.h ****  *
1074:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_xor_release() there.
1075:./include/linux/atomic/atomic-instrumented.h ****  *
1076:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1077:./include/linux/atomic/atomic-instrumented.h ****  */
1078:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1079:./include/linux/atomic/atomic-instrumented.h **** atomic_fetch_xor_release(int i, atomic_t *v)
ARM GAS  /tmp/ccKJN8PY.s 			page 53


1080:./include/linux/atomic/atomic-instrumented.h **** {
1081:./include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
1082:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1083:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_xor_release(i, v);
1084:./include/linux/atomic/atomic-instrumented.h **** }
1085:./include/linux/atomic/atomic-instrumented.h **** 
1086:./include/linux/atomic/atomic-instrumented.h **** /**
1087:./include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_xor_relaxed() - atomic bitwise XOR with relaxed ordering
1088:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value
1089:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1090:./include/linux/atomic/atomic-instrumented.h ****  *
1091:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v ^ @i) with relaxed ordering.
1092:./include/linux/atomic/atomic-instrumented.h ****  *
1093:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_xor_relaxed() there.
1094:./include/linux/atomic/atomic-instrumented.h ****  *
1095:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1096:./include/linux/atomic/atomic-instrumented.h ****  */
1097:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1098:./include/linux/atomic/atomic-instrumented.h **** atomic_fetch_xor_relaxed(int i, atomic_t *v)
1099:./include/linux/atomic/atomic-instrumented.h **** {
1100:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1101:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_xor_relaxed(i, v);
1102:./include/linux/atomic/atomic-instrumented.h **** }
1103:./include/linux/atomic/atomic-instrumented.h **** 
1104:./include/linux/atomic/atomic-instrumented.h **** /**
1105:./include/linux/atomic/atomic-instrumented.h ****  * atomic_xchg() - atomic exchange with full ordering
1106:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1107:./include/linux/atomic/atomic-instrumented.h ****  * @new: int value to assign
1108:./include/linux/atomic/atomic-instrumented.h ****  *
1109:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to @new with full ordering.
1110:./include/linux/atomic/atomic-instrumented.h ****  *
1111:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_xchg() there.
1112:./include/linux/atomic/atomic-instrumented.h ****  *
1113:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1114:./include/linux/atomic/atomic-instrumented.h ****  */
1115:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1116:./include/linux/atomic/atomic-instrumented.h **** atomic_xchg(atomic_t *v, int new)
1117:./include/linux/atomic/atomic-instrumented.h **** {
1118:./include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
1119:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1120:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_xchg(v, new);
1121:./include/linux/atomic/atomic-instrumented.h **** }
1122:./include/linux/atomic/atomic-instrumented.h **** 
1123:./include/linux/atomic/atomic-instrumented.h **** /**
1124:./include/linux/atomic/atomic-instrumented.h ****  * atomic_xchg_acquire() - atomic exchange with acquire ordering
1125:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1126:./include/linux/atomic/atomic-instrumented.h ****  * @new: int value to assign
1127:./include/linux/atomic/atomic-instrumented.h ****  *
1128:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to @new with acquire ordering.
1129:./include/linux/atomic/atomic-instrumented.h ****  *
1130:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_xchg_acquire() there.
1131:./include/linux/atomic/atomic-instrumented.h ****  *
1132:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1133:./include/linux/atomic/atomic-instrumented.h ****  */
1134:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1135:./include/linux/atomic/atomic-instrumented.h **** atomic_xchg_acquire(atomic_t *v, int new)
1136:./include/linux/atomic/atomic-instrumented.h **** {
ARM GAS  /tmp/ccKJN8PY.s 			page 54


1137:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1138:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_xchg_acquire(v, new);
1139:./include/linux/atomic/atomic-instrumented.h **** }
1140:./include/linux/atomic/atomic-instrumented.h **** 
1141:./include/linux/atomic/atomic-instrumented.h **** /**
1142:./include/linux/atomic/atomic-instrumented.h ****  * atomic_xchg_release() - atomic exchange with release ordering
1143:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1144:./include/linux/atomic/atomic-instrumented.h ****  * @new: int value to assign
1145:./include/linux/atomic/atomic-instrumented.h ****  *
1146:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to @new with release ordering.
1147:./include/linux/atomic/atomic-instrumented.h ****  *
1148:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_xchg_release() there.
1149:./include/linux/atomic/atomic-instrumented.h ****  *
1150:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1151:./include/linux/atomic/atomic-instrumented.h ****  */
1152:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1153:./include/linux/atomic/atomic-instrumented.h **** atomic_xchg_release(atomic_t *v, int new)
1154:./include/linux/atomic/atomic-instrumented.h **** {
1155:./include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
1156:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1157:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_xchg_release(v, new);
1158:./include/linux/atomic/atomic-instrumented.h **** }
1159:./include/linux/atomic/atomic-instrumented.h **** 
1160:./include/linux/atomic/atomic-instrumented.h **** /**
1161:./include/linux/atomic/atomic-instrumented.h ****  * atomic_xchg_relaxed() - atomic exchange with relaxed ordering
1162:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1163:./include/linux/atomic/atomic-instrumented.h ****  * @new: int value to assign
1164:./include/linux/atomic/atomic-instrumented.h ****  *
1165:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to @new with relaxed ordering.
1166:./include/linux/atomic/atomic-instrumented.h ****  *
1167:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_xchg_relaxed() there.
1168:./include/linux/atomic/atomic-instrumented.h ****  *
1169:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1170:./include/linux/atomic/atomic-instrumented.h ****  */
1171:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1172:./include/linux/atomic/atomic-instrumented.h **** atomic_xchg_relaxed(atomic_t *v, int new)
1173:./include/linux/atomic/atomic-instrumented.h **** {
1174:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1175:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_xchg_relaxed(v, new);
1176:./include/linux/atomic/atomic-instrumented.h **** }
1177:./include/linux/atomic/atomic-instrumented.h **** 
1178:./include/linux/atomic/atomic-instrumented.h **** /**
1179:./include/linux/atomic/atomic-instrumented.h ****  * atomic_cmpxchg() - atomic compare and exchange with full ordering
1180:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1181:./include/linux/atomic/atomic-instrumented.h ****  * @old: int value to compare with
1182:./include/linux/atomic/atomic-instrumented.h ****  * @new: int value to assign
1183:./include/linux/atomic/atomic-instrumented.h ****  *
1184:./include/linux/atomic/atomic-instrumented.h ****  * If (@v == @old), atomically updates @v to @new with full ordering.
1185:./include/linux/atomic/atomic-instrumented.h ****  * Otherwise, @v is not modified and relaxed ordering is provided.
1186:./include/linux/atomic/atomic-instrumented.h ****  *
1187:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_cmpxchg() there.
1188:./include/linux/atomic/atomic-instrumented.h ****  *
1189:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1190:./include/linux/atomic/atomic-instrumented.h ****  */
1191:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1192:./include/linux/atomic/atomic-instrumented.h **** atomic_cmpxchg(atomic_t *v, int old, int new)
1193:./include/linux/atomic/atomic-instrumented.h **** {
ARM GAS  /tmp/ccKJN8PY.s 			page 55


1194:./include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
1195:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1196:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_cmpxchg(v, old, new);
1197:./include/linux/atomic/atomic-instrumented.h **** }
1198:./include/linux/atomic/atomic-instrumented.h **** 
1199:./include/linux/atomic/atomic-instrumented.h **** /**
1200:./include/linux/atomic/atomic-instrumented.h ****  * atomic_cmpxchg_acquire() - atomic compare and exchange with acquire ordering
1201:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1202:./include/linux/atomic/atomic-instrumented.h ****  * @old: int value to compare with
1203:./include/linux/atomic/atomic-instrumented.h ****  * @new: int value to assign
1204:./include/linux/atomic/atomic-instrumented.h ****  *
1205:./include/linux/atomic/atomic-instrumented.h ****  * If (@v == @old), atomically updates @v to @new with acquire ordering.
1206:./include/linux/atomic/atomic-instrumented.h ****  * Otherwise, @v is not modified and relaxed ordering is provided.
1207:./include/linux/atomic/atomic-instrumented.h ****  *
1208:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_cmpxchg_acquire() there.
1209:./include/linux/atomic/atomic-instrumented.h ****  *
1210:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1211:./include/linux/atomic/atomic-instrumented.h ****  */
1212:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1213:./include/linux/atomic/atomic-instrumented.h **** atomic_cmpxchg_acquire(atomic_t *v, int old, int new)
1214:./include/linux/atomic/atomic-instrumented.h **** {
1215:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1216:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_cmpxchg_acquire(v, old, new);
1217:./include/linux/atomic/atomic-instrumented.h **** }
1218:./include/linux/atomic/atomic-instrumented.h **** 
1219:./include/linux/atomic/atomic-instrumented.h **** /**
1220:./include/linux/atomic/atomic-instrumented.h ****  * atomic_cmpxchg_release() - atomic compare and exchange with release ordering
1221:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1222:./include/linux/atomic/atomic-instrumented.h ****  * @old: int value to compare with
1223:./include/linux/atomic/atomic-instrumented.h ****  * @new: int value to assign
1224:./include/linux/atomic/atomic-instrumented.h ****  *
1225:./include/linux/atomic/atomic-instrumented.h ****  * If (@v == @old), atomically updates @v to @new with release ordering.
1226:./include/linux/atomic/atomic-instrumented.h ****  * Otherwise, @v is not modified and relaxed ordering is provided.
1227:./include/linux/atomic/atomic-instrumented.h ****  *
1228:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_cmpxchg_release() there.
1229:./include/linux/atomic/atomic-instrumented.h ****  *
1230:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1231:./include/linux/atomic/atomic-instrumented.h ****  */
1232:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1233:./include/linux/atomic/atomic-instrumented.h **** atomic_cmpxchg_release(atomic_t *v, int old, int new)
1234:./include/linux/atomic/atomic-instrumented.h **** {
1235:./include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
1236:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1237:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_cmpxchg_release(v, old, new);
1238:./include/linux/atomic/atomic-instrumented.h **** }
1239:./include/linux/atomic/atomic-instrumented.h **** 
1240:./include/linux/atomic/atomic-instrumented.h **** /**
1241:./include/linux/atomic/atomic-instrumented.h ****  * atomic_cmpxchg_relaxed() - atomic compare and exchange with relaxed ordering
1242:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1243:./include/linux/atomic/atomic-instrumented.h ****  * @old: int value to compare with
1244:./include/linux/atomic/atomic-instrumented.h ****  * @new: int value to assign
1245:./include/linux/atomic/atomic-instrumented.h ****  *
1246:./include/linux/atomic/atomic-instrumented.h ****  * If (@v == @old), atomically updates @v to @new with relaxed ordering.
1247:./include/linux/atomic/atomic-instrumented.h ****  * Otherwise, @v is not modified and relaxed ordering is provided.
1248:./include/linux/atomic/atomic-instrumented.h ****  *
1249:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_cmpxchg_relaxed() there.
1250:./include/linux/atomic/atomic-instrumented.h ****  *
ARM GAS  /tmp/ccKJN8PY.s 			page 56


1251:./include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1252:./include/linux/atomic/atomic-instrumented.h ****  */
1253:./include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1254:./include/linux/atomic/atomic-instrumented.h **** atomic_cmpxchg_relaxed(atomic_t *v, int old, int new)
1255:./include/linux/atomic/atomic-instrumented.h **** {
1256:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1257:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_cmpxchg_relaxed(v, old, new);
1258:./include/linux/atomic/atomic-instrumented.h **** }
1259:./include/linux/atomic/atomic-instrumented.h **** 
1260:./include/linux/atomic/atomic-instrumented.h **** /**
1261:./include/linux/atomic/atomic-instrumented.h ****  * atomic_try_cmpxchg() - atomic compare and exchange with full ordering
1262:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1263:./include/linux/atomic/atomic-instrumented.h ****  * @old: pointer to int value to compare with
1264:./include/linux/atomic/atomic-instrumented.h ****  * @new: int value to assign
1265:./include/linux/atomic/atomic-instrumented.h ****  *
1266:./include/linux/atomic/atomic-instrumented.h ****  * If (@v == @old), atomically updates @v to @new with full ordering.
1267:./include/linux/atomic/atomic-instrumented.h ****  * Otherwise, @v is not modified, @old is updated to the current value of @v,
1268:./include/linux/atomic/atomic-instrumented.h ****  * and relaxed ordering is provided.
1269:./include/linux/atomic/atomic-instrumented.h ****  *
1270:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_try_cmpxchg() there.
1271:./include/linux/atomic/atomic-instrumented.h ****  *
1272:./include/linux/atomic/atomic-instrumented.h ****  * Return: @true if the exchange occured, @false otherwise.
1273:./include/linux/atomic/atomic-instrumented.h ****  */
1274:./include/linux/atomic/atomic-instrumented.h **** static __always_inline bool
1275:./include/linux/atomic/atomic-instrumented.h **** atomic_try_cmpxchg(atomic_t *v, int *old, int new)
1276:./include/linux/atomic/atomic-instrumented.h **** {
1277:./include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
1278:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1279:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(old, sizeof(*old));
1280:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_try_cmpxchg(v, old, new);
1281:./include/linux/atomic/atomic-instrumented.h **** }
1282:./include/linux/atomic/atomic-instrumented.h **** 
1283:./include/linux/atomic/atomic-instrumented.h **** /**
1284:./include/linux/atomic/atomic-instrumented.h ****  * atomic_try_cmpxchg_acquire() - atomic compare and exchange with acquire ordering
1285:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1286:./include/linux/atomic/atomic-instrumented.h ****  * @old: pointer to int value to compare with
1287:./include/linux/atomic/atomic-instrumented.h ****  * @new: int value to assign
1288:./include/linux/atomic/atomic-instrumented.h ****  *
1289:./include/linux/atomic/atomic-instrumented.h ****  * If (@v == @old), atomically updates @v to @new with acquire ordering.
1290:./include/linux/atomic/atomic-instrumented.h ****  * Otherwise, @v is not modified, @old is updated to the current value of @v,
1291:./include/linux/atomic/atomic-instrumented.h ****  * and relaxed ordering is provided.
1292:./include/linux/atomic/atomic-instrumented.h ****  *
1293:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_try_cmpxchg_acquire() there.
1294:./include/linux/atomic/atomic-instrumented.h ****  *
1295:./include/linux/atomic/atomic-instrumented.h ****  * Return: @true if the exchange occured, @false otherwise.
1296:./include/linux/atomic/atomic-instrumented.h ****  */
1297:./include/linux/atomic/atomic-instrumented.h **** static __always_inline bool
1298:./include/linux/atomic/atomic-instrumented.h **** atomic_try_cmpxchg_acquire(atomic_t *v, int *old, int new)
1299:./include/linux/atomic/atomic-instrumented.h **** {
1300:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1301:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(old, sizeof(*old));
1302:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_try_cmpxchg_acquire(v, old, new);
1303:./include/linux/atomic/atomic-instrumented.h **** }
1304:./include/linux/atomic/atomic-instrumented.h **** 
1305:./include/linux/atomic/atomic-instrumented.h **** /**
1306:./include/linux/atomic/atomic-instrumented.h ****  * atomic_try_cmpxchg_release() - atomic compare and exchange with release ordering
1307:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
ARM GAS  /tmp/ccKJN8PY.s 			page 57


1308:./include/linux/atomic/atomic-instrumented.h ****  * @old: pointer to int value to compare with
1309:./include/linux/atomic/atomic-instrumented.h ****  * @new: int value to assign
1310:./include/linux/atomic/atomic-instrumented.h ****  *
1311:./include/linux/atomic/atomic-instrumented.h ****  * If (@v == @old), atomically updates @v to @new with release ordering.
1312:./include/linux/atomic/atomic-instrumented.h ****  * Otherwise, @v is not modified, @old is updated to the current value of @v,
1313:./include/linux/atomic/atomic-instrumented.h ****  * and relaxed ordering is provided.
1314:./include/linux/atomic/atomic-instrumented.h ****  *
1315:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_try_cmpxchg_release() there.
1316:./include/linux/atomic/atomic-instrumented.h ****  *
1317:./include/linux/atomic/atomic-instrumented.h ****  * Return: @true if the exchange occured, @false otherwise.
1318:./include/linux/atomic/atomic-instrumented.h ****  */
1319:./include/linux/atomic/atomic-instrumented.h **** static __always_inline bool
1320:./include/linux/atomic/atomic-instrumented.h **** atomic_try_cmpxchg_release(atomic_t *v, int *old, int new)
1321:./include/linux/atomic/atomic-instrumented.h **** {
1322:./include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
1323:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1324:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(old, sizeof(*old));
1325:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_try_cmpxchg_release(v, old, new);
1326:./include/linux/atomic/atomic-instrumented.h **** }
1327:./include/linux/atomic/atomic-instrumented.h **** 
1328:./include/linux/atomic/atomic-instrumented.h **** /**
1329:./include/linux/atomic/atomic-instrumented.h ****  * atomic_try_cmpxchg_relaxed() - atomic compare and exchange with relaxed ordering
1330:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1331:./include/linux/atomic/atomic-instrumented.h ****  * @old: pointer to int value to compare with
1332:./include/linux/atomic/atomic-instrumented.h ****  * @new: int value to assign
1333:./include/linux/atomic/atomic-instrumented.h ****  *
1334:./include/linux/atomic/atomic-instrumented.h ****  * If (@v == @old), atomically updates @v to @new with relaxed ordering.
1335:./include/linux/atomic/atomic-instrumented.h ****  * Otherwise, @v is not modified, @old is updated to the current value of @v,
1336:./include/linux/atomic/atomic-instrumented.h ****  * and relaxed ordering is provided.
1337:./include/linux/atomic/atomic-instrumented.h ****  *
1338:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_try_cmpxchg_relaxed() there.
1339:./include/linux/atomic/atomic-instrumented.h ****  *
1340:./include/linux/atomic/atomic-instrumented.h ****  * Return: @true if the exchange occured, @false otherwise.
1341:./include/linux/atomic/atomic-instrumented.h ****  */
1342:./include/linux/atomic/atomic-instrumented.h **** static __always_inline bool
1343:./include/linux/atomic/atomic-instrumented.h **** atomic_try_cmpxchg_relaxed(atomic_t *v, int *old, int new)
1344:./include/linux/atomic/atomic-instrumented.h **** {
1345:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1346:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(old, sizeof(*old));
1347:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_try_cmpxchg_relaxed(v, old, new);
1348:./include/linux/atomic/atomic-instrumented.h **** }
1349:./include/linux/atomic/atomic-instrumented.h **** 
1350:./include/linux/atomic/atomic-instrumented.h **** /**
1351:./include/linux/atomic/atomic-instrumented.h ****  * atomic_sub_and_test() - atomic subtract and test if zero with full ordering
1352:./include/linux/atomic/atomic-instrumented.h ****  * @i: int value to subtract
1353:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1354:./include/linux/atomic/atomic-instrumented.h ****  *
1355:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - @i) with full ordering.
1356:./include/linux/atomic/atomic-instrumented.h ****  *
1357:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_sub_and_test() there.
1358:./include/linux/atomic/atomic-instrumented.h ****  *
1359:./include/linux/atomic/atomic-instrumented.h ****  * Return: @true if the resulting value of @v is zero, @false otherwise.
1360:./include/linux/atomic/atomic-instrumented.h ****  */
1361:./include/linux/atomic/atomic-instrumented.h **** static __always_inline bool
1362:./include/linux/atomic/atomic-instrumented.h **** atomic_sub_and_test(int i, atomic_t *v)
1363:./include/linux/atomic/atomic-instrumented.h **** {
1364:./include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
ARM GAS  /tmp/ccKJN8PY.s 			page 58


1365:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1366:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_sub_and_test(i, v);
1367:./include/linux/atomic/atomic-instrumented.h **** }
1368:./include/linux/atomic/atomic-instrumented.h **** 
1369:./include/linux/atomic/atomic-instrumented.h **** /**
1370:./include/linux/atomic/atomic-instrumented.h ****  * atomic_dec_and_test() - atomic decrement and test if zero with full ordering
1371:./include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1372:./include/linux/atomic/atomic-instrumented.h ****  *
1373:./include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - 1) with full ordering.
1374:./include/linux/atomic/atomic-instrumented.h ****  *
1375:./include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_dec_and_test() there.
1376:./include/linux/atomic/atomic-instrumented.h ****  *
1377:./include/linux/atomic/atomic-instrumented.h ****  * Return: @true if the resulting value of @v is zero, @false otherwise.
1378:./include/linux/atomic/atomic-instrumented.h ****  */
1379:./include/linux/atomic/atomic-instrumented.h **** static __always_inline bool
1380:./include/linux/atomic/atomic-instrumented.h **** atomic_dec_and_test(atomic_t *v)
 257              		.loc 2 1380 1 is_stmt 1 view .LVU64
1381:./include/linux/atomic/atomic-instrumented.h **** {
1382:./include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
 258              		.loc 2 1382 2 view .LVU65
 259              		.loc 2 1382 2 view .LVU66
 260              		.loc 2 1382 2 view .LVU67
1383:./include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 261              		.loc 2 1383 2 view .LVU68
1384:./include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_dec_and_test(v);
 262              		.loc 2 1384 2 view .LVU69
 263              	.LBB88:
 264              	.LBI88:
1005:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1006:./include/linux/atomic/atomic-arch-fallback.h **** }
1007:./include/linux/atomic/atomic-arch-fallback.h **** 
1008:./include/linux/atomic/atomic-arch-fallback.h **** /**
1009:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_inc_return() - atomic increment with full ordering
1010:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1011:./include/linux/atomic/atomic-arch-fallback.h ****  *
1012:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + 1) with full ordering.
1013:./include/linux/atomic/atomic-arch-fallback.h ****  *
1014:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_inc_return() elsewhere.
1015:./include/linux/atomic/atomic-arch-fallback.h ****  *
1016:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
1017:./include/linux/atomic/atomic-arch-fallback.h ****  */
1018:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1019:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_inc_return(atomic_t *v)
1020:./include/linux/atomic/atomic-arch-fallback.h **** {
1021:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_inc_return)
1022:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_inc_return(v);
1023:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_inc_return_relaxed)
1024:./include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
1025:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
1026:./include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_inc_return_relaxed(v);
1027:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
1028:./include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1029:./include/linux/atomic/atomic-arch-fallback.h **** #else
1030:./include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_add_return(1, v);
1031:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1032:./include/linux/atomic/atomic-arch-fallback.h **** }
1033:./include/linux/atomic/atomic-arch-fallback.h **** 
ARM GAS  /tmp/ccKJN8PY.s 			page 59


1034:./include/linux/atomic/atomic-arch-fallback.h **** /**
1035:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_inc_return_acquire() - atomic increment with acquire ordering
1036:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1037:./include/linux/atomic/atomic-arch-fallback.h ****  *
1038:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + 1) with acquire ordering.
1039:./include/linux/atomic/atomic-arch-fallback.h ****  *
1040:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_inc_return_acquire() elsewhere.
1041:./include/linux/atomic/atomic-arch-fallback.h ****  *
1042:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
1043:./include/linux/atomic/atomic-arch-fallback.h ****  */
1044:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1045:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_inc_return_acquire(atomic_t *v)
1046:./include/linux/atomic/atomic-arch-fallback.h **** {
1047:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_inc_return_acquire)
1048:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_inc_return_acquire(v);
1049:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_inc_return_relaxed)
1050:./include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_inc_return_relaxed(v);
1051:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
1052:./include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1053:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_inc_return)
1054:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_inc_return(v);
1055:./include/linux/atomic/atomic-arch-fallback.h **** #else
1056:./include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_add_return_acquire(1, v);
1057:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1058:./include/linux/atomic/atomic-arch-fallback.h **** }
1059:./include/linux/atomic/atomic-arch-fallback.h **** 
1060:./include/linux/atomic/atomic-arch-fallback.h **** /**
1061:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_inc_return_release() - atomic increment with release ordering
1062:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1063:./include/linux/atomic/atomic-arch-fallback.h ****  *
1064:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + 1) with release ordering.
1065:./include/linux/atomic/atomic-arch-fallback.h ****  *
1066:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_inc_return_release() elsewhere.
1067:./include/linux/atomic/atomic-arch-fallback.h ****  *
1068:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
1069:./include/linux/atomic/atomic-arch-fallback.h ****  */
1070:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1071:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_inc_return_release(atomic_t *v)
1072:./include/linux/atomic/atomic-arch-fallback.h **** {
1073:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_inc_return_release)
1074:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_inc_return_release(v);
1075:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_inc_return_relaxed)
1076:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
1077:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_inc_return_relaxed(v);
1078:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_inc_return)
1079:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_inc_return(v);
1080:./include/linux/atomic/atomic-arch-fallback.h **** #else
1081:./include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_add_return_release(1, v);
1082:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1083:./include/linux/atomic/atomic-arch-fallback.h **** }
1084:./include/linux/atomic/atomic-arch-fallback.h **** 
1085:./include/linux/atomic/atomic-arch-fallback.h **** /**
1086:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_inc_return_relaxed() - atomic increment with relaxed ordering
1087:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1088:./include/linux/atomic/atomic-arch-fallback.h ****  *
1089:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + 1) with relaxed ordering.
1090:./include/linux/atomic/atomic-arch-fallback.h ****  *
ARM GAS  /tmp/ccKJN8PY.s 			page 60


1091:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_inc_return_relaxed() elsewhere.
1092:./include/linux/atomic/atomic-arch-fallback.h ****  *
1093:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
1094:./include/linux/atomic/atomic-arch-fallback.h ****  */
1095:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1096:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_inc_return_relaxed(atomic_t *v)
1097:./include/linux/atomic/atomic-arch-fallback.h **** {
1098:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_inc_return_relaxed)
1099:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_inc_return_relaxed(v);
1100:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_inc_return)
1101:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_inc_return(v);
1102:./include/linux/atomic/atomic-arch-fallback.h **** #else
1103:./include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_add_return_relaxed(1, v);
1104:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1105:./include/linux/atomic/atomic-arch-fallback.h **** }
1106:./include/linux/atomic/atomic-arch-fallback.h **** 
1107:./include/linux/atomic/atomic-arch-fallback.h **** /**
1108:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_inc() - atomic increment with full ordering
1109:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1110:./include/linux/atomic/atomic-arch-fallback.h ****  *
1111:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + 1) with full ordering.
1112:./include/linux/atomic/atomic-arch-fallback.h ****  *
1113:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_inc() elsewhere.
1114:./include/linux/atomic/atomic-arch-fallback.h ****  *
1115:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1116:./include/linux/atomic/atomic-arch-fallback.h ****  */
1117:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1118:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_inc(atomic_t *v)
1119:./include/linux/atomic/atomic-arch-fallback.h **** {
1120:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_inc)
1121:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_inc(v);
1122:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_inc_relaxed)
1123:./include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
1124:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
1125:./include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_fetch_inc_relaxed(v);
1126:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
1127:./include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1128:./include/linux/atomic/atomic-arch-fallback.h **** #else
1129:./include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_fetch_add(1, v);
1130:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1131:./include/linux/atomic/atomic-arch-fallback.h **** }
1132:./include/linux/atomic/atomic-arch-fallback.h **** 
1133:./include/linux/atomic/atomic-arch-fallback.h **** /**
1134:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_inc_acquire() - atomic increment with acquire ordering
1135:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1136:./include/linux/atomic/atomic-arch-fallback.h ****  *
1137:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + 1) with acquire ordering.
1138:./include/linux/atomic/atomic-arch-fallback.h ****  *
1139:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_inc_acquire() elsewhere.
1140:./include/linux/atomic/atomic-arch-fallback.h ****  *
1141:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1142:./include/linux/atomic/atomic-arch-fallback.h ****  */
1143:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1144:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_inc_acquire(atomic_t *v)
1145:./include/linux/atomic/atomic-arch-fallback.h **** {
1146:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_inc_acquire)
1147:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_inc_acquire(v);
ARM GAS  /tmp/ccKJN8PY.s 			page 61


1148:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_inc_relaxed)
1149:./include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_fetch_inc_relaxed(v);
1150:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
1151:./include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1152:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_inc)
1153:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_inc(v);
1154:./include/linux/atomic/atomic-arch-fallback.h **** #else
1155:./include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_fetch_add_acquire(1, v);
1156:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1157:./include/linux/atomic/atomic-arch-fallback.h **** }
1158:./include/linux/atomic/atomic-arch-fallback.h **** 
1159:./include/linux/atomic/atomic-arch-fallback.h **** /**
1160:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_inc_release() - atomic increment with release ordering
1161:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1162:./include/linux/atomic/atomic-arch-fallback.h ****  *
1163:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + 1) with release ordering.
1164:./include/linux/atomic/atomic-arch-fallback.h ****  *
1165:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_inc_release() elsewhere.
1166:./include/linux/atomic/atomic-arch-fallback.h ****  *
1167:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1168:./include/linux/atomic/atomic-arch-fallback.h ****  */
1169:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1170:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_inc_release(atomic_t *v)
1171:./include/linux/atomic/atomic-arch-fallback.h **** {
1172:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_inc_release)
1173:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_inc_release(v);
1174:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_inc_relaxed)
1175:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
1176:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_inc_relaxed(v);
1177:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_inc)
1178:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_inc(v);
1179:./include/linux/atomic/atomic-arch-fallback.h **** #else
1180:./include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_fetch_add_release(1, v);
1181:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1182:./include/linux/atomic/atomic-arch-fallback.h **** }
1183:./include/linux/atomic/atomic-arch-fallback.h **** 
1184:./include/linux/atomic/atomic-arch-fallback.h **** /**
1185:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_inc_relaxed() - atomic increment with relaxed ordering
1186:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1187:./include/linux/atomic/atomic-arch-fallback.h ****  *
1188:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + 1) with relaxed ordering.
1189:./include/linux/atomic/atomic-arch-fallback.h ****  *
1190:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_inc_relaxed() elsewhere.
1191:./include/linux/atomic/atomic-arch-fallback.h ****  *
1192:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1193:./include/linux/atomic/atomic-arch-fallback.h ****  */
1194:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1195:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_inc_relaxed(atomic_t *v)
1196:./include/linux/atomic/atomic-arch-fallback.h **** {
1197:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_inc_relaxed)
1198:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_inc_relaxed(v);
1199:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_inc)
1200:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_inc(v);
1201:./include/linux/atomic/atomic-arch-fallback.h **** #else
1202:./include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_fetch_add_relaxed(1, v);
1203:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1204:./include/linux/atomic/atomic-arch-fallback.h **** }
ARM GAS  /tmp/ccKJN8PY.s 			page 62


1205:./include/linux/atomic/atomic-arch-fallback.h **** 
1206:./include/linux/atomic/atomic-arch-fallback.h **** /**
1207:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_dec() - atomic decrement with relaxed ordering
1208:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1209:./include/linux/atomic/atomic-arch-fallback.h ****  *
1210:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - 1) with relaxed ordering.
1211:./include/linux/atomic/atomic-arch-fallback.h ****  *
1212:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_dec() elsewhere.
1213:./include/linux/atomic/atomic-arch-fallback.h ****  *
1214:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: Nothing.
1215:./include/linux/atomic/atomic-arch-fallback.h ****  */
1216:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline void
1217:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_dec(atomic_t *v)
1218:./include/linux/atomic/atomic-arch-fallback.h **** {
1219:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_dec)
1220:./include/linux/atomic/atomic-arch-fallback.h **** 	arch_atomic_dec(v);
1221:./include/linux/atomic/atomic-arch-fallback.h **** #else
1222:./include/linux/atomic/atomic-arch-fallback.h **** 	raw_atomic_sub(1, v);
1223:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1224:./include/linux/atomic/atomic-arch-fallback.h **** }
1225:./include/linux/atomic/atomic-arch-fallback.h **** 
1226:./include/linux/atomic/atomic-arch-fallback.h **** /**
1227:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_dec_return() - atomic decrement with full ordering
1228:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1229:./include/linux/atomic/atomic-arch-fallback.h ****  *
1230:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - 1) with full ordering.
1231:./include/linux/atomic/atomic-arch-fallback.h ****  *
1232:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_dec_return() elsewhere.
1233:./include/linux/atomic/atomic-arch-fallback.h ****  *
1234:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
1235:./include/linux/atomic/atomic-arch-fallback.h ****  */
1236:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1237:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_dec_return(atomic_t *v)
1238:./include/linux/atomic/atomic-arch-fallback.h **** {
1239:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_dec_return)
1240:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_dec_return(v);
1241:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_dec_return_relaxed)
1242:./include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
1243:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
1244:./include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_dec_return_relaxed(v);
1245:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
1246:./include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1247:./include/linux/atomic/atomic-arch-fallback.h **** #else
1248:./include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_sub_return(1, v);
1249:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1250:./include/linux/atomic/atomic-arch-fallback.h **** }
1251:./include/linux/atomic/atomic-arch-fallback.h **** 
1252:./include/linux/atomic/atomic-arch-fallback.h **** /**
1253:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_dec_return_acquire() - atomic decrement with acquire ordering
1254:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1255:./include/linux/atomic/atomic-arch-fallback.h ****  *
1256:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - 1) with acquire ordering.
1257:./include/linux/atomic/atomic-arch-fallback.h ****  *
1258:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_dec_return_acquire() elsewhere.
1259:./include/linux/atomic/atomic-arch-fallback.h ****  *
1260:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
1261:./include/linux/atomic/atomic-arch-fallback.h ****  */
ARM GAS  /tmp/ccKJN8PY.s 			page 63


1262:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1263:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_dec_return_acquire(atomic_t *v)
1264:./include/linux/atomic/atomic-arch-fallback.h **** {
1265:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_dec_return_acquire)
1266:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_dec_return_acquire(v);
1267:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_dec_return_relaxed)
1268:./include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_dec_return_relaxed(v);
1269:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
1270:./include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1271:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_dec_return)
1272:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_dec_return(v);
1273:./include/linux/atomic/atomic-arch-fallback.h **** #else
1274:./include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_sub_return_acquire(1, v);
1275:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1276:./include/linux/atomic/atomic-arch-fallback.h **** }
1277:./include/linux/atomic/atomic-arch-fallback.h **** 
1278:./include/linux/atomic/atomic-arch-fallback.h **** /**
1279:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_dec_return_release() - atomic decrement with release ordering
1280:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1281:./include/linux/atomic/atomic-arch-fallback.h ****  *
1282:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - 1) with release ordering.
1283:./include/linux/atomic/atomic-arch-fallback.h ****  *
1284:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_dec_return_release() elsewhere.
1285:./include/linux/atomic/atomic-arch-fallback.h ****  *
1286:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
1287:./include/linux/atomic/atomic-arch-fallback.h ****  */
1288:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1289:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_dec_return_release(atomic_t *v)
1290:./include/linux/atomic/atomic-arch-fallback.h **** {
1291:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_dec_return_release)
1292:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_dec_return_release(v);
1293:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_dec_return_relaxed)
1294:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
1295:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_dec_return_relaxed(v);
1296:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_dec_return)
1297:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_dec_return(v);
1298:./include/linux/atomic/atomic-arch-fallback.h **** #else
1299:./include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_sub_return_release(1, v);
1300:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1301:./include/linux/atomic/atomic-arch-fallback.h **** }
1302:./include/linux/atomic/atomic-arch-fallback.h **** 
1303:./include/linux/atomic/atomic-arch-fallback.h **** /**
1304:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_dec_return_relaxed() - atomic decrement with relaxed ordering
1305:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1306:./include/linux/atomic/atomic-arch-fallback.h ****  *
1307:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - 1) with relaxed ordering.
1308:./include/linux/atomic/atomic-arch-fallback.h ****  *
1309:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_dec_return_relaxed() elsewhere.
1310:./include/linux/atomic/atomic-arch-fallback.h ****  *
1311:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
1312:./include/linux/atomic/atomic-arch-fallback.h ****  */
1313:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1314:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_dec_return_relaxed(atomic_t *v)
1315:./include/linux/atomic/atomic-arch-fallback.h **** {
1316:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_dec_return_relaxed)
1317:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_dec_return_relaxed(v);
1318:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_dec_return)
ARM GAS  /tmp/ccKJN8PY.s 			page 64


1319:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_dec_return(v);
1320:./include/linux/atomic/atomic-arch-fallback.h **** #else
1321:./include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_sub_return_relaxed(1, v);
1322:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1323:./include/linux/atomic/atomic-arch-fallback.h **** }
1324:./include/linux/atomic/atomic-arch-fallback.h **** 
1325:./include/linux/atomic/atomic-arch-fallback.h **** /**
1326:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_dec() - atomic decrement with full ordering
1327:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1328:./include/linux/atomic/atomic-arch-fallback.h ****  *
1329:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - 1) with full ordering.
1330:./include/linux/atomic/atomic-arch-fallback.h ****  *
1331:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_dec() elsewhere.
1332:./include/linux/atomic/atomic-arch-fallback.h ****  *
1333:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1334:./include/linux/atomic/atomic-arch-fallback.h ****  */
1335:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1336:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_dec(atomic_t *v)
1337:./include/linux/atomic/atomic-arch-fallback.h **** {
1338:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_dec)
1339:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_dec(v);
1340:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_dec_relaxed)
1341:./include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
1342:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
1343:./include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_fetch_dec_relaxed(v);
1344:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
1345:./include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1346:./include/linux/atomic/atomic-arch-fallback.h **** #else
1347:./include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_fetch_sub(1, v);
1348:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1349:./include/linux/atomic/atomic-arch-fallback.h **** }
1350:./include/linux/atomic/atomic-arch-fallback.h **** 
1351:./include/linux/atomic/atomic-arch-fallback.h **** /**
1352:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_dec_acquire() - atomic decrement with acquire ordering
1353:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1354:./include/linux/atomic/atomic-arch-fallback.h ****  *
1355:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - 1) with acquire ordering.
1356:./include/linux/atomic/atomic-arch-fallback.h ****  *
1357:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_dec_acquire() elsewhere.
1358:./include/linux/atomic/atomic-arch-fallback.h ****  *
1359:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1360:./include/linux/atomic/atomic-arch-fallback.h ****  */
1361:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1362:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_dec_acquire(atomic_t *v)
1363:./include/linux/atomic/atomic-arch-fallback.h **** {
1364:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_dec_acquire)
1365:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_dec_acquire(v);
1366:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_dec_relaxed)
1367:./include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_fetch_dec_relaxed(v);
1368:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
1369:./include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1370:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_dec)
1371:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_dec(v);
1372:./include/linux/atomic/atomic-arch-fallback.h **** #else
1373:./include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_fetch_sub_acquire(1, v);
1374:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1375:./include/linux/atomic/atomic-arch-fallback.h **** }
ARM GAS  /tmp/ccKJN8PY.s 			page 65


1376:./include/linux/atomic/atomic-arch-fallback.h **** 
1377:./include/linux/atomic/atomic-arch-fallback.h **** /**
1378:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_dec_release() - atomic decrement with release ordering
1379:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1380:./include/linux/atomic/atomic-arch-fallback.h ****  *
1381:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - 1) with release ordering.
1382:./include/linux/atomic/atomic-arch-fallback.h ****  *
1383:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_dec_release() elsewhere.
1384:./include/linux/atomic/atomic-arch-fallback.h ****  *
1385:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1386:./include/linux/atomic/atomic-arch-fallback.h ****  */
1387:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1388:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_dec_release(atomic_t *v)
1389:./include/linux/atomic/atomic-arch-fallback.h **** {
1390:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_dec_release)
1391:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_dec_release(v);
1392:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_dec_relaxed)
1393:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
1394:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_dec_relaxed(v);
1395:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_dec)
1396:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_dec(v);
1397:./include/linux/atomic/atomic-arch-fallback.h **** #else
1398:./include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_fetch_sub_release(1, v);
1399:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1400:./include/linux/atomic/atomic-arch-fallback.h **** }
1401:./include/linux/atomic/atomic-arch-fallback.h **** 
1402:./include/linux/atomic/atomic-arch-fallback.h **** /**
1403:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_dec_relaxed() - atomic decrement with relaxed ordering
1404:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1405:./include/linux/atomic/atomic-arch-fallback.h ****  *
1406:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - 1) with relaxed ordering.
1407:./include/linux/atomic/atomic-arch-fallback.h ****  *
1408:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_dec_relaxed() elsewhere.
1409:./include/linux/atomic/atomic-arch-fallback.h ****  *
1410:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1411:./include/linux/atomic/atomic-arch-fallback.h ****  */
1412:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1413:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_dec_relaxed(atomic_t *v)
1414:./include/linux/atomic/atomic-arch-fallback.h **** {
1415:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_dec_relaxed)
1416:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_dec_relaxed(v);
1417:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_dec)
1418:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_dec(v);
1419:./include/linux/atomic/atomic-arch-fallback.h **** #else
1420:./include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_fetch_sub_relaxed(1, v);
1421:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1422:./include/linux/atomic/atomic-arch-fallback.h **** }
1423:./include/linux/atomic/atomic-arch-fallback.h **** 
1424:./include/linux/atomic/atomic-arch-fallback.h **** /**
1425:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_and() - atomic bitwise AND with relaxed ordering
1426:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1427:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1428:./include/linux/atomic/atomic-arch-fallback.h ****  *
1429:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v & @i) with relaxed ordering.
1430:./include/linux/atomic/atomic-arch-fallback.h ****  *
1431:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_and() elsewhere.
1432:./include/linux/atomic/atomic-arch-fallback.h ****  *
ARM GAS  /tmp/ccKJN8PY.s 			page 66


1433:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: Nothing.
1434:./include/linux/atomic/atomic-arch-fallback.h ****  */
1435:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline void
1436:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_and(int i, atomic_t *v)
1437:./include/linux/atomic/atomic-arch-fallback.h **** {
1438:./include/linux/atomic/atomic-arch-fallback.h **** 	arch_atomic_and(i, v);
1439:./include/linux/atomic/atomic-arch-fallback.h **** }
1440:./include/linux/atomic/atomic-arch-fallback.h **** 
1441:./include/linux/atomic/atomic-arch-fallback.h **** /**
1442:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_and() - atomic bitwise AND with full ordering
1443:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1444:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1445:./include/linux/atomic/atomic-arch-fallback.h ****  *
1446:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v & @i) with full ordering.
1447:./include/linux/atomic/atomic-arch-fallback.h ****  *
1448:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_and() elsewhere.
1449:./include/linux/atomic/atomic-arch-fallback.h ****  *
1450:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1451:./include/linux/atomic/atomic-arch-fallback.h ****  */
1452:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1453:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_and(int i, atomic_t *v)
1454:./include/linux/atomic/atomic-arch-fallback.h **** {
1455:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_and)
1456:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_and(i, v);
1457:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_and_relaxed)
1458:./include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
1459:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
1460:./include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_fetch_and_relaxed(i, v);
1461:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
1462:./include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1463:./include/linux/atomic/atomic-arch-fallback.h **** #else
1464:./include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_and"
1465:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1466:./include/linux/atomic/atomic-arch-fallback.h **** }
1467:./include/linux/atomic/atomic-arch-fallback.h **** 
1468:./include/linux/atomic/atomic-arch-fallback.h **** /**
1469:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_and_acquire() - atomic bitwise AND with acquire ordering
1470:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1471:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1472:./include/linux/atomic/atomic-arch-fallback.h ****  *
1473:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v & @i) with acquire ordering.
1474:./include/linux/atomic/atomic-arch-fallback.h ****  *
1475:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_and_acquire() elsewhere.
1476:./include/linux/atomic/atomic-arch-fallback.h ****  *
1477:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1478:./include/linux/atomic/atomic-arch-fallback.h ****  */
1479:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1480:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_and_acquire(int i, atomic_t *v)
1481:./include/linux/atomic/atomic-arch-fallback.h **** {
1482:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_and_acquire)
1483:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_and_acquire(i, v);
1484:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_and_relaxed)
1485:./include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_fetch_and_relaxed(i, v);
1486:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
1487:./include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1488:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_and)
1489:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_and(i, v);
ARM GAS  /tmp/ccKJN8PY.s 			page 67


1490:./include/linux/atomic/atomic-arch-fallback.h **** #else
1491:./include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_and_acquire"
1492:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1493:./include/linux/atomic/atomic-arch-fallback.h **** }
1494:./include/linux/atomic/atomic-arch-fallback.h **** 
1495:./include/linux/atomic/atomic-arch-fallback.h **** /**
1496:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_and_release() - atomic bitwise AND with release ordering
1497:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1498:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1499:./include/linux/atomic/atomic-arch-fallback.h ****  *
1500:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v & @i) with release ordering.
1501:./include/linux/atomic/atomic-arch-fallback.h ****  *
1502:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_and_release() elsewhere.
1503:./include/linux/atomic/atomic-arch-fallback.h ****  *
1504:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1505:./include/linux/atomic/atomic-arch-fallback.h ****  */
1506:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1507:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_and_release(int i, atomic_t *v)
1508:./include/linux/atomic/atomic-arch-fallback.h **** {
1509:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_and_release)
1510:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_and_release(i, v);
1511:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_and_relaxed)
1512:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
1513:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_and_relaxed(i, v);
1514:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_and)
1515:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_and(i, v);
1516:./include/linux/atomic/atomic-arch-fallback.h **** #else
1517:./include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_and_release"
1518:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1519:./include/linux/atomic/atomic-arch-fallback.h **** }
1520:./include/linux/atomic/atomic-arch-fallback.h **** 
1521:./include/linux/atomic/atomic-arch-fallback.h **** /**
1522:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_and_relaxed() - atomic bitwise AND with relaxed ordering
1523:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1524:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1525:./include/linux/atomic/atomic-arch-fallback.h ****  *
1526:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v & @i) with relaxed ordering.
1527:./include/linux/atomic/atomic-arch-fallback.h ****  *
1528:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_and_relaxed() elsewhere.
1529:./include/linux/atomic/atomic-arch-fallback.h ****  *
1530:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1531:./include/linux/atomic/atomic-arch-fallback.h ****  */
1532:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1533:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_and_relaxed(int i, atomic_t *v)
1534:./include/linux/atomic/atomic-arch-fallback.h **** {
1535:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_and_relaxed)
1536:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_and_relaxed(i, v);
1537:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_and)
1538:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_and(i, v);
1539:./include/linux/atomic/atomic-arch-fallback.h **** #else
1540:./include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_and_relaxed"
1541:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1542:./include/linux/atomic/atomic-arch-fallback.h **** }
1543:./include/linux/atomic/atomic-arch-fallback.h **** 
1544:./include/linux/atomic/atomic-arch-fallback.h **** /**
1545:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_andnot() - atomic bitwise AND NOT with relaxed ordering
1546:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
ARM GAS  /tmp/ccKJN8PY.s 			page 68


1547:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1548:./include/linux/atomic/atomic-arch-fallback.h ****  *
1549:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v & ~@i) with relaxed ordering.
1550:./include/linux/atomic/atomic-arch-fallback.h ****  *
1551:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_andnot() elsewhere.
1552:./include/linux/atomic/atomic-arch-fallback.h ****  *
1553:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: Nothing.
1554:./include/linux/atomic/atomic-arch-fallback.h ****  */
1555:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline void
1556:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_andnot(int i, atomic_t *v)
1557:./include/linux/atomic/atomic-arch-fallback.h **** {
1558:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_andnot)
1559:./include/linux/atomic/atomic-arch-fallback.h **** 	arch_atomic_andnot(i, v);
1560:./include/linux/atomic/atomic-arch-fallback.h **** #else
1561:./include/linux/atomic/atomic-arch-fallback.h **** 	raw_atomic_and(~i, v);
1562:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1563:./include/linux/atomic/atomic-arch-fallback.h **** }
1564:./include/linux/atomic/atomic-arch-fallback.h **** 
1565:./include/linux/atomic/atomic-arch-fallback.h **** /**
1566:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_andnot() - atomic bitwise AND NOT with full ordering
1567:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1568:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1569:./include/linux/atomic/atomic-arch-fallback.h ****  *
1570:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v & ~@i) with full ordering.
1571:./include/linux/atomic/atomic-arch-fallback.h ****  *
1572:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_andnot() elsewhere.
1573:./include/linux/atomic/atomic-arch-fallback.h ****  *
1574:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1575:./include/linux/atomic/atomic-arch-fallback.h ****  */
1576:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1577:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_andnot(int i, atomic_t *v)
1578:./include/linux/atomic/atomic-arch-fallback.h **** {
1579:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_andnot)
1580:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_andnot(i, v);
1581:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_andnot_relaxed)
1582:./include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
1583:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
1584:./include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_fetch_andnot_relaxed(i, v);
1585:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
1586:./include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1587:./include/linux/atomic/atomic-arch-fallback.h **** #else
1588:./include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_fetch_and(~i, v);
1589:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1590:./include/linux/atomic/atomic-arch-fallback.h **** }
1591:./include/linux/atomic/atomic-arch-fallback.h **** 
1592:./include/linux/atomic/atomic-arch-fallback.h **** /**
1593:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_andnot_acquire() - atomic bitwise AND NOT with acquire ordering
1594:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1595:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1596:./include/linux/atomic/atomic-arch-fallback.h ****  *
1597:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v & ~@i) with acquire ordering.
1598:./include/linux/atomic/atomic-arch-fallback.h ****  *
1599:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_andnot_acquire() elsewhere.
1600:./include/linux/atomic/atomic-arch-fallback.h ****  *
1601:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1602:./include/linux/atomic/atomic-arch-fallback.h ****  */
1603:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
ARM GAS  /tmp/ccKJN8PY.s 			page 69


1604:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_andnot_acquire(int i, atomic_t *v)
1605:./include/linux/atomic/atomic-arch-fallback.h **** {
1606:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_andnot_acquire)
1607:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_andnot_acquire(i, v);
1608:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_andnot_relaxed)
1609:./include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_fetch_andnot_relaxed(i, v);
1610:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
1611:./include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1612:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_andnot)
1613:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_andnot(i, v);
1614:./include/linux/atomic/atomic-arch-fallback.h **** #else
1615:./include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_fetch_and_acquire(~i, v);
1616:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1617:./include/linux/atomic/atomic-arch-fallback.h **** }
1618:./include/linux/atomic/atomic-arch-fallback.h **** 
1619:./include/linux/atomic/atomic-arch-fallback.h **** /**
1620:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_andnot_release() - atomic bitwise AND NOT with release ordering
1621:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1622:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1623:./include/linux/atomic/atomic-arch-fallback.h ****  *
1624:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v & ~@i) with release ordering.
1625:./include/linux/atomic/atomic-arch-fallback.h ****  *
1626:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_andnot_release() elsewhere.
1627:./include/linux/atomic/atomic-arch-fallback.h ****  *
1628:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1629:./include/linux/atomic/atomic-arch-fallback.h ****  */
1630:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1631:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_andnot_release(int i, atomic_t *v)
1632:./include/linux/atomic/atomic-arch-fallback.h **** {
1633:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_andnot_release)
1634:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_andnot_release(i, v);
1635:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_andnot_relaxed)
1636:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
1637:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_andnot_relaxed(i, v);
1638:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_andnot)
1639:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_andnot(i, v);
1640:./include/linux/atomic/atomic-arch-fallback.h **** #else
1641:./include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_fetch_and_release(~i, v);
1642:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1643:./include/linux/atomic/atomic-arch-fallback.h **** }
1644:./include/linux/atomic/atomic-arch-fallback.h **** 
1645:./include/linux/atomic/atomic-arch-fallback.h **** /**
1646:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_andnot_relaxed() - atomic bitwise AND NOT with relaxed ordering
1647:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1648:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1649:./include/linux/atomic/atomic-arch-fallback.h ****  *
1650:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v & ~@i) with relaxed ordering.
1651:./include/linux/atomic/atomic-arch-fallback.h ****  *
1652:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_andnot_relaxed() elsewhere.
1653:./include/linux/atomic/atomic-arch-fallback.h ****  *
1654:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1655:./include/linux/atomic/atomic-arch-fallback.h ****  */
1656:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1657:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_andnot_relaxed(int i, atomic_t *v)
1658:./include/linux/atomic/atomic-arch-fallback.h **** {
1659:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_andnot_relaxed)
1660:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_andnot_relaxed(i, v);
ARM GAS  /tmp/ccKJN8PY.s 			page 70


1661:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_andnot)
1662:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_andnot(i, v);
1663:./include/linux/atomic/atomic-arch-fallback.h **** #else
1664:./include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_fetch_and_relaxed(~i, v);
1665:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1666:./include/linux/atomic/atomic-arch-fallback.h **** }
1667:./include/linux/atomic/atomic-arch-fallback.h **** 
1668:./include/linux/atomic/atomic-arch-fallback.h **** /**
1669:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_or() - atomic bitwise OR with relaxed ordering
1670:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1671:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1672:./include/linux/atomic/atomic-arch-fallback.h ****  *
1673:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v | @i) with relaxed ordering.
1674:./include/linux/atomic/atomic-arch-fallback.h ****  *
1675:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_or() elsewhere.
1676:./include/linux/atomic/atomic-arch-fallback.h ****  *
1677:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: Nothing.
1678:./include/linux/atomic/atomic-arch-fallback.h ****  */
1679:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline void
1680:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_or(int i, atomic_t *v)
1681:./include/linux/atomic/atomic-arch-fallback.h **** {
1682:./include/linux/atomic/atomic-arch-fallback.h **** 	arch_atomic_or(i, v);
1683:./include/linux/atomic/atomic-arch-fallback.h **** }
1684:./include/linux/atomic/atomic-arch-fallback.h **** 
1685:./include/linux/atomic/atomic-arch-fallback.h **** /**
1686:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_or() - atomic bitwise OR with full ordering
1687:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1688:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1689:./include/linux/atomic/atomic-arch-fallback.h ****  *
1690:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v | @i) with full ordering.
1691:./include/linux/atomic/atomic-arch-fallback.h ****  *
1692:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_or() elsewhere.
1693:./include/linux/atomic/atomic-arch-fallback.h ****  *
1694:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1695:./include/linux/atomic/atomic-arch-fallback.h ****  */
1696:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1697:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_or(int i, atomic_t *v)
1698:./include/linux/atomic/atomic-arch-fallback.h **** {
1699:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_or)
1700:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_or(i, v);
1701:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_or_relaxed)
1702:./include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
1703:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
1704:./include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_fetch_or_relaxed(i, v);
1705:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
1706:./include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1707:./include/linux/atomic/atomic-arch-fallback.h **** #else
1708:./include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_or"
1709:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1710:./include/linux/atomic/atomic-arch-fallback.h **** }
1711:./include/linux/atomic/atomic-arch-fallback.h **** 
1712:./include/linux/atomic/atomic-arch-fallback.h **** /**
1713:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_or_acquire() - atomic bitwise OR with acquire ordering
1714:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1715:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1716:./include/linux/atomic/atomic-arch-fallback.h ****  *
1717:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v | @i) with acquire ordering.
ARM GAS  /tmp/ccKJN8PY.s 			page 71


1718:./include/linux/atomic/atomic-arch-fallback.h ****  *
1719:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_or_acquire() elsewhere.
1720:./include/linux/atomic/atomic-arch-fallback.h ****  *
1721:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1722:./include/linux/atomic/atomic-arch-fallback.h ****  */
1723:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1724:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_or_acquire(int i, atomic_t *v)
1725:./include/linux/atomic/atomic-arch-fallback.h **** {
1726:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_or_acquire)
1727:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_or_acquire(i, v);
1728:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_or_relaxed)
1729:./include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_fetch_or_relaxed(i, v);
1730:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
1731:./include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1732:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_or)
1733:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_or(i, v);
1734:./include/linux/atomic/atomic-arch-fallback.h **** #else
1735:./include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_or_acquire"
1736:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1737:./include/linux/atomic/atomic-arch-fallback.h **** }
1738:./include/linux/atomic/atomic-arch-fallback.h **** 
1739:./include/linux/atomic/atomic-arch-fallback.h **** /**
1740:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_or_release() - atomic bitwise OR with release ordering
1741:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1742:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1743:./include/linux/atomic/atomic-arch-fallback.h ****  *
1744:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v | @i) with release ordering.
1745:./include/linux/atomic/atomic-arch-fallback.h ****  *
1746:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_or_release() elsewhere.
1747:./include/linux/atomic/atomic-arch-fallback.h ****  *
1748:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1749:./include/linux/atomic/atomic-arch-fallback.h ****  */
1750:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1751:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_or_release(int i, atomic_t *v)
1752:./include/linux/atomic/atomic-arch-fallback.h **** {
1753:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_or_release)
1754:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_or_release(i, v);
1755:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_or_relaxed)
1756:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
1757:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_or_relaxed(i, v);
1758:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_or)
1759:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_or(i, v);
1760:./include/linux/atomic/atomic-arch-fallback.h **** #else
1761:./include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_or_release"
1762:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1763:./include/linux/atomic/atomic-arch-fallback.h **** }
1764:./include/linux/atomic/atomic-arch-fallback.h **** 
1765:./include/linux/atomic/atomic-arch-fallback.h **** /**
1766:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_or_relaxed() - atomic bitwise OR with relaxed ordering
1767:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1768:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1769:./include/linux/atomic/atomic-arch-fallback.h ****  *
1770:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v | @i) with relaxed ordering.
1771:./include/linux/atomic/atomic-arch-fallback.h ****  *
1772:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_or_relaxed() elsewhere.
1773:./include/linux/atomic/atomic-arch-fallback.h ****  *
1774:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
ARM GAS  /tmp/ccKJN8PY.s 			page 72


1775:./include/linux/atomic/atomic-arch-fallback.h ****  */
1776:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1777:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_or_relaxed(int i, atomic_t *v)
1778:./include/linux/atomic/atomic-arch-fallback.h **** {
1779:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_or_relaxed)
1780:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_or_relaxed(i, v);
1781:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_or)
1782:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_or(i, v);
1783:./include/linux/atomic/atomic-arch-fallback.h **** #else
1784:./include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_or_relaxed"
1785:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1786:./include/linux/atomic/atomic-arch-fallback.h **** }
1787:./include/linux/atomic/atomic-arch-fallback.h **** 
1788:./include/linux/atomic/atomic-arch-fallback.h **** /**
1789:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_xor() - atomic bitwise XOR with relaxed ordering
1790:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1791:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1792:./include/linux/atomic/atomic-arch-fallback.h ****  *
1793:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v ^ @i) with relaxed ordering.
1794:./include/linux/atomic/atomic-arch-fallback.h ****  *
1795:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_xor() elsewhere.
1796:./include/linux/atomic/atomic-arch-fallback.h ****  *
1797:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: Nothing.
1798:./include/linux/atomic/atomic-arch-fallback.h ****  */
1799:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline void
1800:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_xor(int i, atomic_t *v)
1801:./include/linux/atomic/atomic-arch-fallback.h **** {
1802:./include/linux/atomic/atomic-arch-fallback.h **** 	arch_atomic_xor(i, v);
1803:./include/linux/atomic/atomic-arch-fallback.h **** }
1804:./include/linux/atomic/atomic-arch-fallback.h **** 
1805:./include/linux/atomic/atomic-arch-fallback.h **** /**
1806:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_xor() - atomic bitwise XOR with full ordering
1807:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1808:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1809:./include/linux/atomic/atomic-arch-fallback.h ****  *
1810:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v ^ @i) with full ordering.
1811:./include/linux/atomic/atomic-arch-fallback.h ****  *
1812:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_xor() elsewhere.
1813:./include/linux/atomic/atomic-arch-fallback.h ****  *
1814:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1815:./include/linux/atomic/atomic-arch-fallback.h ****  */
1816:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1817:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_xor(int i, atomic_t *v)
1818:./include/linux/atomic/atomic-arch-fallback.h **** {
1819:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_xor)
1820:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_xor(i, v);
1821:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_xor_relaxed)
1822:./include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
1823:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
1824:./include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_fetch_xor_relaxed(i, v);
1825:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
1826:./include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1827:./include/linux/atomic/atomic-arch-fallback.h **** #else
1828:./include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_xor"
1829:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1830:./include/linux/atomic/atomic-arch-fallback.h **** }
1831:./include/linux/atomic/atomic-arch-fallback.h **** 
ARM GAS  /tmp/ccKJN8PY.s 			page 73


1832:./include/linux/atomic/atomic-arch-fallback.h **** /**
1833:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_xor_acquire() - atomic bitwise XOR with acquire ordering
1834:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1835:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1836:./include/linux/atomic/atomic-arch-fallback.h ****  *
1837:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v ^ @i) with acquire ordering.
1838:./include/linux/atomic/atomic-arch-fallback.h ****  *
1839:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_xor_acquire() elsewhere.
1840:./include/linux/atomic/atomic-arch-fallback.h ****  *
1841:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1842:./include/linux/atomic/atomic-arch-fallback.h ****  */
1843:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1844:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_xor_acquire(int i, atomic_t *v)
1845:./include/linux/atomic/atomic-arch-fallback.h **** {
1846:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_xor_acquire)
1847:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_xor_acquire(i, v);
1848:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_xor_relaxed)
1849:./include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_fetch_xor_relaxed(i, v);
1850:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
1851:./include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1852:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_xor)
1853:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_xor(i, v);
1854:./include/linux/atomic/atomic-arch-fallback.h **** #else
1855:./include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_xor_acquire"
1856:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1857:./include/linux/atomic/atomic-arch-fallback.h **** }
1858:./include/linux/atomic/atomic-arch-fallback.h **** 
1859:./include/linux/atomic/atomic-arch-fallback.h **** /**
1860:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_xor_release() - atomic bitwise XOR with release ordering
1861:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1862:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1863:./include/linux/atomic/atomic-arch-fallback.h ****  *
1864:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v ^ @i) with release ordering.
1865:./include/linux/atomic/atomic-arch-fallback.h ****  *
1866:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_xor_release() elsewhere.
1867:./include/linux/atomic/atomic-arch-fallback.h ****  *
1868:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1869:./include/linux/atomic/atomic-arch-fallback.h ****  */
1870:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1871:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_xor_release(int i, atomic_t *v)
1872:./include/linux/atomic/atomic-arch-fallback.h **** {
1873:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_xor_release)
1874:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_xor_release(i, v);
1875:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_xor_relaxed)
1876:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
1877:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_xor_relaxed(i, v);
1878:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_xor)
1879:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_xor(i, v);
1880:./include/linux/atomic/atomic-arch-fallback.h **** #else
1881:./include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_xor_release"
1882:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1883:./include/linux/atomic/atomic-arch-fallback.h **** }
1884:./include/linux/atomic/atomic-arch-fallback.h **** 
1885:./include/linux/atomic/atomic-arch-fallback.h **** /**
1886:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_xor_relaxed() - atomic bitwise XOR with relaxed ordering
1887:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1888:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
ARM GAS  /tmp/ccKJN8PY.s 			page 74


1889:./include/linux/atomic/atomic-arch-fallback.h ****  *
1890:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v ^ @i) with relaxed ordering.
1891:./include/linux/atomic/atomic-arch-fallback.h ****  *
1892:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_xor_relaxed() elsewhere.
1893:./include/linux/atomic/atomic-arch-fallback.h ****  *
1894:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1895:./include/linux/atomic/atomic-arch-fallback.h ****  */
1896:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1897:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_xor_relaxed(int i, atomic_t *v)
1898:./include/linux/atomic/atomic-arch-fallback.h **** {
1899:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_xor_relaxed)
1900:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_xor_relaxed(i, v);
1901:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_xor)
1902:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_xor(i, v);
1903:./include/linux/atomic/atomic-arch-fallback.h **** #else
1904:./include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_xor_relaxed"
1905:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1906:./include/linux/atomic/atomic-arch-fallback.h **** }
1907:./include/linux/atomic/atomic-arch-fallback.h **** 
1908:./include/linux/atomic/atomic-arch-fallback.h **** /**
1909:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_xchg() - atomic exchange with full ordering
1910:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1911:./include/linux/atomic/atomic-arch-fallback.h ****  * @new: int value to assign
1912:./include/linux/atomic/atomic-arch-fallback.h ****  *
1913:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to @new with full ordering.
1914:./include/linux/atomic/atomic-arch-fallback.h ****  *
1915:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_xchg() elsewhere.
1916:./include/linux/atomic/atomic-arch-fallback.h ****  *
1917:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1918:./include/linux/atomic/atomic-arch-fallback.h ****  */
1919:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1920:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_xchg(atomic_t *v, int new)
1921:./include/linux/atomic/atomic-arch-fallback.h **** {
1922:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_xchg)
1923:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_xchg(v, new);
1924:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_xchg_relaxed)
1925:./include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
1926:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
1927:./include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_xchg_relaxed(v, new);
1928:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
1929:./include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1930:./include/linux/atomic/atomic-arch-fallback.h **** #else
1931:./include/linux/atomic/atomic-arch-fallback.h **** 	return raw_xchg(&v->counter, new);
1932:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1933:./include/linux/atomic/atomic-arch-fallback.h **** }
1934:./include/linux/atomic/atomic-arch-fallback.h **** 
1935:./include/linux/atomic/atomic-arch-fallback.h **** /**
1936:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_xchg_acquire() - atomic exchange with acquire ordering
1937:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1938:./include/linux/atomic/atomic-arch-fallback.h ****  * @new: int value to assign
1939:./include/linux/atomic/atomic-arch-fallback.h ****  *
1940:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to @new with acquire ordering.
1941:./include/linux/atomic/atomic-arch-fallback.h ****  *
1942:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_xchg_acquire() elsewhere.
1943:./include/linux/atomic/atomic-arch-fallback.h ****  *
1944:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1945:./include/linux/atomic/atomic-arch-fallback.h ****  */
ARM GAS  /tmp/ccKJN8PY.s 			page 75


1946:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1947:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_xchg_acquire(atomic_t *v, int new)
1948:./include/linux/atomic/atomic-arch-fallback.h **** {
1949:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_xchg_acquire)
1950:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_xchg_acquire(v, new);
1951:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_xchg_relaxed)
1952:./include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_xchg_relaxed(v, new);
1953:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
1954:./include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1955:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_xchg)
1956:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_xchg(v, new);
1957:./include/linux/atomic/atomic-arch-fallback.h **** #else
1958:./include/linux/atomic/atomic-arch-fallback.h **** 	return raw_xchg_acquire(&v->counter, new);
1959:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1960:./include/linux/atomic/atomic-arch-fallback.h **** }
1961:./include/linux/atomic/atomic-arch-fallback.h **** 
1962:./include/linux/atomic/atomic-arch-fallback.h **** /**
1963:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_xchg_release() - atomic exchange with release ordering
1964:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1965:./include/linux/atomic/atomic-arch-fallback.h ****  * @new: int value to assign
1966:./include/linux/atomic/atomic-arch-fallback.h ****  *
1967:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to @new with release ordering.
1968:./include/linux/atomic/atomic-arch-fallback.h ****  *
1969:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_xchg_release() elsewhere.
1970:./include/linux/atomic/atomic-arch-fallback.h ****  *
1971:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1972:./include/linux/atomic/atomic-arch-fallback.h ****  */
1973:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1974:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_xchg_release(atomic_t *v, int new)
1975:./include/linux/atomic/atomic-arch-fallback.h **** {
1976:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_xchg_release)
1977:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_xchg_release(v, new);
1978:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_xchg_relaxed)
1979:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
1980:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_xchg_relaxed(v, new);
1981:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_xchg)
1982:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_xchg(v, new);
1983:./include/linux/atomic/atomic-arch-fallback.h **** #else
1984:./include/linux/atomic/atomic-arch-fallback.h **** 	return raw_xchg_release(&v->counter, new);
1985:./include/linux/atomic/atomic-arch-fallback.h **** #endif
1986:./include/linux/atomic/atomic-arch-fallback.h **** }
1987:./include/linux/atomic/atomic-arch-fallback.h **** 
1988:./include/linux/atomic/atomic-arch-fallback.h **** /**
1989:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_xchg_relaxed() - atomic exchange with relaxed ordering
1990:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1991:./include/linux/atomic/atomic-arch-fallback.h ****  * @new: int value to assign
1992:./include/linux/atomic/atomic-arch-fallback.h ****  *
1993:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to @new with relaxed ordering.
1994:./include/linux/atomic/atomic-arch-fallback.h ****  *
1995:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_xchg_relaxed() elsewhere.
1996:./include/linux/atomic/atomic-arch-fallback.h ****  *
1997:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1998:./include/linux/atomic/atomic-arch-fallback.h ****  */
1999:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
2000:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_xchg_relaxed(atomic_t *v, int new)
2001:./include/linux/atomic/atomic-arch-fallback.h **** {
2002:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_xchg_relaxed)
ARM GAS  /tmp/ccKJN8PY.s 			page 76


2003:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_xchg_relaxed(v, new);
2004:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_xchg)
2005:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_xchg(v, new);
2006:./include/linux/atomic/atomic-arch-fallback.h **** #else
2007:./include/linux/atomic/atomic-arch-fallback.h **** 	return raw_xchg_relaxed(&v->counter, new);
2008:./include/linux/atomic/atomic-arch-fallback.h **** #endif
2009:./include/linux/atomic/atomic-arch-fallback.h **** }
2010:./include/linux/atomic/atomic-arch-fallback.h **** 
2011:./include/linux/atomic/atomic-arch-fallback.h **** /**
2012:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_cmpxchg() - atomic compare and exchange with full ordering
2013:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
2014:./include/linux/atomic/atomic-arch-fallback.h ****  * @old: int value to compare with
2015:./include/linux/atomic/atomic-arch-fallback.h ****  * @new: int value to assign
2016:./include/linux/atomic/atomic-arch-fallback.h ****  *
2017:./include/linux/atomic/atomic-arch-fallback.h ****  * If (@v == @old), atomically updates @v to @new with full ordering.
2018:./include/linux/atomic/atomic-arch-fallback.h ****  * Otherwise, @v is not modified and relaxed ordering is provided.
2019:./include/linux/atomic/atomic-arch-fallback.h ****  *
2020:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_cmpxchg() elsewhere.
2021:./include/linux/atomic/atomic-arch-fallback.h ****  *
2022:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
2023:./include/linux/atomic/atomic-arch-fallback.h ****  */
2024:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
2025:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_cmpxchg(atomic_t *v, int old, int new)
2026:./include/linux/atomic/atomic-arch-fallback.h **** {
2027:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_cmpxchg)
2028:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_cmpxchg(v, old, new);
2029:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_cmpxchg_relaxed)
2030:./include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
2031:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
2032:./include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_cmpxchg_relaxed(v, old, new);
2033:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
2034:./include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
2035:./include/linux/atomic/atomic-arch-fallback.h **** #else
2036:./include/linux/atomic/atomic-arch-fallback.h **** 	return raw_cmpxchg(&v->counter, old, new);
2037:./include/linux/atomic/atomic-arch-fallback.h **** #endif
2038:./include/linux/atomic/atomic-arch-fallback.h **** }
2039:./include/linux/atomic/atomic-arch-fallback.h **** 
2040:./include/linux/atomic/atomic-arch-fallback.h **** /**
2041:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_cmpxchg_acquire() - atomic compare and exchange with acquire ordering
2042:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
2043:./include/linux/atomic/atomic-arch-fallback.h ****  * @old: int value to compare with
2044:./include/linux/atomic/atomic-arch-fallback.h ****  * @new: int value to assign
2045:./include/linux/atomic/atomic-arch-fallback.h ****  *
2046:./include/linux/atomic/atomic-arch-fallback.h ****  * If (@v == @old), atomically updates @v to @new with acquire ordering.
2047:./include/linux/atomic/atomic-arch-fallback.h ****  * Otherwise, @v is not modified and relaxed ordering is provided.
2048:./include/linux/atomic/atomic-arch-fallback.h ****  *
2049:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_cmpxchg_acquire() elsewhere.
2050:./include/linux/atomic/atomic-arch-fallback.h ****  *
2051:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
2052:./include/linux/atomic/atomic-arch-fallback.h ****  */
2053:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
2054:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_cmpxchg_acquire(atomic_t *v, int old, int new)
2055:./include/linux/atomic/atomic-arch-fallback.h **** {
2056:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_cmpxchg_acquire)
2057:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_cmpxchg_acquire(v, old, new);
2058:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_cmpxchg_relaxed)
2059:./include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_cmpxchg_relaxed(v, old, new);
ARM GAS  /tmp/ccKJN8PY.s 			page 77


2060:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
2061:./include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
2062:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_cmpxchg)
2063:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_cmpxchg(v, old, new);
2064:./include/linux/atomic/atomic-arch-fallback.h **** #else
2065:./include/linux/atomic/atomic-arch-fallback.h **** 	return raw_cmpxchg_acquire(&v->counter, old, new);
2066:./include/linux/atomic/atomic-arch-fallback.h **** #endif
2067:./include/linux/atomic/atomic-arch-fallback.h **** }
2068:./include/linux/atomic/atomic-arch-fallback.h **** 
2069:./include/linux/atomic/atomic-arch-fallback.h **** /**
2070:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_cmpxchg_release() - atomic compare and exchange with release ordering
2071:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
2072:./include/linux/atomic/atomic-arch-fallback.h ****  * @old: int value to compare with
2073:./include/linux/atomic/atomic-arch-fallback.h ****  * @new: int value to assign
2074:./include/linux/atomic/atomic-arch-fallback.h ****  *
2075:./include/linux/atomic/atomic-arch-fallback.h ****  * If (@v == @old), atomically updates @v to @new with release ordering.
2076:./include/linux/atomic/atomic-arch-fallback.h ****  * Otherwise, @v is not modified and relaxed ordering is provided.
2077:./include/linux/atomic/atomic-arch-fallback.h ****  *
2078:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_cmpxchg_release() elsewhere.
2079:./include/linux/atomic/atomic-arch-fallback.h ****  *
2080:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
2081:./include/linux/atomic/atomic-arch-fallback.h ****  */
2082:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
2083:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_cmpxchg_release(atomic_t *v, int old, int new)
2084:./include/linux/atomic/atomic-arch-fallback.h **** {
2085:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_cmpxchg_release)
2086:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_cmpxchg_release(v, old, new);
2087:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_cmpxchg_relaxed)
2088:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
2089:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_cmpxchg_relaxed(v, old, new);
2090:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_cmpxchg)
2091:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_cmpxchg(v, old, new);
2092:./include/linux/atomic/atomic-arch-fallback.h **** #else
2093:./include/linux/atomic/atomic-arch-fallback.h **** 	return raw_cmpxchg_release(&v->counter, old, new);
2094:./include/linux/atomic/atomic-arch-fallback.h **** #endif
2095:./include/linux/atomic/atomic-arch-fallback.h **** }
2096:./include/linux/atomic/atomic-arch-fallback.h **** 
2097:./include/linux/atomic/atomic-arch-fallback.h **** /**
2098:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_cmpxchg_relaxed() - atomic compare and exchange with relaxed ordering
2099:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
2100:./include/linux/atomic/atomic-arch-fallback.h ****  * @old: int value to compare with
2101:./include/linux/atomic/atomic-arch-fallback.h ****  * @new: int value to assign
2102:./include/linux/atomic/atomic-arch-fallback.h ****  *
2103:./include/linux/atomic/atomic-arch-fallback.h ****  * If (@v == @old), atomically updates @v to @new with relaxed ordering.
2104:./include/linux/atomic/atomic-arch-fallback.h ****  * Otherwise, @v is not modified and relaxed ordering is provided.
2105:./include/linux/atomic/atomic-arch-fallback.h ****  *
2106:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_cmpxchg_relaxed() elsewhere.
2107:./include/linux/atomic/atomic-arch-fallback.h ****  *
2108:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
2109:./include/linux/atomic/atomic-arch-fallback.h ****  */
2110:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
2111:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_cmpxchg_relaxed(atomic_t *v, int old, int new)
2112:./include/linux/atomic/atomic-arch-fallback.h **** {
2113:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_cmpxchg_relaxed)
2114:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_cmpxchg_relaxed(v, old, new);
2115:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_cmpxchg)
2116:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_cmpxchg(v, old, new);
ARM GAS  /tmp/ccKJN8PY.s 			page 78


2117:./include/linux/atomic/atomic-arch-fallback.h **** #else
2118:./include/linux/atomic/atomic-arch-fallback.h **** 	return raw_cmpxchg_relaxed(&v->counter, old, new);
2119:./include/linux/atomic/atomic-arch-fallback.h **** #endif
2120:./include/linux/atomic/atomic-arch-fallback.h **** }
2121:./include/linux/atomic/atomic-arch-fallback.h **** 
2122:./include/linux/atomic/atomic-arch-fallback.h **** /**
2123:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_try_cmpxchg() - atomic compare and exchange with full ordering
2124:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
2125:./include/linux/atomic/atomic-arch-fallback.h ****  * @old: pointer to int value to compare with
2126:./include/linux/atomic/atomic-arch-fallback.h ****  * @new: int value to assign
2127:./include/linux/atomic/atomic-arch-fallback.h ****  *
2128:./include/linux/atomic/atomic-arch-fallback.h ****  * If (@v == @old), atomically updates @v to @new with full ordering.
2129:./include/linux/atomic/atomic-arch-fallback.h ****  * Otherwise, @v is not modified, @old is updated to the current value of @v,
2130:./include/linux/atomic/atomic-arch-fallback.h ****  * and relaxed ordering is provided.
2131:./include/linux/atomic/atomic-arch-fallback.h ****  *
2132:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_try_cmpxchg() elsewhere.
2133:./include/linux/atomic/atomic-arch-fallback.h ****  *
2134:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: @true if the exchange occured, @false otherwise.
2135:./include/linux/atomic/atomic-arch-fallback.h ****  */
2136:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline bool
2137:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_try_cmpxchg(atomic_t *v, int *old, int new)
2138:./include/linux/atomic/atomic-arch-fallback.h **** {
2139:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_try_cmpxchg)
2140:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_try_cmpxchg(v, old, new);
2141:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_try_cmpxchg_relaxed)
2142:./include/linux/atomic/atomic-arch-fallback.h **** 	bool ret;
2143:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
2144:./include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_try_cmpxchg_relaxed(v, old, new);
2145:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
2146:./include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
2147:./include/linux/atomic/atomic-arch-fallback.h **** #else
2148:./include/linux/atomic/atomic-arch-fallback.h **** 	int r, o = *old;
2149:./include/linux/atomic/atomic-arch-fallback.h **** 	r = raw_atomic_cmpxchg(v, o, new);
2150:./include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(r != o))
2151:./include/linux/atomic/atomic-arch-fallback.h **** 		*old = r;
2152:./include/linux/atomic/atomic-arch-fallback.h **** 	return likely(r == o);
2153:./include/linux/atomic/atomic-arch-fallback.h **** #endif
2154:./include/linux/atomic/atomic-arch-fallback.h **** }
2155:./include/linux/atomic/atomic-arch-fallback.h **** 
2156:./include/linux/atomic/atomic-arch-fallback.h **** /**
2157:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_try_cmpxchg_acquire() - atomic compare and exchange with acquire ordering
2158:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
2159:./include/linux/atomic/atomic-arch-fallback.h ****  * @old: pointer to int value to compare with
2160:./include/linux/atomic/atomic-arch-fallback.h ****  * @new: int value to assign
2161:./include/linux/atomic/atomic-arch-fallback.h ****  *
2162:./include/linux/atomic/atomic-arch-fallback.h ****  * If (@v == @old), atomically updates @v to @new with acquire ordering.
2163:./include/linux/atomic/atomic-arch-fallback.h ****  * Otherwise, @v is not modified, @old is updated to the current value of @v,
2164:./include/linux/atomic/atomic-arch-fallback.h ****  * and relaxed ordering is provided.
2165:./include/linux/atomic/atomic-arch-fallback.h ****  *
2166:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_try_cmpxchg_acquire() elsewhere.
2167:./include/linux/atomic/atomic-arch-fallback.h ****  *
2168:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: @true if the exchange occured, @false otherwise.
2169:./include/linux/atomic/atomic-arch-fallback.h ****  */
2170:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline bool
2171:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_try_cmpxchg_acquire(atomic_t *v, int *old, int new)
2172:./include/linux/atomic/atomic-arch-fallback.h **** {
2173:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_try_cmpxchg_acquire)
ARM GAS  /tmp/ccKJN8PY.s 			page 79


2174:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_try_cmpxchg_acquire(v, old, new);
2175:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_try_cmpxchg_relaxed)
2176:./include/linux/atomic/atomic-arch-fallback.h **** 	bool ret = arch_atomic_try_cmpxchg_relaxed(v, old, new);
2177:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
2178:./include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
2179:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_try_cmpxchg)
2180:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_try_cmpxchg(v, old, new);
2181:./include/linux/atomic/atomic-arch-fallback.h **** #else
2182:./include/linux/atomic/atomic-arch-fallback.h **** 	int r, o = *old;
2183:./include/linux/atomic/atomic-arch-fallback.h **** 	r = raw_atomic_cmpxchg_acquire(v, o, new);
2184:./include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(r != o))
2185:./include/linux/atomic/atomic-arch-fallback.h **** 		*old = r;
2186:./include/linux/atomic/atomic-arch-fallback.h **** 	return likely(r == o);
2187:./include/linux/atomic/atomic-arch-fallback.h **** #endif
2188:./include/linux/atomic/atomic-arch-fallback.h **** }
2189:./include/linux/atomic/atomic-arch-fallback.h **** 
2190:./include/linux/atomic/atomic-arch-fallback.h **** /**
2191:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_try_cmpxchg_release() - atomic compare and exchange with release ordering
2192:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
2193:./include/linux/atomic/atomic-arch-fallback.h ****  * @old: pointer to int value to compare with
2194:./include/linux/atomic/atomic-arch-fallback.h ****  * @new: int value to assign
2195:./include/linux/atomic/atomic-arch-fallback.h ****  *
2196:./include/linux/atomic/atomic-arch-fallback.h ****  * If (@v == @old), atomically updates @v to @new with release ordering.
2197:./include/linux/atomic/atomic-arch-fallback.h ****  * Otherwise, @v is not modified, @old is updated to the current value of @v,
2198:./include/linux/atomic/atomic-arch-fallback.h ****  * and relaxed ordering is provided.
2199:./include/linux/atomic/atomic-arch-fallback.h ****  *
2200:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_try_cmpxchg_release() elsewhere.
2201:./include/linux/atomic/atomic-arch-fallback.h ****  *
2202:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: @true if the exchange occured, @false otherwise.
2203:./include/linux/atomic/atomic-arch-fallback.h ****  */
2204:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline bool
2205:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_try_cmpxchg_release(atomic_t *v, int *old, int new)
2206:./include/linux/atomic/atomic-arch-fallback.h **** {
2207:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_try_cmpxchg_release)
2208:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_try_cmpxchg_release(v, old, new);
2209:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_try_cmpxchg_relaxed)
2210:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
2211:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_try_cmpxchg_relaxed(v, old, new);
2212:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_try_cmpxchg)
2213:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_try_cmpxchg(v, old, new);
2214:./include/linux/atomic/atomic-arch-fallback.h **** #else
2215:./include/linux/atomic/atomic-arch-fallback.h **** 	int r, o = *old;
2216:./include/linux/atomic/atomic-arch-fallback.h **** 	r = raw_atomic_cmpxchg_release(v, o, new);
2217:./include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(r != o))
2218:./include/linux/atomic/atomic-arch-fallback.h **** 		*old = r;
2219:./include/linux/atomic/atomic-arch-fallback.h **** 	return likely(r == o);
2220:./include/linux/atomic/atomic-arch-fallback.h **** #endif
2221:./include/linux/atomic/atomic-arch-fallback.h **** }
2222:./include/linux/atomic/atomic-arch-fallback.h **** 
2223:./include/linux/atomic/atomic-arch-fallback.h **** /**
2224:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_try_cmpxchg_relaxed() - atomic compare and exchange with relaxed ordering
2225:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
2226:./include/linux/atomic/atomic-arch-fallback.h ****  * @old: pointer to int value to compare with
2227:./include/linux/atomic/atomic-arch-fallback.h ****  * @new: int value to assign
2228:./include/linux/atomic/atomic-arch-fallback.h ****  *
2229:./include/linux/atomic/atomic-arch-fallback.h ****  * If (@v == @old), atomically updates @v to @new with relaxed ordering.
2230:./include/linux/atomic/atomic-arch-fallback.h ****  * Otherwise, @v is not modified, @old is updated to the current value of @v,
ARM GAS  /tmp/ccKJN8PY.s 			page 80


2231:./include/linux/atomic/atomic-arch-fallback.h ****  * and relaxed ordering is provided.
2232:./include/linux/atomic/atomic-arch-fallback.h ****  *
2233:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_try_cmpxchg_relaxed() elsewhere.
2234:./include/linux/atomic/atomic-arch-fallback.h ****  *
2235:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: @true if the exchange occured, @false otherwise.
2236:./include/linux/atomic/atomic-arch-fallback.h ****  */
2237:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline bool
2238:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_try_cmpxchg_relaxed(atomic_t *v, int *old, int new)
2239:./include/linux/atomic/atomic-arch-fallback.h **** {
2240:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_try_cmpxchg_relaxed)
2241:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_try_cmpxchg_relaxed(v, old, new);
2242:./include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_try_cmpxchg)
2243:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_try_cmpxchg(v, old, new);
2244:./include/linux/atomic/atomic-arch-fallback.h **** #else
2245:./include/linux/atomic/atomic-arch-fallback.h **** 	int r, o = *old;
2246:./include/linux/atomic/atomic-arch-fallback.h **** 	r = raw_atomic_cmpxchg_relaxed(v, o, new);
2247:./include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(r != o))
2248:./include/linux/atomic/atomic-arch-fallback.h **** 		*old = r;
2249:./include/linux/atomic/atomic-arch-fallback.h **** 	return likely(r == o);
2250:./include/linux/atomic/atomic-arch-fallback.h **** #endif
2251:./include/linux/atomic/atomic-arch-fallback.h **** }
2252:./include/linux/atomic/atomic-arch-fallback.h **** 
2253:./include/linux/atomic/atomic-arch-fallback.h **** /**
2254:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_sub_and_test() - atomic subtract and test if zero with full ordering
2255:./include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to subtract
2256:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
2257:./include/linux/atomic/atomic-arch-fallback.h ****  *
2258:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - @i) with full ordering.
2259:./include/linux/atomic/atomic-arch-fallback.h ****  *
2260:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_sub_and_test() elsewhere.
2261:./include/linux/atomic/atomic-arch-fallback.h ****  *
2262:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: @true if the resulting value of @v is zero, @false otherwise.
2263:./include/linux/atomic/atomic-arch-fallback.h ****  */
2264:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline bool
2265:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_sub_and_test(int i, atomic_t *v)
2266:./include/linux/atomic/atomic-arch-fallback.h **** {
2267:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_sub_and_test)
2268:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_sub_and_test(i, v);
2269:./include/linux/atomic/atomic-arch-fallback.h **** #else
2270:./include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_sub_return(i, v) == 0;
2271:./include/linux/atomic/atomic-arch-fallback.h **** #endif
2272:./include/linux/atomic/atomic-arch-fallback.h **** }
2273:./include/linux/atomic/atomic-arch-fallback.h **** 
2274:./include/linux/atomic/atomic-arch-fallback.h **** /**
2275:./include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_dec_and_test() - atomic decrement and test if zero with full ordering
2276:./include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
2277:./include/linux/atomic/atomic-arch-fallback.h ****  *
2278:./include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - 1) with full ordering.
2279:./include/linux/atomic/atomic-arch-fallback.h ****  *
2280:./include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_dec_and_test() elsewhere.
2281:./include/linux/atomic/atomic-arch-fallback.h ****  *
2282:./include/linux/atomic/atomic-arch-fallback.h ****  * Return: @true if the resulting value of @v is zero, @false otherwise.
2283:./include/linux/atomic/atomic-arch-fallback.h ****  */
2284:./include/linux/atomic/atomic-arch-fallback.h **** static __always_inline bool
2285:./include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_dec_and_test(atomic_t *v)
 265              		.loc 3 2285 1 view .LVU70
2286:./include/linux/atomic/atomic-arch-fallback.h **** {
ARM GAS  /tmp/ccKJN8PY.s 			page 81


2287:./include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_dec_and_test)
2288:./include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_dec_and_test(v);
2289:./include/linux/atomic/atomic-arch-fallback.h **** #else
2290:./include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_dec_return(v) == 0;
 266              		.loc 3 2290 2 view .LVU71
 267              	.LBB89:
 268              	.LBI89:
1237:./include/linux/atomic/atomic-arch-fallback.h **** {
 269              		.loc 3 1237 1 view .LVU72
1248:./include/linux/atomic/atomic-arch-fallback.h **** #endif
 270              		.loc 3 1248 2 view .LVU73
 271              	.LBB90:
 272              	.LBI90:
 790:./include/linux/atomic/atomic-arch-fallback.h **** {
 273              		.loc 3 790 1 view .LVU74
 274              	.LBB91:
 795:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
 275              		.loc 3 795 2 view .LVU75
 796:./include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_sub_return_relaxed(i, v);
 276              		.loc 3 796 2 view .LVU76
 277              	.LBB92:
 278              	.LBI92:
 279              		.file 6 "./include/asm-generic/barrier.h"
   1:./include/asm-generic/barrier.h **** /* SPDX-License-Identifier: GPL-2.0-or-later */
   2:./include/asm-generic/barrier.h **** /*
   3:./include/asm-generic/barrier.h ****  * Generic barrier definitions.
   4:./include/asm-generic/barrier.h ****  *
   5:./include/asm-generic/barrier.h ****  * It should be possible to use these on really simple architectures,
   6:./include/asm-generic/barrier.h ****  * but it serves more as a starting point for new ports.
   7:./include/asm-generic/barrier.h ****  *
   8:./include/asm-generic/barrier.h ****  * Copyright (C) 2007 Red Hat, Inc. All Rights Reserved.
   9:./include/asm-generic/barrier.h ****  * Written by David Howells (dhowells@redhat.com)
  10:./include/asm-generic/barrier.h ****  */
  11:./include/asm-generic/barrier.h **** 
  12:./include/asm-generic/barrier.h **** #include <linux/rwonce.h>
  13:./include/asm-generic/barrier.h **** 
  14:./include/asm-generic/barrier.h **** static inline void sync(void)
  15:./include/asm-generic/barrier.h **** {
  16:./include/asm-generic/barrier.h **** 	asm volatile("sync" : : : "memory");
  17:./include/asm-generic/barrier.h **** }
  18:./include/asm-generic/barrier.h **** 
  19:./include/asm-generic/barrier.h **** static inline void eieio(void)
  20:./include/asm-generic/barrier.h **** {
  21:./include/asm-generic/barrier.h **** 	asm volatile("eieio" : : : "memory");
  22:./include/asm-generic/barrier.h **** }
  23:./include/asm-generic/barrier.h **** 
  24:./include/asm-generic/barrier.h **** static inline void barrier(void)
 280              		.loc 6 24 20 view .LVU77
 281              	.LBB93:
  25:./include/asm-generic/barrier.h **** {
  26:./include/asm-generic/barrier.h **** 	asm volatile("" : : : "memory");
 282              		.loc 6 26 2 view .LVU78
 283              	.LBE93:
 284              	.LBE92:
 797:./include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
 285              		.loc 3 797 2 view .LVU79
 286              	.LVL17:
ARM GAS  /tmp/ccKJN8PY.s 			page 82


 287              	.LBB94:
 288              	.LBI94:
 171:./arch/arm_m/include/asm/atomic.h **** ATOMIC_OPS(sub, -=, sub)
 289              		.loc 4 171 1 view .LVU80
 290              	.LBB95:
 291              		.loc 4 171 1 view .LVU81
 292              		.loc 4 171 1 view .LVU82
 293              		.loc 4 171 1 view .LVU83
 294              		.syntax unified
 295              	@ 171 "./arch/arm_m/include/asm/atomic.h" 1
 296              		@ atomic_sub_return
 297 0006 53E8002F 	1: ldrex   r2, [r3]
 298 000a A2F10102 	   sub r2, r2, #1
 299 000e 43E80021 	   strex   r1, r2, [r3]
 300 0012 91F0000F 	   teq r1, #0
 301 0016 F6D1     	   bne 1b
 302              	@ 0 "" 2
 303              	.LVL18:
 304              		.loc 4 171 1 view .LVU84
 305              		.loc 4 171 1 is_stmt 0 view .LVU85
 306              		.thumb
 307              		.syntax unified
 308              	.LBE95:
 309              	.LBE94:
 798:./include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
 310              		.loc 3 798 2 is_stmt 1 view .LVU86
 311              	.LBB96:
 312              	.LBI96:
  24:./include/asm-generic/barrier.h **** {
 313              		.loc 6 24 20 view .LVU87
 314              	.LBB97:
 315              		.loc 6 26 2 view .LVU88
 316              	.LBE97:
 317              	.LBE96:
 799:./include/linux/atomic/atomic-arch-fallback.h **** #else
 318              		.loc 3 799 2 view .LVU89
 319              	.LVL19:
 799:./include/linux/atomic/atomic-arch-fallback.h **** #else
 320              		.loc 3 799 2 is_stmt 0 view .LVU90
 321              	.LBE91:
 322              	.LBE90:
 323              	.LBE89:
 324              	.LBE88:
 325              	.LBE87:
 326              		.loc 1 39 8 discriminator 1 view .LVU91
 327 0018 02B1     		cbz	r2, .L14
 328              	.LVL20:
 329              	.L11:
  40:./fs/fs_inode.c ****         destroy_inode(inode);  
  41:./fs/fs_inode.c ****     }
  42:./fs/fs_inode.c **** }
 330              		.loc 1 42 1 view .LVU92
 331 001a 08BD     		pop	{r3, pc}
 332              	.LVL21:
 333              	.L14:
  40:./fs/fs_inode.c ****         destroy_inode(inode);  
 334              		.loc 1 40 9 is_stmt 1 view .LVU93
ARM GAS  /tmp/ccKJN8PY.s 			page 83


 335 001c FFF7FEFF 		bl	destroy_inode
 336              	.LVL22:
 337              		.loc 1 42 1 is_stmt 0 view .LVU94
 338 0020 FBE7     		b	.L11
 339              		.cfi_endproc
 340              	.LFE1038:
 342              		.section	.rodata.str1.4,"aMS",%progbits,1
 343              		.align	2
 344              	.LC0:
 345 0000 696E6F64 		.ascii	"inode_put\000"
 345      655F7075 
 345      7400
 346 000a 0000     		.align	2
 347              	.LC1:
 348 000c 00       		.ascii	"\000"
 349              		.section	.export_table,"aw"
 350              		.align	2
 353              	inode_put_export_struct:
 354 0000 00000000 		.word	.LC0
 355 0004 0C000000 		.word	.LC1
 356 0008 00000000 		.word	inode_put
 357              		.section	.rodata.str1.4
 358 000d 000000   		.align	2
 359              	.LC2:
 360 0010 696E6F64 		.ascii	"inode_get\000"
 360      655F6765 
 360      7400
 361              		.section	.export_table
 362              		.align	2
 365              	inode_get_export_struct:
 366 000c 10000000 		.word	.LC2
 367 0010 0C000000 		.word	.LC1
 368 0014 00000000 		.word	inode_get
 369              		.section	.rodata.str1.4
 370 001a 0000     		.align	2
 371              	.LC3:
 372 001c 64657374 		.ascii	"destroy_inode\000"
 372      726F795F 
 372      696E6F64 
 372      6500
 373              		.section	.export_table
 374              		.align	2
 377              	destroy_inode_export_struct:
 378 0018 1C000000 		.word	.LC3
 379 001c 0C000000 		.word	.LC1
 380 0020 00000000 		.word	destroy_inode
 381              		.section	.rodata.str1.4
 382 002a 0000     		.align	2
 383              	.LC4:
 384 002c 6E65775F 		.ascii	"new_inode\000"
 384      696E6F64 
 384      6500
 385              		.section	.export_table
 386              		.align	2
 389              	new_inode_export_struct:
 390 0024 2C000000 		.word	.LC4
 391 0028 0C000000 		.word	.LC1
ARM GAS  /tmp/ccKJN8PY.s 			page 84


 392 002c 00000000 		.word	new_inode
 393              		.text
 394              	.Letext0:
 395              		.file 7 "./include/asm-generic/int-l64.h"
 396              		.file 8 "./include/asm-generic/posix_types.h"
 397              		.file 9 "./include/uapi/linux/types.h"
 398              		.file 10 "./include/linux/types.h"
 399              		.file 11 "./include/linux/export.h"
 400              		.file 12 "./include/linux/errseq.h"
 401              		.file 13 "./include/linux/time64.h"
 402              		.file 14 "./arch/arm_m/include/asm/spinlock.h"
 403              		.file 15 "./include/linux/spinlock_types_raw.h"
 404              		.file 16 "./include/linux/spinlock_types.h"
 405              		.file 17 "./include/linux/rbtree_types.h"
 406              		.file 18 "./include/linux/uidgid_types.h"
 407              		.file 19 "./include/linux/projid.h"
 408              		.file 20 "./include/linux/fs.h"
 409              		.file 21 "./include/linux/mnt_idmapping.h"
 410              		.file 22 "./include/linux/mutex.h"
 411              		.file 23 "./include/linux/uio.h"
 412              		.file 24 "./include/linux/wait.h"
 413              		.file 25 "./include/linux/xarray.h"
 414              		.file 26 "./include/linux/migrate_mode.h"
 415              		.file 27 "./include/linux/rw_hint.h"
 416              		.file 28 "./include/linux/stddef.h"
 417              		.file 29 "./include/linux/gfp_types.h"
 418              		.file 30 "./include/linux/reciprocal_div.h"
 419              		.file 31 "./include/linux/mm_type.h"
 420              		.file 32 "./include/linux/bvec.h"
 421              		.file 33 "./include/linux/blk_types.h"
 422              		.file 34 "./include/linux/blkdev.h"
 423              		.file 35 "./include/linux/bio.h"
 424              		.file 36 "./include/linux/mempool_super_haper.h"
 425              		.file 37 "./include/linux/mempool.h"
 426              		.file 38 "./include/linux/lockdep_types.h"
 427              		.file 39 "./include/linux/workqueue_types.h"
 428              		.file 40 "./include/linux/blk-mq.h"
 429              		.file 41 "./include/linux/dcache.h"
 430              		.file 42 "./include/uapi/linux/pr.h"
 431              		.file 43 "./include/linux/pr.h"
 432              		.file 44 "./include/linux/hdreg.h"
 433              		.file 45 "./include/linux/lockref.h"
 434              		.file 46 "./include/linux/path.h"
 435              		.file 47 "./include/linux/statfs.h"
 436              		.file 48 "./include/linux/stat.h"
 437              		.file 49 "./include/linux/time.h"
 438              		.file 50 "./arch/arm_m/include/asm/string.h"
 439              		.file 51 "./include/linux/instrumented.h"
 440              		.file 52 "./include/linux/kcsan-checks.h"
 441              		.file 53 "./include/linux/kasan-checks.h"
 442              		.file 54 "<built-in>"
ARM GAS  /tmp/ccKJN8PY.s 			page 85


DEFINED SYMBOLS
                            *ABS*:00000000 fs_inode.c
     /tmp/ccKJN8PY.s:21     .text.inode_get:00000000 $t
     /tmp/ccKJN8PY.s:27     .text.inode_get:00000000 inode_get
     /tmp/ccKJN8PY.s:85     .text.new_inode:00000000 $t
     /tmp/ccKJN8PY.s:91     .text.new_inode:00000000 new_inode
     /tmp/ccKJN8PY.s:184    .text.destroy_inode:00000000 $t
     /tmp/ccKJN8PY.s:190    .text.destroy_inode:00000000 destroy_inode
     /tmp/ccKJN8PY.s:232    .text.inode_put:00000000 $t
     /tmp/ccKJN8PY.s:238    .text.inode_put:00000000 inode_put
     /tmp/ccKJN8PY.s:343    .rodata.str1.4:00000000 $d
     /tmp/ccKJN8PY.s:350    .export_table:00000000 $d
     /tmp/ccKJN8PY.s:353    .export_table:00000000 inode_put_export_struct
     /tmp/ccKJN8PY.s:365    .export_table:0000000c inode_get_export_struct
     /tmp/ccKJN8PY.s:377    .export_table:00000018 destroy_inode_export_struct
     /tmp/ccKJN8PY.s:389    .export_table:00000024 new_inode_export_struct

UNDEFINED SYMBOLS
__smalloc__
memset
ktime_get
__sfree__
