ARM GAS  /tmp/ccapU81z.s 			page 1


   1              		.cpu cortex-m4
   2              		.arch armv7e-m
   3              		.fpu fpv4-sp-d16
   4              		.eabi_attribute 27, 1
   5              		.eabi_attribute 28, 1
   6              		.eabi_attribute 20, 1
   7              		.eabi_attribute 21, 1
   8              		.eabi_attribute 23, 3
   9              		.eabi_attribute 24, 1
  10              		.eabi_attribute 25, 1
  11              		.eabi_attribute 26, 1
  12              		.eabi_attribute 30, 1
  13              		.eabi_attribute 34, 1
  14              		.eabi_attribute 18, 4
  15              		.file	"fs_inode.c"
  16              		.text
  17              	.Ltext0:
  18              		.cfi_sections	.debug_frame
  19              		.file 1 "/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c"
  20              		.section	.text.inode_get,"ax",%progbits
  21              		.align	1
  22              		.global	inode_get
  23              		.syntax unified
  24              		.thumb
  25              		.thumb_func
  27              	inode_get:
  28              	.LVL0:
  29              	.LFB1035:
   1:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** #include <linux/kernel.h>
   2:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** #include <linux/fs.h>
   3:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** #include <linux/spinlock.h>
   4:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** #include <linux/string.h>
   5:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** #include <linux/slab.h>
   6:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** #include <linux/dcache.h>
   7:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** #include <linux/export.h>
   8:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** #include <linux/list.h>
   9:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** #include <linux/fs.h>
  10:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** #include <linux/stat.h>
  11:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** #include <linux/time.h>
  12:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** #include <linux/atomic.h>
  13:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** 
  14:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** 
  15:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** struct inode* new_inode(struct super_block *sb){
  16:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****     struct inode *inode = (struct inode *)kmalloc(sizeof(struct inode), GFP_KERNEL);
  17:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****     if (inode == NULL) return NULL;
  18:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** 	memset(inode,0,sizeof(struct inode));
  19:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****     inode->i_mode    = S_IFCHR | 0777;
  20:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****     time64_t now        = jiffies;
  21:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****     inode->i_sb       = sb;
  22:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** 	atomic_set(&inode->i_count,1);
  23:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****     return inode;
  24:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** }
  25:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** EXPORT_SYMBOL(new_inode);
  26:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** 
  27:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** void destroy_inode(struct inode *node){
  28:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** 	if(node != NULL)
  29:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** 	kfree(node);
ARM GAS  /tmp/ccapU81z.s 			page 2


  30:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** }
  31:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** EXPORT_SYMBOL(destroy_inode);
  32:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** 
  33:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** void inode_get(struct inode *inode){
  30              		.loc 1 33 36 view -0
  31              		.cfi_startproc
  32              		@ args = 0, pretend = 0, frame = 0
  33              		@ frame_needed = 0, uses_anonymous_args = 0
  34              		@ link register save eliminated.
  34:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****     atomic_inc(&inode->i_count);  
  35              		.loc 1 34 5 view .LVU1
  36 0000 7830     		adds	r0, r0, #120
  37              	.LVL1:
  38              	.LBB74:
  39              	.LBI74:
  40              		.file 2 "/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h"
   1:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** // SPDX-License-Identifier: GPL-2.0
   2:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
   3:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** // Generated by scripts/atomic/gen-atomic-instrumented.sh 
   4:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** // DO NOT MODIFY THIS FILE DIRECTLY
   5:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
   6:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /*
   7:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * This file provoides atomic operations with explicit instrumentation (e.g.
   8:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * KASAN, KCSAN), which should be used unless it is necessary to avoid
   9:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * instrumentation. Where it is necessary to aovid instrumenation, the
  10:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * raw_atomic*() operations should be used.
  11:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
  12:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** #ifndef _LINUX_ATOMIC_INSTRUMENTED_H
  13:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** #define _LINUX_ATOMIC_INSTRUMENTED_H
  14:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
  15:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** #include <linux/build_bug.h>
  16:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** #include <linux/compiler.h>
  17:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** #include <linux/instrumented.h>
  18:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
  19:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
  20:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_read() - atomic load with relaxed ordering
  21:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
  22:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
  23:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically loads the value of @v with relaxed ordering.
  24:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
  25:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_read() there.
  26:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
  27:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The value loaded from @v.
  28:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
  29:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
  30:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_read(const atomic_t *v)
  31:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
  32:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read(v, sizeof(*v));
  33:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_read(v);
  34:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
  35:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
  36:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
  37:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_read_acquire() - atomic load with acquire ordering
  38:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
  39:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
  40:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically loads the value of @v with acquire ordering.
  41:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
ARM GAS  /tmp/ccapU81z.s 			page 3


  42:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_read_acquire() there.
  43:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
  44:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The value loaded from @v.
  45:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
  46:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
  47:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_read_acquire(const atomic_t *v)
  48:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
  49:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read(v, sizeof(*v));
  50:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_read_acquire(v);
  51:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
  52:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
  53:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
  54:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_set() - atomic set with relaxed ordering
  55:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
  56:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to assign
  57:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
  58:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically sets @v to @i with relaxed ordering.
  59:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
  60:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_set() there.
  61:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
  62:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: Nothing.
  63:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
  64:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline void
  65:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_set(atomic_t *v, int i)
  66:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
  67:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_write(v, sizeof(*v));
  68:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	raw_atomic_set(v, i);
  69:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
  70:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
  71:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
  72:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_set_release() - atomic set with release ordering
  73:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
  74:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to assign
  75:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
  76:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically sets @v to @i with release ordering.
  77:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
  78:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_set_release() there.
  79:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
  80:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: Nothing.
  81:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
  82:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline void
  83:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_set_release(atomic_t *v, int i)
  84:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
  85:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
  86:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_write(v, sizeof(*v));
  87:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	raw_atomic_set_release(v, i);
  88:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
  89:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
  90:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
  91:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_add() - atomic add with relaxed ordering
  92:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to add
  93:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
  94:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
  95:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + @i) with relaxed ordering.
  96:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
  97:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_add() there.
  98:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
ARM GAS  /tmp/ccapU81z.s 			page 4


  99:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: Nothing.
 100:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 101:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline void
 102:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_add(int i, atomic_t *v)
 103:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 104:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 105:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	raw_atomic_add(i, v);
 106:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 107:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 108:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 109:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_add_return() - atomic add with full ordering
 110:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to add
 111:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 112:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 113:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + @i) with full ordering.
 114:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 115:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_add_return() there.
 116:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 117:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 118:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 119:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 120:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_add_return(int i, atomic_t *v)
 121:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 122:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
 123:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 124:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_add_return(i, v);
 125:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 126:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 127:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 128:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_add_return_acquire() - atomic add with acquire ordering
 129:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to add
 130:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 131:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 132:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + @i) with acquire ordering.
 133:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 134:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_add_return_acquire() there.
 135:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 136:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 137:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 138:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 139:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_add_return_acquire(int i, atomic_t *v)
 140:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 141:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 142:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_add_return_acquire(i, v);
 143:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 144:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 145:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 146:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_add_return_release() - atomic add with release ordering
 147:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to add
 148:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 149:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 150:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + @i) with release ordering.
 151:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 152:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_add_return_release() there.
 153:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 154:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 155:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
ARM GAS  /tmp/ccapU81z.s 			page 5


 156:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 157:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_add_return_release(int i, atomic_t *v)
 158:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 159:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
 160:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 161:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_add_return_release(i, v);
 162:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 163:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 164:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 165:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_add_return_relaxed() - atomic add with relaxed ordering
 166:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to add
 167:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 168:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 169:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + @i) with relaxed ordering.
 170:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 171:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_add_return_relaxed() there.
 172:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 173:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 174:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 175:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 176:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_add_return_relaxed(int i, atomic_t *v)
 177:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 178:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 179:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_add_return_relaxed(i, v);
 180:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 181:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 182:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 183:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_add() - atomic add with full ordering
 184:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to add
 185:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 186:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 187:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + @i) with full ordering.
 188:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 189:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_add() there.
 190:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 191:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 192:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 193:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 194:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_add(int i, atomic_t *v)
 195:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 196:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
 197:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 198:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_add(i, v);
 199:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 200:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 201:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 202:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_add_acquire() - atomic add with acquire ordering
 203:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to add
 204:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 205:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 206:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + @i) with acquire ordering.
 207:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 208:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_add_acquire() there.
 209:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 210:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 211:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 212:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
ARM GAS  /tmp/ccapU81z.s 			page 6


 213:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_add_acquire(int i, atomic_t *v)
 214:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 215:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 216:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_add_acquire(i, v);
 217:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 218:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 219:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 220:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_add_release() - atomic add with release ordering
 221:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to add
 222:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 223:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 224:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + @i) with release ordering.
 225:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 226:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_add_release() there.
 227:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 228:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 229:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 230:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 231:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_add_release(int i, atomic_t *v)
 232:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 233:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
 234:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 235:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_add_release(i, v);
 236:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 237:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 238:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 239:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_add_relaxed() - atomic add with relaxed ordering
 240:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to add
 241:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 242:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 243:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + @i) with relaxed ordering.
 244:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 245:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_add_relaxed() there.
 246:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 247:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 248:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 249:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 250:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_add_relaxed(int i, atomic_t *v)
 251:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 252:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 253:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_add_relaxed(i, v);
 254:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 255:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 256:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 257:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_sub() - atomic subtract with relaxed ordering
 258:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to subtract
 259:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 260:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 261:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - @i) with relaxed ordering.
 262:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 263:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_sub() there.
 264:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 265:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: Nothing.
 266:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 267:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline void
 268:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_sub(int i, atomic_t *v)
 269:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
ARM GAS  /tmp/ccapU81z.s 			page 7


 270:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 271:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	raw_atomic_sub(i, v);
 272:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 273:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 274:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 275:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_sub_return() - atomic subtract with full ordering
 276:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to subtract
 277:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 278:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 279:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - @i) with full ordering.
 280:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 281:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_sub_return() there.
 282:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 283:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 284:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 285:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 286:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_sub_return(int i, atomic_t *v)
 287:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 288:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
 289:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 290:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_sub_return(i, v);
 291:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 292:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 293:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 294:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_sub_return_acquire() - atomic subtract with acquire ordering
 295:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to subtract
 296:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 297:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 298:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - @i) with acquire ordering.
 299:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 300:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_sub_return_acquire() there.
 301:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 302:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 303:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 304:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 305:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_sub_return_acquire(int i, atomic_t *v)
 306:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 307:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 308:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_sub_return_acquire(i, v);
 309:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 310:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 311:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 312:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_sub_return_release() - atomic subtract with release ordering
 313:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to subtract
 314:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 315:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 316:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - @i) with release ordering.
 317:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 318:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_sub_return_release() there.
 319:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 320:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 321:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 322:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 323:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_sub_return_release(int i, atomic_t *v)
 324:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 325:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
 326:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
ARM GAS  /tmp/ccapU81z.s 			page 8


 327:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_sub_return_release(i, v);
 328:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 329:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 330:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 331:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_sub_return_relaxed() - atomic subtract with relaxed ordering
 332:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to subtract
 333:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 334:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 335:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - @i) with relaxed ordering.
 336:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 337:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_sub_return_relaxed() there.
 338:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 339:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 340:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 341:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 342:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_sub_return_relaxed(int i, atomic_t *v)
 343:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 344:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 345:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_sub_return_relaxed(i, v);
 346:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 347:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 348:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 349:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_sub() - atomic subtract with full ordering
 350:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to subtract
 351:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 352:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 353:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - @i) with full ordering.
 354:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 355:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_sub() there.
 356:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 357:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 358:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 359:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 360:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_sub(int i, atomic_t *v)
 361:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 362:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
 363:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 364:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_sub(i, v);
 365:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 366:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 367:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 368:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_sub_acquire() - atomic subtract with acquire ordering
 369:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to subtract
 370:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 371:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 372:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - @i) with acquire ordering.
 373:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 374:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_sub_acquire() there.
 375:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 376:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 377:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 378:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 379:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_sub_acquire(int i, atomic_t *v)
 380:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 381:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 382:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_sub_acquire(i, v);
 383:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
ARM GAS  /tmp/ccapU81z.s 			page 9


 384:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 385:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 386:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_sub_release() - atomic subtract with release ordering
 387:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to subtract
 388:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 389:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 390:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - @i) with release ordering.
 391:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 392:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_sub_release() there.
 393:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 394:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 395:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 396:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 397:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_sub_release(int i, atomic_t *v)
 398:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 399:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
 400:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 401:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_sub_release(i, v);
 402:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 403:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 404:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 405:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_sub_relaxed() - atomic subtract with relaxed ordering
 406:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to subtract
 407:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 408:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 409:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - @i) with relaxed ordering.
 410:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 411:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_sub_relaxed() there.
 412:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 413:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 414:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 415:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 416:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_sub_relaxed(int i, atomic_t *v)
 417:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 418:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 419:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_sub_relaxed(i, v);
 420:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 421:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 422:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 423:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_inc() - atomic increment with relaxed ordering
 424:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 425:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 426:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + 1) with relaxed ordering.
 427:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 428:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_inc() there.
 429:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 430:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: Nothing.
 431:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 432:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline void
 433:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_inc(atomic_t *v)
  41              		.loc 2 433 1 view .LVU2
 434:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 435:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
  42              		.loc 2 435 2 view .LVU3
 436:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	raw_atomic_inc(v);
  43              		.loc 2 436 2 view .LVU4
  44              	.LBB75:
ARM GAS  /tmp/ccapU81z.s 			page 10


  45              	.LBI75:
  46              		.file 3 "/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h"
   1:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** // SPDX-License-Identifier: GPL-2.0
   2:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
   3:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** // Generated by scripts/atomic/gen-atomic-fallback.sh
   4:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** // DO NOT MODIFY THIS FILE DIRECTLY
   5:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
   6:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #ifndef _LINUX_ATOMIC_FALLBACK_H
   7:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define _LINUX_ATOMIC_FALLBACK_H
   8:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
   9:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #include <linux/compiler.h>
  10:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
  11:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_xchg)
  12:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg arch_xchg
  13:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_xchg_relaxed)
  14:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg(...) \
  15:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_fence(arch_xchg, __VA_ARGS__)
  16:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
  17:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_xchg_not_implemented(void);
  18:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg(...) raw_xchg_not_implemented()
  19:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
  20:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
  21:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_xchg_acquire)
  22:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_acquire arch_xchg_acquire
  23:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_xchg_relaxed)
  24:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_acquire(...) \
  25:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_acquire(arch_xchg, __VA_ARGS__)
  26:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_xchg)
  27:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_acquire arch_xchg
  28:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
  29:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_xchg_acquire_not_implemented(void);
  30:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_acquire(...) raw_xchg_acquire_not_implemented()
  31:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
  32:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
  33:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_xchg_release)
  34:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_release arch_xchg_release
  35:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_xchg_relaxed)
  36:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_release(...) \
  37:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_release(arch_xchg, __VA_ARGS__)
  38:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_xchg)
  39:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_release arch_xchg
  40:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
  41:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_xchg_release_not_implemented(void);
  42:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_release(...) raw_xchg_release_not_implemented()
  43:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
  44:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
  45:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_xchg_relaxed)
  46:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_relaxed arch_xchg_relaxed
  47:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_xchg)
  48:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_relaxed arch_xchg
  49:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
  50:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_xchg_relaxed_not_implemented(void);
  51:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_relaxed(...) raw_xchg_relaxed_not_implemented()
  52:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
  53:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
  54:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg)
  55:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg arch_cmpxchg
ARM GAS  /tmp/ccapU81z.s 			page 11


  56:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg_relaxed)
  57:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg(...) \
  58:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_fence(arch_cmpxchg, __VA_ARGS__)
  59:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
  60:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg_not_implemented(void);
  61:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg(...) raw_cmpxchg_not_implemented()
  62:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
  63:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
  64:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg_acquire)
  65:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_acquire arch_cmpxchg_acquire
  66:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg_relaxed)
  67:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_acquire(...) \
  68:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_acquire(arch_cmpxchg, __VA_ARGS__)
  69:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg)
  70:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_acquire arch_cmpxchg
  71:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
  72:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg_acquire_not_implemented(void);
  73:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_acquire(...) raw_cmpxchg_acquire_not_implemented()
  74:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
  75:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
  76:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg_release)
  77:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_release arch_cmpxchg_release
  78:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg_relaxed)
  79:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_release(...) \
  80:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_release(arch_cmpxchg, __VA_ARGS__)
  81:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg)
  82:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_release arch_cmpxchg
  83:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
  84:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg_release_not_implemented(void);
  85:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_release(...) raw_cmpxchg_release_not_implemented()
  86:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
  87:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
  88:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg_relaxed)
  89:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_relaxed arch_cmpxchg_relaxed
  90:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg)
  91:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_relaxed arch_cmpxchg
  92:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
  93:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg_relaxed_not_implemented(void);
  94:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_relaxed(...) raw_cmpxchg_relaxed_not_implemented()
  95:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
  96:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
  97:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg64)
  98:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64 arch_cmpxchg64
  99:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg64_relaxed)
 100:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64(...) \
 101:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_fence(arch_cmpxchg64, __VA_ARGS__)
 102:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 103:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg64_not_implemented(void);
 104:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64(...) raw_cmpxchg64_not_implemented()
 105:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 106:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 107:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg64_acquire)
 108:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_acquire arch_cmpxchg64_acquire
 109:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg64_relaxed)
 110:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_acquire(...) \
 111:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_acquire(arch_cmpxchg64, __VA_ARGS__)
 112:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg64)
ARM GAS  /tmp/ccapU81z.s 			page 12


 113:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_acquire arch_cmpxchg64
 114:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 115:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg64_acquire_not_implemented(void);
 116:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_acquire(...) raw_cmpxchg64_acquire_not_implemented()
 117:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 118:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 119:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg64_release)
 120:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_release arch_cmpxchg64_release
 121:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg64_relaxed)
 122:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_release(...) \
 123:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_release(arch_cmpxchg64, __VA_ARGS__)
 124:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg64)
 125:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_release arch_cmpxchg64
 126:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 127:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg64_release_not_implemented(void);
 128:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_release(...) raw_cmpxchg64_release_not_implemented()
 129:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 130:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 131:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg64_relaxed)
 132:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_relaxed arch_cmpxchg64_relaxed
 133:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg64)
 134:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_relaxed arch_cmpxchg64
 135:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 136:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg64_relaxed_not_implemented(void);
 137:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_relaxed(...) raw_cmpxchg64_relaxed_not_implemented()
 138:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 139:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 140:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg128)
 141:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128 arch_cmpxchg128
 142:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg128_relaxed)
 143:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128(...) \
 144:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_fence(arch_cmpxchg128, __VA_ARGS__)
 145:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 146:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg128_not_implemented(void);
 147:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128(...) raw_cmpxchg128_not_implemented()
 148:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 149:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 150:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg128_acquire)
 151:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_acquire arch_cmpxchg128_acquire
 152:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg128_relaxed)
 153:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_acquire(...) \
 154:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_acquire(arch_cmpxchg128, __VA_ARGS__)
 155:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg128)
 156:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_acquire arch_cmpxchg128
 157:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 158:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg128_acquire_not_implemented(void);
 159:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_acquire(...) raw_cmpxchg128_acquire_not_implemented()
 160:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 161:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 162:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg128_release)
 163:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_release arch_cmpxchg128_release
 164:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg128_relaxed)
 165:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_release(...) \
 166:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_release(arch_cmpxchg128, __VA_ARGS__)
 167:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg128)
 168:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_release arch_cmpxchg128
 169:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
ARM GAS  /tmp/ccapU81z.s 			page 13


 170:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg128_release_not_implemented(void);
 171:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_release(...) raw_cmpxchg128_release_not_implemented()
 172:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 173:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 174:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg128_relaxed)
 175:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_relaxed arch_cmpxchg128_relaxed
 176:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg128)
 177:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_relaxed arch_cmpxchg128
 178:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 179:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg128_relaxed_not_implemented(void);
 180:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_relaxed(...) raw_cmpxchg128_relaxed_not_implemented()
 181:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 182:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 183:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 184:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 185:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 186:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 187:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 188:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 189:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg)
 190:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg arch_try_cmpxchg
 191:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg_relaxed)
 192:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg(...) \
 193:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_fence(arch_try_cmpxchg, __VA_ARGS__)
 194:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 195:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg(_ptr, _oldp, _new) \
 196:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 197:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 198:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg((_ptr), ___o, (_new)); \
 199:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 200:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 201:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 202:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 203:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 204:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 205:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg_acquire)
 206:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_acquire arch_try_cmpxchg_acquire
 207:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg_relaxed)
 208:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_acquire(...) \
 209:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_acquire(arch_try_cmpxchg, __VA_ARGS__)
 210:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg)
 211:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_acquire arch_try_cmpxchg
 212:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 213:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_acquire(_ptr, _oldp, _new) \
 214:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 215:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 216:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg_acquire((_ptr), ___o, (_new)); \
 217:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 218:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 219:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 220:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 221:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 222:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 223:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg_release)
 224:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_release arch_try_cmpxchg_release
 225:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg_relaxed)
 226:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_release(...) \
ARM GAS  /tmp/ccapU81z.s 			page 14


 227:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_release(arch_try_cmpxchg, __VA_ARGS__)
 228:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg)
 229:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_release arch_try_cmpxchg
 230:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 231:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_release(_ptr, _oldp, _new) \
 232:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 233:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 234:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg_release((_ptr), ___o, (_new)); \
 235:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 236:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 237:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 238:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 239:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 240:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 241:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg_relaxed)
 242:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_relaxed arch_try_cmpxchg_relaxed
 243:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg)
 244:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_relaxed arch_try_cmpxchg
 245:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 246:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_relaxed(_ptr, _oldp, _new) \
 247:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 248:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 249:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg_relaxed((_ptr), ___o, (_new)); \
 250:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 251:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 252:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 253:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 254:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 255:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 256:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg64)
 257:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64 arch_try_cmpxchg64
 258:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg64_relaxed)
 259:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64(...) \
 260:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_fence(arch_try_cmpxchg64, __VA_ARGS__)
 261:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 262:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64(_ptr, _oldp, _new) \
 263:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 264:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 265:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg64((_ptr), ___o, (_new)); \
 266:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 267:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 268:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 269:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 270:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 271:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 272:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg64_acquire)
 273:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_acquire arch_try_cmpxchg64_acquire
 274:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg64_relaxed)
 275:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_acquire(...) \
 276:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_acquire(arch_try_cmpxchg64, __VA_ARGS__)
 277:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg64)
 278:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_acquire arch_try_cmpxchg64
 279:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 280:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_acquire(_ptr, _oldp, _new) \
 281:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 282:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 283:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg64_acquire((_ptr), ___o, (_new)); \
ARM GAS  /tmp/ccapU81z.s 			page 15


 284:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 285:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 286:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 287:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 288:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 289:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 290:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg64_release)
 291:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_release arch_try_cmpxchg64_release
 292:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg64_relaxed)
 293:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_release(...) \
 294:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_release(arch_try_cmpxchg64, __VA_ARGS__)
 295:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg64)
 296:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_release arch_try_cmpxchg64
 297:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 298:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_release(_ptr, _oldp, _new) \
 299:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 300:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 301:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg64_release((_ptr), ___o, (_new)); \
 302:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 303:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 304:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 305:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 306:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 307:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 308:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg64_relaxed)
 309:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_relaxed arch_try_cmpxchg64_relaxed
 310:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg64)
 311:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_relaxed arch_try_cmpxchg64
 312:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 313:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_relaxed(_ptr, _oldp, _new) \
 314:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 315:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 316:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg64_relaxed((_ptr), ___o, (_new)); \
 317:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 318:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 319:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 320:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 321:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 322:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 323:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg128)
 324:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128 arch_try_cmpxchg128
 325:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg128_relaxed)
 326:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128(...) \
 327:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_fence(arch_try_cmpxchg128, __VA_ARGS__)
 328:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 329:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128(_ptr, _oldp, _new) \
 330:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 331:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 332:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg128((_ptr), ___o, (_new)); \
 333:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 334:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 335:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 336:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 337:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 338:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 339:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg128_acquire)
 340:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_acquire arch_try_cmpxchg128_acquire
ARM GAS  /tmp/ccapU81z.s 			page 16


 341:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg128_relaxed)
 342:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_acquire(...) \
 343:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_acquire(arch_try_cmpxchg128, __VA_ARGS__)
 344:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg128)
 345:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_acquire arch_try_cmpxchg128
 346:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 347:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_acquire(_ptr, _oldp, _new) \
 348:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 349:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 350:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg128_acquire((_ptr), ___o, (_new)); \
 351:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 352:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 353:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 354:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 355:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 356:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 357:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg128_release)
 358:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_release arch_try_cmpxchg128_release
 359:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg128_relaxed)
 360:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_release(...) \
 361:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_release(arch_try_cmpxchg128, __VA_ARGS__)
 362:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg128)
 363:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_release arch_try_cmpxchg128
 364:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 365:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_release(_ptr, _oldp, _new) \
 366:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 367:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 368:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg128_release((_ptr), ___o, (_new)); \
 369:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 370:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 371:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 372:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 373:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 374:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 375:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg128_relaxed)
 376:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_relaxed arch_try_cmpxchg128_relaxed
 377:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg128)
 378:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_relaxed arch_try_cmpxchg128
 379:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 380:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_relaxed(_ptr, _oldp, _new) \
 381:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 382:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 383:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg128_relaxed((_ptr), ___o, (_new)); \
 384:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 385:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 386:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 387:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 388:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 389:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 390:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_local arch_cmpxchg_local
 391:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 392:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #ifdef arch_try_cmpxchg_local
 393:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_local arch_try_cmpxchg_local
 394:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 395:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_local(_ptr, _oldp, _new) \
 396:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 397:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
ARM GAS  /tmp/ccapU81z.s 			page 17


 398:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg_local((_ptr), ___o, (_new)); \
 399:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 400:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 401:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 402:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 403:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 404:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 405:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_local arch_cmpxchg64_local
 406:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 407:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #ifdef arch_try_cmpxchg64_local
 408:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_local arch_try_cmpxchg64_local
 409:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 410:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_local(_ptr, _oldp, _new) \
 411:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 412:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 413:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg64_local((_ptr), ___o, (_new)); \
 414:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 415:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 416:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 417:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 418:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 419:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 420:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_local arch_cmpxchg128_local
 421:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 422:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #ifdef arch_try_cmpxchg128_local
 423:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_local arch_try_cmpxchg128_local
 424:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 425:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_local(_ptr, _oldp, _new) \
 426:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 427:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 428:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg128_local((_ptr), ___o, (_new)); \
 429:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 430:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 431:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 432:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 433:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 434:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 435:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_sync_cmpxchg arch_sync_cmpxchg
 436:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 437:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #ifdef arch_sync_try_cmpxchg
 438:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_sync_try_cmpxchg arch_sync_try_cmpxchg
 439:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 440:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_sync_try_cmpxchg(_ptr, _oldp, _new) \
 441:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 442:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 443:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_sync_cmpxchg((_ptr), ___o, (_new)); \
 444:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 445:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 446:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 447:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 448:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 449:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 450:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 451:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_read() - atomic load with relaxed ordering
 452:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 453:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 454:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically loads the value of @v with relaxed ordering.
ARM GAS  /tmp/ccapU81z.s 			page 18


 455:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 456:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_read() elsewhere.
 457:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 458:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The value loaded from @v.
 459:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 460:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 461:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_read(const atomic_t *v)
 462:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 463:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_read(v);
 464:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 465:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 466:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 467:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_read_acquire() - atomic load with acquire ordering
 468:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 469:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 470:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically loads the value of @v with acquire ordering.
 471:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 472:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_read_acquire() elsewhere.
 473:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 474:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The value loaded from @v.
 475:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 476:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 477:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_read_acquire(const atomic_t *v)
 478:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 479:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_read_acquire)
 480:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_read_acquire(v);
 481:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 482:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
 483:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 484:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (__native_word(atomic_t)) {
 485:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		ret = smp_load_acquire(&(v)->counter);
 486:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	} else {
 487:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		ret = raw_atomic_read(v);
 488:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		__atomic_acquire_fence();
 489:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	}
 490:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 491:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
 492:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 493:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 494:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 495:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 496:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_set() - atomic set with relaxed ordering
 497:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 498:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to assign
 499:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 500:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically sets @v to @i with relaxed ordering.
 501:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 502:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_set() elsewhere.
 503:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 504:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: Nothing.
 505:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 506:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline void
 507:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_set(atomic_t *v, int i)
 508:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 509:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	arch_atomic_set(v, i);
 510:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 511:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
ARM GAS  /tmp/ccapU81z.s 			page 19


 512:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 513:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_set_release() - atomic set with release ordering
 514:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 515:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to assign
 516:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 517:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically sets @v to @i with release ordering.
 518:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 519:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_set_release() elsewhere.
 520:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 521:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: Nothing.
 522:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 523:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline void
 524:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_set_release(atomic_t *v, int i)
 525:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 526:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_set_release)
 527:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	arch_atomic_set_release(v, i);
 528:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 529:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (__native_word(atomic_t)) {
 530:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		smp_store_release(&(v)->counter, i);
 531:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	} else {
 532:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		__atomic_release_fence();
 533:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		raw_atomic_set(v, i);
 534:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	}
 535:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 536:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 537:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 538:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 539:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_add() - atomic add with relaxed ordering
 540:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to add
 541:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 542:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 543:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + @i) with relaxed ordering.
 544:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 545:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_add() elsewhere.
 546:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 547:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: Nothing.
 548:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 549:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline void
 550:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_add(int i, atomic_t *v)
 551:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 552:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	arch_atomic_add(i, v);
 553:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 554:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 555:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 556:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_add_return() - atomic add with full ordering
 557:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to add
 558:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 559:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 560:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + @i) with full ordering.
 561:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 562:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_add_return() elsewhere.
 563:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 564:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
 565:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 566:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 567:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_add_return(int i, atomic_t *v)
 568:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
ARM GAS  /tmp/ccapU81z.s 			page 20


 569:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_add_return)
 570:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_add_return(i, v);
 571:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_add_return_relaxed)
 572:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
 573:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
 574:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_add_return_relaxed(i, v);
 575:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
 576:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
 577:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 578:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_add_return"
 579:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 580:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 581:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 582:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 583:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_add_return_acquire() - atomic add with acquire ordering
 584:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to add
 585:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 586:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 587:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + @i) with acquire ordering.
 588:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 589:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_add_return_acquire() elsewhere.
 590:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 591:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
 592:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 593:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 594:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_add_return_acquire(int i, atomic_t *v)
 595:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 596:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_add_return_acquire)
 597:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_add_return_acquire(i, v);
 598:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_add_return_relaxed)
 599:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_add_return_relaxed(i, v);
 600:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
 601:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
 602:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_add_return)
 603:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_add_return(i, v);
 604:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 605:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_add_return_acquire"
 606:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 607:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 608:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 609:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 610:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_add_return_release() - atomic add with release ordering
 611:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to add
 612:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 613:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 614:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + @i) with release ordering.
 615:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 616:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_add_return_release() elsewhere.
 617:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 618:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
 619:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 620:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 621:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_add_return_release(int i, atomic_t *v)
 622:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 623:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_add_return_release)
 624:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_add_return_release(i, v);
 625:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_add_return_relaxed)
ARM GAS  /tmp/ccapU81z.s 			page 21


 626:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
 627:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_add_return_relaxed(i, v);
 628:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_add_return)
 629:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_add_return(i, v);
 630:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 631:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_add_return_release"
 632:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 633:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 634:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 635:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 636:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_add_return_relaxed() - atomic add with relaxed ordering
 637:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to add
 638:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 639:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 640:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + @i) with relaxed ordering.
 641:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 642:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_add_return_relaxed() elsewhere.
 643:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 644:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
 645:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 646:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 647:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_add_return_relaxed(int i, atomic_t *v)
 648:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 649:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_add_return_relaxed)
 650:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_add_return_relaxed(i, v);
 651:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_add_return)
 652:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_add_return(i, v);
 653:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 654:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_add_return_relaxed"
 655:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 656:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 657:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 658:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 659:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_add() - atomic add with full ordering
 660:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to add
 661:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 662:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 663:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + @i) with full ordering.
 664:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 665:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_add() elsewhere.
 666:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 667:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
 668:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 669:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 670:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_add(int i, atomic_t *v)
 671:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 672:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_add)
 673:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_add(i, v);
 674:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_add_relaxed)
 675:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
 676:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
 677:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_fetch_add_relaxed(i, v);
 678:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
 679:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
 680:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 681:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_add"
 682:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
ARM GAS  /tmp/ccapU81z.s 			page 22


 683:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 684:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 685:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 686:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_add_acquire() - atomic add with acquire ordering
 687:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to add
 688:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 689:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 690:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + @i) with acquire ordering.
 691:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 692:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_add_acquire() elsewhere.
 693:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 694:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
 695:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 696:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 697:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_add_acquire(int i, atomic_t *v)
 698:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 699:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_add_acquire)
 700:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_add_acquire(i, v);
 701:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_add_relaxed)
 702:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_fetch_add_relaxed(i, v);
 703:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
 704:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
 705:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_add)
 706:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_add(i, v);
 707:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 708:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_add_acquire"
 709:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 710:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 711:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 712:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 713:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_add_release() - atomic add with release ordering
 714:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to add
 715:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 716:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 717:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + @i) with release ordering.
 718:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 719:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_add_release() elsewhere.
 720:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 721:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
 722:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 723:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 724:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_add_release(int i, atomic_t *v)
 725:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 726:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_add_release)
 727:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_add_release(i, v);
 728:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_add_relaxed)
 729:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
 730:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_add_relaxed(i, v);
 731:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_add)
 732:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_add(i, v);
 733:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 734:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_add_release"
 735:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 736:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 737:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 738:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 739:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_add_relaxed() - atomic add with relaxed ordering
ARM GAS  /tmp/ccapU81z.s 			page 23


 740:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to add
 741:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 742:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 743:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + @i) with relaxed ordering.
 744:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 745:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_add_relaxed() elsewhere.
 746:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 747:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
 748:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 749:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 750:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_add_relaxed(int i, atomic_t *v)
 751:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 752:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_add_relaxed)
 753:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_add_relaxed(i, v);
 754:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_add)
 755:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_add(i, v);
 756:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 757:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_add_relaxed"
 758:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 759:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 760:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 761:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 762:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_sub() - atomic subtract with relaxed ordering
 763:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to subtract
 764:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 765:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 766:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - @i) with relaxed ordering.
 767:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 768:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_sub() elsewhere.
 769:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 770:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: Nothing.
 771:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 772:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline void
 773:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_sub(int i, atomic_t *v)
 774:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 775:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	arch_atomic_sub(i, v);
 776:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 777:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 778:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 779:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_sub_return() - atomic subtract with full ordering
 780:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to subtract
 781:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 782:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 783:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - @i) with full ordering.
 784:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 785:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_sub_return() elsewhere.
 786:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 787:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
 788:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 789:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 790:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_sub_return(int i, atomic_t *v)
 791:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 792:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_sub_return)
 793:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_sub_return(i, v);
 794:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_sub_return_relaxed)
 795:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
 796:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
ARM GAS  /tmp/ccapU81z.s 			page 24


 797:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_sub_return_relaxed(i, v);
 798:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
 799:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
 800:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 801:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	volatile int *p = (volatile int *)&v->counter;
 802:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret = *p;
 803:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	*p -= i;
 804:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
 805:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 806:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 807:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 808:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 809:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 810:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_sub_return_acquire() - atomic subtract with acquire ordering
 811:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to subtract
 812:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 813:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 814:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - @i) with acquire ordering.
 815:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 816:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_sub_return_acquire() elsewhere.
 817:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 818:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
 819:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 820:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 821:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_sub_return_acquire(int i, atomic_t *v)
 822:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 823:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_sub_return_acquire)
 824:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_sub_return_acquire(i, v);
 825:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_sub_return_relaxed)
 826:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_sub_return_relaxed(i, v);
 827:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
 828:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
 829:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_sub_return)
 830:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_sub_return(i, v);
 831:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 832:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_sub_return_acquire"
 833:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 834:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 835:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 836:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 837:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_sub_return_release() - atomic subtract with release ordering
 838:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to subtract
 839:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 840:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 841:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - @i) with release ordering.
 842:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 843:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_sub_return_release() elsewhere.
 844:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 845:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
 846:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 847:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 848:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_sub_return_release(int i, atomic_t *v)
 849:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 850:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_sub_return_release)
 851:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_sub_return_release(i, v);
 852:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_sub_return_relaxed)
 853:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
ARM GAS  /tmp/ccapU81z.s 			page 25


 854:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_sub_return_relaxed(i, v);
 855:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_sub_return)
 856:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_sub_return(i, v);
 857:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 858:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_sub_return_release"
 859:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 860:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 861:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 862:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 863:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_sub_return_relaxed() - atomic subtract with relaxed ordering
 864:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to subtract
 865:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 866:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 867:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - @i) with relaxed ordering.
 868:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 869:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_sub_return_relaxed() elsewhere.
 870:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 871:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
 872:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 873:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 874:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_sub_return_relaxed(int i, atomic_t *v)
 875:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 876:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_sub_return_relaxed)
 877:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_sub_return_relaxed(i, v);
 878:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_sub_return)
 879:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_sub_return(i, v);
 880:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 881:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_sub_return_relaxed"
 882:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 883:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 884:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 885:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 886:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_sub() - atomic subtract with full ordering
 887:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to subtract
 888:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 889:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 890:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - @i) with full ordering.
 891:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 892:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_sub() elsewhere.
 893:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 894:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
 895:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 896:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 897:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_sub(int i, atomic_t *v)
 898:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 899:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_sub)
 900:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_sub(i, v);
 901:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_sub_relaxed)
 902:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
 903:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
 904:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_fetch_sub_relaxed(i, v);
 905:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
 906:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
 907:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 908:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_sub"
 909:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 910:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
ARM GAS  /tmp/ccapU81z.s 			page 26


 911:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 912:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 913:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_sub_acquire() - atomic subtract with acquire ordering
 914:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to subtract
 915:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 916:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 917:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - @i) with acquire ordering.
 918:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 919:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_sub_acquire() elsewhere.
 920:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 921:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
 922:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 923:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 924:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_sub_acquire(int i, atomic_t *v)
 925:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 926:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_sub_acquire)
 927:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_sub_acquire(i, v);
 928:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_sub_relaxed)
 929:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_fetch_sub_relaxed(i, v);
 930:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
 931:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
 932:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_sub)
 933:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_sub(i, v);
 934:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 935:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_sub_acquire"
 936:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 937:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 938:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 939:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 940:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_sub_release() - atomic subtract with release ordering
 941:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to subtract
 942:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 943:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 944:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - @i) with release ordering.
 945:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 946:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_sub_release() elsewhere.
 947:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 948:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
 949:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 950:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 951:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_sub_release(int i, atomic_t *v)
 952:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 953:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_sub_release)
 954:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_sub_release(i, v);
 955:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_sub_relaxed)
 956:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
 957:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_sub_relaxed(i, v);
 958:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_sub)
 959:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_sub(i, v);
 960:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 961:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_sub_release"
 962:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 963:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 964:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 965:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 966:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_sub_relaxed() - atomic subtract with relaxed ordering
 967:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to subtract
ARM GAS  /tmp/ccapU81z.s 			page 27


 968:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 969:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 970:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - @i) with relaxed ordering.
 971:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 972:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_sub_relaxed() elsewhere.
 973:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 974:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
 975:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 976:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 977:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_sub_relaxed(int i, atomic_t *v)
 978:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 979:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_sub_relaxed)
 980:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_sub_relaxed(i, v);
 981:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_sub)
 982:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_sub(i, v);
 983:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 984:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_sub_relaxed"
 985:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 986:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 987:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 988:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 989:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_inc() - atomic increment with relaxed ordering
 990:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 991:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 992:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + 1) with relaxed ordering.
 993:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 994:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_inc() elsewhere.
 995:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 996:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: Nothing.
 997:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 998:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline void
 999:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_inc(atomic_t *v)
  47              		.loc 3 999 1 view .LVU5
1000:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1001:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_inc)
1002:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	arch_atomic_inc(v);
1003:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1004:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	raw_atomic_add(1, v);
  48              		.loc 3 1004 2 view .LVU6
  49              	.LBB76:
  50              	.LBI76:
 550:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
  51              		.loc 3 550 1 view .LVU7
 552:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
  52              		.loc 3 552 2 view .LVU8
  53              	.LBB77:
  54              	.LBI77:
  55              		.file 4 "/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h"
   1:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** /* SPDX-License-Identifier: GPL-2.0-only */
   2:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** /*
   3:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****  * arch/arm/include/asm/atomic.h
   4:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****  *
   5:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****  * Copyright (C) 1996 Russell King.
   6:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****  * Copyright (C) 2002 Deep Blue Solutions Ltd.
   7:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****  * Modified for uClinux on STM32F407
   8:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****  */
   9:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #ifndef __ASM_ARM_ATOMIC_H
ARM GAS  /tmp/ccapU81z.s 			page 28


  10:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #define __ASM_ARM_ATOMIC_H
  11:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
  12:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #include <linux/compiler.h> /* Available */
  13:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #include <linux/types.h>    /* Available */
  14:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #include <asm/barrier.h>    /* Available */
  15:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
  16:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** /* Include architecture-specific configuration */
  17:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
  18:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
  19:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #ifdef __KERNEL__
  20:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
  21:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
  22:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
  23:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
  24:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
  25:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** // typedef struct {
  26:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** //     volatile int counter;
  27:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** // } atomic_t;
  28:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
  29:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #define ATOMIC_INIT(i) { (i) }
  30:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
  31:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** /*
  32:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****  * On ARMv7-M, ordinary assignment (str instruction) doesn't clear the local
  33:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****  * strex/ldrex monitor on some implementations. The reason we can use it for
  34:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****  * atomic_set() is the clrex or dummy strex done on every exception return.
  35:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****  */
  36:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #define arch_atomic_read(v) READ_ONCE((v)->counter)
  37:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #define arch_atomic_set(v,i)    WRITE_ONCE(((v)->counter), (i))
  38:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
  39:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** /*
  40:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****  * ARMv6 UP and SMP safe atomic ops.  We use load exclusive and
  41:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****  * store exclusive to ensure that these are atomic.  We may loop
  42:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****  * to ensure that the update happens.
  43:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****  *
  44:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****  * For STM32F407 (Cortex-M4, ARMv7-M), these instructions are available.
  45:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****  */
  46:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
  47:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #define ATOMIC_OP(op, c_op, asm_op)                     \
  48:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** static inline void arch_atomic_##op(int i, atomic_t *v)         \
  49:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** {                                       \
  50:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     unsigned long tmp;                          \
  51:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     int result;                                 \
  52:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****                                         \
  53:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     /* prefetchw(&v->counter); - prefetch not available */ \
  54:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     __asm__ __volatile__("@ atomic_" #op "\n"           \
  55:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "1: ldrex   %0, [%3]\n"                      \
  56:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   " #asm_op " %0, %0, %4\n"                \
  57:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   strex   %1, %0, [%3]\n"                      \
  58:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   teq %1, #0\n"                         \
  59:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   bne 1b"                                \
  60:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     : "=&r" (result), "=&r" (tmp), "+Qo" (v->counter)     \
  61:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     : "r" (&v->counter), "Ir" (i)                 \
  62:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     : "cc");                                   \
  63:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** }
  64:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
  65:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #define ATOMIC_OP_RETURN(op, c_op, asm_op)                  \
  66:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** static inline int arch_atomic_##op##_return_relaxed(int i, atomic_t *v) \
ARM GAS  /tmp/ccapU81z.s 			page 29


  67:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** {                                       \
  68:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     unsigned long tmp;                          \
  69:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     int result;                                 \
  70:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****                                         \
  71:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     /* prefetchw(&v->counter); - prefetch not available */ \
  72:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     __asm__ __volatile__("@ atomic_" #op "_return\n"        \
  73:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "1: ldrex   %0, [%3]\n"                      \
  74:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   " #asm_op " %0, %0, %4\n"                \
  75:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   strex   %1, %0, [%3]\n"                      \
  76:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   teq %1, #0\n"                         \
  77:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   bne 1b"                                \
  78:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     : "=&r" (result), "=&r" (tmp), "+Qo" (v->counter)     \
  79:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     : "r" (&v->counter), "Ir" (i)                 \
  80:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     : "cc");                                   \
  81:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****                                         \
  82:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     return result;                              \
  83:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** }
  84:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
  85:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #define ATOMIC_FETCH_OP(op, c_op, asm_op)                   \
  86:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** static inline int arch_atomic_fetch_##op##_relaxed(int i, atomic_t *v)  \
  87:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** {                                       \
  88:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     unsigned long tmp;                          \
  89:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     int result, val;                             \
  90:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****                                         \
  91:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     /* prefetchw(&v->counter); - prefetch not available */ \
  92:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     __asm__ __volatile__("@ atomic_fetch_" #op "\n"       \
  93:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "1: ldrex   %0, [%4]\n"                      \
  94:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   " #asm_op " %1, %0, %5\n"                \
  95:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   strex   %2, %1, [%4]\n"                      \
  96:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   teq %2, #0\n"                         \
  97:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   bne 1b"                                \
  98:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     : "=&r" (result), "=&r" (val), "=&r" (tmp), "+Qo" (v->counter) \
  99:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     : "r" (&v->counter), "Ir" (i)                 \
 100:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     : "cc");                                   \
 101:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****                                         \
 102:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     return result;                              \
 103:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** }
 104:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
 105:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #define arch_atomic_add_return_relaxed       arch_atomic_add_return_relaxed
 106:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #define arch_atomic_sub_return_relaxed       arch_atomic_sub_return_relaxed
 107:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #define arch_atomic_fetch_add_relaxed        arch_atomic_fetch_add_relaxed
 108:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #define arch_atomic_fetch_sub_relaxed        arch_atomic_fetch_sub_relaxed
 109:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
 110:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #define arch_atomic_fetch_and_relaxed        arch_atomic_fetch_and_relaxed
 111:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #define arch_atomic_fetch_andnot_relaxed     arch_atomic_fetch_andnot_relaxed
 112:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #define arch_atomic_fetch_or_relaxed         arch_atomic_fetch_or_relaxed
 113:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #define arch_atomic_fetch_xor_relaxed        arch_atomic_fetch_xor_relaxed
 114:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
 115:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** static inline int arch_atomic_cmpxchg_relaxed(atomic_t *ptr, int old, int new)
 116:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** {
 117:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     int oldval;
 118:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     unsigned long res;
 119:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
 120:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     /* prefetchw(&ptr->counter); - prefetch not available */
 121:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
 122:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     do {
 123:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****         __asm__ __volatile__("@ atomic_cmpxchg\n"
ARM GAS  /tmp/ccapU81z.s 			page 30


 124:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   ldrex   %1, [%3]\n"
 125:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   mov     %0, #0\n"
 126:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   teq     %1, %4\n"
 127:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   strexeq %0, %5, [%3]\n"
 128:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****         : "=&r" (res), "=&r" (oldval), "+Qo" (ptr->counter)
 129:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****         : "r" (&ptr->counter), "Ir" (old), "r" (new)
 130:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****         : "cc");
 131:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     } while (res);
 132:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
 133:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     return oldval;
 134:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** }
 135:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #define arch_atomic_cmpxchg_relaxed        arch_atomic_cmpxchg_relaxed
 136:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
 137:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** static inline int arch_atomic_fetch_add_unless(atomic_t *v, int a, int u)
 138:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** {
 139:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     int oldval, newval;
 140:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     unsigned long tmp;
 141:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
 142:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     /* smp_mb(); - Memory barriers might need specific implementation */
 143:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     /* prefetchw(&v->counter); - prefetch not available */
 144:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
 145:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     __asm__ __volatile__ ("@ atomic_add_unless\n"
 146:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "1: ldrex   %0, [%4]\n"
 147:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   teq %0, %5\n"
 148:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   beq 2f\n"
 149:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   add %1, %0, %6\n"
 150:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   strex   %2, %1, [%4]\n"
 151:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   teq %2, #0\n"
 152:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   bne 1b\n"
 153:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "2:"
 154:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     : "=&r" (oldval), "=&r" (newval), "=&r" (tmp), "+Qo" (v->counter)
 155:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     : "r" (&v->counter), "r" (u), "r" (a)
 156:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     : "cc");
 157:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
 158:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     if (oldval != u)
 159:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****         ; /* smp_mb(); - Memory barriers might need specific implementation */
 160:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
 161:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     return oldval;
 162:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** }
 163:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #define arch_atomic_fetch_add_unless         arch_atomic_fetch_add_unless
 164:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
 165:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #define ATOMIC_OPS(op, c_op, asm_op)                    \
 166:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     ATOMIC_OP(op, c_op, asm_op)                     \
 167:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     ATOMIC_OP_RETURN(op, c_op, asm_op)                  \
 168:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     ATOMIC_FETCH_OP(op, c_op, asm_op)
 169:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
 170:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** ATOMIC_OPS(add, +=, add)
  56              		.loc 4 170 1 view .LVU9
  57              	.LBB78:
  58              		.loc 4 170 1 view .LVU10
  59              		.loc 4 170 1 view .LVU11
  60              		.loc 4 170 1 view .LVU12
  61              		.syntax unified
  62              	@ 170 "/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h" 1
  63              		@ atomic_add
  64 0002 50E8003F 	1: ldrex   r3, [r0]
  65 0006 03F10103 	   add r3, r3, #1
ARM GAS  /tmp/ccapU81z.s 			page 31


  66 000a 40E80032 	   strex   r2, r3, [r0]
  67 000e 92F0000F 	   teq r2, #0
  68 0012 F6D1     	   bne 1b
  69              	@ 0 "" 2
  70              	.LVL2:
  71              		.loc 4 170 1 is_stmt 0 view .LVU13
  72              		.thumb
  73              		.syntax unified
  74              	.LBE78:
  75              	.LBE77:
  76              	.LBE76:
  77              	.LBE75:
  78              	.LBE74:
  35:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** }
  79              		.loc 1 35 1 view .LVU14
  80 0014 7047     		bx	lr
  81              		.cfi_endproc
  82              	.LFE1035:
  84              		.section	.text.new_inode,"ax",%progbits
  85              		.align	1
  86              		.global	new_inode
  87              		.syntax unified
  88              		.thumb
  89              		.thumb_func
  91              	new_inode:
  92              	.LVL3:
  93              	.LFB1033:
  15:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****     struct inode *inode = (struct inode *)kmalloc(sizeof(struct inode), GFP_KERNEL);
  94              		.loc 1 15 48 is_stmt 1 view -0
  95              		.cfi_startproc
  96              		@ args = 0, pretend = 0, frame = 0
  97              		@ frame_needed = 0, uses_anonymous_args = 0
  15:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****     struct inode *inode = (struct inode *)kmalloc(sizeof(struct inode), GFP_KERNEL);
  98              		.loc 1 15 48 is_stmt 0 view .LVU16
  99 0000 38B5     		push	{r3, r4, r5, lr}
 100              	.LCFI0:
 101              		.cfi_def_cfa_offset 16
 102              		.cfi_offset 3, -16
 103              		.cfi_offset 4, -12
 104              		.cfi_offset 5, -8
 105              		.cfi_offset 14, -4
 106 0002 0546     		mov	r5, r0
  16:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****     if (inode == NULL) return NULL;
 107              		.loc 1 16 5 is_stmt 1 view .LVU17
 108              	.LVL4:
 109              	.LBB79:
 110              	.LBI79:
 111              		.file 5 "/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h"
   1:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* SPDX-License-Identifier: GPL-2.0 */
   2:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /*
   3:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Written by Mark Hemment, 1996 (markhe@nextd.demon.co.uk).
   4:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
   5:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * (C) SGI 2006, Christoph Lameter
   6:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * 	Cleaned up and restructured to ease the addition of alternative
   7:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * 	implementations of SLAB allocators.
   8:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * (C) Linux Foundation 2008-2013
   9:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *      Unified interface for all slab allocators
ARM GAS  /tmp/ccapU81z.s 			page 32


  10:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
  11:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
  12:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifndef _LINUX_SLAB_H
  13:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define	_LINUX_SLAB_H
  14:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
  15:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #include <linux/cache.h>
  16:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #include <linux/overflow.h>
  17:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #include <linux/types.h>
  18:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #include <linux/raid/pq.h>
  19:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #include <linux/gfp_types.h>
  20:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #include <linux/numa.h>
  21:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #include <linux/reciprocal_div.h>
  22:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #include <linux/spinlock.h>
  23:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
  24:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** enum _slab_flag_bits {
  25:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_CONSISTENCY_CHECKS,
  26:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_RED_ZONE,
  27:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_POISON,
  28:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_KMALLOC,
  29:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_HWCACHE_ALIGN,
  30:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_CACHE_DMA,
  31:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_CACHE_DMA32,
  32:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_STORE_USER,
  33:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_PANIC,
  34:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_TYPESAFE_BY_RCU,
  35:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_TRACE,
  36:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_DEBUG_OBJECTS
  37:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_DEBUG_OBJECTS,
  38:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
  39:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_NOLEAKTRACE,
  40:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_NO_MERGE,
  41:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_FAILSLAB
  42:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_FAILSLAB,
  43:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
  44:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_MEMCG
  45:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_ACCOUNT,
  46:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
  47:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_KASAN_GENERIC
  48:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_KASAN,
  49:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
  50:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_NO_USER_FLAGS,
  51:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_KFENCE
  52:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_SKIP_KFENCE,
  53:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
  54:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifndef CONFIG_SLUB_TINY
  55:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_RECLAIM_ACCOUNT,
  56:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
  57:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_OBJECT_POISON,
  58:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_CMPXCHG_DOUBLE,
  59:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_SLAB_OBJ_EXT
  60:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_NO_OBJ_EXT,
  61:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
  62:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_FLAGS_LAST_BIT
  63:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** };
  64:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
  65:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
  66:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
ARM GAS  /tmp/ccapU81z.s 			page 33


  67:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define __SLAB_FLAG_BIT(nr)	((slab_flags_t __force)(1U << (nr)))
  68:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define __SLAB_FLAG_UNUSED	((slab_flags_t __force)(0U))
  69:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
  70:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /*
  71:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Flags to pass to kmem_cache_create().
  72:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * The ones marked DEBUG need CONFIG_SLUB_DEBUG enabled, otherwise are no-op
  73:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
  74:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* DEBUG: Perform (expensive) checks on alloc/free */
  75:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_CONSISTENCY_CHECKS	__SLAB_FLAG_BIT(_SLAB_CONSISTENCY_CHECKS)
  76:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* DEBUG: Red zone objs in a cache */
  77:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_RED_ZONE		__SLAB_FLAG_BIT(_SLAB_RED_ZONE)
  78:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* DEBUG: Poison objects */
  79:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_POISON		__SLAB_FLAG_BIT(_SLAB_POISON)
  80:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* Indicate a kmalloc slab */
  81:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_KMALLOC		__SLAB_FLAG_BIT(_SLAB_KMALLOC)
  82:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /**
  83:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * define SLAB_HWCACHE_ALIGN - Align objects on cache line boundaries.
  84:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
  85:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Sufficiently large objects are aligned on cache line boundary. For object
  86:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * size smaller than a half of cache line size, the alignment is on the half of
  87:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * cache line size. In general, if object size is smaller than 1/2^n of cache
  88:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * line size, the alignment is adjusted to 1/2^n.
  89:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
  90:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * If explicit alignment is also requested by the respective
  91:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * &struct kmem_cache_args field, the greater of both is alignments is applied.
  92:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
  93:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_HWCACHE_ALIGN	__SLAB_FLAG_BIT(_SLAB_HWCACHE_ALIGN)
  94:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* Use GFP_DMA memory */
  95:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_CACHE_DMA		__SLAB_FLAG_BIT(_SLAB_CACHE_DMA)
  96:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* Use GFP_DMA32 memory */
  97:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_CACHE_DMA32	__SLAB_FLAG_BIT(_SLAB_CACHE_DMA32)
  98:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* DEBUG: Store the last owner for bug hunting */
  99:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_STORE_USER		__SLAB_FLAG_BIT(_SLAB_STORE_USER)
 100:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* Panic if kmem_cache_create() fails */
 101:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_PANIC		__SLAB_FLAG_BIT(_SLAB_PANIC)
 102:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /**
 103:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * define SLAB_TYPESAFE_BY_RCU - **WARNING** READ THIS!
 104:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 105:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * This delays freeing the SLAB page by a grace period, it does _NOT_
 106:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * delay object freeing. This means that if you do kmem_cache_free()
 107:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * that memory location is free to be reused at any time. Thus it may
 108:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * be possible to see another object there in the same RCU grace period.
 109:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 110:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * This feature only ensures the memory location backing the object
 111:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * stays valid, the trick to using this is relying on an independent
 112:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * object validation pass. Something like:
 113:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 114:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * ::
 115:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 116:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *  begin:
 117:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *   rcu_read_lock();
 118:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *   obj = lockless_lookup(key);
 119:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *   if (obj) {
 120:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *     if (!try_get_ref(obj)) // might fail for free objects
 121:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *       rcu_read_unlock();
 122:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *       goto begin;
 123:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
ARM GAS  /tmp/ccapU81z.s 			page 34


 124:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *     if (obj->key != key) { // not the object we expected
 125:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *       put_ref(obj);
 126:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *       rcu_read_unlock();
 127:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *       goto begin;
 128:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *     }
 129:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *   }
 130:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *  rcu_read_unlock();
 131:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 132:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * This is useful if we need to approach a kernel structure obliquely,
 133:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * from its address obtained without the usual locking. We can lock
 134:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * the structure to stabilize it and check it's still at the given address,
 135:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * only if we can be sure that the memory has not been meanwhile reused
 136:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * for some other kind of object (which our subsystem's lock might corrupt).
 137:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 138:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * rcu_read_lock before reading the address, then rcu_read_unlock after
 139:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * taking the spinlock within the structure expected at that address.
 140:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 141:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Note that it is not possible to acquire a lock within a structure
 142:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * allocated with SLAB_TYPESAFE_BY_RCU without first acquiring a reference
 143:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * as described above.  The reason is that SLAB_TYPESAFE_BY_RCU pages
 144:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * are not zeroed before being given to the slab, which means that any
 145:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * locks must be initialized after each and every kmem_struct_alloc().
 146:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Alternatively, make the ctor passed to kmem_cache_create() initialize
 147:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * the locks at page-allocation time, as is done in __i915_request_ctor(),
 148:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * sighand_ctor(), and anon_vma_ctor().  Such a ctor permits readers
 149:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * to safely acquire those ctor-initialized locks under rcu_read_lock()
 150:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * protection.
 151:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 152:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Note that SLAB_TYPESAFE_BY_RCU was originally named SLAB_DESTROY_BY_RCU.
 153:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
 154:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_TYPESAFE_BY_RCU	__SLAB_FLAG_BIT(_SLAB_TYPESAFE_BY_RCU)
 155:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* Trace allocations and frees */
 156:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_TRACE		__SLAB_FLAG_BIT(_SLAB_TRACE)
 157:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 158:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* Flag to prevent checks on free */
 159:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_DEBUG_OBJECTS
 160:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** # define SLAB_DEBUG_OBJECTS	__SLAB_FLAG_BIT(_SLAB_DEBUG_OBJECTS)
 161:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #else
 162:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** # define SLAB_DEBUG_OBJECTS	__SLAB_FLAG_UNUSED
 163:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
 164:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 165:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* Avoid kmemleak tracing */
 166:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_NOLEAKTRACE	__SLAB_FLAG_BIT(_SLAB_NOLEAKTRACE)
 167:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 168:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /*
 169:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Prevent merging with compatible kmem caches. This flag should be used
 170:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * cautiously. Valid use cases:
 171:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 172:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * - caches created for self-tests (e.g. kunit)
 173:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * - general caches created and used by a subsystem, only when a
 174:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *   (subsystem-specific) debug option is enabled
 175:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * - performance critical caches, should be very rare and consulted with slab
 176:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *   maintainers, and not used together with CONFIG_SLUB_TINY
 177:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
 178:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_NO_MERGE		__SLAB_FLAG_BIT(_SLAB_NO_MERGE)
 179:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 180:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* Fault injection mark */
ARM GAS  /tmp/ccapU81z.s 			page 35


 181:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_FAILSLAB
 182:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** # define SLAB_FAILSLAB		__SLAB_FLAG_BIT(_SLAB_FAILSLAB)
 183:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #else
 184:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** # define SLAB_FAILSLAB		__SLAB_FLAG_UNUSED
 185:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
 186:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /**
 187:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * define SLAB_ACCOUNT - Account allocations to memcg.
 188:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 189:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * All object allocations from this cache will be memcg accounted, regardless of
 190:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * __GFP_ACCOUNT being or not being passed to individual allocations.
 191:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
 192:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_MEMCG
 193:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** # define SLAB_ACCOUNT		__SLAB_FLAG_BIT(_SLAB_ACCOUNT)
 194:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #else
 195:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** # define SLAB_ACCOUNT		__SLAB_FLAG_UNUSED
 196:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
 197:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 198:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_KASAN_GENERIC
 199:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_KASAN		__SLAB_FLAG_BIT(_SLAB_KASAN)
 200:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #else
 201:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_KASAN		__SLAB_FLAG_UNUSED
 202:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
 203:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 204:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /*
 205:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Ignore user specified debugging flags.
 206:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Intended for caches created for self-tests so they have only flags
 207:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * specified in the code and other flags are ignored.
 208:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
 209:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_NO_USER_FLAGS	__SLAB_FLAG_BIT(_SLAB_NO_USER_FLAGS)
 210:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 211:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_KFENCE
 212:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_SKIP_KFENCE	__SLAB_FLAG_BIT(_SLAB_SKIP_KFENCE)
 213:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #else
 214:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_SKIP_KFENCE	__SLAB_FLAG_UNUSED
 215:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
 216:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 217:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* The following flags affect the page allocator grouping pages by mobility */
 218:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /**
 219:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * define SLAB_RECLAIM_ACCOUNT - Objects are reclaimable.
 220:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 221:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Use this flag for caches that have an associated shrinker. As a result, slab
 222:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * pages are allocated with __GFP_RECLAIMABLE, which affects grouping pages by
 223:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * mobility, and are accounted in SReclaimable counter in /proc/meminfo
 224:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
 225:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifndef CONFIG_SLUB_TINY
 226:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_RECLAIM_ACCOUNT	__SLAB_FLAG_BIT(_SLAB_RECLAIM_ACCOUNT)
 227:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #else
 228:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_RECLAIM_ACCOUNT	__SLAB_FLAG_UNUSED
 229:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
 230:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_TEMPORARY		SLAB_RECLAIM_ACCOUNT	/* Objects are short-lived */
 231:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 232:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* Slab created using create_boot_cache */
 233:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_SLAB_OBJ_EXT
 234:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_NO_OBJ_EXT		__SLAB_FLAG_BIT(_SLAB_NO_OBJ_EXT)
 235:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #else
 236:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_NO_OBJ_EXT		__SLAB_FLAG_UNUSED
 237:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
ARM GAS  /tmp/ccapU81z.s 			page 36


 238:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 239:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /*
 240:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * freeptr_t represents a SLUB freelist pointer, which might be encoded
 241:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * and not dereferenceable if CONFIG_SLAB_FREELIST_HARDENED is enabled.
 242:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
 243:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** typedef struct { unsigned long v; } freeptr_t;
 244:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 245:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /*
 246:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * ZERO_SIZE_PTR will be returned for zero sized kmalloc requests.
 247:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 248:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Dereferencing ZERO_SIZE_PTR will lead to a distinct access fault.
 249:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 250:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * ZERO_SIZE_PTR can be passed to kfree though in the same way that NULL can.
 251:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Both make kfree a no-op.
 252:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
 253:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define ZERO_SIZE_PTR ((void *)16)
 254:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 255:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define ZERO_OR_NULL_PTR(x) ((unsigned long)(x) <= \
 256:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 				(unsigned long)ZERO_SIZE_PTR)
 257:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 258:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 259:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 260:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 261:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 262:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_SLUB_CPU_PARTIAL
 263:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define slub_percpu_partial(c)			((c)->partial)
 264:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 265:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define slub_set_percpu_partial(c, p)		\
 266:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** ({						\
 267:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	slub_percpu_partial(c) = (p)->next;	\
 268:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** })
 269:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 270:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define slub_percpu_partial_read_once(c)	READ_ONCE(slub_percpu_partial(c))
 271:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #else
 272:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define slub_percpu_partial(c)			NULL
 273:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 274:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define slub_set_percpu_partial(c, p)
 275:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 276:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define slub_percpu_partial_read_once(c)	NULL
 277:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 278:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 279:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif // CONFIG_SLUB_CPU_PARTIAL
 280:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 281:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /*
 282:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	* Word size structure that can be atomically updated or read and that
 283:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	* contains both the order and the number of objects that a slab of the
 284:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	* given order would contain.
 285:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	*/				
 286:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** struct kmem_cache_order_objects {
 287:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	unsigned int x;
 288:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** };
 289:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 290:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** struct kmem_cache_node {
 291:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	spinlock_t list_lock;
 292:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	unsigned long nr_partial;
 293:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	struct list_head partial;
 294:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_SLUB_DEBUG
ARM GAS  /tmp/ccapU81z.s 			page 37


 295:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	atomic_long_t nr_slabs;
 296:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	atomic_long_t total_objects;
 297:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	struct list_head full;
 298:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
 299:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** };
 300:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 301:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** struct kmem_cache {
 302:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#ifndef CONFIG_SLUB_TINY
 303:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	//	struct kmem_cache_cpu __percpu *cpu_slab;
 304:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#endif
 305:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		/* Used for retrieving partial slabs, etc. */
 306:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		slab_flags_t flags;
 307:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned long min_partial;
 308:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int size;		/* Object size including metadata */
 309:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int object_size;	/* Object size without metadata */
 310:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		struct reciprocal_value reciprocal_size;
 311:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int offset;		/* Free pointer offset */
 312:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#ifdef CONFIG_SLUB_CPU_PARTIAL
 313:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		/* Number of per cpu partial objects to keep around */
 314:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int cpu_partial;
 315:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		/* Number of per cpu partial slabs to keep around */
 316:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int cpu_partial_slabs;
 317:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#endif
 318:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		struct kmem_cache_order_objects oo;
 319:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	
 320:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		/* Allocation and freeing of slabs */
 321:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		struct kmem_cache_order_objects min;
 322:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		gfp_t allocflags;		/* gfp flags to use on each alloc */
 323:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		int refcount;			/* Refcount for slab cache destroy */
 324:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		void (*ctor)(void *object);	/* Object constructor */
 325:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int inuse;		/* Offset to metadata */
 326:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int align;		/* Alignment */
 327:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int red_left_pad;	/* Left redzone padding size */
 328:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		const char *name;		/* Name (only for display!) */
 329:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		struct list_head list;		/* List of slab caches */
 330:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#ifdef CONFIG_SYSFS
 331:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		struct kobject kobj;		/* For sysfs */
 332:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#endif
 333:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#ifdef CONFIG_SLAB_FREELIST_HARDENED
 334:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned long random;
 335:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#endif
 336:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	
 337:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#ifdef CONFIG_NUMA
 338:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		/*
 339:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 			* Defragmentation by allocating from a remote node.
 340:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 			*/
 341:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int remote_node_defrag_ratio;
 342:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#endif
 343:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	
 344:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#ifdef CONFIG_SLAB_FREELIST_RANDOM
 345:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int *random_seq;
 346:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#endif
 347:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	
 348:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#ifdef CONFIG_KASAN_GENERIC
 349:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		struct kasan_cache kasan_info;
 350:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#endif
 351:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	
ARM GAS  /tmp/ccapU81z.s 			page 38


 352:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#ifdef CONFIG_HARDENED_USERCOPY
 353:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int useroffset;	/* Usercopy region offset */
 354:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int usersize;		/* Usercopy region size */
 355:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#endif
 356:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	
 357:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		struct kmem_cache_node *node[MAX_NUMNODES];
 358:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	};
 359:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 					
 360:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 361:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 362:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 363:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 364:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define KMALLOC_WAIT 1
 365:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 366:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 367:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** extern void* __smalloc__(u32 size, gfp_t flags);
 368:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** extern void  __sfree__(void* addr);
 369:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 370:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 371:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** static void inline *vmalloc(unsigned long size){
 372:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	return __smalloc__(size,GFP_TRANSHUGE_LIGHT);
 373:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** }
 374:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 375:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** static void inline vfree(void *addr){
 376:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	__sfree__(addr);
 377:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** }
 378:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 379:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** static void inline *kmalloc(size_t size, gfp_t flags){
 112              		.loc 5 379 21 view .LVU18
 113              	.LBB80:
 380:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	return __smalloc__((u32)size,flags);
 114              		.loc 5 380 2 view .LVU19
 115              		.loc 5 380 9 is_stmt 0 view .LVU20
 116 0004 4FF44C61 		mov	r1, #3264
 117 0008 8820     		movs	r0, #136
 118              	.LVL5:
 119              		.loc 5 380 9 view .LVU21
 120 000a FFF7FEFF 		bl	__smalloc__
 121              	.LVL6:
 122              		.loc 5 380 9 view .LVU22
 123              	.LBE80:
 124              	.LBE79:
  17:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** 	memset(inode,0,sizeof(struct inode));
 125              		.loc 1 17 5 is_stmt 1 view .LVU23
  17:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** 	memset(inode,0,sizeof(struct inode));
 126              		.loc 1 17 8 is_stmt 0 view .LVU24
 127 000e 0446     		mov	r4, r0
 128 0010 58B1     		cbz	r0, .L2
  18:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****     inode->i_mode    = S_IFCHR | 0777;
 129              		.loc 1 18 2 is_stmt 1 view .LVU25
 130 0012 8822     		movs	r2, #136
 131 0014 0021     		movs	r1, #0
 132 0016 FFF7FEFF 		bl	memset
 133              	.LVL7:
  19:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****     time64_t now        = jiffies;
 134              		.loc 1 19 5 view .LVU26
  19:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****     time64_t now        = jiffies;
ARM GAS  /tmp/ccapU81z.s 			page 39


 135              		.loc 1 19 22 is_stmt 0 view .LVU27
 136 001a 42F2FF13 		movw	r3, #8703
 137 001e 2380     		strh	r3, [r4]	@ movhi
  20:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****     inode->i_sb       = sb;
 138              		.loc 1 20 5 is_stmt 1 view .LVU28
  20:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****     inode->i_sb       = sb;
 139              		.loc 1 20 27 is_stmt 0 view .LVU29
 140 0020 FFF7FEFF 		bl	ktime_get
 141              	.LVL8:
  21:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** 	atomic_set(&inode->i_count,1);
 142              		.loc 1 21 5 is_stmt 1 view .LVU30
  21:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** 	atomic_set(&inode->i_count,1);
 143              		.loc 1 21 23 is_stmt 0 view .LVU31
 144 0024 6561     		str	r5, [r4, #20]
  22:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****     return inode;
 145              		.loc 1 22 2 is_stmt 1 view .LVU32
 146              	.LVL9:
 147              	.LBB81:
 148              	.LBI81:
  65:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 149              		.loc 2 65 1 view .LVU33
  67:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	raw_atomic_set(v, i);
 150              		.loc 2 67 2 view .LVU34
  68:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 151              		.loc 2 68 2 view .LVU35
 152              	.LBB82:
 153              	.LBI82:
 507:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 154              		.loc 3 507 1 view .LVU36
 155              	.LBB83:
 509:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 156              		.loc 3 509 2 view .LVU37
 509:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 157              		.loc 3 509 2 view .LVU38
 158              	.LBB84:
 509:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 159              		.loc 3 509 2 view .LVU39
 509:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 160              		.loc 3 509 2 view .LVU40
 161              	.LBE84:
 509:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 162              		.loc 3 509 2 discriminator 2 view .LVU41
 509:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 163              		.loc 3 509 2 discriminator 2 view .LVU42
 509:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 164              		.loc 3 509 2 discriminator 2 view .LVU43
 165 0026 0123     		movs	r3, #1
 166 0028 A367     		str	r3, [r4, #120]
 509:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 167              		.loc 3 509 2 discriminator 2 view .LVU44
 509:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 168              		.loc 3 509 2 discriminator 2 view .LVU45
 169              	.LVL10:
 509:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 170              		.loc 3 509 2 is_stmt 0 discriminator 2 view .LVU46
 171              	.LBE83:
 172              	.LBE82:
ARM GAS  /tmp/ccapU81z.s 			page 40


 173              	.LBE81:
  23:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** }
 174              		.loc 1 23 5 is_stmt 1 view .LVU47
 175              	.L2:
  24:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** EXPORT_SYMBOL(new_inode);
 176              		.loc 1 24 1 is_stmt 0 view .LVU48
 177 002a 2046     		mov	r0, r4
 178 002c 38BD     		pop	{r3, r4, r5, pc}
  24:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** EXPORT_SYMBOL(new_inode);
 179              		.loc 1 24 1 view .LVU49
 180              		.cfi_endproc
 181              	.LFE1033:
 183              		.section	.text.destroy_inode,"ax",%progbits
 184              		.align	1
 185              		.global	destroy_inode
 186              		.syntax unified
 187              		.thumb
 188              		.thumb_func
 190              	destroy_inode:
 191              	.LVL11:
 192              	.LFB1034:
  27:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** 	if(node != NULL)
 193              		.loc 1 27 39 is_stmt 1 view -0
 194              		.cfi_startproc
 195              		@ args = 0, pretend = 0, frame = 0
 196              		@ frame_needed = 0, uses_anonymous_args = 0
  28:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** 	kfree(node);
 197              		.loc 1 28 2 view .LVU51
  28:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** 	kfree(node);
 198              		.loc 1 28 4 is_stmt 0 view .LVU52
 199 0000 18B1     		cbz	r0, .L8
  27:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** 	if(node != NULL)
 200              		.loc 1 27 39 view .LVU53
 201 0002 08B5     		push	{r3, lr}
 202              	.LCFI1:
 203              		.cfi_def_cfa_offset 8
 204              		.cfi_offset 3, -8
 205              		.cfi_offset 14, -4
  29:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** }
 206              		.loc 1 29 2 is_stmt 1 view .LVU54
 207              	.LVL12:
 208              	.LBB85:
 209              	.LBI85:
 381:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** }
 382:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 383:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** static void inline kfree(const void *ptr){
 210              		.loc 5 383 20 view .LVU55
 211              	.LBB86:
 384:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	__sfree__((void*)ptr);
 212              		.loc 5 384 2 view .LVU56
 213 0004 FFF7FEFF 		bl	__sfree__
 214              	.LVL13:
 215              		.loc 5 384 2 is_stmt 0 view .LVU57
 216              	.LBE86:
 217              	.LBE85:
  30:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** EXPORT_SYMBOL(destroy_inode);
 218              		.loc 1 30 1 view .LVU58
ARM GAS  /tmp/ccapU81z.s 			page 41


 219 0008 08BD     		pop	{r3, pc}
 220              	.LVL14:
 221              	.L8:
 222              	.LCFI2:
 223              		.cfi_def_cfa_offset 0
 224              		.cfi_restore 3
 225              		.cfi_restore 14
  30:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** EXPORT_SYMBOL(destroy_inode);
 226              		.loc 1 30 1 view .LVU59
 227 000a 7047     		bx	lr
 228              		.cfi_endproc
 229              	.LFE1034:
 231              		.section	.rodata.inode_put.str1.4,"aMS",%progbits,1
 232              		.align	2
 233              	.LC0:
 234 0000 72656D6F 		.ascii	"remove inode\012\000"
 234      76652069 
 234      6E6F6465 
 234      0A00
 235              		.section	.text.inode_put,"ax",%progbits
 236              		.align	1
 237              		.global	inode_put
 238              		.syntax unified
 239              		.thumb
 240              		.thumb_func
 242              	inode_put:
 243              	.LVL15:
 244              	.LFB1036:
  36:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** EXPORT_SYMBOL(inode_get);
  37:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** 
  38:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** /**
  39:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****  * inode_put - Decrease inode reference count and free if unused
  40:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****  * @inode: pointer to the inode to release
  41:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****  *
  42:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****  * This function decreases the reference count of the given inode.
  43:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****  * If the count reaches zero, it destroys the inode structure,
  44:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****  * freeing the associated memory.
  45:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****  *
  46:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****  * Typically used when a dentry or file is released and the inode
  47:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****  * is no longer referenced elsewhere.
  48:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****  *
  49:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****  * 
  50:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****  * inode_put -  inode 
  51:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****  * @inode:  inode 
  52:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****  *
  53:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****  *  inode  0 
  54:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****  *  destroy_inode()  inode 
  55:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****  *
  56:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****  *  dentry  inode 
  57:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****  * 
  58:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****  * inodevfs
  59:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****  */
  60:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** void inode_put(struct inode *inode){
 245              		.loc 1 60 36 is_stmt 1 view -0
 246              		.cfi_startproc
 247              		@ args = 0, pretend = 0, frame = 0
 248              		@ frame_needed = 0, uses_anonymous_args = 0
ARM GAS  /tmp/ccapU81z.s 			page 42


  61:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****     if(inode!= NULL)
 249              		.loc 1 61 5 view .LVU61
 250              		.loc 1 61 7 is_stmt 0 view .LVU62
 251 0000 C0B1     		cbz	r0, .L15
  60:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****     if(inode!= NULL)
 252              		.loc 1 60 36 view .LVU63
 253 0002 10B5     		push	{r4, lr}
 254              	.LCFI3:
 255              		.cfi_def_cfa_offset 8
 256              		.cfi_offset 4, -8
 257              		.cfi_offset 14, -4
 258 0004 0446     		mov	r4, r0
  62:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****     if (atomic_dec_and_test(&inode->i_count) || inode->i_count.counter < 0) {  
 259              		.loc 1 62 5 is_stmt 1 view .LVU64
 260              		.loc 1 62 9 is_stmt 0 view .LVU65
 261 0006 00F17803 		add	r3, r0, #120
 262              	.LBB87:
 263              	.LBI87:
 437:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 438:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 439:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 440:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_inc_return() - atomic increment with full ordering
 441:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 442:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 443:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + 1) with full ordering.
 444:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 445:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_inc_return() there.
 446:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 447:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 448:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 449:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 450:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_inc_return(atomic_t *v)
 451:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 452:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
 453:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 454:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_inc_return(v);
 455:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 456:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 457:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 458:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_inc_return_acquire() - atomic increment with acquire ordering
 459:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 460:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 461:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + 1) with acquire ordering.
 462:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 463:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_inc_return_acquire() there.
 464:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 465:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 466:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 467:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 468:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_inc_return_acquire(atomic_t *v)
 469:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 470:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 471:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_inc_return_acquire(v);
 472:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 473:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 474:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 475:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_inc_return_release() - atomic increment with release ordering
ARM GAS  /tmp/ccapU81z.s 			page 43


 476:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 477:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 478:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + 1) with release ordering.
 479:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 480:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_inc_return_release() there.
 481:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 482:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 483:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 484:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 485:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_inc_return_release(atomic_t *v)
 486:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 487:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
 488:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 489:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_inc_return_release(v);
 490:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 491:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 492:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 493:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_inc_return_relaxed() - atomic increment with relaxed ordering
 494:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 495:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 496:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + 1) with relaxed ordering.
 497:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 498:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_inc_return_relaxed() there.
 499:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 500:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 501:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 502:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 503:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_inc_return_relaxed(atomic_t *v)
 504:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 505:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 506:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_inc_return_relaxed(v);
 507:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 508:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 509:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 510:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_inc() - atomic increment with full ordering
 511:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 512:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 513:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + 1) with full ordering.
 514:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 515:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_inc() there.
 516:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 517:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 518:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 519:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 520:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_inc(atomic_t *v)
 521:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 522:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
 523:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 524:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_inc(v);
 525:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 526:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 527:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 528:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_inc_acquire() - atomic increment with acquire ordering
 529:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 530:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 531:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + 1) with acquire ordering.
 532:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
ARM GAS  /tmp/ccapU81z.s 			page 44


 533:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_inc_acquire() there.
 534:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 535:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 536:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 537:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 538:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_inc_acquire(atomic_t *v)
 539:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 540:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 541:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_inc_acquire(v);
 542:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 543:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 544:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 545:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_inc_release() - atomic increment with release ordering
 546:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 547:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 548:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + 1) with release ordering.
 549:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 550:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_inc_release() there.
 551:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 552:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 553:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 554:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 555:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_inc_release(atomic_t *v)
 556:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 557:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
 558:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 559:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_inc_release(v);
 560:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 561:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 562:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 563:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_inc_relaxed() - atomic increment with relaxed ordering
 564:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 565:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 566:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + 1) with relaxed ordering.
 567:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 568:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_inc_relaxed() there.
 569:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 570:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 571:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 572:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 573:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_inc_relaxed(atomic_t *v)
 574:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 575:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 576:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_inc_relaxed(v);
 577:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 578:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 579:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 580:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_dec() - atomic decrement with relaxed ordering
 581:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 582:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 583:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - 1) with relaxed ordering.
 584:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 585:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_dec() there.
 586:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 587:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: Nothing.
 588:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 589:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline void
ARM GAS  /tmp/ccapU81z.s 			page 45


 590:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_dec(atomic_t *v)
 591:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 592:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 593:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	raw_atomic_dec(v);
 594:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 595:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 596:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 597:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_dec_return() - atomic decrement with full ordering
 598:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 599:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 600:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - 1) with full ordering.
 601:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 602:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_dec_return() there.
 603:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 604:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 605:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 606:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 607:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_dec_return(atomic_t *v)
 608:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 609:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
 610:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 611:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_dec_return(v);
 612:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 613:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 614:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 615:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_dec_return_acquire() - atomic decrement with acquire ordering
 616:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 617:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 618:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - 1) with acquire ordering.
 619:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 620:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_dec_return_acquire() there.
 621:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 622:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 623:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 624:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 625:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_dec_return_acquire(atomic_t *v)
 626:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 627:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 628:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_dec_return_acquire(v);
 629:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 630:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 631:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 632:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_dec_return_release() - atomic decrement with release ordering
 633:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 634:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 635:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - 1) with release ordering.
 636:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 637:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_dec_return_release() there.
 638:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 639:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 640:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 641:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 642:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_dec_return_release(atomic_t *v)
 643:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 644:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
 645:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 646:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_dec_return_release(v);
ARM GAS  /tmp/ccapU81z.s 			page 46


 647:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 648:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 649:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 650:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_dec_return_relaxed() - atomic decrement with relaxed ordering
 651:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 652:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 653:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - 1) with relaxed ordering.
 654:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 655:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_dec_return_relaxed() there.
 656:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 657:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 658:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 659:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 660:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_dec_return_relaxed(atomic_t *v)
 661:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 662:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 663:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_dec_return_relaxed(v);
 664:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 665:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 666:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 667:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_dec() - atomic decrement with full ordering
 668:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 669:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 670:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - 1) with full ordering.
 671:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 672:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_dec() there.
 673:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 674:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 675:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 676:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 677:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_dec(atomic_t *v)
 678:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 679:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
 680:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 681:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_dec(v);
 682:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 683:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 684:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 685:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_dec_acquire() - atomic decrement with acquire ordering
 686:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 687:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 688:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - 1) with acquire ordering.
 689:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 690:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_dec_acquire() there.
 691:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 692:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 693:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 694:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 695:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_dec_acquire(atomic_t *v)
 696:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 697:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 698:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_dec_acquire(v);
 699:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 700:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 701:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 702:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_dec_release() - atomic decrement with release ordering
 703:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
ARM GAS  /tmp/ccapU81z.s 			page 47


 704:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 705:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - 1) with release ordering.
 706:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 707:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_dec_release() there.
 708:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 709:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 710:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 711:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 712:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_dec_release(atomic_t *v)
 713:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 714:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
 715:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 716:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_dec_release(v);
 717:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 718:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 719:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 720:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_dec_relaxed() - atomic decrement with relaxed ordering
 721:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 722:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 723:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - 1) with relaxed ordering.
 724:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 725:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_dec_relaxed() there.
 726:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 727:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 728:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 729:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 730:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_dec_relaxed(atomic_t *v)
 731:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 732:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 733:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_dec_relaxed(v);
 734:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 735:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 736:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 737:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_and() - atomic bitwise AND with relaxed ordering
 738:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 739:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 740:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 741:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v & @i) with relaxed ordering.
 742:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 743:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_and() there.
 744:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 745:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: Nothing.
 746:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 747:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline void
 748:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_and(int i, atomic_t *v)
 749:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 750:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 751:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	raw_atomic_and(i, v);
 752:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 753:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 754:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 755:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_and() - atomic bitwise AND with full ordering
 756:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 757:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 758:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 759:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v & @i) with full ordering.
 760:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
ARM GAS  /tmp/ccapU81z.s 			page 48


 761:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_and() there.
 762:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 763:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 764:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 765:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 766:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_and(int i, atomic_t *v)
 767:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 768:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
 769:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 770:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_and(i, v);
 771:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 772:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 773:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 774:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_and_acquire() - atomic bitwise AND with acquire ordering
 775:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 776:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 777:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 778:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v & @i) with acquire ordering.
 779:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 780:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_and_acquire() there.
 781:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 782:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 783:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 784:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 785:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_and_acquire(int i, atomic_t *v)
 786:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 787:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 788:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_and_acquire(i, v);
 789:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 790:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 791:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 792:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_and_release() - atomic bitwise AND with release ordering
 793:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 794:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 795:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 796:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v & @i) with release ordering.
 797:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 798:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_and_release() there.
 799:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 800:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 801:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 802:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 803:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_and_release(int i, atomic_t *v)
 804:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 805:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
 806:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 807:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_and_release(i, v);
 808:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 809:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 810:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 811:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_and_relaxed() - atomic bitwise AND with relaxed ordering
 812:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 813:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 814:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 815:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v & @i) with relaxed ordering.
 816:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 817:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_and_relaxed() there.
ARM GAS  /tmp/ccapU81z.s 			page 49


 818:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 819:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 820:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 821:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 822:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_and_relaxed(int i, atomic_t *v)
 823:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 824:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 825:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_and_relaxed(i, v);
 826:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 827:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 828:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 829:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_andnot() - atomic bitwise AND NOT with relaxed ordering
 830:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 831:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 832:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 833:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v & ~@i) with relaxed ordering.
 834:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 835:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_andnot() there.
 836:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 837:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: Nothing.
 838:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 839:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline void
 840:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_andnot(int i, atomic_t *v)
 841:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 842:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 843:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	raw_atomic_andnot(i, v);
 844:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 845:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 846:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 847:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_andnot() - atomic bitwise AND NOT with full ordering
 848:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 849:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 850:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 851:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v & ~@i) with full ordering.
 852:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 853:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_andnot() there.
 854:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 855:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 856:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 857:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 858:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_andnot(int i, atomic_t *v)
 859:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 860:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
 861:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 862:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_andnot(i, v);
 863:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 864:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 865:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 866:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_andnot_acquire() - atomic bitwise AND NOT with acquire ordering
 867:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 868:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 869:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 870:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v & ~@i) with acquire ordering.
 871:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 872:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_andnot_acquire() there.
 873:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 874:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
ARM GAS  /tmp/ccapU81z.s 			page 50


 875:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 876:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 877:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_andnot_acquire(int i, atomic_t *v)
 878:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 879:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 880:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_andnot_acquire(i, v);
 881:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 882:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 883:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 884:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_andnot_release() - atomic bitwise AND NOT with release ordering
 885:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 886:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 887:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 888:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v & ~@i) with release ordering.
 889:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 890:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_andnot_release() there.
 891:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 892:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 893:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 894:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 895:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_andnot_release(int i, atomic_t *v)
 896:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 897:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
 898:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 899:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_andnot_release(i, v);
 900:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 901:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 902:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 903:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_andnot_relaxed() - atomic bitwise AND NOT with relaxed ordering
 904:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 905:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 906:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 907:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v & ~@i) with relaxed ordering.
 908:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 909:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_andnot_relaxed() there.
 910:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 911:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 912:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 913:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 914:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_andnot_relaxed(int i, atomic_t *v)
 915:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 916:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 917:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_andnot_relaxed(i, v);
 918:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 919:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 920:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 921:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_or() - atomic bitwise OR with relaxed ordering
 922:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 923:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 924:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 925:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v | @i) with relaxed ordering.
 926:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 927:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_or() there.
 928:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 929:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: Nothing.
 930:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 931:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline void
ARM GAS  /tmp/ccapU81z.s 			page 51


 932:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_or(int i, atomic_t *v)
 933:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 934:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 935:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	raw_atomic_or(i, v);
 936:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 937:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 938:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 939:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_or() - atomic bitwise OR with full ordering
 940:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 941:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 942:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 943:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v | @i) with full ordering.
 944:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 945:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_or() there.
 946:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 947:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 948:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 949:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 950:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_or(int i, atomic_t *v)
 951:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 952:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
 953:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 954:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_or(i, v);
 955:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 956:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 957:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 958:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_or_acquire() - atomic bitwise OR with acquire ordering
 959:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 960:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 961:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 962:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v | @i) with acquire ordering.
 963:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 964:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_or_acquire() there.
 965:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 966:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 967:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 968:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 969:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_or_acquire(int i, atomic_t *v)
 970:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 971:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 972:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_or_acquire(i, v);
 973:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 974:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 975:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 976:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_or_release() - atomic bitwise OR with release ordering
 977:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 978:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 979:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 980:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v | @i) with release ordering.
 981:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 982:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_or_release() there.
 983:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 984:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 985:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 986:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 987:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_or_release(int i, atomic_t *v)
 988:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
ARM GAS  /tmp/ccapU81z.s 			page 52


 989:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
 990:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 991:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_or_release(i, v);
 992:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 993:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 994:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 995:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_or_relaxed() - atomic bitwise OR with relaxed ordering
 996:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 997:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 998:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 999:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v | @i) with relaxed ordering.
1000:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1001:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_or_relaxed() there.
1002:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1003:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1004:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1005:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1006:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_or_relaxed(int i, atomic_t *v)
1007:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1008:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1009:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_or_relaxed(i, v);
1010:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1011:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1012:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1013:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_xor() - atomic bitwise XOR with relaxed ordering
1014:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
1015:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1016:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1017:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v ^ @i) with relaxed ordering.
1018:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1019:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_xor() there.
1020:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1021:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: Nothing.
1022:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1023:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline void
1024:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_xor(int i, atomic_t *v)
1025:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1026:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1027:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	raw_atomic_xor(i, v);
1028:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1029:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1030:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1031:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_xor() - atomic bitwise XOR with full ordering
1032:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
1033:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1034:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1035:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v ^ @i) with full ordering.
1036:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1037:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_xor() there.
1038:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1039:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1040:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1041:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1042:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_xor(int i, atomic_t *v)
1043:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1044:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
1045:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
ARM GAS  /tmp/ccapU81z.s 			page 53


1046:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_xor(i, v);
1047:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1048:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1049:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1050:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_xor_acquire() - atomic bitwise XOR with acquire ordering
1051:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
1052:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1053:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1054:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v ^ @i) with acquire ordering.
1055:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1056:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_xor_acquire() there.
1057:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1058:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1059:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1060:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1061:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_xor_acquire(int i, atomic_t *v)
1062:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1063:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1064:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_xor_acquire(i, v);
1065:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1066:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1067:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1068:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_xor_release() - atomic bitwise XOR with release ordering
1069:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
1070:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1071:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1072:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v ^ @i) with release ordering.
1073:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1074:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_xor_release() there.
1075:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1076:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1077:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1078:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1079:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_xor_release(int i, atomic_t *v)
1080:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1081:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
1082:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1083:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_xor_release(i, v);
1084:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1085:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1086:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1087:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_xor_relaxed() - atomic bitwise XOR with relaxed ordering
1088:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
1089:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1090:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1091:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v ^ @i) with relaxed ordering.
1092:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1093:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_xor_relaxed() there.
1094:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1095:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1096:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1097:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1098:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_xor_relaxed(int i, atomic_t *v)
1099:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1100:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1101:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_xor_relaxed(i, v);
1102:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
ARM GAS  /tmp/ccapU81z.s 			page 54


1103:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1104:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1105:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_xchg() - atomic exchange with full ordering
1106:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1107:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @new: int value to assign
1108:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1109:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to @new with full ordering.
1110:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1111:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_xchg() there.
1112:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1113:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1114:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1115:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1116:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_xchg(atomic_t *v, int new)
1117:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1118:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
1119:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1120:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_xchg(v, new);
1121:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1122:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1123:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1124:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_xchg_acquire() - atomic exchange with acquire ordering
1125:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1126:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @new: int value to assign
1127:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1128:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to @new with acquire ordering.
1129:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1130:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_xchg_acquire() there.
1131:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1132:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1133:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1134:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1135:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_xchg_acquire(atomic_t *v, int new)
1136:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1137:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1138:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_xchg_acquire(v, new);
1139:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1140:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1141:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1142:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_xchg_release() - atomic exchange with release ordering
1143:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1144:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @new: int value to assign
1145:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1146:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to @new with release ordering.
1147:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1148:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_xchg_release() there.
1149:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1150:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1151:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1152:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1153:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_xchg_release(atomic_t *v, int new)
1154:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1155:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
1156:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1157:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_xchg_release(v, new);
1158:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1159:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
ARM GAS  /tmp/ccapU81z.s 			page 55


1160:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1161:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_xchg_relaxed() - atomic exchange with relaxed ordering
1162:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1163:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @new: int value to assign
1164:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1165:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to @new with relaxed ordering.
1166:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1167:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_xchg_relaxed() there.
1168:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1169:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1170:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1171:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1172:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_xchg_relaxed(atomic_t *v, int new)
1173:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1174:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1175:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_xchg_relaxed(v, new);
1176:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1177:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1178:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1179:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_cmpxchg() - atomic compare and exchange with full ordering
1180:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1181:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @old: int value to compare with
1182:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @new: int value to assign
1183:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1184:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * If (@v == @old), atomically updates @v to @new with full ordering.
1185:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Otherwise, @v is not modified and relaxed ordering is provided.
1186:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1187:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_cmpxchg() there.
1188:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1189:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1190:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1191:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1192:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_cmpxchg(atomic_t *v, int old, int new)
1193:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1194:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
1195:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1196:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_cmpxchg(v, old, new);
1197:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1198:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1199:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1200:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_cmpxchg_acquire() - atomic compare and exchange with acquire ordering
1201:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1202:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @old: int value to compare with
1203:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @new: int value to assign
1204:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1205:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * If (@v == @old), atomically updates @v to @new with acquire ordering.
1206:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Otherwise, @v is not modified and relaxed ordering is provided.
1207:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1208:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_cmpxchg_acquire() there.
1209:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1210:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1211:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1212:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1213:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_cmpxchg_acquire(atomic_t *v, int old, int new)
1214:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1215:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1216:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_cmpxchg_acquire(v, old, new);
ARM GAS  /tmp/ccapU81z.s 			page 56


1217:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1218:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1219:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1220:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_cmpxchg_release() - atomic compare and exchange with release ordering
1221:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1222:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @old: int value to compare with
1223:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @new: int value to assign
1224:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1225:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * If (@v == @old), atomically updates @v to @new with release ordering.
1226:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Otherwise, @v is not modified and relaxed ordering is provided.
1227:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1228:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_cmpxchg_release() there.
1229:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1230:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1231:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1232:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1233:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_cmpxchg_release(atomic_t *v, int old, int new)
1234:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1235:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
1236:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1237:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_cmpxchg_release(v, old, new);
1238:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1239:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1240:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1241:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_cmpxchg_relaxed() - atomic compare and exchange with relaxed ordering
1242:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1243:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @old: int value to compare with
1244:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @new: int value to assign
1245:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1246:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * If (@v == @old), atomically updates @v to @new with relaxed ordering.
1247:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Otherwise, @v is not modified and relaxed ordering is provided.
1248:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1249:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_cmpxchg_relaxed() there.
1250:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1251:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1252:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1253:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1254:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_cmpxchg_relaxed(atomic_t *v, int old, int new)
1255:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1256:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1257:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_cmpxchg_relaxed(v, old, new);
1258:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1259:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1260:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1261:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_try_cmpxchg() - atomic compare and exchange with full ordering
1262:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1263:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @old: pointer to int value to compare with
1264:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @new: int value to assign
1265:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1266:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * If (@v == @old), atomically updates @v to @new with full ordering.
1267:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Otherwise, @v is not modified, @old is updated to the current value of @v,
1268:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * and relaxed ordering is provided.
1269:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1270:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_try_cmpxchg() there.
1271:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1272:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: @true if the exchange occured, @false otherwise.
1273:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
ARM GAS  /tmp/ccapU81z.s 			page 57


1274:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline bool
1275:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_try_cmpxchg(atomic_t *v, int *old, int new)
1276:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1277:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
1278:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1279:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(old, sizeof(*old));
1280:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_try_cmpxchg(v, old, new);
1281:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1282:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1283:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1284:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_try_cmpxchg_acquire() - atomic compare and exchange with acquire ordering
1285:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1286:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @old: pointer to int value to compare with
1287:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @new: int value to assign
1288:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1289:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * If (@v == @old), atomically updates @v to @new with acquire ordering.
1290:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Otherwise, @v is not modified, @old is updated to the current value of @v,
1291:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * and relaxed ordering is provided.
1292:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1293:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_try_cmpxchg_acquire() there.
1294:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1295:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: @true if the exchange occured, @false otherwise.
1296:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1297:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline bool
1298:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_try_cmpxchg_acquire(atomic_t *v, int *old, int new)
1299:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1300:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1301:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(old, sizeof(*old));
1302:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_try_cmpxchg_acquire(v, old, new);
1303:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1304:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1305:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1306:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_try_cmpxchg_release() - atomic compare and exchange with release ordering
1307:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1308:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @old: pointer to int value to compare with
1309:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @new: int value to assign
1310:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1311:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * If (@v == @old), atomically updates @v to @new with release ordering.
1312:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Otherwise, @v is not modified, @old is updated to the current value of @v,
1313:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * and relaxed ordering is provided.
1314:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1315:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_try_cmpxchg_release() there.
1316:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1317:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: @true if the exchange occured, @false otherwise.
1318:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1319:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline bool
1320:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_try_cmpxchg_release(atomic_t *v, int *old, int new)
1321:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1322:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
1323:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1324:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(old, sizeof(*old));
1325:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_try_cmpxchg_release(v, old, new);
1326:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1327:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1328:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1329:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_try_cmpxchg_relaxed() - atomic compare and exchange with relaxed ordering
1330:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
ARM GAS  /tmp/ccapU81z.s 			page 58


1331:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @old: pointer to int value to compare with
1332:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @new: int value to assign
1333:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1334:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * If (@v == @old), atomically updates @v to @new with relaxed ordering.
1335:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Otherwise, @v is not modified, @old is updated to the current value of @v,
1336:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * and relaxed ordering is provided.
1337:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1338:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_try_cmpxchg_relaxed() there.
1339:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1340:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: @true if the exchange occured, @false otherwise.
1341:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1342:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline bool
1343:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_try_cmpxchg_relaxed(atomic_t *v, int *old, int new)
1344:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1345:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1346:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(old, sizeof(*old));
1347:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_try_cmpxchg_relaxed(v, old, new);
1348:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1349:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1350:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1351:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_sub_and_test() - atomic subtract and test if zero with full ordering
1352:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to subtract
1353:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1354:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1355:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - @i) with full ordering.
1356:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1357:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_sub_and_test() there.
1358:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1359:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: @true if the resulting value of @v is zero, @false otherwise.
1360:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1361:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline bool
1362:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_sub_and_test(int i, atomic_t *v)
1363:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1364:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
1365:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1366:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_sub_and_test(i, v);
1367:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1368:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1369:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1370:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_dec_and_test() - atomic decrement and test if zero with full ordering
1371:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1372:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1373:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - 1) with full ordering.
1374:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1375:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_dec_and_test() there.
1376:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1377:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: @true if the resulting value of @v is zero, @false otherwise.
1378:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1379:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline bool
1380:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_dec_and_test(atomic_t *v)
 264              		.loc 2 1380 1 is_stmt 1 view .LVU66
1381:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1382:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
 265              		.loc 2 1382 2 view .LVU67
 266              		.loc 2 1382 2 view .LVU68
 267              		.loc 2 1382 2 view .LVU69
1383:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
ARM GAS  /tmp/ccapU81z.s 			page 59


 268              		.loc 2 1383 2 view .LVU70
1384:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_dec_and_test(v);
 269              		.loc 2 1384 2 view .LVU71
 270              	.LBB88:
 271              	.LBI88:
1005:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1006:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1007:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1008:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1009:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_inc_return() - atomic increment with full ordering
1010:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1011:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1012:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + 1) with full ordering.
1013:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1014:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_inc_return() elsewhere.
1015:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1016:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
1017:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1018:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1019:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_inc_return(atomic_t *v)
1020:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1021:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_inc_return)
1022:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_inc_return(v);
1023:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_inc_return_relaxed)
1024:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
1025:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
1026:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_inc_return_relaxed(v);
1027:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
1028:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1029:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1030:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_add_return(1, v);
1031:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1032:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1033:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1034:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1035:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_inc_return_acquire() - atomic increment with acquire ordering
1036:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1037:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1038:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + 1) with acquire ordering.
1039:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1040:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_inc_return_acquire() elsewhere.
1041:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1042:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
1043:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1044:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1045:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_inc_return_acquire(atomic_t *v)
1046:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1047:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_inc_return_acquire)
1048:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_inc_return_acquire(v);
1049:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_inc_return_relaxed)
1050:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_inc_return_relaxed(v);
1051:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
1052:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1053:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_inc_return)
1054:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_inc_return(v);
1055:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1056:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_add_return_acquire(1, v);
ARM GAS  /tmp/ccapU81z.s 			page 60


1057:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1058:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1059:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1060:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1061:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_inc_return_release() - atomic increment with release ordering
1062:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1063:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1064:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + 1) with release ordering.
1065:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1066:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_inc_return_release() elsewhere.
1067:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1068:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
1069:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1070:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1071:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_inc_return_release(atomic_t *v)
1072:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1073:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_inc_return_release)
1074:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_inc_return_release(v);
1075:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_inc_return_relaxed)
1076:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
1077:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_inc_return_relaxed(v);
1078:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_inc_return)
1079:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_inc_return(v);
1080:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1081:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_add_return_release(1, v);
1082:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1083:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1084:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1085:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1086:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_inc_return_relaxed() - atomic increment with relaxed ordering
1087:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1088:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1089:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + 1) with relaxed ordering.
1090:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1091:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_inc_return_relaxed() elsewhere.
1092:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1093:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
1094:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1095:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1096:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_inc_return_relaxed(atomic_t *v)
1097:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1098:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_inc_return_relaxed)
1099:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_inc_return_relaxed(v);
1100:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_inc_return)
1101:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_inc_return(v);
1102:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1103:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_add_return_relaxed(1, v);
1104:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1105:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1106:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1107:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1108:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_inc() - atomic increment with full ordering
1109:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1110:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1111:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + 1) with full ordering.
1112:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1113:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_inc() elsewhere.
ARM GAS  /tmp/ccapU81z.s 			page 61


1114:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1115:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1116:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1117:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1118:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_inc(atomic_t *v)
1119:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1120:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_inc)
1121:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_inc(v);
1122:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_inc_relaxed)
1123:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
1124:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
1125:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_fetch_inc_relaxed(v);
1126:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
1127:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1128:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1129:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_fetch_add(1, v);
1130:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1131:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1132:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1133:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1134:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_inc_acquire() - atomic increment with acquire ordering
1135:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1136:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1137:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + 1) with acquire ordering.
1138:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1139:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_inc_acquire() elsewhere.
1140:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1141:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1142:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1143:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1144:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_inc_acquire(atomic_t *v)
1145:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1146:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_inc_acquire)
1147:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_inc_acquire(v);
1148:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_inc_relaxed)
1149:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_fetch_inc_relaxed(v);
1150:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
1151:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1152:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_inc)
1153:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_inc(v);
1154:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1155:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_fetch_add_acquire(1, v);
1156:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1157:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1158:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1159:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1160:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_inc_release() - atomic increment with release ordering
1161:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1162:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1163:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + 1) with release ordering.
1164:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1165:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_inc_release() elsewhere.
1166:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1167:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1168:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1169:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1170:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_inc_release(atomic_t *v)
ARM GAS  /tmp/ccapU81z.s 			page 62


1171:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1172:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_inc_release)
1173:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_inc_release(v);
1174:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_inc_relaxed)
1175:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
1176:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_inc_relaxed(v);
1177:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_inc)
1178:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_inc(v);
1179:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1180:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_fetch_add_release(1, v);
1181:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1182:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1183:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1184:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1185:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_inc_relaxed() - atomic increment with relaxed ordering
1186:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1187:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1188:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + 1) with relaxed ordering.
1189:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1190:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_inc_relaxed() elsewhere.
1191:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1192:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1193:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1194:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1195:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_inc_relaxed(atomic_t *v)
1196:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1197:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_inc_relaxed)
1198:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_inc_relaxed(v);
1199:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_inc)
1200:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_inc(v);
1201:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1202:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_fetch_add_relaxed(1, v);
1203:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1204:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1205:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1206:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1207:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_dec() - atomic decrement with relaxed ordering
1208:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1209:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1210:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - 1) with relaxed ordering.
1211:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1212:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_dec() elsewhere.
1213:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1214:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: Nothing.
1215:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1216:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline void
1217:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_dec(atomic_t *v)
1218:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1219:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_dec)
1220:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	arch_atomic_dec(v);
1221:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1222:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	raw_atomic_sub(1, v);
1223:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1224:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1225:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1226:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1227:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_dec_return() - atomic decrement with full ordering
ARM GAS  /tmp/ccapU81z.s 			page 63


1228:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1229:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1230:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - 1) with full ordering.
1231:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1232:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_dec_return() elsewhere.
1233:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1234:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
1235:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1236:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1237:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_dec_return(atomic_t *v)
1238:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1239:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_dec_return)
1240:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_dec_return(v);
1241:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_dec_return_relaxed)
1242:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
1243:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
1244:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_dec_return_relaxed(v);
1245:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
1246:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1247:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1248:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_sub_return(1, v);
1249:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1250:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1251:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1252:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1253:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_dec_return_acquire() - atomic decrement with acquire ordering
1254:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1255:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1256:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - 1) with acquire ordering.
1257:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1258:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_dec_return_acquire() elsewhere.
1259:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1260:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
1261:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1262:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1263:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_dec_return_acquire(atomic_t *v)
1264:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1265:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_dec_return_acquire)
1266:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_dec_return_acquire(v);
1267:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_dec_return_relaxed)
1268:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_dec_return_relaxed(v);
1269:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
1270:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1271:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_dec_return)
1272:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_dec_return(v);
1273:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1274:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_sub_return_acquire(1, v);
1275:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1276:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1277:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1278:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1279:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_dec_return_release() - atomic decrement with release ordering
1280:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1281:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1282:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - 1) with release ordering.
1283:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1284:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_dec_return_release() elsewhere.
ARM GAS  /tmp/ccapU81z.s 			page 64


1285:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1286:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
1287:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1288:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1289:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_dec_return_release(atomic_t *v)
1290:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1291:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_dec_return_release)
1292:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_dec_return_release(v);
1293:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_dec_return_relaxed)
1294:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
1295:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_dec_return_relaxed(v);
1296:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_dec_return)
1297:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_dec_return(v);
1298:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1299:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_sub_return_release(1, v);
1300:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1301:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1302:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1303:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1304:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_dec_return_relaxed() - atomic decrement with relaxed ordering
1305:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1306:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1307:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - 1) with relaxed ordering.
1308:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1309:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_dec_return_relaxed() elsewhere.
1310:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1311:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
1312:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1313:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1314:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_dec_return_relaxed(atomic_t *v)
1315:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1316:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_dec_return_relaxed)
1317:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_dec_return_relaxed(v);
1318:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_dec_return)
1319:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_dec_return(v);
1320:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1321:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_sub_return_relaxed(1, v);
1322:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1323:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1324:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1325:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1326:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_dec() - atomic decrement with full ordering
1327:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1328:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1329:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - 1) with full ordering.
1330:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1331:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_dec() elsewhere.
1332:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1333:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1334:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1335:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1336:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_dec(atomic_t *v)
1337:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1338:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_dec)
1339:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_dec(v);
1340:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_dec_relaxed)
1341:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
ARM GAS  /tmp/ccapU81z.s 			page 65


1342:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
1343:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_fetch_dec_relaxed(v);
1344:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
1345:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1346:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1347:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_fetch_sub(1, v);
1348:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1349:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1350:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1351:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1352:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_dec_acquire() - atomic decrement with acquire ordering
1353:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1354:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1355:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - 1) with acquire ordering.
1356:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1357:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_dec_acquire() elsewhere.
1358:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1359:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1360:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1361:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1362:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_dec_acquire(atomic_t *v)
1363:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1364:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_dec_acquire)
1365:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_dec_acquire(v);
1366:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_dec_relaxed)
1367:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_fetch_dec_relaxed(v);
1368:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
1369:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1370:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_dec)
1371:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_dec(v);
1372:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1373:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_fetch_sub_acquire(1, v);
1374:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1375:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1376:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1377:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1378:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_dec_release() - atomic decrement with release ordering
1379:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1380:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1381:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - 1) with release ordering.
1382:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1383:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_dec_release() elsewhere.
1384:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1385:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1386:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1387:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1388:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_dec_release(atomic_t *v)
1389:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1390:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_dec_release)
1391:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_dec_release(v);
1392:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_dec_relaxed)
1393:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
1394:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_dec_relaxed(v);
1395:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_dec)
1396:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_dec(v);
1397:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1398:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_fetch_sub_release(1, v);
ARM GAS  /tmp/ccapU81z.s 			page 66


1399:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1400:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1401:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1402:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1403:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_dec_relaxed() - atomic decrement with relaxed ordering
1404:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1405:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1406:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - 1) with relaxed ordering.
1407:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1408:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_dec_relaxed() elsewhere.
1409:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1410:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1411:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1412:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1413:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_dec_relaxed(atomic_t *v)
1414:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1415:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_dec_relaxed)
1416:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_dec_relaxed(v);
1417:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_dec)
1418:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_dec(v);
1419:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1420:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_fetch_sub_relaxed(1, v);
1421:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1422:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1423:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1424:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1425:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_and() - atomic bitwise AND with relaxed ordering
1426:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1427:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1428:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1429:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v & @i) with relaxed ordering.
1430:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1431:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_and() elsewhere.
1432:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1433:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: Nothing.
1434:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1435:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline void
1436:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_and(int i, atomic_t *v)
1437:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1438:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	arch_atomic_and(i, v);
1439:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1440:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1441:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1442:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_and() - atomic bitwise AND with full ordering
1443:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1444:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1445:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1446:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v & @i) with full ordering.
1447:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1448:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_and() elsewhere.
1449:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1450:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1451:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1452:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1453:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_and(int i, atomic_t *v)
1454:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1455:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_and)
ARM GAS  /tmp/ccapU81z.s 			page 67


1456:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_and(i, v);
1457:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_and_relaxed)
1458:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
1459:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
1460:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_fetch_and_relaxed(i, v);
1461:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
1462:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1463:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1464:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_and"
1465:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1466:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1467:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1468:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1469:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_and_acquire() - atomic bitwise AND with acquire ordering
1470:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1471:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1472:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1473:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v & @i) with acquire ordering.
1474:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1475:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_and_acquire() elsewhere.
1476:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1477:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1478:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1479:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1480:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_and_acquire(int i, atomic_t *v)
1481:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1482:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_and_acquire)
1483:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_and_acquire(i, v);
1484:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_and_relaxed)
1485:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_fetch_and_relaxed(i, v);
1486:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
1487:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1488:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_and)
1489:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_and(i, v);
1490:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1491:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_and_acquire"
1492:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1493:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1494:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1495:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1496:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_and_release() - atomic bitwise AND with release ordering
1497:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1498:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1499:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1500:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v & @i) with release ordering.
1501:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1502:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_and_release() elsewhere.
1503:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1504:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1505:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1506:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1507:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_and_release(int i, atomic_t *v)
1508:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1509:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_and_release)
1510:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_and_release(i, v);
1511:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_and_relaxed)
1512:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
ARM GAS  /tmp/ccapU81z.s 			page 68


1513:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_and_relaxed(i, v);
1514:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_and)
1515:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_and(i, v);
1516:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1517:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_and_release"
1518:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1519:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1520:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1521:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1522:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_and_relaxed() - atomic bitwise AND with relaxed ordering
1523:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1524:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1525:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1526:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v & @i) with relaxed ordering.
1527:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1528:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_and_relaxed() elsewhere.
1529:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1530:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1531:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1532:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1533:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_and_relaxed(int i, atomic_t *v)
1534:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1535:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_and_relaxed)
1536:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_and_relaxed(i, v);
1537:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_and)
1538:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_and(i, v);
1539:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1540:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_and_relaxed"
1541:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1542:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1543:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1544:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1545:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_andnot() - atomic bitwise AND NOT with relaxed ordering
1546:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1547:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1548:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1549:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v & ~@i) with relaxed ordering.
1550:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1551:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_andnot() elsewhere.
1552:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1553:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: Nothing.
1554:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1555:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline void
1556:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_andnot(int i, atomic_t *v)
1557:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1558:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_andnot)
1559:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	arch_atomic_andnot(i, v);
1560:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1561:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	raw_atomic_and(~i, v);
1562:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1563:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1564:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1565:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1566:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_andnot() - atomic bitwise AND NOT with full ordering
1567:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1568:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1569:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
ARM GAS  /tmp/ccapU81z.s 			page 69


1570:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v & ~@i) with full ordering.
1571:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1572:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_andnot() elsewhere.
1573:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1574:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1575:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1576:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1577:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_andnot(int i, atomic_t *v)
1578:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1579:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_andnot)
1580:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_andnot(i, v);
1581:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_andnot_relaxed)
1582:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
1583:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
1584:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_fetch_andnot_relaxed(i, v);
1585:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
1586:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1587:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1588:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_fetch_and(~i, v);
1589:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1590:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1591:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1592:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1593:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_andnot_acquire() - atomic bitwise AND NOT with acquire ordering
1594:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1595:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1596:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1597:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v & ~@i) with acquire ordering.
1598:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1599:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_andnot_acquire() elsewhere.
1600:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1601:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1602:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1603:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1604:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_andnot_acquire(int i, atomic_t *v)
1605:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1606:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_andnot_acquire)
1607:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_andnot_acquire(i, v);
1608:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_andnot_relaxed)
1609:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_fetch_andnot_relaxed(i, v);
1610:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
1611:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1612:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_andnot)
1613:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_andnot(i, v);
1614:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1615:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_fetch_and_acquire(~i, v);
1616:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1617:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1618:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1619:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1620:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_andnot_release() - atomic bitwise AND NOT with release ordering
1621:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1622:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1623:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1624:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v & ~@i) with release ordering.
1625:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1626:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_andnot_release() elsewhere.
ARM GAS  /tmp/ccapU81z.s 			page 70


1627:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1628:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1629:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1630:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1631:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_andnot_release(int i, atomic_t *v)
1632:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1633:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_andnot_release)
1634:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_andnot_release(i, v);
1635:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_andnot_relaxed)
1636:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
1637:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_andnot_relaxed(i, v);
1638:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_andnot)
1639:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_andnot(i, v);
1640:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1641:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_fetch_and_release(~i, v);
1642:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1643:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1644:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1645:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1646:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_andnot_relaxed() - atomic bitwise AND NOT with relaxed ordering
1647:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1648:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1649:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1650:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v & ~@i) with relaxed ordering.
1651:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1652:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_andnot_relaxed() elsewhere.
1653:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1654:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1655:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1656:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1657:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_andnot_relaxed(int i, atomic_t *v)
1658:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1659:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_andnot_relaxed)
1660:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_andnot_relaxed(i, v);
1661:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_andnot)
1662:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_andnot(i, v);
1663:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1664:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_fetch_and_relaxed(~i, v);
1665:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1666:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1667:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1668:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1669:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_or() - atomic bitwise OR with relaxed ordering
1670:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1671:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1672:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1673:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v | @i) with relaxed ordering.
1674:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1675:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_or() elsewhere.
1676:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1677:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: Nothing.
1678:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1679:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline void
1680:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_or(int i, atomic_t *v)
1681:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1682:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	arch_atomic_or(i, v);
1683:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
ARM GAS  /tmp/ccapU81z.s 			page 71


1684:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1685:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1686:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_or() - atomic bitwise OR with full ordering
1687:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1688:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1689:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1690:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v | @i) with full ordering.
1691:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1692:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_or() elsewhere.
1693:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1694:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1695:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1696:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1697:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_or(int i, atomic_t *v)
1698:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1699:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_or)
1700:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_or(i, v);
1701:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_or_relaxed)
1702:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
1703:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
1704:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_fetch_or_relaxed(i, v);
1705:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
1706:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1707:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1708:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_or"
1709:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1710:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1711:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1712:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1713:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_or_acquire() - atomic bitwise OR with acquire ordering
1714:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1715:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1716:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1717:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v | @i) with acquire ordering.
1718:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1719:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_or_acquire() elsewhere.
1720:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1721:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1722:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1723:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1724:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_or_acquire(int i, atomic_t *v)
1725:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1726:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_or_acquire)
1727:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_or_acquire(i, v);
1728:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_or_relaxed)
1729:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_fetch_or_relaxed(i, v);
1730:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
1731:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1732:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_or)
1733:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_or(i, v);
1734:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1735:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_or_acquire"
1736:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1737:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1738:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1739:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1740:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_or_release() - atomic bitwise OR with release ordering
ARM GAS  /tmp/ccapU81z.s 			page 72


1741:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1742:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1743:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1744:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v | @i) with release ordering.
1745:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1746:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_or_release() elsewhere.
1747:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1748:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1749:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1750:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1751:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_or_release(int i, atomic_t *v)
1752:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1753:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_or_release)
1754:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_or_release(i, v);
1755:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_or_relaxed)
1756:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
1757:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_or_relaxed(i, v);
1758:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_or)
1759:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_or(i, v);
1760:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1761:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_or_release"
1762:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1763:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1764:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1765:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1766:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_or_relaxed() - atomic bitwise OR with relaxed ordering
1767:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1768:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1769:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1770:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v | @i) with relaxed ordering.
1771:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1772:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_or_relaxed() elsewhere.
1773:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1774:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1775:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1776:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1777:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_or_relaxed(int i, atomic_t *v)
1778:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1779:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_or_relaxed)
1780:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_or_relaxed(i, v);
1781:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_or)
1782:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_or(i, v);
1783:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1784:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_or_relaxed"
1785:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1786:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1787:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1788:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1789:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_xor() - atomic bitwise XOR with relaxed ordering
1790:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1791:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1792:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1793:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v ^ @i) with relaxed ordering.
1794:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1795:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_xor() elsewhere.
1796:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1797:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: Nothing.
ARM GAS  /tmp/ccapU81z.s 			page 73


1798:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1799:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline void
1800:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_xor(int i, atomic_t *v)
1801:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1802:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	arch_atomic_xor(i, v);
1803:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1804:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1805:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1806:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_xor() - atomic bitwise XOR with full ordering
1807:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1808:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1809:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1810:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v ^ @i) with full ordering.
1811:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1812:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_xor() elsewhere.
1813:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1814:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1815:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1816:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1817:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_xor(int i, atomic_t *v)
1818:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1819:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_xor)
1820:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_xor(i, v);
1821:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_xor_relaxed)
1822:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
1823:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
1824:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_fetch_xor_relaxed(i, v);
1825:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
1826:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1827:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1828:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_xor"
1829:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1830:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1831:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1832:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1833:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_xor_acquire() - atomic bitwise XOR with acquire ordering
1834:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1835:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1836:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1837:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v ^ @i) with acquire ordering.
1838:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1839:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_xor_acquire() elsewhere.
1840:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1841:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1842:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1843:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1844:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_xor_acquire(int i, atomic_t *v)
1845:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1846:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_xor_acquire)
1847:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_xor_acquire(i, v);
1848:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_xor_relaxed)
1849:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_fetch_xor_relaxed(i, v);
1850:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
1851:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1852:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_xor)
1853:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_xor(i, v);
1854:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
ARM GAS  /tmp/ccapU81z.s 			page 74


1855:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_xor_acquire"
1856:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1857:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1858:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1859:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1860:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_xor_release() - atomic bitwise XOR with release ordering
1861:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1862:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1863:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1864:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v ^ @i) with release ordering.
1865:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1866:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_xor_release() elsewhere.
1867:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1868:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1869:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1870:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1871:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_xor_release(int i, atomic_t *v)
1872:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1873:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_xor_release)
1874:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_xor_release(i, v);
1875:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_xor_relaxed)
1876:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
1877:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_xor_relaxed(i, v);
1878:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_xor)
1879:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_xor(i, v);
1880:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1881:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_xor_release"
1882:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1883:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1884:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1885:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1886:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_xor_relaxed() - atomic bitwise XOR with relaxed ordering
1887:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1888:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1889:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1890:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v ^ @i) with relaxed ordering.
1891:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1892:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_xor_relaxed() elsewhere.
1893:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1894:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1895:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1896:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1897:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_xor_relaxed(int i, atomic_t *v)
1898:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1899:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_xor_relaxed)
1900:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_xor_relaxed(i, v);
1901:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_xor)
1902:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_xor(i, v);
1903:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1904:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_xor_relaxed"
1905:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1906:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1907:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1908:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1909:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_xchg() - atomic exchange with full ordering
1910:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1911:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @new: int value to assign
ARM GAS  /tmp/ccapU81z.s 			page 75


1912:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1913:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to @new with full ordering.
1914:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1915:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_xchg() elsewhere.
1916:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1917:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1918:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1919:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1920:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_xchg(atomic_t *v, int new)
1921:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1922:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_xchg)
1923:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_xchg(v, new);
1924:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_xchg_relaxed)
1925:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
1926:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
1927:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_xchg_relaxed(v, new);
1928:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
1929:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1930:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1931:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_xchg(&v->counter, new);
1932:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1933:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1934:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1935:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1936:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_xchg_acquire() - atomic exchange with acquire ordering
1937:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1938:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @new: int value to assign
1939:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1940:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to @new with acquire ordering.
1941:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1942:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_xchg_acquire() elsewhere.
1943:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1944:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1945:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1946:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1947:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_xchg_acquire(atomic_t *v, int new)
1948:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1949:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_xchg_acquire)
1950:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_xchg_acquire(v, new);
1951:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_xchg_relaxed)
1952:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_xchg_relaxed(v, new);
1953:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
1954:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1955:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_xchg)
1956:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_xchg(v, new);
1957:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1958:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_xchg_acquire(&v->counter, new);
1959:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1960:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1961:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1962:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1963:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_xchg_release() - atomic exchange with release ordering
1964:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1965:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @new: int value to assign
1966:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1967:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to @new with release ordering.
1968:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
ARM GAS  /tmp/ccapU81z.s 			page 76


1969:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_xchg_release() elsewhere.
1970:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1971:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1972:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1973:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1974:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_xchg_release(atomic_t *v, int new)
1975:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1976:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_xchg_release)
1977:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_xchg_release(v, new);
1978:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_xchg_relaxed)
1979:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
1980:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_xchg_relaxed(v, new);
1981:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_xchg)
1982:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_xchg(v, new);
1983:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1984:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_xchg_release(&v->counter, new);
1985:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1986:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1987:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1988:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1989:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_xchg_relaxed() - atomic exchange with relaxed ordering
1990:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1991:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @new: int value to assign
1992:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1993:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to @new with relaxed ordering.
1994:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1995:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_xchg_relaxed() elsewhere.
1996:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1997:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1998:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1999:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
2000:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_xchg_relaxed(atomic_t *v, int new)
2001:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
2002:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_xchg_relaxed)
2003:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_xchg_relaxed(v, new);
2004:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_xchg)
2005:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_xchg(v, new);
2006:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
2007:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_xchg_relaxed(&v->counter, new);
2008:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
2009:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
2010:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
2011:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
2012:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_cmpxchg() - atomic compare and exchange with full ordering
2013:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
2014:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @old: int value to compare with
2015:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @new: int value to assign
2016:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2017:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * If (@v == @old), atomically updates @v to @new with full ordering.
2018:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Otherwise, @v is not modified and relaxed ordering is provided.
2019:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2020:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_cmpxchg() elsewhere.
2021:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2022:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
2023:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
2024:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
2025:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_cmpxchg(atomic_t *v, int old, int new)
ARM GAS  /tmp/ccapU81z.s 			page 77


2026:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
2027:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_cmpxchg)
2028:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_cmpxchg(v, old, new);
2029:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_cmpxchg_relaxed)
2030:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
2031:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
2032:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_cmpxchg_relaxed(v, old, new);
2033:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
2034:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
2035:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
2036:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_cmpxchg(&v->counter, old, new);
2037:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
2038:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
2039:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
2040:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
2041:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_cmpxchg_acquire() - atomic compare and exchange with acquire ordering
2042:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
2043:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @old: int value to compare with
2044:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @new: int value to assign
2045:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2046:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * If (@v == @old), atomically updates @v to @new with acquire ordering.
2047:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Otherwise, @v is not modified and relaxed ordering is provided.
2048:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2049:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_cmpxchg_acquire() elsewhere.
2050:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2051:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
2052:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
2053:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
2054:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_cmpxchg_acquire(atomic_t *v, int old, int new)
2055:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
2056:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_cmpxchg_acquire)
2057:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_cmpxchg_acquire(v, old, new);
2058:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_cmpxchg_relaxed)
2059:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_cmpxchg_relaxed(v, old, new);
2060:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
2061:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
2062:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_cmpxchg)
2063:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_cmpxchg(v, old, new);
2064:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
2065:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_cmpxchg_acquire(&v->counter, old, new);
2066:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
2067:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
2068:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
2069:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
2070:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_cmpxchg_release() - atomic compare and exchange with release ordering
2071:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
2072:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @old: int value to compare with
2073:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @new: int value to assign
2074:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2075:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * If (@v == @old), atomically updates @v to @new with release ordering.
2076:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Otherwise, @v is not modified and relaxed ordering is provided.
2077:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2078:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_cmpxchg_release() elsewhere.
2079:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2080:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
2081:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
2082:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
ARM GAS  /tmp/ccapU81z.s 			page 78


2083:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_cmpxchg_release(atomic_t *v, int old, int new)
2084:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
2085:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_cmpxchg_release)
2086:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_cmpxchg_release(v, old, new);
2087:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_cmpxchg_relaxed)
2088:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
2089:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_cmpxchg_relaxed(v, old, new);
2090:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_cmpxchg)
2091:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_cmpxchg(v, old, new);
2092:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
2093:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_cmpxchg_release(&v->counter, old, new);
2094:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
2095:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
2096:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
2097:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
2098:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_cmpxchg_relaxed() - atomic compare and exchange with relaxed ordering
2099:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
2100:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @old: int value to compare with
2101:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @new: int value to assign
2102:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2103:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * If (@v == @old), atomically updates @v to @new with relaxed ordering.
2104:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Otherwise, @v is not modified and relaxed ordering is provided.
2105:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2106:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_cmpxchg_relaxed() elsewhere.
2107:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2108:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
2109:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
2110:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
2111:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_cmpxchg_relaxed(atomic_t *v, int old, int new)
2112:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
2113:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_cmpxchg_relaxed)
2114:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_cmpxchg_relaxed(v, old, new);
2115:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_cmpxchg)
2116:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_cmpxchg(v, old, new);
2117:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
2118:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_cmpxchg_relaxed(&v->counter, old, new);
2119:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
2120:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
2121:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
2122:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
2123:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_try_cmpxchg() - atomic compare and exchange with full ordering
2124:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
2125:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @old: pointer to int value to compare with
2126:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @new: int value to assign
2127:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2128:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * If (@v == @old), atomically updates @v to @new with full ordering.
2129:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Otherwise, @v is not modified, @old is updated to the current value of @v,
2130:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * and relaxed ordering is provided.
2131:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2132:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_try_cmpxchg() elsewhere.
2133:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2134:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: @true if the exchange occured, @false otherwise.
2135:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
2136:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline bool
2137:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_try_cmpxchg(atomic_t *v, int *old, int new)
2138:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
2139:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_try_cmpxchg)
ARM GAS  /tmp/ccapU81z.s 			page 79


2140:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_try_cmpxchg(v, old, new);
2141:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_try_cmpxchg_relaxed)
2142:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	bool ret;
2143:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
2144:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_try_cmpxchg_relaxed(v, old, new);
2145:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
2146:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
2147:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
2148:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int r, o = *old;
2149:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	r = raw_atomic_cmpxchg(v, o, new);
2150:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(r != o))
2151:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*old = r;
2152:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return likely(r == o);
2153:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
2154:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
2155:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
2156:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
2157:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_try_cmpxchg_acquire() - atomic compare and exchange with acquire ordering
2158:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
2159:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @old: pointer to int value to compare with
2160:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @new: int value to assign
2161:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2162:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * If (@v == @old), atomically updates @v to @new with acquire ordering.
2163:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Otherwise, @v is not modified, @old is updated to the current value of @v,
2164:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * and relaxed ordering is provided.
2165:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2166:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_try_cmpxchg_acquire() elsewhere.
2167:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2168:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: @true if the exchange occured, @false otherwise.
2169:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
2170:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline bool
2171:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_try_cmpxchg_acquire(atomic_t *v, int *old, int new)
2172:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
2173:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_try_cmpxchg_acquire)
2174:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_try_cmpxchg_acquire(v, old, new);
2175:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_try_cmpxchg_relaxed)
2176:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	bool ret = arch_atomic_try_cmpxchg_relaxed(v, old, new);
2177:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
2178:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
2179:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_try_cmpxchg)
2180:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_try_cmpxchg(v, old, new);
2181:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
2182:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int r, o = *old;
2183:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	r = raw_atomic_cmpxchg_acquire(v, o, new);
2184:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(r != o))
2185:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*old = r;
2186:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return likely(r == o);
2187:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
2188:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
2189:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
2190:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
2191:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_try_cmpxchg_release() - atomic compare and exchange with release ordering
2192:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
2193:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @old: pointer to int value to compare with
2194:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @new: int value to assign
2195:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2196:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * If (@v == @old), atomically updates @v to @new with release ordering.
ARM GAS  /tmp/ccapU81z.s 			page 80


2197:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Otherwise, @v is not modified, @old is updated to the current value of @v,
2198:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * and relaxed ordering is provided.
2199:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2200:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_try_cmpxchg_release() elsewhere.
2201:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2202:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: @true if the exchange occured, @false otherwise.
2203:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
2204:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline bool
2205:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_try_cmpxchg_release(atomic_t *v, int *old, int new)
2206:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
2207:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_try_cmpxchg_release)
2208:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_try_cmpxchg_release(v, old, new);
2209:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_try_cmpxchg_relaxed)
2210:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
2211:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_try_cmpxchg_relaxed(v, old, new);
2212:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_try_cmpxchg)
2213:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_try_cmpxchg(v, old, new);
2214:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
2215:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int r, o = *old;
2216:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	r = raw_atomic_cmpxchg_release(v, o, new);
2217:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(r != o))
2218:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*old = r;
2219:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return likely(r == o);
2220:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
2221:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
2222:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
2223:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
2224:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_try_cmpxchg_relaxed() - atomic compare and exchange with relaxed ordering
2225:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
2226:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @old: pointer to int value to compare with
2227:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @new: int value to assign
2228:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2229:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * If (@v == @old), atomically updates @v to @new with relaxed ordering.
2230:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Otherwise, @v is not modified, @old is updated to the current value of @v,
2231:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * and relaxed ordering is provided.
2232:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2233:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_try_cmpxchg_relaxed() elsewhere.
2234:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2235:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: @true if the exchange occured, @false otherwise.
2236:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
2237:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline bool
2238:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_try_cmpxchg_relaxed(atomic_t *v, int *old, int new)
2239:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
2240:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_try_cmpxchg_relaxed)
2241:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_try_cmpxchg_relaxed(v, old, new);
2242:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_try_cmpxchg)
2243:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_try_cmpxchg(v, old, new);
2244:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
2245:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int r, o = *old;
2246:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	r = raw_atomic_cmpxchg_relaxed(v, o, new);
2247:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(r != o))
2248:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*old = r;
2249:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return likely(r == o);
2250:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
2251:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
2252:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
2253:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
ARM GAS  /tmp/ccapU81z.s 			page 81


2254:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_sub_and_test() - atomic subtract and test if zero with full ordering
2255:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to subtract
2256:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
2257:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2258:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - @i) with full ordering.
2259:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2260:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_sub_and_test() elsewhere.
2261:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2262:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: @true if the resulting value of @v is zero, @false otherwise.
2263:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
2264:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline bool
2265:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_sub_and_test(int i, atomic_t *v)
2266:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
2267:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_sub_and_test)
2268:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_sub_and_test(i, v);
2269:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
2270:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_sub_return(i, v) == 0;
2271:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
2272:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
2273:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
2274:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
2275:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_dec_and_test() - atomic decrement and test if zero with full ordering
2276:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
2277:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2278:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - 1) with full ordering.
2279:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2280:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_dec_and_test() elsewhere.
2281:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2282:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: @true if the resulting value of @v is zero, @false otherwise.
2283:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
2284:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline bool
2285:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_dec_and_test(atomic_t *v)
 272              		.loc 3 2285 1 view .LVU72
2286:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
2287:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_dec_and_test)
2288:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_dec_and_test(v);
2289:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
2290:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_dec_return(v) == 0;
 273              		.loc 3 2290 2 view .LVU73
 274              	.LBB89:
 275              	.LBI89:
1237:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 276              		.loc 3 1237 1 view .LVU74
1248:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 277              		.loc 3 1248 2 view .LVU75
 278              	.LVL16:
 279              	.LBB90:
 280              	.LBI90:
 790:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 281              		.loc 3 790 1 view .LVU76
 282              	.LBB91:
 795:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
 283              		.loc 3 795 2 view .LVU77
 796:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_sub_return_relaxed(i, v);
 284              		.loc 3 796 2 view .LVU78
 285              	.LBB92:
 286              	.LBI92:
ARM GAS  /tmp/ccapU81z.s 			page 82


 287              		.file 6 "/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h"
   1:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** /* SPDX-License-Identifier: GPL-2.0-or-later */
   2:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** /*
   3:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h ****  * Generic barrier definitions.
   4:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h ****  *
   5:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h ****  * It should be possible to use these on really simple architectures,
   6:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h ****  * but it serves more as a starting point for new ports.
   7:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h ****  *
   8:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h ****  * Copyright (C) 2007 Red Hat, Inc. All Rights Reserved.
   9:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h ****  * Written by David Howells (dhowells@redhat.com)
  10:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h ****  */
  11:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** 
  12:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** #include <linux/rwonce.h>
  13:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** 
  14:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** static inline void sync(void)
  15:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** {
  16:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** 	asm volatile("sync" : : : "memory");
  17:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** }
  18:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** 
  19:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** static inline void eieio(void)
  20:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** {
  21:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** 	asm volatile("eieio" : : : "memory");
  22:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** }
  23:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** 
  24:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** static inline void barrier(void)
 288              		.loc 6 24 20 view .LVU79
 289              	.LBB93:
  25:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** {
  26:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** 	asm volatile("" : : : "memory");
 290              		.loc 6 26 2 view .LVU80
 291              	.LBE93:
 292              	.LBE92:
 797:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
 293              		.loc 3 797 2 view .LVU81
 294              	.LVL17:
 295              	.LBB94:
 296              	.LBI94:
 171:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** ATOMIC_OPS(sub, -=, sub)
 297              		.loc 4 171 1 view .LVU82
 298              	.LBB95:
 299              		.loc 4 171 1 view .LVU83
 300              		.loc 4 171 1 view .LVU84
 301              		.loc 4 171 1 view .LVU85
 302              		.syntax unified
 303              	@ 171 "/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h" 1
 304              		@ atomic_sub_return
 305 000a 53E8002F 	1: ldrex   r2, [r3]
 306 000e A2F10102 	   sub r2, r2, #1
 307 0012 43E80021 	   strex   r1, r2, [r3]
 308 0016 91F0000F 	   teq r1, #0
 309 001a F6D1     	   bne 1b
 310              	@ 0 "" 2
 311              	.LVL18:
 312              		.loc 4 171 1 view .LVU86
 313              		.loc 4 171 1 is_stmt 0 view .LVU87
 314              		.thumb
 315              		.syntax unified
ARM GAS  /tmp/ccapU81z.s 			page 83


 316              	.LBE95:
 317              	.LBE94:
 798:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
 318              		.loc 3 798 2 is_stmt 1 view .LVU88
 319              	.LBB96:
 320              	.LBI96:
  24:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** {
 321              		.loc 6 24 20 view .LVU89
 322              	.LBB97:
 323              		.loc 6 26 2 view .LVU90
 324              	.LBE97:
 325              	.LBE96:
 799:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 326              		.loc 3 799 2 view .LVU91
 327              	.LVL19:
 799:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 328              		.loc 3 799 2 is_stmt 0 view .LVU92
 329              	.LBE91:
 330              	.LBE90:
 331              	.LBE89:
 332              	.LBE88:
 333              	.LBE87:
 334              		.loc 1 62 8 discriminator 1 view .LVU93
 335 001c 12B1     		cbz	r2, .L13
 336              		.loc 1 62 63 discriminator 1 view .LVU94
 337 001e 836F     		ldr	r3, [r0, #120]
 338              		.loc 1 62 46 discriminator 1 view .LVU95
 339 0020 002B     		cmp	r3, #0
 340 0022 06DA     		bge	.L11
 341              	.L13:
  63:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****         pr_info("remove inode\n");
 342              		.loc 1 63 9 is_stmt 1 view .LVU96
 343 0024 0449     		ldr	r1, .L18
 344 0026 0620     		movs	r0, #6
 345              	.LVL20:
 346              		.loc 1 63 9 is_stmt 0 view .LVU97
 347 0028 FFF7FEFF 		bl	printk
 348              	.LVL21:
  64:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****         destroy_inode(inode);  
 349              		.loc 1 64 9 is_stmt 1 view .LVU98
 350 002c 2046     		mov	r0, r4
 351 002e FFF7FEFF 		bl	destroy_inode
 352              	.LVL22:
 353              	.L11:
  65:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c ****     }
  66:/mnt/c/Users/31740/Desktop/newcore/fs/fs_inode.c **** }
 354              		.loc 1 66 1 is_stmt 0 view .LVU99
 355 0032 10BD     		pop	{r4, pc}
 356              	.LVL23:
 357              	.L15:
 358              	.LCFI4:
 359              		.cfi_def_cfa_offset 0
 360              		.cfi_restore 4
 361              		.cfi_restore 14
 362              		.loc 1 66 1 view .LVU100
 363 0034 7047     		bx	lr
 364              	.L19:
ARM GAS  /tmp/ccapU81z.s 			page 84


 365 0036 00BF     		.align	2
 366              	.L18:
 367 0038 00000000 		.word	.LC0
 368              		.cfi_endproc
 369              	.LFE1036:
 371              		.section	.rodata.str1.4,"aMS",%progbits,1
 372              		.align	2
 373              	.LC1:
 374 0000 696E6F64 		.ascii	"inode_put\000"
 374      655F7075 
 374      7400
 375 000a 0000     		.align	2
 376              	.LC2:
 377 000c 00       		.ascii	"\000"
 378              		.section	.export_table,"aw"
 379              		.align	2
 382              	inode_put_export_struct:
 383 0000 00000000 		.word	.LC1
 384 0004 0C000000 		.word	.LC2
 385 0008 00000000 		.word	inode_put
 386              		.section	.rodata.str1.4
 387 000d 000000   		.align	2
 388              	.LC3:
 389 0010 696E6F64 		.ascii	"inode_get\000"
 389      655F6765 
 389      7400
 390              		.section	.export_table
 391              		.align	2
 394              	inode_get_export_struct:
 395 000c 10000000 		.word	.LC3
 396 0010 0C000000 		.word	.LC2
 397 0014 00000000 		.word	inode_get
 398              		.section	.rodata.str1.4
 399 001a 0000     		.align	2
 400              	.LC4:
 401 001c 64657374 		.ascii	"destroy_inode\000"
 401      726F795F 
 401      696E6F64 
 401      6500
 402              		.section	.export_table
 403              		.align	2
 406              	destroy_inode_export_struct:
 407 0018 1C000000 		.word	.LC4
 408 001c 0C000000 		.word	.LC2
 409 0020 00000000 		.word	destroy_inode
 410              		.section	.rodata.str1.4
 411 002a 0000     		.align	2
 412              	.LC5:
 413 002c 6E65775F 		.ascii	"new_inode\000"
 413      696E6F64 
 413      6500
 414              		.section	.export_table
 415              		.align	2
 418              	new_inode_export_struct:
 419 0024 2C000000 		.word	.LC5
 420 0028 0C000000 		.word	.LC2
 421 002c 00000000 		.word	new_inode
ARM GAS  /tmp/ccapU81z.s 			page 85


 422              		.text
 423              	.Letext0:
 424              		.file 7 "/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/int-l64.h"
 425              		.file 8 "/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/posix_types.h"
 426              		.file 9 "/mnt/c/Users/31740/Desktop/newcore/include/uapi/linux/types.h"
 427              		.file 10 "/mnt/c/Users/31740/Desktop/newcore/include/linux/types.h"
 428              		.file 11 "/mnt/c/Users/31740/Desktop/newcore/include/linux/export.h"
 429              		.file 12 "/mnt/c/Users/31740/Desktop/newcore/include/linux/errseq.h"
 430              		.file 13 "/mnt/c/Users/31740/Desktop/newcore/include/linux/time64.h"
 431              		.file 14 "/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h"
 432              		.file 15 "/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock_types_raw.h"
 433              		.file 16 "/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock_types.h"
 434              		.file 17 "/mnt/c/Users/31740/Desktop/newcore/include/linux/rbtree_types.h"
 435              		.file 18 "/mnt/c/Users/31740/Desktop/newcore/include/linux/uidgid_types.h"
 436              		.file 19 "/mnt/c/Users/31740/Desktop/newcore/include/linux/projid.h"
 437              		.file 20 "/mnt/c/Users/31740/Desktop/newcore/include/linux/fs.h"
 438              		.file 21 "/mnt/c/Users/31740/Desktop/newcore/include/linux/mnt_idmapping.h"
 439              		.file 22 "/mnt/c/Users/31740/Desktop/newcore/include/linux/mutex.h"
 440              		.file 23 "/mnt/c/Users/31740/Desktop/newcore/include/linux/uio.h"
 441              		.file 24 "/mnt/c/Users/31740/Desktop/newcore/include/linux/wait.h"
 442              		.file 25 "/mnt/c/Users/31740/Desktop/newcore/include/linux/xarray.h"
 443              		.file 26 "/mnt/c/Users/31740/Desktop/newcore/include/linux/migrate_mode.h"
 444              		.file 27 "/mnt/c/Users/31740/Desktop/newcore/include/linux/rw_hint.h"
 445              		.file 28 "/mnt/c/Users/31740/Desktop/newcore/include/linux/stddef.h"
 446              		.file 29 "/mnt/c/Users/31740/Desktop/newcore/include/linux/gfp_types.h"
 447              		.file 30 "/mnt/c/Users/31740/Desktop/newcore/include/linux/reciprocal_div.h"
 448              		.file 31 "/mnt/c/Users/31740/Desktop/newcore/include/linux/mm_type.h"
 449              		.file 32 "/mnt/c/Users/31740/Desktop/newcore/include/linux/bvec.h"
 450              		.file 33 "/mnt/c/Users/31740/Desktop/newcore/include/linux/blk_types.h"
 451              		.file 34 "/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h"
 452              		.file 35 "/mnt/c/Users/31740/Desktop/newcore/include/linux/bio.h"
 453              		.file 36 "/mnt/c/Users/31740/Desktop/newcore/include/linux/mempool_super_haper.h"
 454              		.file 37 "/mnt/c/Users/31740/Desktop/newcore/include/linux/mempool.h"
 455              		.file 38 "/mnt/c/Users/31740/Desktop/newcore/include/linux/lockdep_types.h"
 456              		.file 39 "/mnt/c/Users/31740/Desktop/newcore/include/linux/workqueue_types.h"
 457              		.file 40 "/mnt/c/Users/31740/Desktop/newcore/include/linux/blk-mq.h"
 458              		.file 41 "/mnt/c/Users/31740/Desktop/newcore/include/linux/dcache.h"
 459              		.file 42 "/mnt/c/Users/31740/Desktop/newcore/include/uapi/linux/pr.h"
 460              		.file 43 "/mnt/c/Users/31740/Desktop/newcore/include/linux/pr.h"
 461              		.file 44 "/mnt/c/Users/31740/Desktop/newcore/include/linux/hdreg.h"
 462              		.file 45 "/mnt/c/Users/31740/Desktop/newcore/include/linux/lockref.h"
 463              		.file 46 "/mnt/c/Users/31740/Desktop/newcore/include/linux/path.h"
 464              		.file 47 "/mnt/c/Users/31740/Desktop/newcore/include/linux/statfs.h"
 465              		.file 48 "/mnt/c/Users/31740/Desktop/newcore/include/linux/stat.h"
 466              		.file 49 "/mnt/c/Users/31740/Desktop/newcore/include/linux/printk.h"
 467              		.file 50 "/mnt/c/Users/31740/Desktop/newcore/include/linux/time.h"
 468              		.file 51 "/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/string.h"
 469              		.file 52 "/mnt/c/Users/31740/Desktop/newcore/include/linux/instrumented.h"
 470              		.file 53 "/mnt/c/Users/31740/Desktop/newcore/include/linux/kcsan-checks.h"
 471              		.file 54 "/mnt/c/Users/31740/Desktop/newcore/include/linux/kasan-checks.h"
 472              		.file 55 "<built-in>"
ARM GAS  /tmp/ccapU81z.s 			page 86


DEFINED SYMBOLS
                            *ABS*:00000000 fs_inode.c
     /tmp/ccapU81z.s:21     .text.inode_get:00000000 $t
     /tmp/ccapU81z.s:27     .text.inode_get:00000000 inode_get
     /tmp/ccapU81z.s:85     .text.new_inode:00000000 $t
     /tmp/ccapU81z.s:91     .text.new_inode:00000000 new_inode
     /tmp/ccapU81z.s:184    .text.destroy_inode:00000000 $t
     /tmp/ccapU81z.s:190    .text.destroy_inode:00000000 destroy_inode
     /tmp/ccapU81z.s:232    .rodata.inode_put.str1.4:00000000 $d
     /tmp/ccapU81z.s:236    .text.inode_put:00000000 $t
     /tmp/ccapU81z.s:242    .text.inode_put:00000000 inode_put
     /tmp/ccapU81z.s:367    .text.inode_put:00000038 $d
     /tmp/ccapU81z.s:372    .rodata.str1.4:00000000 $d
     /tmp/ccapU81z.s:379    .export_table:00000000 $d
     /tmp/ccapU81z.s:382    .export_table:00000000 inode_put_export_struct
     /tmp/ccapU81z.s:394    .export_table:0000000c inode_get_export_struct
     /tmp/ccapU81z.s:406    .export_table:00000018 destroy_inode_export_struct
     /tmp/ccapU81z.s:418    .export_table:00000024 new_inode_export_struct

UNDEFINED SYMBOLS
__smalloc__
memset
ktime_get
__sfree__
printk
