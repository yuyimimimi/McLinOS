ARM GAS  /tmp/cctjQXNb.s 			page 1


   1              		.cpu cortex-m4
   2              		.arch armv7e-m
   3              		.fpu fpv4-sp-d16
   4              		.eabi_attribute 27, 1
   5              		.eabi_attribute 28, 1
   6              		.eabi_attribute 20, 1
   7              		.eabi_attribute 21, 1
   8              		.eabi_attribute 23, 3
   9              		.eabi_attribute 24, 1
  10              		.eabi_attribute 25, 1
  11              		.eabi_attribute 26, 1
  12              		.eabi_attribute 30, 1
  13              		.eabi_attribute 34, 1
  14              		.eabi_attribute 18, 4
  15              		.file	"bio.c"
  16              		.text
  17              	.Ltext0:
  18              		.cfi_sections	.debug_frame
  19              		.file 1 "/mnt/c/Users/31740/Desktop/newcore/block/bio.c"
  20              		.section	.text.__spin_unlock,"ax",%progbits
  21              		.align	1
  22              		.syntax unified
  23              		.thumb
  24              		.thumb_func
  26              	__spin_unlock:
  27              	.LVL0:
  28              	.LFB252:
  29              		.file 2 "/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h"
   1:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h **** #ifndef __SPIN_LOCK_H_
   2:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h **** #define __SPIN_LOCK_H_
   3:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h **** 
   4:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h **** #include <linux/sched.h>
   5:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h **** 
   6:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h **** typedef struct { 
   7:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h ****      int flag; 
   8:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h **** } arch_spinlock_t;
   9:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h **** 
  10:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h **** static int __spin_init(arch_spinlock_t *lock) 
  11:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h **** {
  12:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h ****     lock->flag = 0;
  13:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h **** }
  14:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h **** 
  15:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h **** static int __spin_lock(arch_spinlock_t *lock) {
  16:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h **** 
  17:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h ****     stop_all_scheduler();
  18:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h ****     if(lock->flag == 0){
  19:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h ****           lock->flag = 1;  
  20:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h ****           start_all_scheduler();
  21:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h ****         return 1;
  22:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h ****     }
  23:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h ****     else
  24:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h ****     {
  25:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h ****         start_all_scheduler();
  26:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h ****         return 0;
  27:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h ****     }
  28:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h **** }
  29:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h **** 
ARM GAS  /tmp/cctjQXNb.s 			page 2


  30:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h **** static void  __spin_unlock( arch_spinlock_t *lock ){
  30              		.loc 2 30 52 view -0
  31              		.cfi_startproc
  32              		@ args = 0, pretend = 0, frame = 0
  33              		@ frame_needed = 0, uses_anonymous_args = 0
  34              		@ link register save eliminated.
  31:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h ****     lock->flag = 0;
  35              		.loc 2 31 5 view .LVU1
  36              		.loc 2 31 16 is_stmt 0 view .LVU2
  37 0000 0023     		movs	r3, #0
  38 0002 0360     		str	r3, [r0]
  32:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h **** }
  39              		.loc 2 32 1 view .LVU3
  40 0004 7047     		bx	lr
  41              		.cfi_endproc
  42              	.LFE252:
  44              		.section	.text.spin_unlock,"ax",%progbits
  45              		.align	1
  46              		.syntax unified
  47              		.thumb
  48              		.thumb_func
  50              	spin_unlock:
  51              	.LVL1:
  52              	.LFB255:
  53              		.file 3 "/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h"
   1:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h **** #ifndef __SPINLOCK_H__
   2:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h **** #define __SPINLOCK_H__
   3:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h **** 
   4:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h **** #include <linux/types.h>
   5:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h **** #include <linux/spinlock_types.h>
   6:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h **** #include <linux/sched.h>
   7:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h **** 
   8:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h **** 
   9:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h **** 
  10:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h **** static void spin_lock_init(spinlock_t* lock){
  11:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h ****     __spin_init(&lock->rlock.raw_lock);
  12:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h **** }
  13:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h **** 
  14:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h **** static void spin_lock(spinlock_t* lock)
  15:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h **** {  
  16:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h ****     while (1)
  17:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h ****     {
  18:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h ****         if(__spin_lock(&lock->rlock.raw_lock) == 1){
  19:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h ****             lock->owner = get_current_task();
  20:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h ****             break;
  21:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h ****         }
  22:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h ****         else  if(lock->owner == get_current_task()){  //å¦‚æžœå·²ç»è¢«é”ä½ä½†æ˜¯é”æ˜¯è‡ªå·±çš„ï
  23:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h ****             return;   
  24:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h ****         }
  25:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h ****         else{
  26:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h ****             __delay(5); //ä¸»åŠ¨è®©å‡ºæ—¶é—´ç‰‡
  27:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h ****         }
  28:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h ****     }
  29:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h **** }
  30:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h **** 
  31:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h **** static void spin_unlock(spinlock_t* lock)
  32:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h **** {
ARM GAS  /tmp/cctjQXNb.s 			page 3


  54              		.loc 3 32 1 is_stmt 1 view -0
  55              		.cfi_startproc
  56              		@ args = 0, pretend = 0, frame = 0
  57              		@ frame_needed = 0, uses_anonymous_args = 0
  58              		.loc 3 32 1 is_stmt 0 view .LVU5
  59 0000 08B5     		push	{r3, lr}
  60              	.LCFI0:
  61              		.cfi_def_cfa_offset 8
  62              		.cfi_offset 3, -8
  63              		.cfi_offset 14, -4
  33:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h ****     __spin_unlock(&lock->rlock.raw_lock);
  64              		.loc 3 33 5 is_stmt 1 view .LVU6
  65 0002 FFF7FEFF 		bl	__spin_unlock
  66              	.LVL2:
  34:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h **** }
  67              		.loc 3 34 1 is_stmt 0 view .LVU7
  68 0006 08BD     		pop	{r3, pc}
  69              		.cfi_endproc
  70              	.LFE255:
  72              		.section	.text.bio_alloc_bioset,"ax",%progbits
  73              		.align	1
  74              		.global	bio_alloc_bioset
  75              		.syntax unified
  76              		.thumb
  77              		.thumb_func
  79              	bio_alloc_bioset:
  80              	.LVL3:
  81              	.LFB1034:
   1:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** #include <linux/kernel.h>
   2:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** #include <linux/string.h>
   3:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** #include <linux/blkdev.h>
   4:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** #include <linux/bio.h>  
   5:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** #include <linux/slab.h>
   6:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** #include <linux/errno.h>
   7:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** #include <linux/spinlock.h>
   8:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** #include <linux/kthread.h>
   9:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** 
  10:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** #define BIO_INLINE_VECS 4
  11:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** 
  12:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** struct bio_set fs_bio_set;
  13:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** 
  14:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** struct bio *bio_alloc_bioset(struct block_device *bdev, unsigned short nr_iovecs,
  15:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     blk_opf_t opf, gfp_t gfp_mask,
  16:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     struct bio_set *bs)
  17:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** {
  82              		.loc 1 17 1 is_stmt 1 view -0
  83              		.cfi_startproc
  84              		@ args = 4, pretend = 0, frame = 0
  85              		@ frame_needed = 0, uses_anonymous_args = 0
  86              		.loc 1 17 1 is_stmt 0 view .LVU9
  87 0000 2DE9F047 		push	{r4, r5, r6, r7, r8, r9, r10, lr}
  88              	.LCFI1:
  89              		.cfi_def_cfa_offset 32
  90              		.cfi_offset 4, -32
  91              		.cfi_offset 5, -28
  92              		.cfi_offset 6, -24
  93              		.cfi_offset 7, -20
ARM GAS  /tmp/cctjQXNb.s 			page 4


  94              		.cfi_offset 8, -16
  95              		.cfi_offset 9, -12
  96              		.cfi_offset 10, -8
  97              		.cfi_offset 14, -4
  98 0004 8046     		mov	r8, r0
  99 0006 0D46     		mov	r5, r1
 100 0008 1746     		mov	r7, r2
 101 000a 9946     		mov	r9, r3
  18:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     struct bio *bio;
 102              		.loc 1 18 5 is_stmt 1 view .LVU10
  19:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     size_t bio_size;
 103              		.loc 1 19 5 view .LVU11
  20:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bool use_inline_vecs = false;
 104              		.loc 1 20 5 view .LVU12
 105              	.LVL4:
  21:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     if (nr_iovecs <= BIO_INLINE_VECS)
 106              		.loc 1 21 5 view .LVU13
 107              		.loc 1 21 8 is_stmt 0 view .LVU14
 108 000c 0429     		cmp	r1, #4
 109 000e 2CD8     		bhi	.L10
  22:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     {
  23:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****         use_inline_vecs = true;
 110              		.loc 1 23 9 is_stmt 1 view .LVU15
 111              	.LVL5:
  24:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****         bio_size = sizeof(struct bio) + sizeof(struct bio_vec) * nr_iovecs;
 112              		.loc 1 24 9 view .LVU16
 113              		.loc 1 24 64 is_stmt 0 view .LVU17
 114 0010 01EB4106 		add	r6, r1, r1, lsl #1
 115 0014 B600     		lsls	r6, r6, #2
 116              		.loc 1 24 18 view .LVU18
 117 0016 4436     		adds	r6, r6, #68
 118              	.LVL6:
  23:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****         bio_size = sizeof(struct bio) + sizeof(struct bio_vec) * nr_iovecs;
 119              		.loc 1 23 25 view .LVU19
 120 0018 4FF0010A 		mov	r10, #1
 121              	.LVL7:
 122              	.L5:
  25:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     } 
  26:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     else bio_size = sizeof(struct bio);  
  27:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bio = kmalloc(bio_size, gfp_mask);
 123              		.loc 1 27 5 is_stmt 1 view .LVU20
 124              	.LBB80:
 125              	.LBI80:
 126              		.file 4 "/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h"
   1:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* SPDX-License-Identifier: GPL-2.0 */
   2:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /*
   3:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Written by Mark Hemment, 1996 (markhe@nextd.demon.co.uk).
   4:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
   5:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * (C) SGI 2006, Christoph Lameter
   6:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * 	Cleaned up and restructured to ease the addition of alternative
   7:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * 	implementations of SLAB allocators.
   8:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * (C) Linux Foundation 2008-2013
   9:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *      Unified interface for all slab allocators
  10:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
  11:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
  12:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifndef _LINUX_SLAB_H
  13:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define	_LINUX_SLAB_H
ARM GAS  /tmp/cctjQXNb.s 			page 5


  14:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
  15:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #include <linux/cache.h>
  16:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #include <linux/overflow.h>
  17:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #include <linux/types.h>
  18:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #include <linux/raid/pq.h>
  19:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #include <linux/gfp_types.h>
  20:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #include <linux/numa.h>
  21:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #include <linux/reciprocal_div.h>
  22:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #include <linux/spinlock.h>
  23:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
  24:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** enum _slab_flag_bits {
  25:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_CONSISTENCY_CHECKS,
  26:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_RED_ZONE,
  27:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_POISON,
  28:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_KMALLOC,
  29:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_HWCACHE_ALIGN,
  30:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_CACHE_DMA,
  31:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_CACHE_DMA32,
  32:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_STORE_USER,
  33:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_PANIC,
  34:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_TYPESAFE_BY_RCU,
  35:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_TRACE,
  36:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_DEBUG_OBJECTS
  37:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_DEBUG_OBJECTS,
  38:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
  39:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_NOLEAKTRACE,
  40:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_NO_MERGE,
  41:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_FAILSLAB
  42:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_FAILSLAB,
  43:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
  44:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_MEMCG
  45:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_ACCOUNT,
  46:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
  47:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_KASAN_GENERIC
  48:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_KASAN,
  49:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
  50:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_NO_USER_FLAGS,
  51:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_KFENCE
  52:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_SKIP_KFENCE,
  53:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
  54:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifndef CONFIG_SLUB_TINY
  55:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_RECLAIM_ACCOUNT,
  56:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
  57:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_OBJECT_POISON,
  58:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_CMPXCHG_DOUBLE,
  59:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_SLAB_OBJ_EXT
  60:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_NO_OBJ_EXT,
  61:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
  62:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	_SLAB_FLAGS_LAST_BIT
  63:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** };
  64:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
  65:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
  66:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
  67:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define __SLAB_FLAG_BIT(nr)	((slab_flags_t __force)(1U << (nr)))
  68:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define __SLAB_FLAG_UNUSED	((slab_flags_t __force)(0U))
  69:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
  70:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /*
ARM GAS  /tmp/cctjQXNb.s 			page 6


  71:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Flags to pass to kmem_cache_create().
  72:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * The ones marked DEBUG need CONFIG_SLUB_DEBUG enabled, otherwise are no-op
  73:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
  74:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* DEBUG: Perform (expensive) checks on alloc/free */
  75:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_CONSISTENCY_CHECKS	__SLAB_FLAG_BIT(_SLAB_CONSISTENCY_CHECKS)
  76:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* DEBUG: Red zone objs in a cache */
  77:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_RED_ZONE		__SLAB_FLAG_BIT(_SLAB_RED_ZONE)
  78:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* DEBUG: Poison objects */
  79:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_POISON		__SLAB_FLAG_BIT(_SLAB_POISON)
  80:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* Indicate a kmalloc slab */
  81:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_KMALLOC		__SLAB_FLAG_BIT(_SLAB_KMALLOC)
  82:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /**
  83:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * define SLAB_HWCACHE_ALIGN - Align objects on cache line boundaries.
  84:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
  85:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Sufficiently large objects are aligned on cache line boundary. For object
  86:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * size smaller than a half of cache line size, the alignment is on the half of
  87:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * cache line size. In general, if object size is smaller than 1/2^n of cache
  88:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * line size, the alignment is adjusted to 1/2^n.
  89:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
  90:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * If explicit alignment is also requested by the respective
  91:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * &struct kmem_cache_args field, the greater of both is alignments is applied.
  92:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
  93:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_HWCACHE_ALIGN	__SLAB_FLAG_BIT(_SLAB_HWCACHE_ALIGN)
  94:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* Use GFP_DMA memory */
  95:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_CACHE_DMA		__SLAB_FLAG_BIT(_SLAB_CACHE_DMA)
  96:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* Use GFP_DMA32 memory */
  97:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_CACHE_DMA32	__SLAB_FLAG_BIT(_SLAB_CACHE_DMA32)
  98:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* DEBUG: Store the last owner for bug hunting */
  99:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_STORE_USER		__SLAB_FLAG_BIT(_SLAB_STORE_USER)
 100:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* Panic if kmem_cache_create() fails */
 101:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_PANIC		__SLAB_FLAG_BIT(_SLAB_PANIC)
 102:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /**
 103:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * define SLAB_TYPESAFE_BY_RCU - **WARNING** READ THIS!
 104:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 105:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * This delays freeing the SLAB page by a grace period, it does _NOT_
 106:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * delay object freeing. This means that if you do kmem_cache_free()
 107:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * that memory location is free to be reused at any time. Thus it may
 108:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * be possible to see another object there in the same RCU grace period.
 109:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 110:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * This feature only ensures the memory location backing the object
 111:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * stays valid, the trick to using this is relying on an independent
 112:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * object validation pass. Something like:
 113:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 114:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * ::
 115:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 116:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *  begin:
 117:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *   rcu_read_lock();
 118:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *   obj = lockless_lookup(key);
 119:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *   if (obj) {
 120:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *     if (!try_get_ref(obj)) // might fail for free objects
 121:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *       rcu_read_unlock();
 122:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *       goto begin;
 123:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 124:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *     if (obj->key != key) { // not the object we expected
 125:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *       put_ref(obj);
 126:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *       rcu_read_unlock();
 127:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *       goto begin;
ARM GAS  /tmp/cctjQXNb.s 			page 7


 128:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *     }
 129:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *   }
 130:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *  rcu_read_unlock();
 131:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 132:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * This is useful if we need to approach a kernel structure obliquely,
 133:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * from its address obtained without the usual locking. We can lock
 134:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * the structure to stabilize it and check it's still at the given address,
 135:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * only if we can be sure that the memory has not been meanwhile reused
 136:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * for some other kind of object (which our subsystem's lock might corrupt).
 137:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 138:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * rcu_read_lock before reading the address, then rcu_read_unlock after
 139:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * taking the spinlock within the structure expected at that address.
 140:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 141:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Note that it is not possible to acquire a lock within a structure
 142:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * allocated with SLAB_TYPESAFE_BY_RCU without first acquiring a reference
 143:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * as described above.  The reason is that SLAB_TYPESAFE_BY_RCU pages
 144:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * are not zeroed before being given to the slab, which means that any
 145:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * locks must be initialized after each and every kmem_struct_alloc().
 146:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Alternatively, make the ctor passed to kmem_cache_create() initialize
 147:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * the locks at page-allocation time, as is done in __i915_request_ctor(),
 148:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * sighand_ctor(), and anon_vma_ctor().  Such a ctor permits readers
 149:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * to safely acquire those ctor-initialized locks under rcu_read_lock()
 150:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * protection.
 151:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 152:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Note that SLAB_TYPESAFE_BY_RCU was originally named SLAB_DESTROY_BY_RCU.
 153:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
 154:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_TYPESAFE_BY_RCU	__SLAB_FLAG_BIT(_SLAB_TYPESAFE_BY_RCU)
 155:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* Trace allocations and frees */
 156:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_TRACE		__SLAB_FLAG_BIT(_SLAB_TRACE)
 157:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 158:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* Flag to prevent checks on free */
 159:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_DEBUG_OBJECTS
 160:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** # define SLAB_DEBUG_OBJECTS	__SLAB_FLAG_BIT(_SLAB_DEBUG_OBJECTS)
 161:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #else
 162:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** # define SLAB_DEBUG_OBJECTS	__SLAB_FLAG_UNUSED
 163:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
 164:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 165:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* Avoid kmemleak tracing */
 166:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_NOLEAKTRACE	__SLAB_FLAG_BIT(_SLAB_NOLEAKTRACE)
 167:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 168:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /*
 169:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Prevent merging with compatible kmem caches. This flag should be used
 170:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * cautiously. Valid use cases:
 171:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 172:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * - caches created for self-tests (e.g. kunit)
 173:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * - general caches created and used by a subsystem, only when a
 174:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *   (subsystem-specific) debug option is enabled
 175:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * - performance critical caches, should be very rare and consulted with slab
 176:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *   maintainers, and not used together with CONFIG_SLUB_TINY
 177:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
 178:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_NO_MERGE		__SLAB_FLAG_BIT(_SLAB_NO_MERGE)
 179:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 180:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* Fault injection mark */
 181:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_FAILSLAB
 182:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** # define SLAB_FAILSLAB		__SLAB_FLAG_BIT(_SLAB_FAILSLAB)
 183:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #else
 184:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** # define SLAB_FAILSLAB		__SLAB_FLAG_UNUSED
ARM GAS  /tmp/cctjQXNb.s 			page 8


 185:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
 186:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /**
 187:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * define SLAB_ACCOUNT - Account allocations to memcg.
 188:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 189:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * All object allocations from this cache will be memcg accounted, regardless of
 190:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * __GFP_ACCOUNT being or not being passed to individual allocations.
 191:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
 192:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_MEMCG
 193:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** # define SLAB_ACCOUNT		__SLAB_FLAG_BIT(_SLAB_ACCOUNT)
 194:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #else
 195:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** # define SLAB_ACCOUNT		__SLAB_FLAG_UNUSED
 196:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
 197:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 198:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_KASAN_GENERIC
 199:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_KASAN		__SLAB_FLAG_BIT(_SLAB_KASAN)
 200:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #else
 201:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_KASAN		__SLAB_FLAG_UNUSED
 202:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
 203:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 204:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /*
 205:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Ignore user specified debugging flags.
 206:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Intended for caches created for self-tests so they have only flags
 207:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * specified in the code and other flags are ignored.
 208:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
 209:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_NO_USER_FLAGS	__SLAB_FLAG_BIT(_SLAB_NO_USER_FLAGS)
 210:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 211:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_KFENCE
 212:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_SKIP_KFENCE	__SLAB_FLAG_BIT(_SLAB_SKIP_KFENCE)
 213:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #else
 214:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_SKIP_KFENCE	__SLAB_FLAG_UNUSED
 215:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
 216:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 217:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* The following flags affect the page allocator grouping pages by mobility */
 218:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /**
 219:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * define SLAB_RECLAIM_ACCOUNT - Objects are reclaimable.
 220:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 221:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Use this flag for caches that have an associated shrinker. As a result, slab
 222:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * pages are allocated with __GFP_RECLAIMABLE, which affects grouping pages by
 223:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * mobility, and are accounted in SReclaimable counter in /proc/meminfo
 224:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
 225:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifndef CONFIG_SLUB_TINY
 226:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_RECLAIM_ACCOUNT	__SLAB_FLAG_BIT(_SLAB_RECLAIM_ACCOUNT)
 227:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #else
 228:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_RECLAIM_ACCOUNT	__SLAB_FLAG_UNUSED
 229:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
 230:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_TEMPORARY		SLAB_RECLAIM_ACCOUNT	/* Objects are short-lived */
 231:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 232:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /* Slab created using create_boot_cache */
 233:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_SLAB_OBJ_EXT
 234:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_NO_OBJ_EXT		__SLAB_FLAG_BIT(_SLAB_NO_OBJ_EXT)
 235:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #else
 236:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define SLAB_NO_OBJ_EXT		__SLAB_FLAG_UNUSED
 237:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
 238:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 239:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /*
 240:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * freeptr_t represents a SLUB freelist pointer, which might be encoded
 241:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * and not dereferenceable if CONFIG_SLAB_FREELIST_HARDENED is enabled.
ARM GAS  /tmp/cctjQXNb.s 			page 9


 242:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
 243:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** typedef struct { unsigned long v; } freeptr_t;
 244:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 245:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /*
 246:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * ZERO_SIZE_PTR will be returned for zero sized kmalloc requests.
 247:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 248:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Dereferencing ZERO_SIZE_PTR will lead to a distinct access fault.
 249:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  *
 250:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * ZERO_SIZE_PTR can be passed to kfree though in the same way that NULL can.
 251:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  * Both make kfree a no-op.
 252:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h ****  */
 253:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define ZERO_SIZE_PTR ((void *)16)
 254:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 255:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define ZERO_OR_NULL_PTR(x) ((unsigned long)(x) <= \
 256:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 				(unsigned long)ZERO_SIZE_PTR)
 257:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 258:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 259:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 260:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 261:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 262:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_SLUB_CPU_PARTIAL
 263:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define slub_percpu_partial(c)			((c)->partial)
 264:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 265:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define slub_set_percpu_partial(c, p)		\
 266:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** ({						\
 267:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	slub_percpu_partial(c) = (p)->next;	\
 268:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** })
 269:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 270:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define slub_percpu_partial_read_once(c)	READ_ONCE(slub_percpu_partial(c))
 271:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #else
 272:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define slub_percpu_partial(c)			NULL
 273:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 274:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define slub_set_percpu_partial(c, p)
 275:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 276:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define slub_percpu_partial_read_once(c)	NULL
 277:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 278:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 279:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif // CONFIG_SLUB_CPU_PARTIAL
 280:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 281:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** /*
 282:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	* Word size structure that can be atomically updated or read and that
 283:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	* contains both the order and the number of objects that a slab of the
 284:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	* given order would contain.
 285:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	*/				
 286:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** struct kmem_cache_order_objects {
 287:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	unsigned int x;
 288:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** };
 289:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 290:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** struct kmem_cache_node {
 291:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	spinlock_t list_lock;
 292:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	unsigned long nr_partial;
 293:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	struct list_head partial;
 294:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #ifdef CONFIG_SLUB_DEBUG
 295:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	atomic_long_t nr_slabs;
 296:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	atomic_long_t total_objects;
 297:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	struct list_head full;
 298:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #endif
ARM GAS  /tmp/cctjQXNb.s 			page 10


 299:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** };
 300:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 301:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** struct kmem_cache {
 302:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#ifndef CONFIG_SLUB_TINY
 303:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	//	struct kmem_cache_cpu __percpu *cpu_slab;
 304:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#endif
 305:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		/* Used for retrieving partial slabs, etc. */
 306:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		slab_flags_t flags;
 307:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned long min_partial;
 308:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int size;		/* Object size including metadata */
 309:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int object_size;	/* Object size without metadata */
 310:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		struct reciprocal_value reciprocal_size;
 311:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int offset;		/* Free pointer offset */
 312:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#ifdef CONFIG_SLUB_CPU_PARTIAL
 313:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		/* Number of per cpu partial objects to keep around */
 314:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int cpu_partial;
 315:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		/* Number of per cpu partial slabs to keep around */
 316:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int cpu_partial_slabs;
 317:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#endif
 318:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		struct kmem_cache_order_objects oo;
 319:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	
 320:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		/* Allocation and freeing of slabs */
 321:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		struct kmem_cache_order_objects min;
 322:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		gfp_t allocflags;		/* gfp flags to use on each alloc */
 323:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		int refcount;			/* Refcount for slab cache destroy */
 324:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		void (*ctor)(void *object);	/* Object constructor */
 325:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int inuse;		/* Offset to metadata */
 326:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int align;		/* Alignment */
 327:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int red_left_pad;	/* Left redzone padding size */
 328:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		const char *name;		/* Name (only for display!) */
 329:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		struct list_head list;		/* List of slab caches */
 330:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#ifdef CONFIG_SYSFS
 331:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		struct kobject kobj;		/* For sysfs */
 332:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#endif
 333:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#ifdef CONFIG_SLAB_FREELIST_HARDENED
 334:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned long random;
 335:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#endif
 336:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	
 337:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#ifdef CONFIG_NUMA
 338:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		/*
 339:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 			* Defragmentation by allocating from a remote node.
 340:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 			*/
 341:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int remote_node_defrag_ratio;
 342:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#endif
 343:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	
 344:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#ifdef CONFIG_SLAB_FREELIST_RANDOM
 345:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int *random_seq;
 346:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#endif
 347:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	
 348:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#ifdef CONFIG_KASAN_GENERIC
 349:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		struct kasan_cache kasan_info;
 350:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#endif
 351:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	
 352:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#ifdef CONFIG_HARDENED_USERCOPY
 353:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int useroffset;	/* Usercopy region offset */
 354:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		unsigned int usersize;		/* Usercopy region size */
 355:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	#endif
ARM GAS  /tmp/cctjQXNb.s 			page 11


 356:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	
 357:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 		struct kmem_cache_node *node[MAX_NUMNODES];
 358:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	};
 359:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 					
 360:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 361:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 362:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 363:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 364:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** #define KMALLOC_WAIT 1
 365:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 366:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 367:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** extern void* __smalloc__(u32 size, gfp_t flags);
 368:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** extern void  __sfree__(void* addr);
 369:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 370:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 371:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** static void inline *vmalloc(unsigned long size){
 372:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	return __smalloc__(size,GFP_TRANSHUGE_LIGHT);
 373:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** }
 374:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 375:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** static void inline vfree(void *addr){
 376:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	__sfree__(addr);
 377:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** }
 378:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 379:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** static void inline *kmalloc(size_t size, gfp_t flags){
 127              		.loc 4 379 21 view .LVU21
 128              	.LBB81:
 380:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	return __smalloc__((u32)size,flags);
 129              		.loc 4 380 2 view .LVU22
 130              		.loc 4 380 9 is_stmt 0 view .LVU23
 131 001c 4946     		mov	r1, r9
 132              	.LVL8:
 133              		.loc 4 380 9 view .LVU24
 134 001e 3046     		mov	r0, r6
 135              	.LVL9:
 136              		.loc 4 380 9 view .LVU25
 137 0020 FFF7FEFF 		bl	__smalloc__
 138              	.LVL10:
 139              		.loc 4 380 9 view .LVU26
 140              	.LBE81:
 141              	.LBE80:
  28:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     if (!bio) return NULL;
 142              		.loc 1 28 5 is_stmt 1 view .LVU27
 143              		.loc 1 28 8 is_stmt 0 view .LVU28
 144 0024 0446     		mov	r4, r0
 145 0026 E8B1     		cbz	r0, .L4
  29:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     memset(bio, 0, bio_size);
 146              		.loc 1 29 5 is_stmt 1 view .LVU29
 147 0028 3246     		mov	r2, r6
 148 002a 0021     		movs	r1, #0
 149 002c FFF7FEFF 		bl	memset
 150              	.LVL11:
  30:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     if (use_inline_vecs) 
 151              		.loc 1 30 5 view .LVU30
 152              		.loc 1 30 8 is_stmt 0 view .LVU31
 153 0030 BAF1000F 		cmp	r10, #0
 154 0034 1DD0     		beq	.L7
  31:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     {
ARM GAS  /tmp/cctjQXNb.s 			page 12


  32:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****         bio->bi_io_vec   = bio->bi_inline_vecs;
 155              		.loc 1 32 9 is_stmt 1 view .LVU32
 156              		.loc 1 32 28 is_stmt 0 view .LVU33
 157 0036 04F14403 		add	r3, r4, #68
 158              		.loc 1 32 26 view .LVU34
 159 003a E363     		str	r3, [r4, #60]
  33:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****         bio->bi_max_vecs = nr_iovecs;
 160              		.loc 1 33 9 is_stmt 1 view .LVU35
 161              		.loc 1 33 26 is_stmt 0 view .LVU36
 162 003c E586     		strh	r5, [r4, #54]	@ movhi
 163              	.LVL12:
 164              	.L8:
  34:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     }
  35:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     else 
  36:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     {
  37:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****         bio->bi_io_vec = kmalloc_array(nr_iovecs, sizeof(struct bio_vec), gfp_mask);
  38:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****         if (!bio->bi_io_vec) {
  39:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****             kfree(bio);
  40:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****             return NULL;
  41:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****         }
  42:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****         bio->bi_max_vecs = nr_iovecs;
  43:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     }
  44:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bio->bi_next   = NULL;
 165              		.loc 1 44 5 is_stmt 1 view .LVU37
 166              		.loc 1 44 20 is_stmt 0 view .LVU38
 167 003e 0023     		movs	r3, #0
 168 0040 2360     		str	r3, [r4]
  45:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bio->bi_bdev   = NULL;
 169              		.loc 1 45 5 is_stmt 1 view .LVU39
 170              		.loc 1 45 20 is_stmt 0 view .LVU40
 171 0042 6360     		str	r3, [r4, #4]
  46:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bio->bi_opf    = 0;
 172              		.loc 1 46 5 is_stmt 1 view .LVU41
 173              		.loc 1 46 20 is_stmt 0 view .LVU42
 174 0044 A360     		str	r3, [r4, #8]
  47:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bio->bi_flags  = 0;
 175              		.loc 1 47 5 is_stmt 1 view .LVU43
 176              		.loc 1 47 20 is_stmt 0 view .LVU44
 177 0046 A381     		strh	r3, [r4, #12]	@ movhi
  48:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bio->bi_status = BLK_STS_OK;
 178              		.loc 1 48 5 is_stmt 1 view .LVU45
 179              		.loc 1 48 20 is_stmt 0 view .LVU46
 180 0048 6374     		strb	r3, [r4, #17]
  49:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     atomic_set(&bio->__bi_remaining, 1);
 181              		.loc 1 49 5 is_stmt 1 view .LVU47
 182              	.LVL13:
 183              	.LBB82:
 184              	.LBI82:
 185              		.file 5 "/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h"
   1:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** // SPDX-License-Identifier: GPL-2.0
   2:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
   3:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** // Generated by scripts/atomic/gen-atomic-instrumented.sh 
   4:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** // DO NOT MODIFY THIS FILE DIRECTLY
   5:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
   6:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /*
   7:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * This file provoides atomic operations with explicit instrumentation (e.g.
   8:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * KASAN, KCSAN), which should be used unless it is necessary to avoid
ARM GAS  /tmp/cctjQXNb.s 			page 13


   9:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * instrumentation. Where it is necessary to aovid instrumenation, the
  10:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * raw_atomic*() operations should be used.
  11:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
  12:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** #ifndef _LINUX_ATOMIC_INSTRUMENTED_H
  13:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** #define _LINUX_ATOMIC_INSTRUMENTED_H
  14:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
  15:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** #include <linux/build_bug.h>
  16:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** #include <linux/compiler.h>
  17:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** #include <linux/instrumented.h>
  18:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
  19:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
  20:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_read() - atomic load with relaxed ordering
  21:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
  22:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
  23:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically loads the value of @v with relaxed ordering.
  24:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
  25:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_read() there.
  26:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
  27:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The value loaded from @v.
  28:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
  29:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
  30:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_read(const atomic_t *v)
  31:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
  32:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read(v, sizeof(*v));
  33:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_read(v);
  34:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
  35:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
  36:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
  37:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_read_acquire() - atomic load with acquire ordering
  38:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
  39:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
  40:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically loads the value of @v with acquire ordering.
  41:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
  42:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_read_acquire() there.
  43:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
  44:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The value loaded from @v.
  45:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
  46:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
  47:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_read_acquire(const atomic_t *v)
  48:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
  49:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read(v, sizeof(*v));
  50:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_read_acquire(v);
  51:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
  52:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
  53:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
  54:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_set() - atomic set with relaxed ordering
  55:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
  56:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to assign
  57:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
  58:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically sets @v to @i with relaxed ordering.
  59:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
  60:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_set() there.
  61:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
  62:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: Nothing.
  63:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
  64:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline void
  65:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_set(atomic_t *v, int i)
ARM GAS  /tmp/cctjQXNb.s 			page 14


 186              		.loc 5 65 1 view .LVU48
  66:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
  67:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_write(v, sizeof(*v));
 187              		.loc 5 67 2 view .LVU49
  68:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	raw_atomic_set(v, i);
 188              		.loc 5 68 2 view .LVU50
 189              	.LBB83:
 190              	.LBI83:
 191              		.file 6 "/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h"
   1:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** // SPDX-License-Identifier: GPL-2.0
   2:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
   3:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** // Generated by scripts/atomic/gen-atomic-fallback.sh
   4:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** // DO NOT MODIFY THIS FILE DIRECTLY
   5:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
   6:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #ifndef _LINUX_ATOMIC_FALLBACK_H
   7:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define _LINUX_ATOMIC_FALLBACK_H
   8:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
   9:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #include <linux/compiler.h>
  10:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
  11:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_xchg)
  12:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg arch_xchg
  13:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_xchg_relaxed)
  14:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg(...) \
  15:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_fence(arch_xchg, __VA_ARGS__)
  16:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
  17:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_xchg_not_implemented(void);
  18:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg(...) raw_xchg_not_implemented()
  19:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
  20:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
  21:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_xchg_acquire)
  22:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_acquire arch_xchg_acquire
  23:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_xchg_relaxed)
  24:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_acquire(...) \
  25:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_acquire(arch_xchg, __VA_ARGS__)
  26:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_xchg)
  27:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_acquire arch_xchg
  28:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
  29:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_xchg_acquire_not_implemented(void);
  30:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_acquire(...) raw_xchg_acquire_not_implemented()
  31:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
  32:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
  33:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_xchg_release)
  34:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_release arch_xchg_release
  35:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_xchg_relaxed)
  36:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_release(...) \
  37:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_release(arch_xchg, __VA_ARGS__)
  38:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_xchg)
  39:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_release arch_xchg
  40:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
  41:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_xchg_release_not_implemented(void);
  42:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_release(...) raw_xchg_release_not_implemented()
  43:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
  44:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
  45:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_xchg_relaxed)
  46:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_relaxed arch_xchg_relaxed
  47:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_xchg)
  48:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_relaxed arch_xchg
ARM GAS  /tmp/cctjQXNb.s 			page 15


  49:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
  50:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_xchg_relaxed_not_implemented(void);
  51:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_xchg_relaxed(...) raw_xchg_relaxed_not_implemented()
  52:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
  53:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
  54:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg)
  55:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg arch_cmpxchg
  56:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg_relaxed)
  57:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg(...) \
  58:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_fence(arch_cmpxchg, __VA_ARGS__)
  59:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
  60:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg_not_implemented(void);
  61:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg(...) raw_cmpxchg_not_implemented()
  62:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
  63:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
  64:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg_acquire)
  65:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_acquire arch_cmpxchg_acquire
  66:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg_relaxed)
  67:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_acquire(...) \
  68:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_acquire(arch_cmpxchg, __VA_ARGS__)
  69:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg)
  70:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_acquire arch_cmpxchg
  71:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
  72:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg_acquire_not_implemented(void);
  73:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_acquire(...) raw_cmpxchg_acquire_not_implemented()
  74:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
  75:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
  76:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg_release)
  77:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_release arch_cmpxchg_release
  78:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg_relaxed)
  79:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_release(...) \
  80:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_release(arch_cmpxchg, __VA_ARGS__)
  81:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg)
  82:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_release arch_cmpxchg
  83:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
  84:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg_release_not_implemented(void);
  85:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_release(...) raw_cmpxchg_release_not_implemented()
  86:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
  87:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
  88:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg_relaxed)
  89:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_relaxed arch_cmpxchg_relaxed
  90:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg)
  91:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_relaxed arch_cmpxchg
  92:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
  93:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg_relaxed_not_implemented(void);
  94:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_relaxed(...) raw_cmpxchg_relaxed_not_implemented()
  95:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
  96:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
  97:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg64)
  98:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64 arch_cmpxchg64
  99:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg64_relaxed)
 100:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64(...) \
 101:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_fence(arch_cmpxchg64, __VA_ARGS__)
 102:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 103:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg64_not_implemented(void);
 104:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64(...) raw_cmpxchg64_not_implemented()
 105:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
ARM GAS  /tmp/cctjQXNb.s 			page 16


 106:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 107:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg64_acquire)
 108:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_acquire arch_cmpxchg64_acquire
 109:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg64_relaxed)
 110:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_acquire(...) \
 111:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_acquire(arch_cmpxchg64, __VA_ARGS__)
 112:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg64)
 113:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_acquire arch_cmpxchg64
 114:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 115:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg64_acquire_not_implemented(void);
 116:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_acquire(...) raw_cmpxchg64_acquire_not_implemented()
 117:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 118:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 119:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg64_release)
 120:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_release arch_cmpxchg64_release
 121:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg64_relaxed)
 122:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_release(...) \
 123:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_release(arch_cmpxchg64, __VA_ARGS__)
 124:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg64)
 125:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_release arch_cmpxchg64
 126:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 127:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg64_release_not_implemented(void);
 128:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_release(...) raw_cmpxchg64_release_not_implemented()
 129:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 130:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 131:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg64_relaxed)
 132:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_relaxed arch_cmpxchg64_relaxed
 133:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg64)
 134:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_relaxed arch_cmpxchg64
 135:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 136:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg64_relaxed_not_implemented(void);
 137:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_relaxed(...) raw_cmpxchg64_relaxed_not_implemented()
 138:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 139:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 140:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg128)
 141:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128 arch_cmpxchg128
 142:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg128_relaxed)
 143:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128(...) \
 144:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_fence(arch_cmpxchg128, __VA_ARGS__)
 145:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 146:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg128_not_implemented(void);
 147:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128(...) raw_cmpxchg128_not_implemented()
 148:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 149:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 150:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg128_acquire)
 151:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_acquire arch_cmpxchg128_acquire
 152:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg128_relaxed)
 153:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_acquire(...) \
 154:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_acquire(arch_cmpxchg128, __VA_ARGS__)
 155:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg128)
 156:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_acquire arch_cmpxchg128
 157:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 158:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg128_acquire_not_implemented(void);
 159:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_acquire(...) raw_cmpxchg128_acquire_not_implemented()
 160:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 161:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 162:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg128_release)
ARM GAS  /tmp/cctjQXNb.s 			page 17


 163:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_release arch_cmpxchg128_release
 164:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg128_relaxed)
 165:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_release(...) \
 166:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_release(arch_cmpxchg128, __VA_ARGS__)
 167:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg128)
 168:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_release arch_cmpxchg128
 169:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 170:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg128_release_not_implemented(void);
 171:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_release(...) raw_cmpxchg128_release_not_implemented()
 172:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 173:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 174:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_cmpxchg128_relaxed)
 175:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_relaxed arch_cmpxchg128_relaxed
 176:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_cmpxchg128)
 177:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_relaxed arch_cmpxchg128
 178:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 179:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** extern void raw_cmpxchg128_relaxed_not_implemented(void);
 180:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_relaxed(...) raw_cmpxchg128_relaxed_not_implemented()
 181:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 182:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 183:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 184:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 185:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 186:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 187:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 188:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 189:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg)
 190:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg arch_try_cmpxchg
 191:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg_relaxed)
 192:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg(...) \
 193:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_fence(arch_try_cmpxchg, __VA_ARGS__)
 194:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 195:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg(_ptr, _oldp, _new) \
 196:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 197:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 198:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg((_ptr), ___o, (_new)); \
 199:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 200:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 201:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 202:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 203:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 204:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 205:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg_acquire)
 206:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_acquire arch_try_cmpxchg_acquire
 207:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg_relaxed)
 208:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_acquire(...) \
 209:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_acquire(arch_try_cmpxchg, __VA_ARGS__)
 210:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg)
 211:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_acquire arch_try_cmpxchg
 212:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 213:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_acquire(_ptr, _oldp, _new) \
 214:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 215:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 216:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg_acquire((_ptr), ___o, (_new)); \
 217:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 218:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 219:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
ARM GAS  /tmp/cctjQXNb.s 			page 18


 220:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 221:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 222:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 223:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg_release)
 224:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_release arch_try_cmpxchg_release
 225:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg_relaxed)
 226:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_release(...) \
 227:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_release(arch_try_cmpxchg, __VA_ARGS__)
 228:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg)
 229:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_release arch_try_cmpxchg
 230:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 231:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_release(_ptr, _oldp, _new) \
 232:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 233:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 234:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg_release((_ptr), ___o, (_new)); \
 235:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 236:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 237:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 238:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 239:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 240:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 241:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg_relaxed)
 242:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_relaxed arch_try_cmpxchg_relaxed
 243:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg)
 244:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_relaxed arch_try_cmpxchg
 245:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 246:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_relaxed(_ptr, _oldp, _new) \
 247:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 248:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 249:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg_relaxed((_ptr), ___o, (_new)); \
 250:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 251:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 252:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 253:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 254:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 255:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 256:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg64)
 257:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64 arch_try_cmpxchg64
 258:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg64_relaxed)
 259:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64(...) \
 260:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_fence(arch_try_cmpxchg64, __VA_ARGS__)
 261:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 262:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64(_ptr, _oldp, _new) \
 263:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 264:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 265:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg64((_ptr), ___o, (_new)); \
 266:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 267:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 268:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 269:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 270:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 271:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 272:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg64_acquire)
 273:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_acquire arch_try_cmpxchg64_acquire
 274:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg64_relaxed)
 275:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_acquire(...) \
 276:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_acquire(arch_try_cmpxchg64, __VA_ARGS__)
ARM GAS  /tmp/cctjQXNb.s 			page 19


 277:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg64)
 278:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_acquire arch_try_cmpxchg64
 279:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 280:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_acquire(_ptr, _oldp, _new) \
 281:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 282:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 283:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg64_acquire((_ptr), ___o, (_new)); \
 284:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 285:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 286:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 287:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 288:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 289:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 290:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg64_release)
 291:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_release arch_try_cmpxchg64_release
 292:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg64_relaxed)
 293:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_release(...) \
 294:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_release(arch_try_cmpxchg64, __VA_ARGS__)
 295:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg64)
 296:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_release arch_try_cmpxchg64
 297:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 298:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_release(_ptr, _oldp, _new) \
 299:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 300:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 301:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg64_release((_ptr), ___o, (_new)); \
 302:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 303:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 304:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 305:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 306:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 307:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 308:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg64_relaxed)
 309:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_relaxed arch_try_cmpxchg64_relaxed
 310:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg64)
 311:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_relaxed arch_try_cmpxchg64
 312:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 313:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_relaxed(_ptr, _oldp, _new) \
 314:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 315:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 316:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg64_relaxed((_ptr), ___o, (_new)); \
 317:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 318:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 319:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 320:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 321:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 322:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 323:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg128)
 324:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128 arch_try_cmpxchg128
 325:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg128_relaxed)
 326:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128(...) \
 327:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_fence(arch_try_cmpxchg128, __VA_ARGS__)
 328:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 329:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128(_ptr, _oldp, _new) \
 330:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 331:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 332:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg128((_ptr), ___o, (_new)); \
 333:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
ARM GAS  /tmp/cctjQXNb.s 			page 20


 334:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 335:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 336:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 337:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 338:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 339:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg128_acquire)
 340:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_acquire arch_try_cmpxchg128_acquire
 341:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg128_relaxed)
 342:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_acquire(...) \
 343:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_acquire(arch_try_cmpxchg128, __VA_ARGS__)
 344:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg128)
 345:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_acquire arch_try_cmpxchg128
 346:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 347:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_acquire(_ptr, _oldp, _new) \
 348:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 349:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 350:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg128_acquire((_ptr), ___o, (_new)); \
 351:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 352:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 353:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 354:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 355:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 356:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 357:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg128_release)
 358:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_release arch_try_cmpxchg128_release
 359:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg128_relaxed)
 360:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_release(...) \
 361:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_op_release(arch_try_cmpxchg128, __VA_ARGS__)
 362:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg128)
 363:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_release arch_try_cmpxchg128
 364:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 365:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_release(_ptr, _oldp, _new) \
 366:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 367:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 368:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg128_release((_ptr), ___o, (_new)); \
 369:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 370:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 371:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 372:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 373:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 374:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 375:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_try_cmpxchg128_relaxed)
 376:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_relaxed arch_try_cmpxchg128_relaxed
 377:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_try_cmpxchg128)
 378:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_relaxed arch_try_cmpxchg128
 379:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 380:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_relaxed(_ptr, _oldp, _new) \
 381:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 382:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 383:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg128_relaxed((_ptr), ___o, (_new)); \
 384:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 385:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 386:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 387:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 388:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 389:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 390:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg_local arch_cmpxchg_local
ARM GAS  /tmp/cctjQXNb.s 			page 21


 391:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 392:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #ifdef arch_try_cmpxchg_local
 393:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_local arch_try_cmpxchg_local
 394:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 395:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg_local(_ptr, _oldp, _new) \
 396:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 397:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 398:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg_local((_ptr), ___o, (_new)); \
 399:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 400:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 401:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 402:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 403:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 404:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 405:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg64_local arch_cmpxchg64_local
 406:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 407:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #ifdef arch_try_cmpxchg64_local
 408:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_local arch_try_cmpxchg64_local
 409:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 410:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg64_local(_ptr, _oldp, _new) \
 411:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 412:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 413:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg64_local((_ptr), ___o, (_new)); \
 414:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 415:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 416:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 417:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 418:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 419:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 420:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_cmpxchg128_local arch_cmpxchg128_local
 421:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 422:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #ifdef arch_try_cmpxchg128_local
 423:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_local arch_try_cmpxchg128_local
 424:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 425:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_try_cmpxchg128_local(_ptr, _oldp, _new) \
 426:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 427:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 428:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_cmpxchg128_local((_ptr), ___o, (_new)); \
 429:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 430:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 431:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 432:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
 433:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 434:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 435:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_sync_cmpxchg arch_sync_cmpxchg
 436:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 437:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #ifdef arch_sync_try_cmpxchg
 438:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_sync_try_cmpxchg arch_sync_try_cmpxchg
 439:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 440:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #define raw_sync_try_cmpxchg(_ptr, _oldp, _new) \
 441:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** ({ \
 442:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	typeof(*(_ptr)) *___op = (_oldp), ___o = *___op, ___r; \
 443:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	___r = raw_sync_cmpxchg((_ptr), ___o, (_new)); \
 444:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(___r != ___o)) \
 445:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*___op = ___r; \
 446:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	likely(___r == ___o); \
 447:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** })
ARM GAS  /tmp/cctjQXNb.s 			page 22


 448:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 449:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 450:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 451:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_read() - atomic load with relaxed ordering
 452:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 453:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 454:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically loads the value of @v with relaxed ordering.
 455:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 456:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_read() elsewhere.
 457:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 458:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The value loaded from @v.
 459:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 460:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 461:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_read(const atomic_t *v)
 462:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 463:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_read(v);
 464:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 465:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 466:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 467:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_read_acquire() - atomic load with acquire ordering
 468:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 469:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 470:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically loads the value of @v with acquire ordering.
 471:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 472:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_read_acquire() elsewhere.
 473:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 474:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The value loaded from @v.
 475:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 476:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 477:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_read_acquire(const atomic_t *v)
 478:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 479:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_read_acquire)
 480:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_read_acquire(v);
 481:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 482:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
 483:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 484:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (__native_word(atomic_t)) {
 485:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		ret = smp_load_acquire(&(v)->counter);
 486:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	} else {
 487:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		ret = raw_atomic_read(v);
 488:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		__atomic_acquire_fence();
 489:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	}
 490:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 491:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
 492:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 493:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 494:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 495:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 496:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_set() - atomic set with relaxed ordering
 497:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 498:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to assign
 499:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 500:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically sets @v to @i with relaxed ordering.
 501:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 502:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_set() elsewhere.
 503:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 504:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: Nothing.
ARM GAS  /tmp/cctjQXNb.s 			page 23


 505:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 506:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline void
 507:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_set(atomic_t *v, int i)
 192              		.loc 6 507 1 view .LVU51
 193              	.LBB84:
 508:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 509:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	arch_atomic_set(v, i);
 194              		.loc 6 509 2 view .LVU52
 195              		.loc 6 509 2 view .LVU53
 196              	.LBB85:
 197              		.loc 6 509 2 view .LVU54
 198              		.loc 6 509 2 view .LVU55
 199              	.LBE85:
 200              		.loc 6 509 2 discriminator 2 view .LVU56
 201              		.loc 6 509 2 discriminator 2 view .LVU57
 202              		.loc 6 509 2 discriminator 2 view .LVU58
 203 004a 0122     		movs	r2, #1
 204 004c 6261     		str	r2, [r4, #20]
 205              		.loc 6 509 2 discriminator 2 view .LVU59
 206              		.loc 6 509 2 discriminator 2 view .LVU60
 207              	.LVL14:
 208              		.loc 6 509 2 is_stmt 0 discriminator 2 view .LVU61
 209              	.LBE84:
 210              	.LBE83:
 211              	.LBE82:
  50:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     atomic_set(&bio->__bi_cnt, 1);
 212              		.loc 1 50 5 is_stmt 1 view .LVU62
 213              	.LBB86:
 214              	.LBI86:
  65:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 215              		.loc 5 65 1 view .LVU63
  67:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	raw_atomic_set(v, i);
 216              		.loc 5 67 2 view .LVU64
 217              		.loc 5 68 2 view .LVU65
 218              	.LBB87:
 219              	.LBI87:
 507:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 220              		.loc 6 507 1 view .LVU66
 221              	.LBB88:
 222              		.loc 6 509 2 view .LVU67
 223              		.loc 6 509 2 view .LVU68
 224              	.LBB89:
 225              		.loc 6 509 2 view .LVU69
 226              		.loc 6 509 2 view .LVU70
 227              	.LBE89:
 228              		.loc 6 509 2 discriminator 2 view .LVU71
 229              		.loc 6 509 2 discriminator 2 view .LVU72
 230              		.loc 6 509 2 discriminator 2 view .LVU73
 231 004e A263     		str	r2, [r4, #56]
 232              		.loc 6 509 2 discriminator 2 view .LVU74
 233              		.loc 6 509 2 discriminator 2 view .LVU75
 234              	.LVL15:
 235              		.loc 6 509 2 is_stmt 0 discriminator 2 view .LVU76
 236              	.LBE88:
 237              	.LBE87:
 238              	.LBE86:
  51:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bio->bi_iter.bi_sector = 0;
ARM GAS  /tmp/cctjQXNb.s 			page 24


 239              		.loc 1 51 5 is_stmt 1 view .LVU77
 240              		.loc 1 51 28 is_stmt 0 view .LVU78
 241 0050 A361     		str	r3, [r4, #24]
  52:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bio->bi_iter.bi_size   = 0;
 242              		.loc 1 52 5 is_stmt 1 view .LVU79
 243              		.loc 1 52 28 is_stmt 0 view .LVU80
 244 0052 E361     		str	r3, [r4, #28]
  53:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bio->bi_iter.bi_idx    = 0;
 245              		.loc 1 53 5 is_stmt 1 view .LVU81
 246              		.loc 1 53 28 is_stmt 0 view .LVU82
 247 0054 2362     		str	r3, [r4, #32]
  54:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bio->bi_iter.bi_bvec_done = 0;
 248              		.loc 1 54 5 is_stmt 1 view .LVU83
 249              		.loc 1 54 31 is_stmt 0 view .LVU84
 250 0056 6362     		str	r3, [r4, #36]
  55:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bio->bi_vcnt    = 0;
 251              		.loc 1 55 5 is_stmt 1 view .LVU85
 252              		.loc 1 55 21 is_stmt 0 view .LVU86
 253 0058 A386     		strh	r3, [r4, #52]	@ movhi
  56:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bio->bi_end_io  = NULL;
 254              		.loc 1 56 5 is_stmt 1 view .LVU87
 255              		.loc 1 56 21 is_stmt 0 view .LVU88
 256 005a E362     		str	r3, [r4, #44]
  57:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bio->bi_private = NULL;
 257              		.loc 1 57 5 is_stmt 1 view .LVU89
 258              		.loc 1 57 21 is_stmt 0 view .LVU90
 259 005c 2363     		str	r3, [r4, #48]
  58:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bio->bi_bdev = bdev;
 260              		.loc 1 58 5 is_stmt 1 view .LVU91
 261              		.loc 1 58 18 is_stmt 0 view .LVU92
 262 005e C4F80480 		str	r8, [r4, #4]
  59:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bio->bi_opf  = opf;
 263              		.loc 1 59 5 is_stmt 1 view .LVU93
 264              		.loc 1 59 18 is_stmt 0 view .LVU94
 265 0062 A760     		str	r7, [r4, #8]
  60:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     return bio;
 266              		.loc 1 60 5 is_stmt 1 view .LVU95
 267              	.LVL16:
 268              	.L4:
  61:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** }
 269              		.loc 1 61 1 is_stmt 0 view .LVU96
 270 0064 2046     		mov	r0, r4
 271 0066 BDE8F087 		pop	{r4, r5, r6, r7, r8, r9, r10, pc}
 272              	.LVL17:
 273              	.L10:
  20:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     if (nr_iovecs <= BIO_INLINE_VECS)
 274              		.loc 1 20 10 view .LVU97
 275 006a 4FF0000A 		mov	r10, #0
  26:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bio = kmalloc(bio_size, gfp_mask);
 276              		.loc 1 26 19 view .LVU98
 277 006e 4426     		movs	r6, #68
 278 0070 D4E7     		b	.L5
 279              	.LVL18:
 280              	.L7:
  37:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****         if (!bio->bi_io_vec) {
 281              		.loc 1 37 9 is_stmt 1 view .LVU99
 282              	.LBB90:
ARM GAS  /tmp/cctjQXNb.s 			page 25


 283              	.LBI90:
 381:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** }
 382:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 383:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** static void inline kfree(const void *ptr){
 384:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	__sfree__((void*)ptr);
 385:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** }
 386:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 387:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 388:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 
 389:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** static inline void *kmalloc_array(size_t n, size_t size, gfp_t flags){
 284              		.loc 4 389 21 view .LVU100
 285              	.LBB91:
 390:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	return kmalloc(n * size, flags);
 286              		.loc 4 390 2 view .LVU101
 287              		.loc 4 390 9 is_stmt 0 view .LVU102
 288 0072 05EB4500 		add	r0, r5, r5, lsl #1
 289              	.LVL19:
 290              	.LBB92:
 291              	.LBI92:
 379:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	return __smalloc__((u32)size,flags);
 292              		.loc 4 379 21 is_stmt 1 view .LVU103
 293              	.LBB93:
 380:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** }
 294              		.loc 4 380 2 view .LVU104
 380:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** }
 295              		.loc 4 380 9 is_stmt 0 view .LVU105
 296 0076 4946     		mov	r1, r9
 297 0078 8000     		lsls	r0, r0, #2
 298 007a FFF7FEFF 		bl	__smalloc__
 299              	.LVL20:
 300 007e 0646     		mov	r6, r0
 301              	.LVL21:
 380:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** }
 302              		.loc 4 380 9 view .LVU106
 303              	.LBE93:
 304              	.LBE92:
 305              	.LBE91:
 306              	.LBE90:
  37:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****         if (!bio->bi_io_vec) {
 307              		.loc 1 37 24 discriminator 1 view .LVU107
 308 0080 E063     		str	r0, [r4, #60]
  38:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****             kfree(bio);
 309              		.loc 1 38 9 is_stmt 1 view .LVU108
  38:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****             kfree(bio);
 310              		.loc 1 38 12 is_stmt 0 view .LVU109
 311 0082 08B1     		cbz	r0, .L12
  42:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     }
 312              		.loc 1 42 9 is_stmt 1 view .LVU110
  42:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     }
 313              		.loc 1 42 26 is_stmt 0 view .LVU111
 314 0084 E586     		strh	r5, [r4, #54]	@ movhi
 315 0086 DAE7     		b	.L8
 316              	.L12:
  39:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****             return NULL;
 317              		.loc 1 39 13 is_stmt 1 view .LVU112
 318              	.LVL22:
 319              	.LBB94:
ARM GAS  /tmp/cctjQXNb.s 			page 26


 320              	.LBI94:
 383:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	__sfree__((void*)ptr);
 321              		.loc 4 383 20 view .LVU113
 322              	.LBB95:
 384:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** }
 323              		.loc 4 384 2 view .LVU114
 324 0088 2046     		mov	r0, r4
 325 008a FFF7FEFF 		bl	__sfree__
 326              	.LVL23:
 384:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** }
 327              		.loc 4 384 2 is_stmt 0 view .LVU115
 328              	.LBE95:
 329              	.LBE94:
  40:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****         }
 330              		.loc 1 40 13 is_stmt 1 view .LVU116
  40:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****         }
 331              		.loc 1 40 20 is_stmt 0 view .LVU117
 332 008e 3446     		mov	r4, r6
 333              	.LVL24:
  40:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****         }
 334              		.loc 1 40 20 view .LVU118
 335 0090 E8E7     		b	.L4
 336              		.cfi_endproc
 337              	.LFE1034:
 339              		.section	.text.bio_put,"ax",%progbits
 340              		.align	1
 341              		.global	bio_put
 342              		.syntax unified
 343              		.thumb
 344              		.thumb_func
 346              	bio_put:
 347              	.LVL25:
 348              	.LFB1035:
  62:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** EXPORT_SYMBOL(bio_alloc_bioset);
  63:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****  
  64:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** 
  65:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** 
  66:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** void bio_put(struct bio *bio)
  67:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** {
 349              		.loc 1 67 1 is_stmt 1 view -0
 350              		.cfi_startproc
 351              		@ args = 0, pretend = 0, frame = 0
 352              		@ frame_needed = 0, uses_anonymous_args = 0
  68:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     if(!bio)return;
 353              		.loc 1 68 5 view .LVU120
 354              		.loc 1 68 7 is_stmt 0 view .LVU121
 355 0000 C0B1     		cbz	r0, .L17
  67:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     if(!bio)return;
 356              		.loc 1 67 1 view .LVU122
 357 0002 10B5     		push	{r4, lr}
 358              	.LCFI2:
 359              		.cfi_def_cfa_offset 8
 360              		.cfi_offset 4, -8
 361              		.cfi_offset 14, -4
 362 0004 0446     		mov	r4, r0
  69:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     if (atomic_dec_and_test(&bio->__bi_cnt)) {
 363              		.loc 1 69 5 is_stmt 1 view .LVU123
ARM GAS  /tmp/cctjQXNb.s 			page 27


 364              		.loc 1 69 9 is_stmt 0 view .LVU124
 365 0006 00F13803 		add	r3, r0, #56
 366              	.LBB96:
 367              	.LBI96:
  69:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
  70:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
  71:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
  72:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_set_release() - atomic set with release ordering
  73:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
  74:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to assign
  75:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
  76:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically sets @v to @i with release ordering.
  77:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
  78:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_set_release() there.
  79:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
  80:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: Nothing.
  81:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
  82:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline void
  83:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_set_release(atomic_t *v, int i)
  84:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
  85:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
  86:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_write(v, sizeof(*v));
  87:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	raw_atomic_set_release(v, i);
  88:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
  89:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
  90:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
  91:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_add() - atomic add with relaxed ordering
  92:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to add
  93:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
  94:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
  95:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + @i) with relaxed ordering.
  96:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
  97:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_add() there.
  98:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
  99:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: Nothing.
 100:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 101:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline void
 102:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_add(int i, atomic_t *v)
 103:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 104:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 105:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	raw_atomic_add(i, v);
 106:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 107:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 108:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 109:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_add_return() - atomic add with full ordering
 110:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to add
 111:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 112:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 113:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + @i) with full ordering.
 114:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 115:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_add_return() there.
 116:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 117:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 118:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 119:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 120:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_add_return(int i, atomic_t *v)
 121:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
ARM GAS  /tmp/cctjQXNb.s 			page 28


 122:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
 123:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 124:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_add_return(i, v);
 125:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 126:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 127:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 128:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_add_return_acquire() - atomic add with acquire ordering
 129:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to add
 130:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 131:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 132:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + @i) with acquire ordering.
 133:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 134:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_add_return_acquire() there.
 135:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 136:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 137:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 138:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 139:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_add_return_acquire(int i, atomic_t *v)
 140:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 141:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 142:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_add_return_acquire(i, v);
 143:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 144:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 145:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 146:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_add_return_release() - atomic add with release ordering
 147:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to add
 148:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 149:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 150:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + @i) with release ordering.
 151:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 152:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_add_return_release() there.
 153:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 154:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 155:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 156:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 157:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_add_return_release(int i, atomic_t *v)
 158:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 159:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
 160:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 161:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_add_return_release(i, v);
 162:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 163:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 164:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 165:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_add_return_relaxed() - atomic add with relaxed ordering
 166:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to add
 167:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 168:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 169:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + @i) with relaxed ordering.
 170:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 171:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_add_return_relaxed() there.
 172:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 173:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 174:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 175:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 176:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_add_return_relaxed(int i, atomic_t *v)
 177:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 178:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
ARM GAS  /tmp/cctjQXNb.s 			page 29


 179:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_add_return_relaxed(i, v);
 180:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 181:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 182:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 183:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_add() - atomic add with full ordering
 184:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to add
 185:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 186:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 187:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + @i) with full ordering.
 188:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 189:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_add() there.
 190:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 191:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 192:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 193:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 194:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_add(int i, atomic_t *v)
 195:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 196:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
 197:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 198:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_add(i, v);
 199:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 200:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 201:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 202:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_add_acquire() - atomic add with acquire ordering
 203:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to add
 204:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 205:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 206:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + @i) with acquire ordering.
 207:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 208:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_add_acquire() there.
 209:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 210:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 211:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 212:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 213:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_add_acquire(int i, atomic_t *v)
 214:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 215:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 216:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_add_acquire(i, v);
 217:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 218:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 219:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 220:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_add_release() - atomic add with release ordering
 221:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to add
 222:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 223:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 224:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + @i) with release ordering.
 225:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 226:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_add_release() there.
 227:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 228:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 229:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 230:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 231:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_add_release(int i, atomic_t *v)
 232:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 233:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
 234:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 235:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_add_release(i, v);
ARM GAS  /tmp/cctjQXNb.s 			page 30


 236:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 237:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 238:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 239:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_add_relaxed() - atomic add with relaxed ordering
 240:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to add
 241:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 242:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 243:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + @i) with relaxed ordering.
 244:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 245:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_add_relaxed() there.
 246:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 247:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 248:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 249:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 250:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_add_relaxed(int i, atomic_t *v)
 251:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 252:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 253:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_add_relaxed(i, v);
 254:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 255:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 256:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 257:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_sub() - atomic subtract with relaxed ordering
 258:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to subtract
 259:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 260:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 261:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - @i) with relaxed ordering.
 262:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 263:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_sub() there.
 264:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 265:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: Nothing.
 266:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 267:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline void
 268:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_sub(int i, atomic_t *v)
 269:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 270:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 271:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	raw_atomic_sub(i, v);
 272:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 273:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 274:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 275:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_sub_return() - atomic subtract with full ordering
 276:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to subtract
 277:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 278:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 279:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - @i) with full ordering.
 280:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 281:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_sub_return() there.
 282:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 283:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 284:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 285:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 286:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_sub_return(int i, atomic_t *v)
 287:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 288:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
 289:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 290:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_sub_return(i, v);
 291:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 292:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
ARM GAS  /tmp/cctjQXNb.s 			page 31


 293:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 294:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_sub_return_acquire() - atomic subtract with acquire ordering
 295:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to subtract
 296:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 297:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 298:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - @i) with acquire ordering.
 299:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 300:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_sub_return_acquire() there.
 301:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 302:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 303:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 304:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 305:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_sub_return_acquire(int i, atomic_t *v)
 306:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 307:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 308:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_sub_return_acquire(i, v);
 309:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 310:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 311:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 312:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_sub_return_release() - atomic subtract with release ordering
 313:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to subtract
 314:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 315:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 316:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - @i) with release ordering.
 317:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 318:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_sub_return_release() there.
 319:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 320:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 321:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 322:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 323:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_sub_return_release(int i, atomic_t *v)
 324:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 325:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
 326:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 327:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_sub_return_release(i, v);
 328:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 329:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 330:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 331:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_sub_return_relaxed() - atomic subtract with relaxed ordering
 332:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to subtract
 333:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 334:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 335:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - @i) with relaxed ordering.
 336:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 337:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_sub_return_relaxed() there.
 338:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 339:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 340:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 341:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 342:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_sub_return_relaxed(int i, atomic_t *v)
 343:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 344:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 345:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_sub_return_relaxed(i, v);
 346:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 347:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 348:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 349:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_sub() - atomic subtract with full ordering
ARM GAS  /tmp/cctjQXNb.s 			page 32


 350:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to subtract
 351:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 352:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 353:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - @i) with full ordering.
 354:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 355:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_sub() there.
 356:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 357:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 358:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 359:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 360:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_sub(int i, atomic_t *v)
 361:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 362:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
 363:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 364:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_sub(i, v);
 365:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 366:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 367:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 368:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_sub_acquire() - atomic subtract with acquire ordering
 369:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to subtract
 370:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 371:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 372:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - @i) with acquire ordering.
 373:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 374:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_sub_acquire() there.
 375:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 376:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 377:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 378:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 379:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_sub_acquire(int i, atomic_t *v)
 380:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 381:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 382:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_sub_acquire(i, v);
 383:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 384:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 385:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 386:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_sub_release() - atomic subtract with release ordering
 387:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to subtract
 388:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 389:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 390:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - @i) with release ordering.
 391:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 392:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_sub_release() there.
 393:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 394:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 395:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 396:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 397:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_sub_release(int i, atomic_t *v)
 398:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 399:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
 400:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 401:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_sub_release(i, v);
 402:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 403:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 404:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 405:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_sub_relaxed() - atomic subtract with relaxed ordering
 406:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to subtract
ARM GAS  /tmp/cctjQXNb.s 			page 33


 407:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 408:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 409:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - @i) with relaxed ordering.
 410:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 411:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_sub_relaxed() there.
 412:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 413:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 414:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 415:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 416:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_sub_relaxed(int i, atomic_t *v)
 417:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 418:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 419:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_sub_relaxed(i, v);
 420:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 421:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 422:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 423:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_inc() - atomic increment with relaxed ordering
 424:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 425:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 426:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + 1) with relaxed ordering.
 427:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 428:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_inc() there.
 429:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 430:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: Nothing.
 431:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 432:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline void
 433:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_inc(atomic_t *v)
 434:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 435:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 436:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	raw_atomic_inc(v);
 437:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 438:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 439:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 440:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_inc_return() - atomic increment with full ordering
 441:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 442:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 443:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + 1) with full ordering.
 444:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 445:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_inc_return() there.
 446:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 447:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 448:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 449:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 450:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_inc_return(atomic_t *v)
 451:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 452:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
 453:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 454:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_inc_return(v);
 455:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 456:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 457:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 458:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_inc_return_acquire() - atomic increment with acquire ordering
 459:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 460:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 461:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + 1) with acquire ordering.
 462:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 463:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_inc_return_acquire() there.
ARM GAS  /tmp/cctjQXNb.s 			page 34


 464:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 465:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 466:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 467:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 468:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_inc_return_acquire(atomic_t *v)
 469:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 470:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 471:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_inc_return_acquire(v);
 472:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 473:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 474:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 475:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_inc_return_release() - atomic increment with release ordering
 476:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 477:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 478:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + 1) with release ordering.
 479:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 480:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_inc_return_release() there.
 481:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 482:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 483:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 484:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 485:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_inc_return_release(atomic_t *v)
 486:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 487:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
 488:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 489:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_inc_return_release(v);
 490:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 491:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 492:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 493:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_inc_return_relaxed() - atomic increment with relaxed ordering
 494:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 495:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 496:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + 1) with relaxed ordering.
 497:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 498:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_inc_return_relaxed() there.
 499:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 500:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 501:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 502:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 503:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_inc_return_relaxed(atomic_t *v)
 504:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 505:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 506:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_inc_return_relaxed(v);
 507:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 508:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 509:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 510:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_inc() - atomic increment with full ordering
 511:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 512:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 513:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + 1) with full ordering.
 514:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 515:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_inc() there.
 516:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 517:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 518:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 519:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 520:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_inc(atomic_t *v)
ARM GAS  /tmp/cctjQXNb.s 			page 35


 521:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 522:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
 523:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 524:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_inc(v);
 525:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 526:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 527:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 528:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_inc_acquire() - atomic increment with acquire ordering
 529:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 530:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 531:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + 1) with acquire ordering.
 532:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 533:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_inc_acquire() there.
 534:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 535:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 536:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 537:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 538:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_inc_acquire(atomic_t *v)
 539:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 540:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 541:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_inc_acquire(v);
 542:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 543:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 544:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 545:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_inc_release() - atomic increment with release ordering
 546:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 547:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 548:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + 1) with release ordering.
 549:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 550:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_inc_release() there.
 551:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 552:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 553:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 554:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 555:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_inc_release(atomic_t *v)
 556:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 557:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
 558:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 559:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_inc_release(v);
 560:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 561:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 562:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 563:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_inc_relaxed() - atomic increment with relaxed ordering
 564:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 565:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 566:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v + 1) with relaxed ordering.
 567:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 568:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_inc_relaxed() there.
 569:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 570:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 571:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 572:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 573:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_inc_relaxed(atomic_t *v)
 574:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 575:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 576:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_inc_relaxed(v);
 577:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
ARM GAS  /tmp/cctjQXNb.s 			page 36


 578:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 579:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 580:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_dec() - atomic decrement with relaxed ordering
 581:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 582:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 583:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - 1) with relaxed ordering.
 584:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 585:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_dec() there.
 586:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 587:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: Nothing.
 588:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 589:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline void
 590:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_dec(atomic_t *v)
 591:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 592:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 593:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	raw_atomic_dec(v);
 594:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 595:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 596:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 597:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_dec_return() - atomic decrement with full ordering
 598:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 599:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 600:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - 1) with full ordering.
 601:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 602:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_dec_return() there.
 603:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 604:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 605:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 606:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 607:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_dec_return(atomic_t *v)
 608:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 609:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
 610:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 611:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_dec_return(v);
 612:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 613:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 614:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 615:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_dec_return_acquire() - atomic decrement with acquire ordering
 616:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 617:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 618:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - 1) with acquire ordering.
 619:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 620:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_dec_return_acquire() there.
 621:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 622:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 623:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 624:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 625:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_dec_return_acquire(atomic_t *v)
 626:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 627:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 628:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_dec_return_acquire(v);
 629:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 630:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 631:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 632:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_dec_return_release() - atomic decrement with release ordering
 633:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 634:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
ARM GAS  /tmp/cctjQXNb.s 			page 37


 635:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - 1) with release ordering.
 636:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 637:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_dec_return_release() there.
 638:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 639:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 640:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 641:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 642:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_dec_return_release(atomic_t *v)
 643:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 644:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
 645:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 646:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_dec_return_release(v);
 647:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 648:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 649:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 650:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_dec_return_relaxed() - atomic decrement with relaxed ordering
 651:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 652:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 653:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - 1) with relaxed ordering.
 654:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 655:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_dec_return_relaxed() there.
 656:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 657:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The updated value of @v.
 658:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 659:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 660:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_dec_return_relaxed(atomic_t *v)
 661:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 662:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 663:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_dec_return_relaxed(v);
 664:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 665:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 666:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 667:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_dec() - atomic decrement with full ordering
 668:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 669:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 670:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - 1) with full ordering.
 671:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 672:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_dec() there.
 673:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 674:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 675:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 676:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 677:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_dec(atomic_t *v)
 678:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 679:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
 680:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 681:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_dec(v);
 682:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 683:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 684:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 685:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_dec_acquire() - atomic decrement with acquire ordering
 686:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 687:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 688:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - 1) with acquire ordering.
 689:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 690:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_dec_acquire() there.
 691:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
ARM GAS  /tmp/cctjQXNb.s 			page 38


 692:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 693:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 694:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 695:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_dec_acquire(atomic_t *v)
 696:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 697:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 698:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_dec_acquire(v);
 699:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 700:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 701:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 702:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_dec_release() - atomic decrement with release ordering
 703:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 704:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 705:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - 1) with release ordering.
 706:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 707:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_dec_release() there.
 708:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 709:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 710:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 711:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 712:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_dec_release(atomic_t *v)
 713:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 714:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
 715:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 716:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_dec_release(v);
 717:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 718:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 719:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 720:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_dec_relaxed() - atomic decrement with relaxed ordering
 721:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 722:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 723:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - 1) with relaxed ordering.
 724:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 725:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_dec_relaxed() there.
 726:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 727:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 728:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 729:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 730:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_dec_relaxed(atomic_t *v)
 731:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 732:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 733:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_dec_relaxed(v);
 734:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 735:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 736:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 737:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_and() - atomic bitwise AND with relaxed ordering
 738:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 739:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 740:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 741:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v & @i) with relaxed ordering.
 742:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 743:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_and() there.
 744:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 745:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: Nothing.
 746:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 747:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline void
 748:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_and(int i, atomic_t *v)
ARM GAS  /tmp/cctjQXNb.s 			page 39


 749:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 750:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 751:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	raw_atomic_and(i, v);
 752:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 753:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 754:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 755:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_and() - atomic bitwise AND with full ordering
 756:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 757:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 758:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 759:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v & @i) with full ordering.
 760:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 761:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_and() there.
 762:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 763:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 764:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 765:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 766:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_and(int i, atomic_t *v)
 767:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 768:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
 769:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 770:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_and(i, v);
 771:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 772:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 773:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 774:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_and_acquire() - atomic bitwise AND with acquire ordering
 775:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 776:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 777:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 778:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v & @i) with acquire ordering.
 779:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 780:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_and_acquire() there.
 781:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 782:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 783:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 784:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 785:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_and_acquire(int i, atomic_t *v)
 786:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 787:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 788:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_and_acquire(i, v);
 789:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 790:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 791:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 792:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_and_release() - atomic bitwise AND with release ordering
 793:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 794:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 795:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 796:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v & @i) with release ordering.
 797:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 798:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_and_release() there.
 799:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 800:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 801:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 802:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 803:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_and_release(int i, atomic_t *v)
 804:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 805:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
ARM GAS  /tmp/cctjQXNb.s 			page 40


 806:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 807:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_and_release(i, v);
 808:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 809:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 810:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 811:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_and_relaxed() - atomic bitwise AND with relaxed ordering
 812:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 813:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 814:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 815:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v & @i) with relaxed ordering.
 816:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 817:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_and_relaxed() there.
 818:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 819:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 820:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 821:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 822:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_and_relaxed(int i, atomic_t *v)
 823:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 824:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 825:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_and_relaxed(i, v);
 826:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 827:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 828:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 829:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_andnot() - atomic bitwise AND NOT with relaxed ordering
 830:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 831:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 832:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 833:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v & ~@i) with relaxed ordering.
 834:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 835:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_andnot() there.
 836:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 837:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: Nothing.
 838:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 839:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline void
 840:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_andnot(int i, atomic_t *v)
 841:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 842:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 843:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	raw_atomic_andnot(i, v);
 844:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 845:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 846:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 847:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_andnot() - atomic bitwise AND NOT with full ordering
 848:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 849:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 850:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 851:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v & ~@i) with full ordering.
 852:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 853:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_andnot() there.
 854:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 855:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 856:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 857:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 858:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_andnot(int i, atomic_t *v)
 859:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 860:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
 861:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 862:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_andnot(i, v);
ARM GAS  /tmp/cctjQXNb.s 			page 41


 863:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 864:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 865:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 866:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_andnot_acquire() - atomic bitwise AND NOT with acquire ordering
 867:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 868:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 869:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 870:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v & ~@i) with acquire ordering.
 871:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 872:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_andnot_acquire() there.
 873:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 874:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 875:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 876:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 877:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_andnot_acquire(int i, atomic_t *v)
 878:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 879:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 880:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_andnot_acquire(i, v);
 881:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 882:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 883:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 884:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_andnot_release() - atomic bitwise AND NOT with release ordering
 885:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 886:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 887:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 888:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v & ~@i) with release ordering.
 889:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 890:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_andnot_release() there.
 891:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 892:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 893:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 894:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 895:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_andnot_release(int i, atomic_t *v)
 896:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 897:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
 898:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 899:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_andnot_release(i, v);
 900:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 901:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 902:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 903:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_andnot_relaxed() - atomic bitwise AND NOT with relaxed ordering
 904:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 905:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 906:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 907:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v & ~@i) with relaxed ordering.
 908:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 909:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_andnot_relaxed() there.
 910:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 911:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 912:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 913:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 914:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_andnot_relaxed(int i, atomic_t *v)
 915:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 916:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 917:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_andnot_relaxed(i, v);
 918:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 919:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
ARM GAS  /tmp/cctjQXNb.s 			page 42


 920:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 921:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_or() - atomic bitwise OR with relaxed ordering
 922:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 923:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 924:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 925:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v | @i) with relaxed ordering.
 926:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 927:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_or() there.
 928:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 929:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: Nothing.
 930:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 931:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline void
 932:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_or(int i, atomic_t *v)
 933:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 934:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 935:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	raw_atomic_or(i, v);
 936:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 937:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 938:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 939:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_or() - atomic bitwise OR with full ordering
 940:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 941:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 942:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 943:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v | @i) with full ordering.
 944:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 945:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_or() there.
 946:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 947:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 948:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 949:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 950:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_or(int i, atomic_t *v)
 951:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 952:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
 953:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 954:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_or(i, v);
 955:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 956:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 957:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 958:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_or_acquire() - atomic bitwise OR with acquire ordering
 959:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 960:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 961:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 962:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v | @i) with acquire ordering.
 963:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 964:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_or_acquire() there.
 965:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 966:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 967:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 968:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 969:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_or_acquire(int i, atomic_t *v)
 970:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 971:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 972:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_or_acquire(i, v);
 973:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 974:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 975:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 976:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_or_release() - atomic bitwise OR with release ordering
ARM GAS  /tmp/cctjQXNb.s 			page 43


 977:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 978:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 979:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 980:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v | @i) with release ordering.
 981:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 982:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_or_release() there.
 983:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 984:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
 985:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
 986:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
 987:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_or_release(int i, atomic_t *v)
 988:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
 989:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
 990:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 991:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_or_release(i, v);
 992:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
 993:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
 994:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
 995:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_or_relaxed() - atomic bitwise OR with relaxed ordering
 996:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
 997:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
 998:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
 999:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v | @i) with relaxed ordering.
1000:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1001:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_or_relaxed() there.
1002:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1003:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1004:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1005:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1006:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_or_relaxed(int i, atomic_t *v)
1007:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1008:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1009:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_or_relaxed(i, v);
1010:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1011:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1012:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1013:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_xor() - atomic bitwise XOR with relaxed ordering
1014:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
1015:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1016:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1017:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v ^ @i) with relaxed ordering.
1018:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1019:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_xor() there.
1020:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1021:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: Nothing.
1022:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1023:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline void
1024:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_xor(int i, atomic_t *v)
1025:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1026:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1027:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	raw_atomic_xor(i, v);
1028:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1029:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1030:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1031:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_xor() - atomic bitwise XOR with full ordering
1032:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
1033:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
ARM GAS  /tmp/cctjQXNb.s 			page 44


1034:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1035:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v ^ @i) with full ordering.
1036:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1037:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_xor() there.
1038:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1039:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1040:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1041:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1042:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_xor(int i, atomic_t *v)
1043:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1044:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
1045:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1046:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_xor(i, v);
1047:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1048:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1049:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1050:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_xor_acquire() - atomic bitwise XOR with acquire ordering
1051:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
1052:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1053:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1054:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v ^ @i) with acquire ordering.
1055:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1056:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_xor_acquire() there.
1057:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1058:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1059:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1060:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1061:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_xor_acquire(int i, atomic_t *v)
1062:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1063:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1064:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_xor_acquire(i, v);
1065:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1066:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1067:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1068:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_xor_release() - atomic bitwise XOR with release ordering
1069:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
1070:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1071:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1072:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v ^ @i) with release ordering.
1073:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1074:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_xor_release() there.
1075:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1076:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1077:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1078:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1079:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_xor_release(int i, atomic_t *v)
1080:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1081:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
1082:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1083:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_xor_release(i, v);
1084:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1085:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1086:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1087:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_fetch_xor_relaxed() - atomic bitwise XOR with relaxed ordering
1088:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value
1089:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1090:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
ARM GAS  /tmp/cctjQXNb.s 			page 45


1091:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v ^ @i) with relaxed ordering.
1092:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1093:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_fetch_xor_relaxed() there.
1094:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1095:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1096:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1097:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1098:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_fetch_xor_relaxed(int i, atomic_t *v)
1099:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1100:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1101:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_fetch_xor_relaxed(i, v);
1102:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1103:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1104:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1105:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_xchg() - atomic exchange with full ordering
1106:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1107:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @new: int value to assign
1108:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1109:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to @new with full ordering.
1110:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1111:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_xchg() there.
1112:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1113:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1114:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1115:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1116:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_xchg(atomic_t *v, int new)
1117:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1118:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
1119:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1120:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_xchg(v, new);
1121:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1122:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1123:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1124:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_xchg_acquire() - atomic exchange with acquire ordering
1125:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1126:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @new: int value to assign
1127:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1128:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to @new with acquire ordering.
1129:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1130:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_xchg_acquire() there.
1131:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1132:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1133:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1134:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1135:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_xchg_acquire(atomic_t *v, int new)
1136:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1137:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1138:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_xchg_acquire(v, new);
1139:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1140:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1141:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1142:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_xchg_release() - atomic exchange with release ordering
1143:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1144:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @new: int value to assign
1145:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1146:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to @new with release ordering.
1147:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
ARM GAS  /tmp/cctjQXNb.s 			page 46


1148:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_xchg_release() there.
1149:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1150:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1151:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1152:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1153:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_xchg_release(atomic_t *v, int new)
1154:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1155:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
1156:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1157:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_xchg_release(v, new);
1158:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1159:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1160:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1161:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_xchg_relaxed() - atomic exchange with relaxed ordering
1162:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1163:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @new: int value to assign
1164:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1165:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to @new with relaxed ordering.
1166:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1167:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_xchg_relaxed() there.
1168:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1169:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1170:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1171:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1172:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_xchg_relaxed(atomic_t *v, int new)
1173:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1174:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1175:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_xchg_relaxed(v, new);
1176:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1177:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1178:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1179:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_cmpxchg() - atomic compare and exchange with full ordering
1180:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1181:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @old: int value to compare with
1182:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @new: int value to assign
1183:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1184:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * If (@v == @old), atomically updates @v to @new with full ordering.
1185:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Otherwise, @v is not modified and relaxed ordering is provided.
1186:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1187:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_cmpxchg() there.
1188:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1189:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1190:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1191:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1192:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_cmpxchg(atomic_t *v, int old, int new)
1193:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1194:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
1195:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1196:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_cmpxchg(v, old, new);
1197:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1198:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1199:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1200:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_cmpxchg_acquire() - atomic compare and exchange with acquire ordering
1201:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1202:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @old: int value to compare with
1203:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @new: int value to assign
1204:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
ARM GAS  /tmp/cctjQXNb.s 			page 47


1205:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * If (@v == @old), atomically updates @v to @new with acquire ordering.
1206:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Otherwise, @v is not modified and relaxed ordering is provided.
1207:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1208:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_cmpxchg_acquire() there.
1209:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1210:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1211:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1212:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1213:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_cmpxchg_acquire(atomic_t *v, int old, int new)
1214:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1215:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1216:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_cmpxchg_acquire(v, old, new);
1217:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1218:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1219:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1220:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_cmpxchg_release() - atomic compare and exchange with release ordering
1221:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1222:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @old: int value to compare with
1223:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @new: int value to assign
1224:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1225:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * If (@v == @old), atomically updates @v to @new with release ordering.
1226:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Otherwise, @v is not modified and relaxed ordering is provided.
1227:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1228:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_cmpxchg_release() there.
1229:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1230:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1231:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1232:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1233:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_cmpxchg_release(atomic_t *v, int old, int new)
1234:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1235:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
1236:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1237:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_cmpxchg_release(v, old, new);
1238:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1239:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1240:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1241:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_cmpxchg_relaxed() - atomic compare and exchange with relaxed ordering
1242:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1243:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @old: int value to compare with
1244:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @new: int value to assign
1245:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1246:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * If (@v == @old), atomically updates @v to @new with relaxed ordering.
1247:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Otherwise, @v is not modified and relaxed ordering is provided.
1248:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1249:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_cmpxchg_relaxed() there.
1250:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1251:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: The original value of @v.
1252:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1253:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline int
1254:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_cmpxchg_relaxed(atomic_t *v, int old, int new)
1255:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1256:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1257:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_cmpxchg_relaxed(v, old, new);
1258:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1259:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1260:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1261:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_try_cmpxchg() - atomic compare and exchange with full ordering
ARM GAS  /tmp/cctjQXNb.s 			page 48


1262:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1263:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @old: pointer to int value to compare with
1264:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @new: int value to assign
1265:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1266:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * If (@v == @old), atomically updates @v to @new with full ordering.
1267:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Otherwise, @v is not modified, @old is updated to the current value of @v,
1268:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * and relaxed ordering is provided.
1269:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1270:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_try_cmpxchg() there.
1271:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1272:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: @true if the exchange occured, @false otherwise.
1273:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1274:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline bool
1275:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_try_cmpxchg(atomic_t *v, int *old, int new)
1276:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1277:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
1278:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1279:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(old, sizeof(*old));
1280:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_try_cmpxchg(v, old, new);
1281:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1282:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1283:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1284:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_try_cmpxchg_acquire() - atomic compare and exchange with acquire ordering
1285:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1286:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @old: pointer to int value to compare with
1287:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @new: int value to assign
1288:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1289:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * If (@v == @old), atomically updates @v to @new with acquire ordering.
1290:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Otherwise, @v is not modified, @old is updated to the current value of @v,
1291:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * and relaxed ordering is provided.
1292:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1293:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_try_cmpxchg_acquire() there.
1294:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1295:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: @true if the exchange occured, @false otherwise.
1296:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1297:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline bool
1298:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_try_cmpxchg_acquire(atomic_t *v, int *old, int new)
1299:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1300:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1301:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(old, sizeof(*old));
1302:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_try_cmpxchg_acquire(v, old, new);
1303:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1304:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1305:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1306:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_try_cmpxchg_release() - atomic compare and exchange with release ordering
1307:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1308:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @old: pointer to int value to compare with
1309:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @new: int value to assign
1310:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1311:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * If (@v == @old), atomically updates @v to @new with release ordering.
1312:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Otherwise, @v is not modified, @old is updated to the current value of @v,
1313:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * and relaxed ordering is provided.
1314:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1315:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_try_cmpxchg_release() there.
1316:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1317:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: @true if the exchange occured, @false otherwise.
1318:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
ARM GAS  /tmp/cctjQXNb.s 			page 49


1319:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline bool
1320:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_try_cmpxchg_release(atomic_t *v, int *old, int new)
1321:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1322:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_release();
1323:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1324:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(old, sizeof(*old));
1325:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_try_cmpxchg_release(v, old, new);
1326:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1327:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1328:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1329:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_try_cmpxchg_relaxed() - atomic compare and exchange with relaxed ordering
1330:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1331:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @old: pointer to int value to compare with
1332:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @new: int value to assign
1333:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1334:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * If (@v == @old), atomically updates @v to @new with relaxed ordering.
1335:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Otherwise, @v is not modified, @old is updated to the current value of @v,
1336:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * and relaxed ordering is provided.
1337:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1338:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_try_cmpxchg_relaxed() there.
1339:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1340:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: @true if the exchange occured, @false otherwise.
1341:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1342:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline bool
1343:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_try_cmpxchg_relaxed(atomic_t *v, int *old, int new)
1344:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1345:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1346:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(old, sizeof(*old));
1347:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_try_cmpxchg_relaxed(v, old, new);
1348:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1349:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1350:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1351:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_sub_and_test() - atomic subtract and test if zero with full ordering
1352:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @i: int value to subtract
1353:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1354:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1355:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - @i) with full ordering.
1356:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1357:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_sub_and_test() there.
1358:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1359:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: @true if the resulting value of @v is zero, @false otherwise.
1360:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1361:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline bool
1362:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_sub_and_test(int i, atomic_t *v)
1363:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1364:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
1365:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
1366:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_sub_and_test(i, v);
1367:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** }
1368:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 
1369:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** /**
1370:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * atomic_dec_and_test() - atomic decrement and test if zero with full ordering
1371:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * @v: pointer to atomic_t
1372:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1373:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Atomically updates @v to (@v - 1) with full ordering.
1374:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1375:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Unsafe to use in noinstr code; use raw_atomic_dec_and_test() there.
ARM GAS  /tmp/cctjQXNb.s 			page 50


1376:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  *
1377:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  * Return: @true if the resulting value of @v is zero, @false otherwise.
1378:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h ****  */
1379:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** static __always_inline bool
1380:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** atomic_dec_and_test(atomic_t *v)
 368              		.loc 5 1380 1 is_stmt 1 view .LVU125
1381:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** {
1382:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	kcsan_mb();
 369              		.loc 5 1382 2 view .LVU126
 370              		.loc 5 1382 2 view .LVU127
 371              		.loc 5 1382 2 view .LVU128
1383:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	instrument_atomic_read_write(v, sizeof(*v));
 372              		.loc 5 1383 2 view .LVU129
1384:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-instrumented.h **** 	return raw_atomic_dec_and_test(v);
 373              		.loc 5 1384 2 view .LVU130
 374              	.LBB97:
 375              	.LBI97:
 510:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 511:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 512:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 513:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_set_release() - atomic set with release ordering
 514:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 515:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to assign
 516:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 517:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically sets @v to @i with release ordering.
 518:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 519:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_set_release() elsewhere.
 520:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 521:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: Nothing.
 522:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 523:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline void
 524:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_set_release(atomic_t *v, int i)
 525:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 526:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_set_release)
 527:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	arch_atomic_set_release(v, i);
 528:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 529:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (__native_word(atomic_t)) {
 530:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		smp_store_release(&(v)->counter, i);
 531:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	} else {
 532:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		__atomic_release_fence();
 533:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		raw_atomic_set(v, i);
 534:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	}
 535:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 536:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 537:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 538:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 539:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_add() - atomic add with relaxed ordering
 540:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to add
 541:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 542:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 543:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + @i) with relaxed ordering.
 544:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 545:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_add() elsewhere.
 546:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 547:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: Nothing.
 548:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 549:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline void
ARM GAS  /tmp/cctjQXNb.s 			page 51


 550:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_add(int i, atomic_t *v)
 551:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 552:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	arch_atomic_add(i, v);
 553:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 554:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 555:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 556:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_add_return() - atomic add with full ordering
 557:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to add
 558:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 559:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 560:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + @i) with full ordering.
 561:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 562:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_add_return() elsewhere.
 563:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 564:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
 565:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 566:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 567:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_add_return(int i, atomic_t *v)
 568:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 569:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_add_return)
 570:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_add_return(i, v);
 571:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_add_return_relaxed)
 572:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
 573:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
 574:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_add_return_relaxed(i, v);
 575:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
 576:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
 577:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 578:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_add_return"
 579:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 580:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 581:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 582:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 583:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_add_return_acquire() - atomic add with acquire ordering
 584:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to add
 585:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 586:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 587:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + @i) with acquire ordering.
 588:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 589:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_add_return_acquire() elsewhere.
 590:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 591:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
 592:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 593:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 594:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_add_return_acquire(int i, atomic_t *v)
 595:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 596:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_add_return_acquire)
 597:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_add_return_acquire(i, v);
 598:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_add_return_relaxed)
 599:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_add_return_relaxed(i, v);
 600:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
 601:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
 602:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_add_return)
 603:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_add_return(i, v);
 604:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 605:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_add_return_acquire"
 606:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
ARM GAS  /tmp/cctjQXNb.s 			page 52


 607:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 608:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 609:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 610:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_add_return_release() - atomic add with release ordering
 611:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to add
 612:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 613:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 614:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + @i) with release ordering.
 615:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 616:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_add_return_release() elsewhere.
 617:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 618:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
 619:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 620:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 621:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_add_return_release(int i, atomic_t *v)
 622:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 623:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_add_return_release)
 624:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_add_return_release(i, v);
 625:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_add_return_relaxed)
 626:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
 627:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_add_return_relaxed(i, v);
 628:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_add_return)
 629:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_add_return(i, v);
 630:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 631:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_add_return_release"
 632:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 633:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 634:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 635:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 636:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_add_return_relaxed() - atomic add with relaxed ordering
 637:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to add
 638:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 639:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 640:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + @i) with relaxed ordering.
 641:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 642:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_add_return_relaxed() elsewhere.
 643:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 644:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
 645:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 646:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 647:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_add_return_relaxed(int i, atomic_t *v)
 648:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 649:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_add_return_relaxed)
 650:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_add_return_relaxed(i, v);
 651:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_add_return)
 652:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_add_return(i, v);
 653:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 654:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_add_return_relaxed"
 655:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 656:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 657:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 658:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 659:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_add() - atomic add with full ordering
 660:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to add
 661:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 662:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 663:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + @i) with full ordering.
ARM GAS  /tmp/cctjQXNb.s 			page 53


 664:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 665:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_add() elsewhere.
 666:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 667:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
 668:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 669:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 670:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_add(int i, atomic_t *v)
 671:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 672:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_add)
 673:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_add(i, v);
 674:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_add_relaxed)
 675:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
 676:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
 677:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_fetch_add_relaxed(i, v);
 678:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
 679:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
 680:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 681:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_add"
 682:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 683:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 684:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 685:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 686:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_add_acquire() - atomic add with acquire ordering
 687:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to add
 688:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 689:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 690:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + @i) with acquire ordering.
 691:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 692:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_add_acquire() elsewhere.
 693:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 694:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
 695:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 696:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 697:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_add_acquire(int i, atomic_t *v)
 698:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 699:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_add_acquire)
 700:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_add_acquire(i, v);
 701:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_add_relaxed)
 702:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_fetch_add_relaxed(i, v);
 703:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
 704:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
 705:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_add)
 706:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_add(i, v);
 707:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 708:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_add_acquire"
 709:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 710:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 711:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 712:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 713:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_add_release() - atomic add with release ordering
 714:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to add
 715:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 716:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 717:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + @i) with release ordering.
 718:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 719:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_add_release() elsewhere.
 720:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
ARM GAS  /tmp/cctjQXNb.s 			page 54


 721:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
 722:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 723:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 724:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_add_release(int i, atomic_t *v)
 725:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 726:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_add_release)
 727:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_add_release(i, v);
 728:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_add_relaxed)
 729:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
 730:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_add_relaxed(i, v);
 731:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_add)
 732:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_add(i, v);
 733:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 734:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_add_release"
 735:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 736:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 737:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 738:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 739:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_add_relaxed() - atomic add with relaxed ordering
 740:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to add
 741:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 742:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 743:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + @i) with relaxed ordering.
 744:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 745:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_add_relaxed() elsewhere.
 746:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 747:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
 748:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 749:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 750:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_add_relaxed(int i, atomic_t *v)
 751:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 752:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_add_relaxed)
 753:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_add_relaxed(i, v);
 754:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_add)
 755:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_add(i, v);
 756:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 757:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_add_relaxed"
 758:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 759:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 760:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 761:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 762:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_sub() - atomic subtract with relaxed ordering
 763:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to subtract
 764:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 765:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 766:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - @i) with relaxed ordering.
 767:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 768:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_sub() elsewhere.
 769:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 770:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: Nothing.
 771:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 772:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline void
 773:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_sub(int i, atomic_t *v)
 774:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 775:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	arch_atomic_sub(i, v);
 776:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 777:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
ARM GAS  /tmp/cctjQXNb.s 			page 55


 778:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 779:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_sub_return() - atomic subtract with full ordering
 780:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to subtract
 781:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 782:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 783:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - @i) with full ordering.
 784:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 785:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_sub_return() elsewhere.
 786:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 787:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
 788:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 789:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 790:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_sub_return(int i, atomic_t *v)
 791:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 792:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_sub_return)
 793:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_sub_return(i, v);
 794:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_sub_return_relaxed)
 795:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
 796:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
 797:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_sub_return_relaxed(i, v);
 798:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
 799:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
 800:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 801:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	volatile int *p = (volatile int *)&v->counter;
 802:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret = *p;
 803:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	*p -= i;
 804:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
 805:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 806:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 807:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 808:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 809:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 810:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_sub_return_acquire() - atomic subtract with acquire ordering
 811:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to subtract
 812:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 813:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 814:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - @i) with acquire ordering.
 815:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 816:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_sub_return_acquire() elsewhere.
 817:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 818:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
 819:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 820:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 821:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_sub_return_acquire(int i, atomic_t *v)
 822:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 823:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_sub_return_acquire)
 824:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_sub_return_acquire(i, v);
 825:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_sub_return_relaxed)
 826:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_sub_return_relaxed(i, v);
 827:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
 828:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
 829:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_sub_return)
 830:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_sub_return(i, v);
 831:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 832:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_sub_return_acquire"
 833:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 834:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
ARM GAS  /tmp/cctjQXNb.s 			page 56


 835:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 836:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 837:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_sub_return_release() - atomic subtract with release ordering
 838:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to subtract
 839:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 840:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 841:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - @i) with release ordering.
 842:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 843:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_sub_return_release() elsewhere.
 844:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 845:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
 846:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 847:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 848:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_sub_return_release(int i, atomic_t *v)
 849:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 850:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_sub_return_release)
 851:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_sub_return_release(i, v);
 852:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_sub_return_relaxed)
 853:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
 854:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_sub_return_relaxed(i, v);
 855:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_sub_return)
 856:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_sub_return(i, v);
 857:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 858:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_sub_return_release"
 859:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 860:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 861:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 862:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 863:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_sub_return_relaxed() - atomic subtract with relaxed ordering
 864:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to subtract
 865:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 866:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 867:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - @i) with relaxed ordering.
 868:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 869:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_sub_return_relaxed() elsewhere.
 870:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 871:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
 872:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 873:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 874:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_sub_return_relaxed(int i, atomic_t *v)
 875:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 876:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_sub_return_relaxed)
 877:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_sub_return_relaxed(i, v);
 878:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_sub_return)
 879:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_sub_return(i, v);
 880:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 881:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_sub_return_relaxed"
 882:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 883:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 884:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 885:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 886:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_sub() - atomic subtract with full ordering
 887:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to subtract
 888:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 889:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 890:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - @i) with full ordering.
 891:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
ARM GAS  /tmp/cctjQXNb.s 			page 57


 892:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_sub() elsewhere.
 893:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 894:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
 895:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 896:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 897:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_sub(int i, atomic_t *v)
 898:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 899:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_sub)
 900:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_sub(i, v);
 901:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_sub_relaxed)
 902:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
 903:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
 904:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_fetch_sub_relaxed(i, v);
 905:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
 906:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
 907:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 908:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_sub"
 909:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 910:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 911:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 912:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 913:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_sub_acquire() - atomic subtract with acquire ordering
 914:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to subtract
 915:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 916:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 917:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - @i) with acquire ordering.
 918:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 919:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_sub_acquire() elsewhere.
 920:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 921:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
 922:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 923:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 924:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_sub_acquire(int i, atomic_t *v)
 925:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 926:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_sub_acquire)
 927:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_sub_acquire(i, v);
 928:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_sub_relaxed)
 929:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_fetch_sub_relaxed(i, v);
 930:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
 931:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
 932:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_sub)
 933:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_sub(i, v);
 934:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 935:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_sub_acquire"
 936:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 937:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 938:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 939:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 940:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_sub_release() - atomic subtract with release ordering
 941:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to subtract
 942:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 943:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 944:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - @i) with release ordering.
 945:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 946:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_sub_release() elsewhere.
 947:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 948:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
ARM GAS  /tmp/cctjQXNb.s 			page 58


 949:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 950:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 951:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_sub_release(int i, atomic_t *v)
 952:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 953:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_sub_release)
 954:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_sub_release(i, v);
 955:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_sub_relaxed)
 956:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
 957:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_sub_relaxed(i, v);
 958:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_sub)
 959:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_sub(i, v);
 960:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 961:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_sub_release"
 962:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 963:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 964:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 965:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 966:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_sub_relaxed() - atomic subtract with relaxed ordering
 967:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to subtract
 968:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 969:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 970:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - @i) with relaxed ordering.
 971:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 972:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_sub_relaxed() elsewhere.
 973:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 974:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
 975:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 976:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
 977:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_sub_relaxed(int i, atomic_t *v)
 978:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 979:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_sub_relaxed)
 980:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_sub_relaxed(i, v);
 981:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_sub)
 982:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_sub(i, v);
 983:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 984:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_sub_relaxed"
 985:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 986:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
 987:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
 988:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
 989:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_inc() - atomic increment with relaxed ordering
 990:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
 991:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 992:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + 1) with relaxed ordering.
 993:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 994:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_inc() elsewhere.
 995:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
 996:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: Nothing.
 997:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
 998:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline void
 999:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_inc(atomic_t *v)
1000:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1001:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_inc)
1002:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	arch_atomic_inc(v);
1003:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1004:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	raw_atomic_add(1, v);
1005:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
ARM GAS  /tmp/cctjQXNb.s 			page 59


1006:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1007:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1008:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1009:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_inc_return() - atomic increment with full ordering
1010:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1011:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1012:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + 1) with full ordering.
1013:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1014:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_inc_return() elsewhere.
1015:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1016:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
1017:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1018:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1019:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_inc_return(atomic_t *v)
1020:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1021:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_inc_return)
1022:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_inc_return(v);
1023:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_inc_return_relaxed)
1024:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
1025:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
1026:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_inc_return_relaxed(v);
1027:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
1028:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1029:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1030:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_add_return(1, v);
1031:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1032:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1033:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1034:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1035:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_inc_return_acquire() - atomic increment with acquire ordering
1036:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1037:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1038:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + 1) with acquire ordering.
1039:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1040:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_inc_return_acquire() elsewhere.
1041:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1042:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
1043:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1044:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1045:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_inc_return_acquire(atomic_t *v)
1046:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1047:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_inc_return_acquire)
1048:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_inc_return_acquire(v);
1049:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_inc_return_relaxed)
1050:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_inc_return_relaxed(v);
1051:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
1052:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1053:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_inc_return)
1054:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_inc_return(v);
1055:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1056:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_add_return_acquire(1, v);
1057:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1058:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1059:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1060:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1061:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_inc_return_release() - atomic increment with release ordering
1062:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
ARM GAS  /tmp/cctjQXNb.s 			page 60


1063:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1064:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + 1) with release ordering.
1065:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1066:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_inc_return_release() elsewhere.
1067:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1068:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
1069:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1070:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1071:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_inc_return_release(atomic_t *v)
1072:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1073:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_inc_return_release)
1074:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_inc_return_release(v);
1075:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_inc_return_relaxed)
1076:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
1077:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_inc_return_relaxed(v);
1078:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_inc_return)
1079:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_inc_return(v);
1080:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1081:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_add_return_release(1, v);
1082:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1083:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1084:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1085:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1086:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_inc_return_relaxed() - atomic increment with relaxed ordering
1087:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1088:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1089:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + 1) with relaxed ordering.
1090:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1091:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_inc_return_relaxed() elsewhere.
1092:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1093:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
1094:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1095:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1096:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_inc_return_relaxed(atomic_t *v)
1097:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1098:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_inc_return_relaxed)
1099:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_inc_return_relaxed(v);
1100:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_inc_return)
1101:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_inc_return(v);
1102:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1103:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_add_return_relaxed(1, v);
1104:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1105:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1106:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1107:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1108:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_inc() - atomic increment with full ordering
1109:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1110:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1111:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + 1) with full ordering.
1112:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1113:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_inc() elsewhere.
1114:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1115:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1116:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1117:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1118:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_inc(atomic_t *v)
1119:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
ARM GAS  /tmp/cctjQXNb.s 			page 61


1120:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_inc)
1121:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_inc(v);
1122:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_inc_relaxed)
1123:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
1124:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
1125:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_fetch_inc_relaxed(v);
1126:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
1127:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1128:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1129:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_fetch_add(1, v);
1130:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1131:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1132:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1133:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1134:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_inc_acquire() - atomic increment with acquire ordering
1135:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1136:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1137:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + 1) with acquire ordering.
1138:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1139:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_inc_acquire() elsewhere.
1140:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1141:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1142:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1143:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1144:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_inc_acquire(atomic_t *v)
1145:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1146:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_inc_acquire)
1147:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_inc_acquire(v);
1148:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_inc_relaxed)
1149:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_fetch_inc_relaxed(v);
1150:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
1151:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1152:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_inc)
1153:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_inc(v);
1154:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1155:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_fetch_add_acquire(1, v);
1156:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1157:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1158:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1159:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1160:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_inc_release() - atomic increment with release ordering
1161:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1162:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1163:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + 1) with release ordering.
1164:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1165:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_inc_release() elsewhere.
1166:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1167:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1168:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1169:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1170:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_inc_release(atomic_t *v)
1171:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1172:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_inc_release)
1173:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_inc_release(v);
1174:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_inc_relaxed)
1175:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
1176:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_inc_relaxed(v);
ARM GAS  /tmp/cctjQXNb.s 			page 62


1177:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_inc)
1178:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_inc(v);
1179:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1180:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_fetch_add_release(1, v);
1181:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1182:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1183:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1184:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1185:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_inc_relaxed() - atomic increment with relaxed ordering
1186:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1187:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1188:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v + 1) with relaxed ordering.
1189:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1190:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_inc_relaxed() elsewhere.
1191:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1192:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1193:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1194:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1195:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_inc_relaxed(atomic_t *v)
1196:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1197:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_inc_relaxed)
1198:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_inc_relaxed(v);
1199:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_inc)
1200:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_inc(v);
1201:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1202:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_fetch_add_relaxed(1, v);
1203:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1204:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1205:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1206:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1207:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_dec() - atomic decrement with relaxed ordering
1208:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1209:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1210:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - 1) with relaxed ordering.
1211:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1212:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_dec() elsewhere.
1213:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1214:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: Nothing.
1215:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1216:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline void
1217:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_dec(atomic_t *v)
1218:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1219:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_dec)
1220:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	arch_atomic_dec(v);
1221:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1222:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	raw_atomic_sub(1, v);
1223:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1224:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1225:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1226:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1227:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_dec_return() - atomic decrement with full ordering
1228:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1229:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1230:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - 1) with full ordering.
1231:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1232:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_dec_return() elsewhere.
1233:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
ARM GAS  /tmp/cctjQXNb.s 			page 63


1234:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
1235:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1236:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1237:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_dec_return(atomic_t *v)
1238:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1239:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_dec_return)
1240:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_dec_return(v);
1241:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_dec_return_relaxed)
1242:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
1243:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
1244:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_dec_return_relaxed(v);
1245:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
1246:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1247:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1248:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_sub_return(1, v);
1249:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1250:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1251:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1252:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1253:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_dec_return_acquire() - atomic decrement with acquire ordering
1254:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1255:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1256:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - 1) with acquire ordering.
1257:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1258:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_dec_return_acquire() elsewhere.
1259:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1260:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
1261:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1262:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1263:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_dec_return_acquire(atomic_t *v)
1264:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1265:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_dec_return_acquire)
1266:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_dec_return_acquire(v);
1267:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_dec_return_relaxed)
1268:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_dec_return_relaxed(v);
1269:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
1270:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1271:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_dec_return)
1272:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_dec_return(v);
1273:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1274:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_sub_return_acquire(1, v);
1275:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1276:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1277:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1278:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1279:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_dec_return_release() - atomic decrement with release ordering
1280:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1281:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1282:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - 1) with release ordering.
1283:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1284:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_dec_return_release() elsewhere.
1285:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1286:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
1287:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1288:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1289:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_dec_return_release(atomic_t *v)
1290:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
ARM GAS  /tmp/cctjQXNb.s 			page 64


1291:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_dec_return_release)
1292:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_dec_return_release(v);
1293:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_dec_return_relaxed)
1294:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
1295:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_dec_return_relaxed(v);
1296:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_dec_return)
1297:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_dec_return(v);
1298:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1299:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_sub_return_release(1, v);
1300:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1301:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1302:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1303:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1304:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_dec_return_relaxed() - atomic decrement with relaxed ordering
1305:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1306:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1307:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - 1) with relaxed ordering.
1308:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1309:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_dec_return_relaxed() elsewhere.
1310:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1311:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The updated value of @v.
1312:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1313:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1314:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_dec_return_relaxed(atomic_t *v)
1315:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1316:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_dec_return_relaxed)
1317:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_dec_return_relaxed(v);
1318:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_dec_return)
1319:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_dec_return(v);
1320:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1321:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_sub_return_relaxed(1, v);
1322:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1323:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1324:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1325:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1326:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_dec() - atomic decrement with full ordering
1327:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1328:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1329:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - 1) with full ordering.
1330:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1331:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_dec() elsewhere.
1332:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1333:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1334:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1335:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1336:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_dec(atomic_t *v)
1337:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1338:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_dec)
1339:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_dec(v);
1340:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_dec_relaxed)
1341:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
1342:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
1343:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_fetch_dec_relaxed(v);
1344:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
1345:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1346:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1347:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_fetch_sub(1, v);
ARM GAS  /tmp/cctjQXNb.s 			page 65


1348:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1349:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1350:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1351:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1352:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_dec_acquire() - atomic decrement with acquire ordering
1353:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1354:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1355:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - 1) with acquire ordering.
1356:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1357:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_dec_acquire() elsewhere.
1358:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1359:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1360:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1361:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1362:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_dec_acquire(atomic_t *v)
1363:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1364:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_dec_acquire)
1365:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_dec_acquire(v);
1366:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_dec_relaxed)
1367:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_fetch_dec_relaxed(v);
1368:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
1369:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1370:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_dec)
1371:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_dec(v);
1372:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1373:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_fetch_sub_acquire(1, v);
1374:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1375:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1376:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1377:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1378:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_dec_release() - atomic decrement with release ordering
1379:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1380:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1381:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - 1) with release ordering.
1382:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1383:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_dec_release() elsewhere.
1384:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1385:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1386:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1387:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1388:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_dec_release(atomic_t *v)
1389:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1390:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_dec_release)
1391:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_dec_release(v);
1392:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_dec_relaxed)
1393:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
1394:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_dec_relaxed(v);
1395:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_dec)
1396:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_dec(v);
1397:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1398:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_fetch_sub_release(1, v);
1399:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1400:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1401:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1402:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1403:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_dec_relaxed() - atomic decrement with relaxed ordering
1404:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
ARM GAS  /tmp/cctjQXNb.s 			page 66


1405:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1406:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - 1) with relaxed ordering.
1407:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1408:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_dec_relaxed() elsewhere.
1409:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1410:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1411:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1412:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1413:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_dec_relaxed(atomic_t *v)
1414:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1415:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_dec_relaxed)
1416:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_dec_relaxed(v);
1417:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_dec)
1418:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_dec(v);
1419:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1420:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_fetch_sub_relaxed(1, v);
1421:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1422:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1423:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1424:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1425:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_and() - atomic bitwise AND with relaxed ordering
1426:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1427:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1428:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1429:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v & @i) with relaxed ordering.
1430:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1431:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_and() elsewhere.
1432:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1433:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: Nothing.
1434:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1435:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline void
1436:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_and(int i, atomic_t *v)
1437:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1438:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	arch_atomic_and(i, v);
1439:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1440:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1441:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1442:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_and() - atomic bitwise AND with full ordering
1443:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1444:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1445:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1446:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v & @i) with full ordering.
1447:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1448:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_and() elsewhere.
1449:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1450:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1451:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1452:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1453:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_and(int i, atomic_t *v)
1454:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1455:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_and)
1456:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_and(i, v);
1457:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_and_relaxed)
1458:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
1459:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
1460:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_fetch_and_relaxed(i, v);
1461:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
ARM GAS  /tmp/cctjQXNb.s 			page 67


1462:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1463:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1464:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_and"
1465:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1466:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1467:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1468:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1469:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_and_acquire() - atomic bitwise AND with acquire ordering
1470:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1471:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1472:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1473:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v & @i) with acquire ordering.
1474:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1475:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_and_acquire() elsewhere.
1476:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1477:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1478:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1479:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1480:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_and_acquire(int i, atomic_t *v)
1481:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1482:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_and_acquire)
1483:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_and_acquire(i, v);
1484:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_and_relaxed)
1485:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_fetch_and_relaxed(i, v);
1486:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
1487:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1488:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_and)
1489:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_and(i, v);
1490:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1491:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_and_acquire"
1492:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1493:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1494:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1495:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1496:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_and_release() - atomic bitwise AND with release ordering
1497:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1498:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1499:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1500:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v & @i) with release ordering.
1501:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1502:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_and_release() elsewhere.
1503:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1504:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1505:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1506:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1507:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_and_release(int i, atomic_t *v)
1508:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1509:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_and_release)
1510:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_and_release(i, v);
1511:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_and_relaxed)
1512:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
1513:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_and_relaxed(i, v);
1514:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_and)
1515:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_and(i, v);
1516:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1517:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_and_release"
1518:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
ARM GAS  /tmp/cctjQXNb.s 			page 68


1519:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1520:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1521:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1522:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_and_relaxed() - atomic bitwise AND with relaxed ordering
1523:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1524:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1525:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1526:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v & @i) with relaxed ordering.
1527:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1528:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_and_relaxed() elsewhere.
1529:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1530:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1531:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1532:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1533:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_and_relaxed(int i, atomic_t *v)
1534:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1535:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_and_relaxed)
1536:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_and_relaxed(i, v);
1537:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_and)
1538:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_and(i, v);
1539:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1540:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_and_relaxed"
1541:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1542:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1543:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1544:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1545:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_andnot() - atomic bitwise AND NOT with relaxed ordering
1546:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1547:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1548:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1549:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v & ~@i) with relaxed ordering.
1550:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1551:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_andnot() elsewhere.
1552:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1553:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: Nothing.
1554:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1555:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline void
1556:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_andnot(int i, atomic_t *v)
1557:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1558:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_andnot)
1559:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	arch_atomic_andnot(i, v);
1560:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1561:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	raw_atomic_and(~i, v);
1562:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1563:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1564:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1565:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1566:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_andnot() - atomic bitwise AND NOT with full ordering
1567:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1568:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1569:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1570:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v & ~@i) with full ordering.
1571:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1572:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_andnot() elsewhere.
1573:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1574:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1575:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
ARM GAS  /tmp/cctjQXNb.s 			page 69


1576:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1577:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_andnot(int i, atomic_t *v)
1578:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1579:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_andnot)
1580:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_andnot(i, v);
1581:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_andnot_relaxed)
1582:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
1583:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
1584:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_fetch_andnot_relaxed(i, v);
1585:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
1586:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1587:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1588:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_fetch_and(~i, v);
1589:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1590:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1591:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1592:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1593:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_andnot_acquire() - atomic bitwise AND NOT with acquire ordering
1594:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1595:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1596:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1597:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v & ~@i) with acquire ordering.
1598:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1599:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_andnot_acquire() elsewhere.
1600:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1601:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1602:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1603:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1604:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_andnot_acquire(int i, atomic_t *v)
1605:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1606:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_andnot_acquire)
1607:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_andnot_acquire(i, v);
1608:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_andnot_relaxed)
1609:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_fetch_andnot_relaxed(i, v);
1610:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
1611:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1612:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_andnot)
1613:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_andnot(i, v);
1614:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1615:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_fetch_and_acquire(~i, v);
1616:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1617:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1618:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1619:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1620:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_andnot_release() - atomic bitwise AND NOT with release ordering
1621:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1622:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1623:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1624:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v & ~@i) with release ordering.
1625:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1626:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_andnot_release() elsewhere.
1627:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1628:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1629:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1630:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1631:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_andnot_release(int i, atomic_t *v)
1632:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
ARM GAS  /tmp/cctjQXNb.s 			page 70


1633:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_andnot_release)
1634:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_andnot_release(i, v);
1635:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_andnot_relaxed)
1636:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
1637:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_andnot_relaxed(i, v);
1638:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_andnot)
1639:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_andnot(i, v);
1640:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1641:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_fetch_and_release(~i, v);
1642:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1643:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1644:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1645:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1646:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_andnot_relaxed() - atomic bitwise AND NOT with relaxed ordering
1647:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1648:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1649:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1650:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v & ~@i) with relaxed ordering.
1651:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1652:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_andnot_relaxed() elsewhere.
1653:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1654:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1655:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1656:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1657:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_andnot_relaxed(int i, atomic_t *v)
1658:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1659:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_andnot_relaxed)
1660:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_andnot_relaxed(i, v);
1661:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_andnot)
1662:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_andnot(i, v);
1663:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1664:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_fetch_and_relaxed(~i, v);
1665:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1666:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1667:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1668:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1669:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_or() - atomic bitwise OR with relaxed ordering
1670:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1671:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1672:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1673:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v | @i) with relaxed ordering.
1674:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1675:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_or() elsewhere.
1676:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1677:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: Nothing.
1678:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1679:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline void
1680:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_or(int i, atomic_t *v)
1681:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1682:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	arch_atomic_or(i, v);
1683:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1684:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1685:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1686:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_or() - atomic bitwise OR with full ordering
1687:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1688:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1689:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
ARM GAS  /tmp/cctjQXNb.s 			page 71


1690:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v | @i) with full ordering.
1691:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1692:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_or() elsewhere.
1693:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1694:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1695:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1696:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1697:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_or(int i, atomic_t *v)
1698:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1699:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_or)
1700:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_or(i, v);
1701:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_or_relaxed)
1702:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
1703:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
1704:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_fetch_or_relaxed(i, v);
1705:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
1706:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1707:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1708:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_or"
1709:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1710:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1711:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1712:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1713:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_or_acquire() - atomic bitwise OR with acquire ordering
1714:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1715:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1716:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1717:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v | @i) with acquire ordering.
1718:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1719:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_or_acquire() elsewhere.
1720:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1721:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1722:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1723:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1724:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_or_acquire(int i, atomic_t *v)
1725:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1726:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_or_acquire)
1727:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_or_acquire(i, v);
1728:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_or_relaxed)
1729:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_fetch_or_relaxed(i, v);
1730:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
1731:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1732:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_or)
1733:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_or(i, v);
1734:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1735:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_or_acquire"
1736:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1737:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1738:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1739:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1740:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_or_release() - atomic bitwise OR with release ordering
1741:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1742:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1743:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1744:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v | @i) with release ordering.
1745:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1746:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_or_release() elsewhere.
ARM GAS  /tmp/cctjQXNb.s 			page 72


1747:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1748:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1749:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1750:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1751:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_or_release(int i, atomic_t *v)
1752:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1753:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_or_release)
1754:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_or_release(i, v);
1755:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_or_relaxed)
1756:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
1757:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_or_relaxed(i, v);
1758:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_or)
1759:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_or(i, v);
1760:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1761:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_or_release"
1762:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1763:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1764:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1765:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1766:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_or_relaxed() - atomic bitwise OR with relaxed ordering
1767:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1768:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1769:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1770:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v | @i) with relaxed ordering.
1771:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1772:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_or_relaxed() elsewhere.
1773:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1774:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1775:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1776:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1777:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_or_relaxed(int i, atomic_t *v)
1778:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1779:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_or_relaxed)
1780:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_or_relaxed(i, v);
1781:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_or)
1782:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_or(i, v);
1783:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1784:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_or_relaxed"
1785:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1786:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1787:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1788:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1789:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_xor() - atomic bitwise XOR with relaxed ordering
1790:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1791:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1792:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1793:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v ^ @i) with relaxed ordering.
1794:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1795:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_xor() elsewhere.
1796:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1797:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: Nothing.
1798:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1799:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline void
1800:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_xor(int i, atomic_t *v)
1801:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1802:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	arch_atomic_xor(i, v);
1803:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
ARM GAS  /tmp/cctjQXNb.s 			page 73


1804:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1805:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1806:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_xor() - atomic bitwise XOR with full ordering
1807:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1808:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1809:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1810:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v ^ @i) with full ordering.
1811:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1812:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_xor() elsewhere.
1813:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1814:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1815:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1816:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1817:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_xor(int i, atomic_t *v)
1818:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1819:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_xor)
1820:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_xor(i, v);
1821:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_xor_relaxed)
1822:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
1823:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
1824:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_fetch_xor_relaxed(i, v);
1825:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
1826:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1827:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1828:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_xor"
1829:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1830:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1831:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1832:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1833:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_xor_acquire() - atomic bitwise XOR with acquire ordering
1834:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1835:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1836:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1837:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v ^ @i) with acquire ordering.
1838:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1839:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_xor_acquire() elsewhere.
1840:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1841:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1842:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1843:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1844:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_xor_acquire(int i, atomic_t *v)
1845:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1846:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_xor_acquire)
1847:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_xor_acquire(i, v);
1848:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_xor_relaxed)
1849:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_fetch_xor_relaxed(i, v);
1850:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
1851:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1852:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_xor)
1853:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_xor(i, v);
1854:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1855:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_xor_acquire"
1856:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1857:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1858:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1859:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1860:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_xor_release() - atomic bitwise XOR with release ordering
ARM GAS  /tmp/cctjQXNb.s 			page 74


1861:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1862:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1863:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1864:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v ^ @i) with release ordering.
1865:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1866:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_xor_release() elsewhere.
1867:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1868:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1869:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1870:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1871:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_xor_release(int i, atomic_t *v)
1872:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1873:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_xor_release)
1874:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_xor_release(i, v);
1875:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_xor_relaxed)
1876:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
1877:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_xor_relaxed(i, v);
1878:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_xor)
1879:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_xor(i, v);
1880:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1881:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_xor_release"
1882:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1883:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1884:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1885:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1886:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_fetch_xor_relaxed() - atomic bitwise XOR with relaxed ordering
1887:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value
1888:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1889:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1890:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v ^ @i) with relaxed ordering.
1891:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1892:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_fetch_xor_relaxed() elsewhere.
1893:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1894:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1895:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1896:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1897:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_fetch_xor_relaxed(int i, atomic_t *v)
1898:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1899:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_fetch_xor_relaxed)
1900:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_xor_relaxed(i, v);
1901:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_fetch_xor)
1902:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_fetch_xor(i, v);
1903:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1904:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #error "Unable to define raw_atomic_fetch_xor_relaxed"
1905:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1906:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1907:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1908:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1909:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_xchg() - atomic exchange with full ordering
1910:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1911:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @new: int value to assign
1912:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1913:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to @new with full ordering.
1914:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1915:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_xchg() elsewhere.
1916:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1917:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
ARM GAS  /tmp/cctjQXNb.s 			page 75


1918:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1919:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1920:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_xchg(atomic_t *v, int new)
1921:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1922:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_xchg)
1923:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_xchg(v, new);
1924:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_xchg_relaxed)
1925:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
1926:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
1927:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_xchg_relaxed(v, new);
1928:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
1929:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1930:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1931:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_xchg(&v->counter, new);
1932:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1933:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1934:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1935:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1936:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_xchg_acquire() - atomic exchange with acquire ordering
1937:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1938:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @new: int value to assign
1939:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1940:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to @new with acquire ordering.
1941:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1942:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_xchg_acquire() elsewhere.
1943:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1944:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1945:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1946:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1947:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_xchg_acquire(atomic_t *v, int new)
1948:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1949:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_xchg_acquire)
1950:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_xchg_acquire(v, new);
1951:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_xchg_relaxed)
1952:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_xchg_relaxed(v, new);
1953:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
1954:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
1955:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_xchg)
1956:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_xchg(v, new);
1957:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1958:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_xchg_acquire(&v->counter, new);
1959:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1960:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1961:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1962:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1963:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_xchg_release() - atomic exchange with release ordering
1964:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1965:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @new: int value to assign
1966:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1967:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to @new with release ordering.
1968:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1969:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_xchg_release() elsewhere.
1970:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1971:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1972:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1973:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
1974:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_xchg_release(atomic_t *v, int new)
ARM GAS  /tmp/cctjQXNb.s 			page 76


1975:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
1976:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_xchg_release)
1977:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_xchg_release(v, new);
1978:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_xchg_relaxed)
1979:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
1980:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_xchg_relaxed(v, new);
1981:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_xchg)
1982:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_xchg(v, new);
1983:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
1984:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_xchg_release(&v->counter, new);
1985:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
1986:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
1987:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
1988:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
1989:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_xchg_relaxed() - atomic exchange with relaxed ordering
1990:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
1991:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @new: int value to assign
1992:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1993:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to @new with relaxed ordering.
1994:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1995:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_xchg_relaxed() elsewhere.
1996:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
1997:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
1998:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
1999:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
2000:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_xchg_relaxed(atomic_t *v, int new)
2001:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
2002:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_xchg_relaxed)
2003:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_xchg_relaxed(v, new);
2004:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_xchg)
2005:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_xchg(v, new);
2006:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
2007:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_xchg_relaxed(&v->counter, new);
2008:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
2009:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
2010:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
2011:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
2012:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_cmpxchg() - atomic compare and exchange with full ordering
2013:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
2014:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @old: int value to compare with
2015:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @new: int value to assign
2016:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2017:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * If (@v == @old), atomically updates @v to @new with full ordering.
2018:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Otherwise, @v is not modified and relaxed ordering is provided.
2019:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2020:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_cmpxchg() elsewhere.
2021:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2022:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
2023:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
2024:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
2025:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_cmpxchg(atomic_t *v, int old, int new)
2026:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
2027:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_cmpxchg)
2028:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_cmpxchg(v, old, new);
2029:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_cmpxchg_relaxed)
2030:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret;
2031:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
ARM GAS  /tmp/cctjQXNb.s 			page 77


2032:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_cmpxchg_relaxed(v, old, new);
2033:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
2034:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
2035:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
2036:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_cmpxchg(&v->counter, old, new);
2037:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
2038:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
2039:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
2040:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
2041:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_cmpxchg_acquire() - atomic compare and exchange with acquire ordering
2042:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
2043:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @old: int value to compare with
2044:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @new: int value to assign
2045:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2046:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * If (@v == @old), atomically updates @v to @new with acquire ordering.
2047:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Otherwise, @v is not modified and relaxed ordering is provided.
2048:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2049:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_cmpxchg_acquire() elsewhere.
2050:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2051:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
2052:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
2053:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
2054:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_cmpxchg_acquire(atomic_t *v, int old, int new)
2055:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
2056:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_cmpxchg_acquire)
2057:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_cmpxchg_acquire(v, old, new);
2058:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_cmpxchg_relaxed)
2059:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int ret = arch_atomic_cmpxchg_relaxed(v, old, new);
2060:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
2061:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
2062:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_cmpxchg)
2063:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_cmpxchg(v, old, new);
2064:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
2065:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_cmpxchg_acquire(&v->counter, old, new);
2066:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
2067:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
2068:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
2069:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
2070:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_cmpxchg_release() - atomic compare and exchange with release ordering
2071:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
2072:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @old: int value to compare with
2073:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @new: int value to assign
2074:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2075:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * If (@v == @old), atomically updates @v to @new with release ordering.
2076:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Otherwise, @v is not modified and relaxed ordering is provided.
2077:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2078:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_cmpxchg_release() elsewhere.
2079:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2080:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
2081:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
2082:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
2083:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_cmpxchg_release(atomic_t *v, int old, int new)
2084:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
2085:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_cmpxchg_release)
2086:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_cmpxchg_release(v, old, new);
2087:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_cmpxchg_relaxed)
2088:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
ARM GAS  /tmp/cctjQXNb.s 			page 78


2089:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_cmpxchg_relaxed(v, old, new);
2090:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_cmpxchg)
2091:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_cmpxchg(v, old, new);
2092:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
2093:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_cmpxchg_release(&v->counter, old, new);
2094:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
2095:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
2096:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
2097:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
2098:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_cmpxchg_relaxed() - atomic compare and exchange with relaxed ordering
2099:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
2100:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @old: int value to compare with
2101:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @new: int value to assign
2102:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2103:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * If (@v == @old), atomically updates @v to @new with relaxed ordering.
2104:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Otherwise, @v is not modified and relaxed ordering is provided.
2105:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2106:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_cmpxchg_relaxed() elsewhere.
2107:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2108:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: The original value of @v.
2109:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
2110:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline int
2111:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_cmpxchg_relaxed(atomic_t *v, int old, int new)
2112:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
2113:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_cmpxchg_relaxed)
2114:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_cmpxchg_relaxed(v, old, new);
2115:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_cmpxchg)
2116:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_cmpxchg(v, old, new);
2117:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
2118:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_cmpxchg_relaxed(&v->counter, old, new);
2119:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
2120:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
2121:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
2122:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
2123:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_try_cmpxchg() - atomic compare and exchange with full ordering
2124:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
2125:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @old: pointer to int value to compare with
2126:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @new: int value to assign
2127:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2128:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * If (@v == @old), atomically updates @v to @new with full ordering.
2129:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Otherwise, @v is not modified, @old is updated to the current value of @v,
2130:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * and relaxed ordering is provided.
2131:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2132:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_try_cmpxchg() elsewhere.
2133:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2134:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: @true if the exchange occured, @false otherwise.
2135:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
2136:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline bool
2137:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_try_cmpxchg(atomic_t *v, int *old, int new)
2138:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
2139:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_try_cmpxchg)
2140:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_try_cmpxchg(v, old, new);
2141:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_try_cmpxchg_relaxed)
2142:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	bool ret;
2143:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
2144:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_try_cmpxchg_relaxed(v, old, new);
2145:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
ARM GAS  /tmp/cctjQXNb.s 			page 79


2146:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
2147:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
2148:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int r, o = *old;
2149:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	r = raw_atomic_cmpxchg(v, o, new);
2150:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(r != o))
2151:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*old = r;
2152:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return likely(r == o);
2153:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
2154:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
2155:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
2156:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
2157:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_try_cmpxchg_acquire() - atomic compare and exchange with acquire ordering
2158:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
2159:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @old: pointer to int value to compare with
2160:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @new: int value to assign
2161:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2162:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * If (@v == @old), atomically updates @v to @new with acquire ordering.
2163:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Otherwise, @v is not modified, @old is updated to the current value of @v,
2164:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * and relaxed ordering is provided.
2165:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2166:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_try_cmpxchg_acquire() elsewhere.
2167:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2168:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: @true if the exchange occured, @false otherwise.
2169:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
2170:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline bool
2171:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_try_cmpxchg_acquire(atomic_t *v, int *old, int new)
2172:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
2173:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_try_cmpxchg_acquire)
2174:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_try_cmpxchg_acquire(v, old, new);
2175:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_try_cmpxchg_relaxed)
2176:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	bool ret = arch_atomic_try_cmpxchg_relaxed(v, old, new);
2177:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_acquire_fence();
2178:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
2179:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_try_cmpxchg)
2180:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_try_cmpxchg(v, old, new);
2181:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
2182:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int r, o = *old;
2183:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	r = raw_atomic_cmpxchg_acquire(v, o, new);
2184:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(r != o))
2185:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*old = r;
2186:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return likely(r == o);
2187:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
2188:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
2189:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
2190:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
2191:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_try_cmpxchg_release() - atomic compare and exchange with release ordering
2192:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
2193:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @old: pointer to int value to compare with
2194:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @new: int value to assign
2195:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2196:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * If (@v == @old), atomically updates @v to @new with release ordering.
2197:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Otherwise, @v is not modified, @old is updated to the current value of @v,
2198:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * and relaxed ordering is provided.
2199:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2200:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_try_cmpxchg_release() elsewhere.
2201:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2202:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: @true if the exchange occured, @false otherwise.
ARM GAS  /tmp/cctjQXNb.s 			page 80


2203:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
2204:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline bool
2205:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_try_cmpxchg_release(atomic_t *v, int *old, int new)
2206:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
2207:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_try_cmpxchg_release)
2208:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_try_cmpxchg_release(v, old, new);
2209:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_try_cmpxchg_relaxed)
2210:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_release_fence();
2211:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_try_cmpxchg_relaxed(v, old, new);
2212:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_try_cmpxchg)
2213:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_try_cmpxchg(v, old, new);
2214:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
2215:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int r, o = *old;
2216:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	r = raw_atomic_cmpxchg_release(v, o, new);
2217:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(r != o))
2218:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*old = r;
2219:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return likely(r == o);
2220:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
2221:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
2222:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
2223:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
2224:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_try_cmpxchg_relaxed() - atomic compare and exchange with relaxed ordering
2225:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
2226:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @old: pointer to int value to compare with
2227:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @new: int value to assign
2228:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2229:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * If (@v == @old), atomically updates @v to @new with relaxed ordering.
2230:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Otherwise, @v is not modified, @old is updated to the current value of @v,
2231:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * and relaxed ordering is provided.
2232:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2233:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_try_cmpxchg_relaxed() elsewhere.
2234:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2235:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: @true if the exchange occured, @false otherwise.
2236:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
2237:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline bool
2238:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_try_cmpxchg_relaxed(atomic_t *v, int *old, int new)
2239:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
2240:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_try_cmpxchg_relaxed)
2241:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_try_cmpxchg_relaxed(v, old, new);
2242:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #elif defined(arch_atomic_try_cmpxchg)
2243:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_try_cmpxchg(v, old, new);
2244:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
2245:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	int r, o = *old;
2246:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	r = raw_atomic_cmpxchg_relaxed(v, o, new);
2247:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	if (unlikely(r != o))
2248:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 		*old = r;
2249:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return likely(r == o);
2250:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
2251:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
2252:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
2253:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
2254:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_sub_and_test() - atomic subtract and test if zero with full ordering
2255:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @i: int value to subtract
2256:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
2257:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2258:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - @i) with full ordering.
2259:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
ARM GAS  /tmp/cctjQXNb.s 			page 81


2260:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_sub_and_test() elsewhere.
2261:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2262:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: @true if the resulting value of @v is zero, @false otherwise.
2263:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
2264:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline bool
2265:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_sub_and_test(int i, atomic_t *v)
2266:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
2267:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_sub_and_test)
2268:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_sub_and_test(i, v);
2269:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
2270:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_sub_return(i, v) == 0;
2271:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
2272:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** }
2273:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 
2274:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** /**
2275:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * raw_atomic_dec_and_test() - atomic decrement and test if zero with full ordering
2276:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * @v: pointer to atomic_t
2277:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2278:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Atomically updates @v to (@v - 1) with full ordering.
2279:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2280:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Safe to use in noinstr code; prefer atomic_dec_and_test() elsewhere.
2281:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  *
2282:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  * Return: @true if the resulting value of @v is zero, @false otherwise.
2283:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h ****  */
2284:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** static __always_inline bool
2285:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** raw_atomic_dec_and_test(atomic_t *v)
 376              		.loc 6 2285 1 view .LVU131
2286:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
2287:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #if defined(arch_atomic_dec_and_test)
2288:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return arch_atomic_dec_and_test(v);
2289:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
2290:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return raw_atomic_dec_return(v) == 0;
 377              		.loc 6 2290 2 view .LVU132
 378              	.LBB98:
 379              	.LBI98:
1237:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 380              		.loc 6 1237 1 view .LVU133
1248:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #endif
 381              		.loc 6 1248 2 view .LVU134
 382              	.LVL26:
 383              	.LBB99:
 384              	.LBI99:
 790:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** {
 385              		.loc 6 790 1 view .LVU135
 386              	.LBB100:
 795:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_pre_full_fence();
 387              		.loc 6 795 2 view .LVU136
 796:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	ret = arch_atomic_sub_return_relaxed(i, v);
 388              		.loc 6 796 2 view .LVU137
 389              	.LBB101:
 390              	.LBI101:
 391              		.file 7 "/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h"
   1:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** /* SPDX-License-Identifier: GPL-2.0-or-later */
   2:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** /*
   3:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h ****  * Generic barrier definitions.
   4:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h ****  *
   5:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h ****  * It should be possible to use these on really simple architectures,
ARM GAS  /tmp/cctjQXNb.s 			page 82


   6:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h ****  * but it serves more as a starting point for new ports.
   7:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h ****  *
   8:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h ****  * Copyright (C) 2007 Red Hat, Inc. All Rights Reserved.
   9:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h ****  * Written by David Howells (dhowells@redhat.com)
  10:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h ****  */
  11:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** 
  12:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** #include <linux/rwonce.h>
  13:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** 
  14:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** static inline void sync(void)
  15:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** {
  16:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** 	asm volatile("sync" : : : "memory");
  17:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** }
  18:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** 
  19:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** static inline void eieio(void)
  20:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** {
  21:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** 	asm volatile("eieio" : : : "memory");
  22:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** }
  23:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** 
  24:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** static inline void barrier(void)
 392              		.loc 7 24 20 view .LVU138
 393              	.LBB102:
  25:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** {
  26:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** 	asm volatile("" : : : "memory");
 394              		.loc 7 26 2 view .LVU139
 395              	.LBE102:
 396              	.LBE101:
 797:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	__atomic_post_full_fence();
 397              		.loc 6 797 2 view .LVU140
 398              	.LVL27:
 399              	.LBB103:
 400              	.LBI103:
 401              		.file 8 "/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h"
   1:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** /* SPDX-License-Identifier: GPL-2.0-only */
   2:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** /*
   3:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****  * arch/arm/include/asm/atomic.h
   4:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****  *
   5:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****  * Copyright (C) 1996 Russell King.
   6:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****  * Copyright (C) 2002 Deep Blue Solutions Ltd.
   7:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****  * Modified for uClinux on STM32F407
   8:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****  */
   9:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #ifndef __ASM_ARM_ATOMIC_H
  10:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #define __ASM_ARM_ATOMIC_H
  11:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
  12:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #include <linux/compiler.h> /* Available */
  13:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #include <linux/types.h>    /* Available */
  14:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #include <asm/barrier.h>    /* Available */
  15:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
  16:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** /* Include architecture-specific configuration */
  17:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
  18:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
  19:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #ifdef __KERNEL__
  20:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
  21:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
  22:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
  23:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
  24:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
  25:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** // typedef struct {
ARM GAS  /tmp/cctjQXNb.s 			page 83


  26:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** //     volatile int counter;
  27:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** // } atomic_t;
  28:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
  29:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #define ATOMIC_INIT(i) { (i) }
  30:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
  31:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** /*
  32:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****  * On ARMv7-M, ordinary assignment (str instruction) doesn't clear the local
  33:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****  * strex/ldrex monitor on some implementations. The reason we can use it for
  34:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****  * atomic_set() is the clrex or dummy strex done on every exception return.
  35:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****  */
  36:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #define arch_atomic_read(v) READ_ONCE((v)->counter)
  37:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #define arch_atomic_set(v,i)    WRITE_ONCE(((v)->counter), (i))
  38:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
  39:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** /*
  40:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****  * ARMv6 UP and SMP safe atomic ops.  We use load exclusive and
  41:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****  * store exclusive to ensure that these are atomic.  We may loop
  42:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****  * to ensure that the update happens.
  43:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****  *
  44:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****  * For STM32F407 (Cortex-M4, ARMv7-M), these instructions are available.
  45:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****  */
  46:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
  47:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #define ATOMIC_OP(op, c_op, asm_op)                     \
  48:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** static inline void arch_atomic_##op(int i, atomic_t *v)         \
  49:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** {                                       \
  50:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     unsigned long tmp;                          \
  51:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     int result;                                 \
  52:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****                                         \
  53:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     /* prefetchw(&v->counter); - prefetch not available */ \
  54:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     __asm__ __volatile__("@ atomic_" #op "\n"           \
  55:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "1: ldrex   %0, [%3]\n"                      \
  56:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   " #asm_op " %0, %0, %4\n"                \
  57:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   strex   %1, %0, [%3]\n"                      \
  58:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   teq %1, #0\n"                         \
  59:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   bne 1b"                                \
  60:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     : "=&r" (result), "=&r" (tmp), "+Qo" (v->counter)     \
  61:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     : "r" (&v->counter), "Ir" (i)                 \
  62:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     : "cc");                                   \
  63:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** }
  64:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
  65:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #define ATOMIC_OP_RETURN(op, c_op, asm_op)                  \
  66:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** static inline int arch_atomic_##op##_return_relaxed(int i, atomic_t *v) \
  67:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** {                                       \
  68:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     unsigned long tmp;                          \
  69:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     int result;                                 \
  70:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****                                         \
  71:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     /* prefetchw(&v->counter); - prefetch not available */ \
  72:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     __asm__ __volatile__("@ atomic_" #op "_return\n"        \
  73:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "1: ldrex   %0, [%3]\n"                      \
  74:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   " #asm_op " %0, %0, %4\n"                \
  75:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   strex   %1, %0, [%3]\n"                      \
  76:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   teq %1, #0\n"                         \
  77:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   bne 1b"                                \
  78:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     : "=&r" (result), "=&r" (tmp), "+Qo" (v->counter)     \
  79:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     : "r" (&v->counter), "Ir" (i)                 \
  80:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     : "cc");                                   \
  81:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****                                         \
  82:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     return result;                              \
ARM GAS  /tmp/cctjQXNb.s 			page 84


  83:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** }
  84:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
  85:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #define ATOMIC_FETCH_OP(op, c_op, asm_op)                   \
  86:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** static inline int arch_atomic_fetch_##op##_relaxed(int i, atomic_t *v)  \
  87:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** {                                       \
  88:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     unsigned long tmp;                          \
  89:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     int result, val;                             \
  90:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****                                         \
  91:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     /* prefetchw(&v->counter); - prefetch not available */ \
  92:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     __asm__ __volatile__("@ atomic_fetch_" #op "\n"       \
  93:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "1: ldrex   %0, [%4]\n"                      \
  94:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   " #asm_op " %1, %0, %5\n"                \
  95:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   strex   %2, %1, [%4]\n"                      \
  96:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   teq %2, #0\n"                         \
  97:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   bne 1b"                                \
  98:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     : "=&r" (result), "=&r" (val), "=&r" (tmp), "+Qo" (v->counter) \
  99:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     : "r" (&v->counter), "Ir" (i)                 \
 100:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     : "cc");                                   \
 101:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****                                         \
 102:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     return result;                              \
 103:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** }
 104:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
 105:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #define arch_atomic_add_return_relaxed       arch_atomic_add_return_relaxed
 106:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #define arch_atomic_sub_return_relaxed       arch_atomic_sub_return_relaxed
 107:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #define arch_atomic_fetch_add_relaxed        arch_atomic_fetch_add_relaxed
 108:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #define arch_atomic_fetch_sub_relaxed        arch_atomic_fetch_sub_relaxed
 109:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
 110:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #define arch_atomic_fetch_and_relaxed        arch_atomic_fetch_and_relaxed
 111:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #define arch_atomic_fetch_andnot_relaxed     arch_atomic_fetch_andnot_relaxed
 112:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #define arch_atomic_fetch_or_relaxed         arch_atomic_fetch_or_relaxed
 113:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #define arch_atomic_fetch_xor_relaxed        arch_atomic_fetch_xor_relaxed
 114:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
 115:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** static inline int arch_atomic_cmpxchg_relaxed(atomic_t *ptr, int old, int new)
 116:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** {
 117:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     int oldval;
 118:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     unsigned long res;
 119:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
 120:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     /* prefetchw(&ptr->counter); - prefetch not available */
 121:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
 122:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     do {
 123:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****         __asm__ __volatile__("@ atomic_cmpxchg\n"
 124:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   ldrex   %1, [%3]\n"
 125:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   mov     %0, #0\n"
 126:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   teq     %1, %4\n"
 127:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   strexeq %0, %5, [%3]\n"
 128:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****         : "=&r" (res), "=&r" (oldval), "+Qo" (ptr->counter)
 129:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****         : "r" (&ptr->counter), "Ir" (old), "r" (new)
 130:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****         : "cc");
 131:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     } while (res);
 132:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
 133:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     return oldval;
 134:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** }
 135:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #define arch_atomic_cmpxchg_relaxed        arch_atomic_cmpxchg_relaxed
 136:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
 137:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** static inline int arch_atomic_fetch_add_unless(atomic_t *v, int a, int u)
 138:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** {
 139:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     int oldval, newval;
ARM GAS  /tmp/cctjQXNb.s 			page 85


 140:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     unsigned long tmp;
 141:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
 142:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     /* smp_mb(); - Memory barriers might need specific implementation */
 143:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     /* prefetchw(&v->counter); - prefetch not available */
 144:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
 145:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     __asm__ __volatile__ ("@ atomic_add_unless\n"
 146:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "1: ldrex   %0, [%4]\n"
 147:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   teq %0, %5\n"
 148:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   beq 2f\n"
 149:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   add %1, %0, %6\n"
 150:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   strex   %2, %1, [%4]\n"
 151:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   teq %2, #0\n"
 152:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "   bne 1b\n"
 153:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** "2:"
 154:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     : "=&r" (oldval), "=&r" (newval), "=&r" (tmp), "+Qo" (v->counter)
 155:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     : "r" (&v->counter), "r" (u), "r" (a)
 156:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     : "cc");
 157:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
 158:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     if (oldval != u)
 159:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****         ; /* smp_mb(); - Memory barriers might need specific implementation */
 160:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
 161:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     return oldval;
 162:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** }
 163:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #define arch_atomic_fetch_add_unless         arch_atomic_fetch_add_unless
 164:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
 165:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** #define ATOMIC_OPS(op, c_op, asm_op)                    \
 166:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     ATOMIC_OP(op, c_op, asm_op)                     \
 167:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     ATOMIC_OP_RETURN(op, c_op, asm_op)                  \
 168:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h ****     ATOMIC_FETCH_OP(op, c_op, asm_op)
 169:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** 
 170:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** ATOMIC_OPS(add, +=, add)
 171:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h **** ATOMIC_OPS(sub, -=, sub)
 402              		.loc 8 171 1 view .LVU141
 403              	.LBB104:
 404              		.loc 8 171 1 view .LVU142
 405              		.loc 8 171 1 view .LVU143
 406              		.loc 8 171 1 view .LVU144
 407              		.syntax unified
 408              	@ 171 "/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/atomic.h" 1
 409              		@ atomic_sub_return
 410 000a 53E8002F 	1: ldrex   r2, [r3]
 411 000e A2F10102 	   sub r2, r2, #1
 412 0012 43E80021 	   strex   r1, r2, [r3]
 413 0016 91F0000F 	   teq r1, #0
 414 001a F6D1     	   bne 1b
 415              	@ 0 "" 2
 416              	.LVL28:
 417              		.loc 8 171 1 view .LVU145
 418              		.loc 8 171 1 is_stmt 0 view .LVU146
 419              		.thumb
 420              		.syntax unified
 421              	.LBE104:
 422              	.LBE103:
 798:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** 	return ret;
 423              		.loc 6 798 2 is_stmt 1 view .LVU147
 424              	.LBB105:
 425              	.LBI105:
ARM GAS  /tmp/cctjQXNb.s 			page 86


  24:/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/barrier.h **** {
 426              		.loc 7 24 20 view .LVU148
 427              	.LBB106:
 428              		.loc 7 26 2 view .LVU149
 429              	.LBE106:
 430              	.LBE105:
 799:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 431              		.loc 6 799 2 view .LVU150
 432              	.LVL29:
 799:/mnt/c/Users/31740/Desktop/newcore/include/linux/atomic/atomic-arch-fallback.h **** #else
 433              		.loc 6 799 2 is_stmt 0 view .LVU151
 434              	.LBE100:
 435              	.LBE99:
 436              	.LBE98:
 437              	.LBE97:
 438              	.LBE96:
 439              		.loc 1 69 8 discriminator 1 view .LVU152
 440 001c 4AB9     		cbnz	r2, .L13
  70:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****         if (bio->bi_io_vec != bio->bi_inline_vecs) {
 441              		.loc 1 70 9 is_stmt 1 view .LVU153
 442              		.loc 1 70 16 is_stmt 0 view .LVU154
 443 001e C06B     		ldr	r0, [r0, #60]
 444              	.LVL30:
 445              		.loc 1 70 28 view .LVU155
 446 0020 04F14403 		add	r3, r4, #68
 447              		.loc 1 70 12 view .LVU156
 448 0024 9842     		cmp	r0, r3
 449 0026 01D0     		beq	.L15
  71:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****             kfree(bio->bi_io_vec);
 450              		.loc 1 71 13 is_stmt 1 view .LVU157
 451              	.LVL31:
 452              	.LBB107:
 453              	.LBI107:
 383:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	__sfree__((void*)ptr);
 454              		.loc 4 383 20 view .LVU158
 455              	.LBB108:
 384:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** }
 456              		.loc 4 384 2 view .LVU159
 457 0028 FFF7FEFF 		bl	__sfree__
 458              	.LVL32:
 459              	.L15:
 384:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** }
 460              		.loc 4 384 2 is_stmt 0 view .LVU160
 461              	.LBE108:
 462              	.LBE107:
  72:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****         }
  73:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****         kfree(bio);
 463              		.loc 1 73 9 is_stmt 1 view .LVU161
 464              	.LBB109:
 465              	.LBI109:
 383:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** 	__sfree__((void*)ptr);
 466              		.loc 4 383 20 view .LVU162
 467              	.LBB110:
 384:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** }
 468              		.loc 4 384 2 view .LVU163
 469 002c 2046     		mov	r0, r4
 470 002e FFF7FEFF 		bl	__sfree__
ARM GAS  /tmp/cctjQXNb.s 			page 87


 471              	.LVL33:
 472              	.L13:
 384:/mnt/c/Users/31740/Desktop/newcore/include/linux/slab.h **** }
 473              		.loc 4 384 2 is_stmt 0 view .LVU164
 474              	.LBE110:
 475              	.LBE109:
  74:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     }
  75:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bio = NULL;
  76:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** }
 476              		.loc 1 76 1 view .LVU165
 477 0032 10BD     		pop	{r4, pc}
 478              	.LVL34:
 479              	.L17:
 480              	.LCFI3:
 481              		.cfi_def_cfa_offset 0
 482              		.cfi_restore 4
 483              		.cfi_restore 14
 484              		.loc 1 76 1 view .LVU166
 485 0034 7047     		bx	lr
 486              		.cfi_endproc
 487              	.LFE1035:
 489              		.section	.text.__spin_lock,"ax",%progbits
 490              		.align	1
 491              		.syntax unified
 492              		.thumb
 493              		.thumb_func
 495              	__spin_lock:
 496              	.LVL35:
 497              	.LFB251:
  15:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h **** 
 498              		.loc 2 15 47 is_stmt 1 view -0
 499              		.cfi_startproc
 500              		@ args = 0, pretend = 0, frame = 0
 501              		@ frame_needed = 0, uses_anonymous_args = 0
  15:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h **** 
 502              		.loc 2 15 47 is_stmt 0 view .LVU168
 503 0000 38B5     		push	{r3, r4, r5, lr}
 504              	.LCFI4:
 505              		.cfi_def_cfa_offset 16
 506              		.cfi_offset 3, -16
 507              		.cfi_offset 4, -12
 508              		.cfi_offset 5, -8
 509              		.cfi_offset 14, -4
 510 0002 0446     		mov	r4, r0
  17:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h ****     if(lock->flag == 0){
 511              		.loc 2 17 5 is_stmt 1 view .LVU169
 512 0004 FFF7FEFF 		bl	stop_all_scheduler
 513              	.LVL36:
  18:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h ****           lock->flag = 1;  
 514              		.loc 2 18 5 view .LVU170
  18:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h ****           lock->flag = 1;  
 515              		.loc 2 18 12 is_stmt 0 view .LVU171
 516 0008 2368     		ldr	r3, [r4]
  18:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h ****           lock->flag = 1;  
 517              		.loc 2 18 7 view .LVU172
 518 000a 2BB9     		cbnz	r3, .L21
  19:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h ****           start_all_scheduler();
ARM GAS  /tmp/cctjQXNb.s 			page 88


 519              		.loc 2 19 11 is_stmt 1 view .LVU173
  19:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h ****           start_all_scheduler();
 520              		.loc 2 19 22 is_stmt 0 view .LVU174
 521 000c 0125     		movs	r5, #1
 522 000e 2560     		str	r5, [r4]
  20:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h ****         return 1;
 523              		.loc 2 20 11 is_stmt 1 view .LVU175
 524 0010 FFF7FEFF 		bl	start_all_scheduler
 525              	.LVL37:
  21:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h ****     }
 526              		.loc 2 21 9 view .LVU176
  21:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h ****     }
 527              		.loc 2 21 16 is_stmt 0 view .LVU177
 528 0014 2846     		mov	r0, r5
 529              	.L20:
  28:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h **** 
 530              		.loc 2 28 1 view .LVU178
 531 0016 38BD     		pop	{r3, r4, r5, pc}
 532              	.LVL38:
 533              	.L21:
  25:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h ****         return 0;
 534              		.loc 2 25 9 is_stmt 1 view .LVU179
 535 0018 FFF7FEFF 		bl	start_all_scheduler
 536              	.LVL39:
  26:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h ****     }
 537              		.loc 2 26 9 view .LVU180
  26:/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/spinlock.h ****     }
 538              		.loc 2 26 16 is_stmt 0 view .LVU181
 539 001c 0020     		movs	r0, #0
 540 001e FAE7     		b	.L20
 541              		.cfi_endproc
 542              	.LFE251:
 544              		.section	.text.spin_lock,"ax",%progbits
 545              		.align	1
 546              		.syntax unified
 547              		.thumb
 548              		.thumb_func
 550              	spin_lock:
 551              	.LVL40:
 552              	.LFB254:
  15:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h ****     while (1)
 553              		.loc 3 15 1 is_stmt 1 view -0
 554              		.cfi_startproc
 555              		@ args = 0, pretend = 0, frame = 0
 556              		@ frame_needed = 0, uses_anonymous_args = 0
  15:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h ****     while (1)
 557              		.loc 3 15 1 is_stmt 0 view .LVU183
 558 0000 38B5     		push	{r3, r4, r5, lr}
 559              	.LCFI5:
 560              		.cfi_def_cfa_offset 16
 561              		.cfi_offset 3, -16
 562              		.cfi_offset 4, -12
 563              		.cfi_offset 5, -8
 564              		.cfi_offset 14, -4
 565 0002 0446     		mov	r4, r0
 566 0004 06E0     		b	.L27
 567              	.LVL41:
ARM GAS  /tmp/cctjQXNb.s 			page 89


 568              	.L29:
  19:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h ****             break;
 569              		.loc 3 19 13 is_stmt 1 view .LVU184
  19:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h ****             break;
 570              		.loc 3 19 27 is_stmt 0 view .LVU185
 571 0006 FFF7FEFF 		bl	get_current_task
 572              	.LVL42:
  19:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h ****             break;
 573              		.loc 3 19 25 discriminator 1 view .LVU186
 574 000a 2060     		str	r0, [r4]
  20:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h ****         }
 575              		.loc 3 20 13 is_stmt 1 view .LVU187
 576              	.L24:
  29:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h **** 
 577              		.loc 3 29 1 is_stmt 0 view .LVU188
 578 000c 38BD     		pop	{r3, r4, r5, pc}
 579              	.LVL43:
 580              	.L30:
  26:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h ****         }
 581              		.loc 3 26 13 is_stmt 1 view .LVU189
 582 000e 0520     		movs	r0, #5
 583 0010 FFF7FEFF 		bl	__delay
 584              	.LVL44:
  16:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h ****     {
 585              		.loc 3 16 11 view .LVU190
 586              	.L27:
  16:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h ****     {
 587              		.loc 3 16 5 view .LVU191
  18:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h ****             lock->owner = get_current_task();
 588              		.loc 3 18 9 view .LVU192
  18:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h ****             lock->owner = get_current_task();
 589              		.loc 3 18 12 is_stmt 0 view .LVU193
 590 0014 2046     		mov	r0, r4
 591 0016 FFF7FEFF 		bl	__spin_lock
 592              	.LVL45:
  18:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h ****             lock->owner = get_current_task();
 593              		.loc 3 18 11 discriminator 1 view .LVU194
 594 001a 0128     		cmp	r0, #1
 595 001c F3D0     		beq	.L29
  22:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h ****             return;   
 596              		.loc 3 22 15 is_stmt 1 view .LVU195
  22:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h ****             return;   
 597              		.loc 3 22 22 is_stmt 0 view .LVU196
 598 001e 2568     		ldr	r5, [r4]
  22:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h ****             return;   
 599              		.loc 3 22 33 view .LVU197
 600 0020 FFF7FEFF 		bl	get_current_task
 601              	.LVL46:
  22:/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock.h ****             return;   
 602              		.loc 3 22 17 discriminator 1 view .LVU198
 603 0024 8542     		cmp	r5, r0
 604 0026 F2D1     		bne	.L30
 605 0028 F0E7     		b	.L24
 606              		.cfi_endproc
 607              	.LFE254:
 609              		.section	.text.submit_bio_wait,"ax",%progbits
 610              		.align	1
ARM GAS  /tmp/cctjQXNb.s 			page 90


 611              		.global	submit_bio_wait
 612              		.syntax unified
 613              		.thumb
 614              		.thumb_func
 616              	submit_bio_wait:
 617              	.LVL47:
 618              	.LFB1038:
  77:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** 
  78:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** EXPORT_SYMBOL(bio_put);
  79:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** 
  80:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** 
  81:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** 
  82:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** int bio_add_page(struct bio *bio, struct page *page,
  83:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     unsigned int len, unsigned int offset)
  84:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** {
  85:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     return __bio_add_page(bio,page,len,offset);
  86:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** }
  87:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** EXPORT_SYMBOL(bio_add_page);
  88:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** 
  89:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** 
  90:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** 
  91:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** int __bio_add_page(struct bio *bio, struct page *page,
  92:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     unsigned int len, unsigned int off)
  93:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** {
  94:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     struct bio_vec *bv;
  95:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     if (unlikely(!bio || !page || off >= PAGE_SIZE)) return  -ENOMEM;;
  96:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     if (bio->bi_vcnt >= bio->bi_max_vecs) return -ENOMEM;
  97:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     if (bio->bi_iter.bi_size + len > (256 << PAGE_SHIFT))return -ENOMEM;;
  98:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bv = &bio->bi_io_vec[bio->bi_vcnt];
  99:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bv->bv_page           = page;
 100:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bv->bv_offset         = off;
 101:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bv->bv_len            = len;
 102:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bio->bi_iter.bi_size += len;
 103:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bio->bi_vcnt++;
 104:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     return 0;
 105:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** }
 106:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** 
 107:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** 
 108:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** 
 109:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** 
 110:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** void submit_bio_wait(struct bio *bio)
 111:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** {
 619              		.loc 1 111 1 is_stmt 1 view -0
 620              		.cfi_startproc
 621              		@ args = 0, pretend = 0, frame = 0
 622              		@ frame_needed = 0, uses_anonymous_args = 0
 623              		.loc 1 111 1 is_stmt 0 view .LVU200
 624 0000 70B5     		push	{r4, r5, r6, lr}
 625              	.LCFI6:
 626              		.cfi_def_cfa_offset 16
 627              		.cfi_offset 4, -16
 628              		.cfi_offset 5, -12
 629              		.cfi_offset 6, -8
 630              		.cfi_offset 14, -4
 631 0002 0446     		mov	r4, r0
 112:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     struct request *rq =  blk_get_request(bio->bi_bdev->bd_queue,bio->bi_opf,GFP_KERNEL);  
 632              		.loc 1 112 5 is_stmt 1 view .LVU201
ARM GAS  /tmp/cctjQXNb.s 			page 91


 633              		.loc 1 112 46 is_stmt 0 view .LVU202
 634 0004 4368     		ldr	r3, [r0, #4]
 635              		.loc 1 112 27 view .LVU203
 636 0006 DD68     		ldr	r5, [r3, #12]
 637 0008 8668     		ldr	r6, [r0, #8]
 638              	.LVL48:
 639              	.LBB111:
 640              	.LBI111:
 641              		.file 9 "/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h"
   1:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** /* SPDX-License-Identifier: GPL-2.0 */
   2:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** /*
   3:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****  * Portions Copyright (C) 1992 Drew Eckhardt
   4:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****  */
   5:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** #ifndef _LINUX_BLKDEV_H
   6:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** #define _LINUX_BLKDEV_H
   7:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
   8:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** #include <linux/types.h>
   9:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** #include <linux/blk-mq.h>
  10:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** #include <linux/blk_types.h>
  11:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** #include <linux/refcount_types.h>
  12:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** #include <linux/lockdep_types.h>
  13:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** #include <linux/blk_types.h>
  14:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** #include <linux/workqueue_types.h>
  15:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** #include <linux/blk.h>
  16:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** #include <linux/pr.h>
  17:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** #include <linux/hdreg.h>
  18:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** #include <linux/kdev_t.h>
  19:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
  20:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** struct gendisk;
  21:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
  22:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
  23:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** /*
  24:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****  * Maximum number of blkcg policies allowed to be registered concurrently.
  25:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****  * Defined here to simplify include dependency.
  26:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****  */
  27:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** #define BLKCG_MAX_POLS		6
  28:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
  29:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** #define DISK_MAX_PARTS			256
  30:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** #define DISK_NAME_LEN			32
  31:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
  32:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** #define PARTITION_META_INFO_VOLNAMELTH	64
  33:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** /*
  34:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****  * Enough for the string representation of any kind of UUID plus NULL.
  35:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****  * EFI UUID is 36 characters. MSDOS UUID is 11 characters.
  36:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****  */
  37:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** #define PARTITION_META_INFO_UUIDLTH	(UUID_STRING_LEN + 1)
  38:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
  39:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** struct partition_meta_info {
  40:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	char uuid[PARTITION_META_INFO_UUIDLTH];
  41:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	u8 volname[PARTITION_META_INFO_VOLNAMELTH];
  42:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** };
  43:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
  44:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** /**
  45:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****  * DOC: genhd capability flags
  46:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****  *
  47:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****  * ``GENHD_FL_REMOVABLE``: indicates that the block device gives access to
  48:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****  * removable media.  When set, the device remains present even when media is not
ARM GAS  /tmp/cctjQXNb.s 			page 92


  49:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****  * inserted.  Shall not be set for devices which are removed entirely when the
  50:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****  * media is removed.
  51:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****  *
  52:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****  * ``GENHD_FL_HIDDEN``: the block device is hidden; it doesn't produce events,
  53:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****  * doesn't appear in sysfs, and can't be opened from userspace or using
  54:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****  * blkdev_get*. Used for the underlying components of multipath devices.
  55:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****  *
  56:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****  * ``GENHD_FL_NO_PART``: partition support is disabled.  The kernel will not
  57:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****  * scan for partitions from add_disk, and users can't add partitions manually.
  58:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****  *
  59:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****  */
  60:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** enum {
  61:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	GENHD_FL_REMOVABLE			= 1 << 0,
  62:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	GENHD_FL_HIDDEN				= 1 << 1,
  63:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	GENHD_FL_NO_PART			= 1 << 2,
  64:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** };
  65:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
  66:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** enum {
  67:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	DISK_EVENT_MEDIA_CHANGE			= 1 << 0, /* media changed */
  68:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	DISK_EVENT_EJECT_REQUEST		= 1 << 1, /* eject requested */
  69:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** };
  70:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
  71:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** enum {
  72:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	/* Poll even if events_poll_msecs is unset */
  73:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	DISK_EVENT_FLAG_POLL			= 1 << 0,
  74:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	/* Forward events to udev */
  75:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	DISK_EVENT_FLAG_UEVENT			= 1 << 1,
  76:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	/* Block event polling when open for exclusive write */
  77:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	DISK_EVENT_FLAG_BLOCK_ON_EXCL_WRITE	= 1 << 2,
  78:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** };
  79:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
  80:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
  81:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
  82:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** enum blk_integrity_checksum {
  83:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	BLK_INTEGRITY_CSUM_NONE		= 0,
  84:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	BLK_INTEGRITY_CSUM_IP		= 1,
  85:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	BLK_INTEGRITY_CSUM_CRC		= 2,
  86:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	BLK_INTEGRITY_CSUM_CRC64	= 3,
  87:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** } __packed ;
  88:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
  89:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** struct blk_integrity {
  90:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned char				flags;
  91:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	enum blk_integrity_checksum		csum_type;
  92:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned char				tuple_size;
  93:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned char				pi_offset;
  94:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned char				interval_exp;
  95:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned char				tag_size;
  96:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** };
  97:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
  98:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
  99:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** typedef unsigned int __bitwise blk_mode_t;
 100:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 101:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** /* open for reading */
 102:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** #define BLK_OPEN_READ		((__force blk_mode_t)(1 << 0))
 103:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** /* open for writing */
 104:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** #define BLK_OPEN_WRITE		((__force blk_mode_t)(1 << 1))
 105:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** /* open exclusively (vs other exclusive openers */
ARM GAS  /tmp/cctjQXNb.s 			page 93


 106:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** #define BLK_OPEN_EXCL		((__force blk_mode_t)(1 << 2))
 107:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** /* opened with O_NDELAY */
 108:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** #define BLK_OPEN_NDELAY		((__force blk_mode_t)(1 << 3))
 109:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** /* open for "writes" only for ioctls (specialy hack for floppy.c) */
 110:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** #define BLK_OPEN_WRITE_IOCTL	((__force blk_mode_t)(1 << 4))
 111:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** /* open is exclusive wrt all other BLK_OPEN_WRITE opens to the device */
 112:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** #define BLK_OPEN_RESTRICT_WRITES	((__force blk_mode_t)(1 << 5))
 113:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** /* return partition scanning errors */
 114:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** #define BLK_OPEN_STRICT_SCAN	((__force blk_mode_t)(1 << 6))
 115:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 116:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 117:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** enum block_device_flags_t
 118:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** {
 119:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	BLOCK_DEVICE_FLAG_NOT_INITIALIZED,       //æœªåˆå§‹åŒ–å­˜å‚¨è®¾å¤‡
 120:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     BLOCK_DEVICE_FLAG_MBR,                   //å•mbråˆ†åŒº
 121:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     BLOCK_DEVICE_FLAG_GPT,                   //å•gptåˆ†åŒº
 122:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     BLOCK_DEVICE_FLAG_PROTECTIVE_MBR ,       //ä¿æŠ¤MBRåˆ†åŒº(gptåˆ†åŒº,ä¸ºäº†å…¼å®¹æ—§çš„æ“MBRåˆ
 123:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     BLOCK_DEVICE_FLAG_BROKEN_MBR,            //æŸåçš„MBRåˆ†åŒº
 124:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     BLOCK_DEVICE_FLAG_BROKEN_GPT,            //æŸåçš„GPTåˆ†åŒº
 125:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     BLOCK_DEVICE_FLAG_BROKEN_PROTECTIVE_MBR, //æŸåçš„ä¿æŠ¤MBRåˆ†åŒº
 126:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** };
 127:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 128:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** static const char *block_device_flag_to_string(enum block_device_flags_t flag) {
 129:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     switch (flag) {
 130:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****         case BLOCK_DEVICE_FLAG_MBR:
 131:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****             return "BLOCK_DEVICE_FLAG_MBR";
 132:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****         case BLOCK_DEVICE_FLAG_GPT:
 133:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****             return "BLOCK_DEVICE_FLAG_GPT";
 134:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****         case BLOCK_DEVICE_FLAG_PROTECTIVE_MBR:
 135:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****             return "BLOCK_DEVICE_FLAG_PROTECTIVE_MBR";
 136:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****         case BLOCK_DEVICE_FLAG_NOT_INITIALIZED:
 137:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****             return "BLOCK_DEVICE_FLAG_NOT_INITIALIZED";
 138:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****         case BLOCK_DEVICE_FLAG_BROKEN_MBR:
 139:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****             return "BLOCK_DEVICE_FLAG_BROKEN_MBR";
 140:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****         case BLOCK_DEVICE_FLAG_BROKEN_GPT:
 141:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****             return "BLOCK_DEVICE_FLAG_BROKEN_GPT";
 142:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****         case BLOCK_DEVICE_FLAG_BROKEN_PROTECTIVE_MBR:
 143:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****             return "BLOCK_DEVICE_FLAG_BROKEN_PROTECTIVE_MBR";
 144:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****         default:
 145:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****             return "Unknown flag";
 146:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     }
 147:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** }
 148:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 149:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 150:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 151:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** struct gpt_header {
 152:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     uint64_t signature;             // å¿…é¡»æ˜¯ "EFI PART"
 153:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     uint32_t revision;              // ä¿®è®¢ç‰ˆæœ¬ï¼Œé€šå¸¸ä¸º0x00010000
 154:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     uint32_t header_size;           // å¤´éƒ¨å¤§å°ï¼ˆé€šå¸¸ä¸º92å­—èŠ‚ï¼‰
 155:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     uint32_t header_crc32;          // å¤´éƒ¨çš„CRC32æ ¡éªŒå’Œ
 156:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     uint32_t reserved;              // ä¿ç•™å­—æ®µ
 157:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     uint64_t my_lba;                // å½“å‰GPTè¡¨æ‰€åœ¨çš„LBA
 158:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     uint64_t backup_lba;            // å¤‡ä»½GPTè¡¨æ‰€åœ¨çš„LBA
 159:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     uint64_t first_usable_lba;      // ç¬¬ä¸€ä¸ªå¯ç”¨çš„LBAï¼ˆGPTåˆ†åŒºçš„å¼€å§‹ä½ç½®ï¼‰
 160:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     uint64_t last_usable_lba;       // æœ€åŽä¸€ä¸ªå¯ç”¨çš„LBAï¼ˆGPTåˆ†åŒºçš„ç»“æŸä½ç½®ï¼‰
 161:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     uint8_t disk_guid[16];          // ç£ç›˜çš„GUID
 162:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     uint64_t partition_entry_start_lba; // åˆ†åŒºè¡¨çš„èµ·å§‹LBA
ARM GAS  /tmp/cctjQXNb.s 			page 94


 163:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     uint32_t partition_entry_count; // åˆ†åŒºè¡¨é¡¹çš„æ•°é‡    
 164:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     uint32_t partition_entry_size;  // æ¯ä¸ªåˆ†åŒºè¡¨é¡¹çš„å¤§å°
 165:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     uint32_t partition_entry_crc32; // åˆ†åŒºè¡¨é¡¹çš„CRC32æ ¡éªŒå’Œ
 166:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** } __attribute__((packed));
 167:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 168:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 169:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** struct gpt_partition_entry {
 170:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     uint8_t partition_type_guid[16];   // åˆ†åŒºç±»åž‹çš„GUID
 171:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     uint8_t unique_partition_guid[16]; // åˆ†åŒºçš„å”¯ä¸€GUID
 172:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     uint64_t starting_lba;             // åˆ†åŒºçš„èµ·å§‹LBA
 173:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     uint64_t ending_lba;               // åˆ†åŒºçš„ç»“æŸLBA
 174:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     uint64_t attributes;               // åˆ†åŒºå±žæ€§
 175:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     uint16_t partition_name[36];       // åˆ†åŒºåç§°ï¼ˆUTF-16ç¼–ç ï¼‰
 176:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** }__attribute__((packed));
 177:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 178:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 179:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** struct gpt_partition {
 180:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     struct gpt_header header;
 181:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     struct gpt_partition_entry entries[8];
 182:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** };
 183:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 184:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 185:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** struct mbr_partition {
 186:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     uint8_t boot_ind;   // å¯åŠ¨æ ‡å¿—ï¼ˆ0x80è¡¨ç¤ºæ´»åŠ¨åˆ†åŒºï¼‰
 187:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     
 188:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     uint8_t start_head; 
 189:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     uint8_t start_sector; 
 190:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     uint8_t start_cyl;  
 191:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 192:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     uint8_t sys_ind;    // ç³»ç»Ÿid(åˆ†åŒºç±»åž‹)
 193:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 194:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     uint8_t end_head;   
 195:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     uint8_t end_sector; 
 196:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     uint8_t end_cyl;    
 197:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     
 198:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     uint32_t start_lba; // åˆ†åŒºçš„èµ·å§‹åœ°å€
 199:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     
 200:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     uint32_t nr_sectors; // åˆ†åŒºå¤§å°
 201:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** }__attribute__((packed));
 202:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 203:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 204:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** struct partition {
 205:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	struct gpt_partition gpt_partition;
 206:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	struct mbr_partition mbr_partition[4];   
 207:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** };
 208:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 209:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 210:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 211:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 212:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 213:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** struct gendisk {
 214:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	int major;
 215:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	int first_minor;
 216:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	int minors;
 217:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	char disk_name[DISK_NAME_LEN];	/* name of major driver */
 218:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned short events;		/* supported events */
 219:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned short event_flags;	/* flags related to event processing */
ARM GAS  /tmp/cctjQXNb.s 			page 95


 220:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	struct xarray part_tbl;
 221:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	struct block_device *part0;
 222:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	const struct block_device_operations *fops; 
 223:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****  	struct request_queue *queue;
 224:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	void *private_data;
 225:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 226:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** //	struct bio_set bio_split;    /*ä¸ºèŠ‚çº¦å†…å­˜ä¸ä½¿ç”¨*/
 227:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 228:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	int flags;
 229:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned long state;
 230:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 231:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** #define GD_NEED_PART_SCAN		0
 232:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** #define GD_READ_ONLY			1
 233:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** #define GD_DEAD				2
 234:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** #define GD_NATIVE_CAPACITY		3
 235:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** #define GD_ADDED			4
 236:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** #define GD_SUPPRESS_PART_SCAN		5
 237:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** #define GD_OWNS_QUEUE			6
 238:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 239:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	struct mutex open_mutex;	/* open/close mutex */
 240:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned open_partitions;	/* number of open partitions */   
 241:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** //	struct backing_dev_info	*bdi;
 242:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** //	struct kobject queue_kobj;	/* the queue/ directory */
 243:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	struct kobject *slave_dir;
 244:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** #ifdef CONFIG_BLOCK_HOLDER_DEPRECATED
 245:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	  struct list_head slave_bdevs;
 246:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** #endif
 247:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	int node_id;
 248:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** //	struct badblocks *bb;
 249:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	struct lockdep_map lockdep_map;
 250:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	u64 diskseq;
 251:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	blk_mode_t open_mode;
 252:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	struct blk_independent_access_ranges *ia_ranges;
 253:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** };
 254:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 255:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 256:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 257:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 258:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** typedef unsigned int __bitwise blk_features_t;
 259:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** /* internal flags in queue_limits.flags */
 260:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** typedef unsigned int __bitwise blk_flags_t;
 261:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 262:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** struct queue_limits {
 263:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	blk_features_t		features;
 264:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	blk_flags_t		flags;
 265:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned long		seg_boundary_mask;
 266:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned long		virt_boundary_mask;
 267:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 268:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned int		max_hw_sectors;
 269:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned int		max_dev_sectors;
 270:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned int		chunk_sectors;
 271:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned int		max_sectors;
 272:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned int		max_user_sectors;
 273:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned int		max_segment_size;
 274:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned int		physical_block_size;
 275:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned int		logical_block_size;
 276:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned int		alignment_offset;
ARM GAS  /tmp/cctjQXNb.s 			page 96


 277:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned int		io_min;
 278:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned int		io_opt;
 279:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned int		max_discard_sectors;
 280:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned int		max_hw_discard_sectors;
 281:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned int		max_user_discard_sectors;
 282:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned int		max_secure_erase_sectors;
 283:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned int		max_write_zeroes_sectors;
 284:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned int		max_hw_zone_append_sectors;
 285:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned int		max_zone_append_sectors;
 286:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned int		discard_granularity;
 287:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned int		discard_alignment;
 288:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned int		zone_write_granularity;
 289:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 290:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	/* atomic write limits */
 291:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned int		atomic_write_hw_max;
 292:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned int		atomic_write_max_sectors;
 293:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned int		atomic_write_hw_boundary;
 294:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned int		atomic_write_boundary_sectors;
 295:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned int		atomic_write_hw_unit_min;
 296:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned int		atomic_write_unit_min;
 297:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned int		atomic_write_hw_unit_max;
 298:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned int		atomic_write_unit_max;
 299:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 300:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned short		max_segments;
 301:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned short		max_integrity_segments;
 302:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned short		max_discard_segments;
 303:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 304:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned int		max_open_zones;
 305:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned int		max_active_zones;
 306:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 307:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	/*
 308:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	 * Drivers that set dma_alignment to less than 511 must be prepared to
 309:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	 * handle individual bvec's that are not a multiple of a SECTOR_SIZE
 310:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	 * due to possible offsets.
 311:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	 */
 312:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned int		dma_alignment;
 313:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned int		dma_pad_mask;
 314:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 315:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	struct blk_integrity	integrity;
 316:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** };
 317:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 318:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** struct blk_zone {
 319:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	uint8_t magic;
 320:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** };
 321:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 322:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** typedef int (*report_zones_cb)(struct blk_zone *zone, unsigned int idx,
 323:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     void *data);
 324:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 325:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 326:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 327:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // struct request_queue {
 328:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 329:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	void			*queuedata;           //å­˜å‚¨ç§æœ‰æ•°æ®
 330:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	struct elevator_queue	*elevator;   //æŒ‡å‘ioè°ƒåº¦å™¨çš„å®žçŽ°
 331:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	const struct blk_mq_ops	*mq_ops;     //æŒ‡å‘å—è®¾å¤‡å¤šé˜Ÿåˆ—
 332:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	struct blk_mq_ctx __percpu	*queue_ctx; //æŒ‡å‘æ¯ä¸ª CPU çš„ä¸Šä¸‹æ–‡ç»“æž„
 333:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	unsigned long		queue_flags;         //é˜Ÿåˆ—çš„æ ‡å¿—ä½
ARM GAS  /tmp/cctjQXNb.s 			page 97


 334:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	unsigned int		rq_timeout;        //è¯·æ±‚è¶…æ—¶æ—¶é—´
 335:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	unsigned int		queue_depth;       //é˜Ÿåˆ—æ·±åº¦
 336:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	refcount_t		refs;              //å¼•ç”¨è®¡æ•°
 337:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	unsigned int		nr_hw_queues;  //ç¡¬ä»¶é˜Ÿåˆ—æ•°é‡
 338:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	struct xarray		hctx_table;     //ç¡¬ä»¶ä¸Šä¸‹æ–‡ï¼ˆhardware contextï¼‰çš„ç´¢å¼•è¡¨ã€‚
 339:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	struct percpu_ref	q_usage_counter; //é˜Ÿåˆ—ä½¿ç”¨è®¡æ•°å™¨ã€‚
 340:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	struct lock_class_key	io_lock_cls_key; //I/O é”çš„è°ƒè¯•ä¿¡æ¯ã€‚
 341:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	struct lockdep_map	io_lockdep_map;     
 342:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	struct lock_class_key	q_lock_cls_key;   //é˜Ÿåˆ—é”çš„è°ƒè¯•ä¿¡æ¯ã€‚
 343:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	struct lockdep_map	q_lockdep_map;
 344:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	struct request		*last_merge;          //ä¸Šä¸€æ¬¡åˆå¹¶çš„è¯·æ±‚ã€‚
 345:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	spinlock_t		queue_lock;				  //é˜Ÿåˆ—çš„è‡ªæ—‹é”ã€‚
 346:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	int			quiesce_depth;			     //é™æ­¢ï¼ˆquiesceï¼‰æ·±åº¦
 347:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	struct gendisk		*disk;				//æŒ‡å‘å…³è”çš„ç£ç›˜è®¾å¤‡ã€‚
 348:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	struct kobject *mq_kobj; //å¤šé˜Ÿåˆ—çš„å†…æ ¸å¯¹è±¡ã€‚ç”¨äºŽ sysfs æ–‡ä»¶ç³»ç»Ÿï¼Œå°†é˜Ÿåˆ—çš„å
 349:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	struct queue_limits	limits;//é˜Ÿåˆ—çš„é™åˆ¶å‚æ•°ã€‚å®šä¹‰äº†é˜Ÿåˆ—çš„ç‰©ç†å’Œé€»è¾‘é™åˆ¶ï¼ˆ
 350:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	atomic_t		pm_only;     //ç”µæºç®¡ç†ç›¸å…³çš„æ ‡å¿—
 351:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	struct blk_queue_stats	*stats; //é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯
 352:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	struct rq_qos		*rq_qos;         //è¯·æ±‚æœåŠ¡è´¨é‡ï¼ˆQoSï¼‰ç»“æž„åŠå…¶äº’æ–¥é”ã€‚
 353:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	struct mutex		rq_qos_mutex;
 354:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	int			id;							//é˜Ÿåˆ—çš„å”¯ä¸€æ ‡è¯†ç¬¦
 355:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	unsigned long		nr_requests;	    //é˜Ÿåˆ—æ”¯æŒçš„æœ€å¤§è¯·æ±‚æ•°ã€‚
 356:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	struct timer_list	timeout;			//è¶…æ—¶è®¡æ—¶å™¨å’Œå·¥ä½œé˜Ÿåˆ—ã€‚
 357:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	struct work_struct	timeout_work;
 358:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	atomic_t		nr_active_requests_shared_tags; //å…±äº«æ ‡ç­¾çš„æ´»è·ƒè¯·æ±‚æ•°
 359:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	struct blk_mq_tags	*sched_shared_tags;           //è°ƒåº¦å™¨çš„å…±äº«æ ‡ç­¾ã€‚
 360:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	struct list_head	icq_list;          //I/O ä¸Šä¸‹æ–‡é˜Ÿåˆ—é“¾è¡¨
 361:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	int			node;					//NUMA èŠ‚ç‚¹ IDã€‚
 362:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	spinlock_t		requeue_lock;    //é‡æŽ’é˜Ÿåˆ—çš„é”ã€é“¾è¡¨å’Œå·¥ä½œé˜Ÿåˆ—ã€‚
 363:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	struct list_head	requeue_list;
 364:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** //     struct delayed_work	requeue_work;
 365:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	struct blk_flush_queue	*fq;        //åˆ·æ–°é˜Ÿåˆ—åŠå…¶é“¾è¡¨
 366:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	struct list_head	flush_list;
 367:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	struct mutex		sysfs_lock;          //sysfs å’Œé™åˆ¶å‚æ•°çš„äº’æ–¥é”ã€‚
 368:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	struct mutex		sysfs_dir_lock;
 369:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	struct mutex		limits_lock;
 370:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	struct list_head	unused_hctx_list;     //æœªä½¿ç”¨çš„ç¡¬ä»¶ä¸Šä¸‹æ–‡é“¾è¡¨åŠå…¶é”ã€‚
 371:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	spinlock_t		unused_hctx_lock;
 372:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	int			mq_freeze_depth;             //å¤šé˜Ÿåˆ—å†»ç»“æ·±åº¦ã€‚
 373:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	struct rcu_head		rcu_head;           //RCUï¼ˆRead-Copy-Updateï¼‰é‡Šæ”¾é’©å­ã€‚
 374:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	wait_queue_head_t	mq_freeze_wq;         //å¤šé˜Ÿåˆ—å†»ç»“çš„ç­‰å¾…é˜Ÿåˆ—å’Œé”ã€‚
 375:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	struct mutex		mq_freeze_lock; 
 376:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	struct blk_mq_tag_set	*tag_set;       //æ ‡ç­¾é›†åŠå…¶é“¾è¡¨ã€‚
 377:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	struct list_head	tag_set_list;
 378:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	struct dentry		*debugfs_dir;       //debugfs æ–‡ä»¶ç³»ç»Ÿçš„ç›®å½•é¡¹ã€‚
 379:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	struct dentry		*sched_debugfs_dir;
 380:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	struct dentry		*rqos_debugfs_dir;
 381:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	struct mutex		debugfs_mutex;     //debugfs æ“ä½œçš„äº’æ–¥é”ã€‚
 382:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	bool			mq_sysfs_init_done;    //å¤šé˜Ÿåˆ— sysfs åˆå§‹åŒ–å®Œæˆæ ‡å¿—ã€‚
 383:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // };
 384:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 385:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 386:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** typedef void(*request_fn_t)(struct request *req);
 387:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 388:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** struct request_queue {
 389:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 390:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	void			*queuedata;             //å­˜å‚¨ç§æœ‰æ•°æ®
ARM GAS  /tmp/cctjQXNb.s 			page 98


 391:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	struct request		*last_merge;        //ä¸Šä¸€æ¬¡åˆå¹¶çš„è¯·æ±‚ã€‚
 392:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	spinlock_t		queue_lock;				//é˜Ÿåˆ—çš„è‡ªæ—‹é”ã€‚
 393:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	int			quiesce_depth;			    //é™æ­¢ï¼ˆquiesceï¼‰æ·±åº¦
 394:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	struct gendisk		*disk;				//æŒ‡å‘å…³è”çš„ç£ç›˜è®¾å¤‡ã€‚
 395:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	struct queue_limits	limits;             //é˜Ÿåˆ—çš„é™åˆ¶å‚æ•°ã€‚å®šä¹‰äº†é˜Ÿåˆ—çš„ç‰©ç†å’Œé€»è¾
 396:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	int			id;							//é˜Ÿåˆ—çš„å”¯ä¸€æ ‡è¯†ç¬¦
 397:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned long		nr_requests;	    //é˜Ÿåˆ—æ”¯æŒçš„æœ€å¤§è¯·æ±‚æ•°ã€‚
 398:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	struct list_head	icq_list;           //I/O ä¸Šä¸‹æ–‡é˜Ÿåˆ—é“¾è¡¨
 399:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	int			node;					    //NUMA èŠ‚ç‚¹ IDã€‚
 400:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	request_fn_t q_fn;                      //å•é˜Ÿåˆ—è®¾å¤‡æ“ä½œ
 401:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	spinlock_t*  q_lock;
 402:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** };
 403:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 404:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 405:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 406:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 407:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** static inline dev_t disk_devt(struct gendisk *disk)
 408:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** {
 409:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	return MKDEV(disk->major, disk->first_minor);
 410:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** }
 411:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 412:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 413:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** /* blk_validate_limits() validates bsize, so drivers don't usually need to */
 414:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** static inline int blk_validate_block_size(unsigned long bsize)
 415:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** {
 416:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	if (bsize < 512 || bsize > PAGE_SIZE || !is_power_of_2(bsize))
 417:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 		return -EINVAL;
 418:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 419:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	return 0;
 420:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** }
 421:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 422:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // static inline bool blk_op_is_passthrough(blk_opf_t op)
 423:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // {
 424:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	op &= REQ_OP_MASK;
 425:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // 	return op == REQ_OP_DRV_IN || op == REQ_OP_DRV_OUT;
 426:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** // }
 427:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 428:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 429:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 430:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** extern struct request_queue *request_queue_init(int id, struct gendisk *gd,gfp_t flags);
 431:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 432:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** extern void request_queue_add(struct request_queue *q, struct request *req);
 433:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 434:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** extern void request_queue_remove(struct request_queue *q, struct request *req);
 435:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 436:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** extern void process_requests_in_queue(struct request_queue *q);
 437:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 438:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** extern struct request *blk_fetch_request(struct request_queue *q);
 439:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 440:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** extern void __blk_insert_request(struct request *rq, struct bio *bio);
 441:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 442:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** extern void __blk_cleanup_queue(struct request_queue *q);
 443:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 444:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** static __always_inline struct request_queue *blk_alloc_queue(gfp_t flags){
 445:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	return request_queue_init(0, NULL, flags);
 446:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** }
 447:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** static __always_inline struct request_queue *blk_init_queue(request_fn_t fn,spinlock_t *lock){
ARM GAS  /tmp/cctjQXNb.s 			page 99


 448:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	struct request_queue * q= request_queue_init(0, NULL, GFP_KERNEL);
 449:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	q->q_fn = fn;
 450:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	q->q_lock = lock;
 451:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	return q;
 452:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** }
 453:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** static __always_inline void blk_mq_insert_request(struct request_queue *q, struct request *req){
 454:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	request_queue_add(q, req);
 455:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** }
 456:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** static __always_inline void blk_queue_make_request(struct request_queue *q, struct request *req){
 457:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	request_queue_add(q, req);
 458:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** }
 459:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** static __always_inline void blk_mq_submit_bio(struct request *rq, struct bio *bio){  
 460:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	__blk_insert_request(rq, bio);
 461:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** }
 462:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** static __always_inline void blk_insert_request(struct request_queue *q, struct request *req){
 463:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	request_queue_add(q, req);
 464:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** }
 465:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** static __always_inline void blk_submit_bio(struct request *rq, struct bio *bio){  
 466:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	__blk_insert_request(rq, bio);
 467:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** }
 468:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 469:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** static __always_inline void blk_mq_end_request(struct request *rq,blk_status_t error){
 470:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	request_queue_remove(rq->q,rq);
 471:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** }
 472:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 473:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** static __always_inline void end_request(struct request *rq){
 474:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	request_queue_remove(rq->q,rq);
 475:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** }
 476:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** static void blk_cleanup_queue(struct request_queue *q){
 477:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	__blk_cleanup_queue(q);
 478:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** }
 479:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 480:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** extern void __put_disk(struct gendisk *disk);
 481:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 482:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** static void put_disk(struct gendisk *disk){
 483:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	__put_disk(disk);
 484:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** }
 485:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 486:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** #define wait_for_completion(x) 
 487:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 488:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** struct io_comp_batch {
 489:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	struct list_head req_list;
 490:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	bool need_ts;
 491:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	void (*complete)(struct io_comp_batch *);
 492:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** };
 493:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 494:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 495:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** enum blk_unique_id {
 496:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	/* these match the Designator Types specified in SPC */
 497:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	BLK_UID_T10	= 1,
 498:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	BLK_UID_EUI64	= 2,
 499:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	BLK_UID_NAA	= 3,
 500:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** };
 501:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 502:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 503:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** struct block_device_operations {
 504:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	void (*submit_bio)(struct bio *bio);
ARM GAS  /tmp/cctjQXNb.s 			page 100


 505:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	int (*poll_bio)(struct bio *bio, struct io_comp_batch *iob,
 506:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 			unsigned int flags);
 507:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	int (*open)(struct gendisk *disk, blk_mode_t mode);
 508:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	void (*release)(struct gendisk *disk);
 509:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	int (*ioctl)(struct block_device *bdev, blk_mode_t mode,
 510:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 			unsigned cmd, unsigned long arg);
 511:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	int (*compat_ioctl)(struct block_device *bdev, blk_mode_t mode,
 512:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 			unsigned cmd, unsigned long arg);
 513:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	unsigned int (*check_events) (struct gendisk *disk,
 514:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 				      unsigned int clearing);
 515:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	void (*unlock_native_capacity) (struct gendisk *);
 516:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	int (*getgeo)(struct block_device *, struct hd_geometry *);
 517:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	int (*set_read_only)(struct block_device *bdev, bool ro);
 518:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	void (*free_disk)(struct gendisk *disk);
 519:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	/* this callback is with swap_lock and sometimes page table lock held */
 520:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	void (*swap_slot_free_notify) (struct block_device *, unsigned long);
 521:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	int (*report_zones)(struct gendisk *, sector_t sector,
 522:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 			unsigned int nr_zones, report_zones_cb cb, void *data);
 523:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	char *(*devnode)(struct gendisk *disk, umode_t *mode);
 524:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	/* returns the length of the identifier or a negative errno: */
 525:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	int (*get_unique_id)(struct gendisk *disk, u8 id[16],
 526:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 			enum blk_unique_id id_type);
 527:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	void *owner;
 528:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	const struct pr_ops *pr_ops;
 529:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 530:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	/*
 531:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	 * Special callback for probing GPT entry at a given sector.
 532:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	 * Needed by Android devices, used by GPT scanner and MMC blk
 533:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	 * driver.
 534:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	 */
 535:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	int (*alternative_gpt_sector)(struct gendisk *disk, sector_t *sector);
 536:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** };
 537:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 538:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 539:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** extern struct gendisk *__gendisk_alloc(int major,int minors);
 540:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 541:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** static inline struct gendisk *alloc_disk(int minors){
 542:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	return __gendisk_alloc(0, minors);
 543:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** }
 544:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****  
 545:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** extern void __put_disk(struct gendisk *disk);
 546:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** static void del_gendisk(struct gendisk *disk){
 547:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	__put_disk(disk);
 548:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** }
 549:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 550:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 551:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 552:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 553:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 554:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 555:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 
 556:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** static __always_inline struct request * blk_get_request(struct request_queue *q , unsigned int op, 
 642              		.loc 9 556 41 is_stmt 1 view .LVU204
 643              	.LBB112:
 557:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** {
 558:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     if(!q) return NULL;
 644              		.loc 9 558 5 view .LVU205
ARM GAS  /tmp/cctjQXNb.s 			page 101


 645              		.loc 9 558 7 is_stmt 0 view .LVU206
 646 000a 3DB1     		cbz	r5, .L32
 559:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     struct request *rq =  request_alloc(q,gfp_mask, 1);
 647              		.loc 9 559 5 is_stmt 1 view .LVU207
 648              		.loc 9 559 27 is_stmt 0 view .LVU208
 649 000c 0122     		movs	r2, #1
 650 000e 4FF44C61 		mov	r1, #3264
 651 0012 2846     		mov	r0, r5
 652              	.LVL49:
 653              		.loc 9 559 27 view .LVU209
 654 0014 FFF7FEFF 		bl	request_alloc
 655              	.LVL50:
 656 0018 0546     		mov	r5, r0
 657              	.LVL51:
 560:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     rq->cmd_flags = op;
 658              		.loc 9 560 5 is_stmt 1 view .LVU210
 659              		.loc 9 560 19 is_stmt 0 view .LVU211
 660 001a 4660     		str	r6, [r0, #4]
 561:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h ****     return rq;
 661              		.loc 9 561 5 is_stmt 1 view .LVU212
 662              	.LVL52:
 663              	.L32:
 664              		.loc 9 561 5 is_stmt 0 view .LVU213
 665              	.LBE112:
 666              	.LBE111:
 113:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     rq->__sector = bio->bi_iter.bi_sector + bio->bi_bdev->bd_start_sect;
 667              		.loc 1 113 5 is_stmt 1 view .LVU214
 668              		.loc 1 113 32 is_stmt 0 view .LVU215
 669 001c A369     		ldr	r3, [r4, #24]
 670              		.loc 1 113 48 view .LVU216
 671 001e 6268     		ldr	r2, [r4, #4]
 672              		.loc 1 113 57 view .LVU217
 673 0020 1268     		ldr	r2, [r2]
 674              		.loc 1 113 43 view .LVU218
 675 0022 1344     		add	r3, r3, r2
 676              		.loc 1 113 18 view .LVU219
 677 0024 EB61     		str	r3, [r5, #28]
 114:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     blk_submit_bio(rq,bio);   
 678              		.loc 1 114 5 is_stmt 1 view .LVU220
 679              	.LVL53:
 680              	.LBB113:
 681              	.LBI113:
 465:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	__blk_insert_request(rq, bio);
 682              		.loc 9 465 29 view .LVU221
 683              	.LBB114:
 466:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** }
 684              		.loc 9 466 2 view .LVU222
 685 0026 2146     		mov	r1, r4
 686 0028 2846     		mov	r0, r5
 687 002a FFF7FEFF 		bl	__blk_insert_request
 688              	.LVL54:
 466:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** }
 689              		.loc 9 466 2 is_stmt 0 view .LVU223
 690              	.LBE114:
 691              	.LBE113:
 115:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     spin_lock(&bio->bi_bdev->bd_queue->queue_lock);
 692              		.loc 1 115 5 is_stmt 1 view .LVU224
ARM GAS  /tmp/cctjQXNb.s 			page 102


 693              		.loc 1 115 19 is_stmt 0 view .LVU225
 694 002e 6368     		ldr	r3, [r4, #4]
 695              		.loc 1 115 28 view .LVU226
 696 0030 D868     		ldr	r0, [r3, #12]
 697              		.loc 1 115 5 view .LVU227
 698 0032 0830     		adds	r0, r0, #8
 699 0034 FFF7FEFF 		bl	spin_lock
 700              	.LVL55:
 116:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     blk_queue_make_request(bio->bi_bdev->bd_queue, rq); 
 701              		.loc 1 116 5 is_stmt 1 view .LVU228
 702              		.loc 1 116 31 is_stmt 0 view .LVU229
 703 0038 6368     		ldr	r3, [r4, #4]
 704              	.LVL56:
 705              	.LBB115:
 706              	.LBI115:
 456:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** 	request_queue_add(q, req);
 707              		.loc 9 456 29 is_stmt 1 view .LVU230
 708              	.LBB116:
 457:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** }
 709              		.loc 9 457 2 view .LVU231
 710 003a 2946     		mov	r1, r5
 711 003c D868     		ldr	r0, [r3, #12]
 712 003e FFF7FEFF 		bl	request_queue_add
 713              	.LVL57:
 457:/mnt/c/Users/31740/Desktop/newcore/include/linux/blkdev.h **** }
 714              		.loc 9 457 2 is_stmt 0 view .LVU232
 715              	.LBE116:
 716              	.LBE115:
 117:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     spin_unlock(&bio->bi_bdev->bd_queue->queue_lock);
 717              		.loc 1 117 5 is_stmt 1 view .LVU233
 718              		.loc 1 117 21 is_stmt 0 view .LVU234
 719 0042 6368     		ldr	r3, [r4, #4]
 720              		.loc 1 117 30 view .LVU235
 721 0044 D868     		ldr	r0, [r3, #12]
 722              		.loc 1 117 5 view .LVU236
 723 0046 0830     		adds	r0, r0, #8
 724 0048 FFF7FEFF 		bl	spin_unlock
 725              	.LVL58:
 118:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bio->bi_bdev->bd_queue->q_fn(bio->bi_bdev->bd_queue);
 726              		.loc 1 118 5 is_stmt 1 view .LVU237
 727              		.loc 1 118 8 is_stmt 0 view .LVU238
 728 004c 6368     		ldr	r3, [r4, #4]
 729              		.loc 1 118 17 view .LVU239
 730 004e D868     		ldr	r0, [r3, #12]
 731              		.loc 1 118 27 view .LVU240
 732 0050 D0F8D830 		ldr	r3, [r0, #216]
 733              		.loc 1 118 5 view .LVU241
 734 0054 9847     		blx	r3
 735              	.LVL59:
 119:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     if(bio->bi_end_io!= NULL)
 736              		.loc 1 119 5 is_stmt 1 view .LVU242
 737              		.loc 1 119 11 is_stmt 0 view .LVU243
 738 0056 E36A     		ldr	r3, [r4, #44]
 739              		.loc 1 119 7 view .LVU244
 740 0058 0BB1     		cbz	r3, .L31
 120:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****         bio->bi_end_io(bio);
 741              		.loc 1 120 9 is_stmt 1 view .LVU245
ARM GAS  /tmp/cctjQXNb.s 			page 103


 742 005a 2046     		mov	r0, r4
 743 005c 9847     		blx	r3
 744              	.LVL60:
 745              	.L31:
 121:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** }
 746              		.loc 1 121 1 is_stmt 0 view .LVU246
 747 005e 70BD     		pop	{r4, r5, r6, pc}
 748              		.loc 1 121 1 view .LVU247
 749              		.cfi_endproc
 750              	.LFE1038:
 752              		.section	.text.submit_bio,"ax",%progbits
 753              		.align	1
 754              		.global	submit_bio
 755              		.syntax unified
 756              		.thumb
 757              		.thumb_func
 759              	submit_bio:
 760              	.LVL61:
 761              	.LFB1039:
 122:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** EXPORT_SYMBOL(submit_bio_wait);
 123:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** 
 124:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** 
 125:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** 
 126:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** 
 127:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** 
 128:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** static int number;
 129:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** void submit_bio(struct bio *bio){
 762              		.loc 1 129 33 is_stmt 1 view -0
 763              		.cfi_startproc
 764              		@ args = 0, pretend = 0, frame = 0
 765              		@ frame_needed = 0, uses_anonymous_args = 0
 766              		.loc 1 129 33 is_stmt 0 view .LVU249
 767 0000 08B5     		push	{r3, lr}
 768              	.LCFI7:
 769              		.cfi_def_cfa_offset 8
 770              		.cfi_offset 3, -8
 771              		.cfi_offset 14, -4
 130:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     submit_bio_wait(bio);
 772              		.loc 1 130 5 is_stmt 1 view .LVU250
 773 0002 FFF7FEFF 		bl	submit_bio_wait
 774              	.LVL62:
 131:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** }
 775              		.loc 1 131 1 is_stmt 0 view .LVU251
 776 0006 08BD     		pop	{r3, pc}
 777              		.cfi_endproc
 778              	.LFE1039:
 780              		.section	.text.kthread_run,"ax",%progbits
 781              		.align	1
 782              		.syntax unified
 783              		.thumb
 784              		.thumb_func
 786              	kthread_run:
 787              	.LVL63:
 788              	.LFB1033:
 789              		.file 10 "/mnt/c/Users/31740/Desktop/newcore/include/linux/kthread.h"
   1:/mnt/c/Users/31740/Desktop/newcore/include/linux/kthread.h **** #ifndef _KTHREADS_H_
   2:/mnt/c/Users/31740/Desktop/newcore/include/linux/kthread.h **** #define _KTHREADS_H_
ARM GAS  /tmp/cctjQXNb.s 			page 104


   3:/mnt/c/Users/31740/Desktop/newcore/include/linux/kthread.h **** 
   4:/mnt/c/Users/31740/Desktop/newcore/include/linux/kthread.h **** #include <linux/sched.h>
   5:/mnt/c/Users/31740/Desktop/newcore/include/linux/kthread.h **** #include <linux/sprintf.h>
   6:/mnt/c/Users/31740/Desktop/newcore/include/linux/kthread.h **** #include <linux/stdarg.h>
   7:/mnt/c/Users/31740/Desktop/newcore/include/linux/kthread.h **** #include <generated/autoconf.h>
   8:/mnt/c/Users/31740/Desktop/newcore/include/linux/kthread.h **** 
   9:/mnt/c/Users/31740/Desktop/newcore/include/linux/kthread.h **** #define KTHREAD_DEFAULT_PRIORITY CONFIG_KTHREAD_DEFAULT_PRIORITY
  10:/mnt/c/Users/31740/Desktop/newcore/include/linux/kthread.h **** #define KTHREAD_DEFAULT_STACK_SIZE 1024*CONFIG_KTHREAD_DEFAULT_STACK_SIZE
  11:/mnt/c/Users/31740/Desktop/newcore/include/linux/kthread.h **** #define default_core_number CONFIG_KTHREAD_DEFAULT_USE_CPU_CORE
  12:/mnt/c/Users/31740/Desktop/newcore/include/linux/kthread.h **** 
  13:/mnt/c/Users/31740/Desktop/newcore/include/linux/kthread.h **** static struct task_struct *kthread_run(
  14:/mnt/c/Users/31740/Desktop/newcore/include/linux/kthread.h ****     int (*threadfn)(void *data), void *data, const char namefmt[],...)
  15:/mnt/c/Users/31740/Desktop/newcore/include/linux/kthread.h **** {
 790              		.loc 10 15 1 is_stmt 1 view -0
 791              		.cfi_startproc
 792              		@ args = 4, pretend = 8, frame = 136
 793              		@ frame_needed = 0, uses_anonymous_args = 1
 794              		.loc 10 15 1 is_stmt 0 view .LVU253
 795 0000 0CB4     		push	{r2, r3}
 796              	.LCFI8:
 797              		.cfi_def_cfa_offset 8
 798              		.cfi_offset 2, -8
 799              		.cfi_offset 3, -4
 800 0002 2DE9F041 		push	{r4, r5, r6, r7, r8, lr}
 801              	.LCFI9:
 802              		.cfi_def_cfa_offset 32
 803              		.cfi_offset 4, -32
 804              		.cfi_offset 5, -28
 805              		.cfi_offset 6, -24
 806              		.cfi_offset 7, -20
 807              		.cfi_offset 8, -16
 808              		.cfi_offset 14, -12
 809 0006 A6B0     		sub	sp, sp, #152
 810              	.LCFI10:
 811              		.cfi_def_cfa_offset 184
 812 0008 0646     		mov	r6, r0
 813 000a 0F46     		mov	r7, r1
 814 000c 2CAC     		add	r4, sp, #176
 815 000e 54F8045B 		ldr	r5, [r4], #4
  16:/mnt/c/Users/31740/Desktop/newcore/include/linux/kthread.h ****     block_scheduler(NULL);
 816              		.loc 10 16 5 is_stmt 1 view .LVU254
 817 0012 0020     		movs	r0, #0
 818              	.LVL64:
 819              		.loc 10 16 5 is_stmt 0 view .LVU255
 820 0014 FFF7FEFF 		bl	block_scheduler
 821              	.LVL65:
  17:/mnt/c/Users/31740/Desktop/newcore/include/linux/kthread.h ****     char name[128];
 822              		.loc 10 17 5 is_stmt 1 view .LVU256
  18:/mnt/c/Users/31740/Desktop/newcore/include/linux/kthread.h ****     va_list args;
 823              		.loc 10 18 5 view .LVU257
  19:/mnt/c/Users/31740/Desktop/newcore/include/linux/kthread.h ****     va_start(args, namefmt);
 824              		.loc 10 19 5 view .LVU258
 825 0018 0594     		str	r4, [sp, #20]
  20:/mnt/c/Users/31740/Desktop/newcore/include/linux/kthread.h ****     vsnprintf(name, sizeof(name), namefmt, args);
 826              		.loc 10 20 5 view .LVU259
 827 001a 0DF11808 		add	r8, sp, #24
 828 001e 2346     		mov	r3, r4
ARM GAS  /tmp/cctjQXNb.s 			page 105


 829 0020 2A46     		mov	r2, r5
 830 0022 8021     		movs	r1, #128
 831 0024 4046     		mov	r0, r8
 832 0026 FFF7FEFF 		bl	vsnprintf
 833              	.LVL66:
  21:/mnt/c/Users/31740/Desktop/newcore/include/linux/kthread.h ****     va_end(args);
 834              		.loc 10 21 5 view .LVU260
  22:/mnt/c/Users/31740/Desktop/newcore/include/linux/kthread.h ****     struct task_struct *t = task_run(
 835              		.loc 10 22 5 view .LVU261
 836              		.loc 10 22 29 is_stmt 0 view .LVU262
 837 002a 0025     		movs	r5, #0
 838 002c 0295     		str	r5, [sp, #8]
 839 002e 0195     		str	r5, [sp, #4]
 840 0030 CDF80080 		str	r8, [sp]
 841 0034 0823     		movs	r3, #8
 842 0036 3A46     		mov	r2, r7
 843 0038 4FF48051 		mov	r1, #4096
 844 003c 3046     		mov	r0, r6
 845 003e FFF7FEFF 		bl	task_run
 846              	.LVL67:
 847 0042 0446     		mov	r4, r0
 848              	.LVL68:
  23:/mnt/c/Users/31740/Desktop/newcore/include/linux/kthread.h ****     threadfn,KTHREAD_DEFAULT_STACK_SIZE,data,KTHREAD_DEFAULT_PRIORITY,name,default_core_number,0);
  24:/mnt/c/Users/31740/Desktop/newcore/include/linux/kthread.h ****     run_scheduler(NULL);
 849              		.loc 10 24 5 is_stmt 1 view .LVU263
 850 0044 2846     		mov	r0, r5
 851              	.LVL69:
 852              		.loc 10 24 5 is_stmt 0 view .LVU264
 853 0046 FFF7FEFF 		bl	run_scheduler
 854              	.LVL70:
  25:/mnt/c/Users/31740/Desktop/newcore/include/linux/kthread.h ****     return t;
 855              		.loc 10 25 5 is_stmt 1 view .LVU265
  26:/mnt/c/Users/31740/Desktop/newcore/include/linux/kthread.h **** }
 856              		.loc 10 26 1 is_stmt 0 view .LVU266
 857 004a 2046     		mov	r0, r4
 858 004c 26B0     		add	sp, sp, #152
 859              	.LCFI11:
 860              		.cfi_def_cfa_offset 32
 861              		@ sp needed
 862 004e BDE8F041 		pop	{r4, r5, r6, r7, r8, lr}
 863              	.LCFI12:
 864              		.cfi_restore 14
 865              		.cfi_restore 8
 866              		.cfi_restore 7
 867              		.cfi_restore 6
 868              		.cfi_restore 5
 869              		.cfi_restore 4
 870              		.cfi_def_cfa_offset 8
 871              	.LVL71:
 872              		.loc 10 26 1 view .LVU267
 873 0052 02B0     		add	sp, sp, #8
 874              	.LCFI13:
 875              		.cfi_restore 3
 876              		.cfi_restore 2
 877              		.cfi_def_cfa_offset 0
 878 0054 7047     		bx	lr
 879              		.cfi_endproc
ARM GAS  /tmp/cctjQXNb.s 			page 106


 880              	.LFE1033:
 882              		.section	.rodata.submit_bh.str1.4,"aMS",%progbits,1
 883              		.align	2
 884              	.LC0:
 885 0000 5F726571 		.ascii	"_request io thread %d\000"
 885      75657374 
 885      20696F20 
 885      74687265 
 885      61642025 
 886              		.section	.text.submit_bh,"ax",%progbits
 887              		.align	1
 888              		.global	submit_bh
 889              		.syntax unified
 890              		.thumb
 891              		.thumb_func
 893              	submit_bh:
 894              	.LVL72:
 895              	.LFB1040:
 132:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** EXPORT_SYMBOL(submit_bio);
 133:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** 
 134:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** void submit_bh(struct bio *bio){
 896              		.loc 1 134 32 is_stmt 1 view -0
 897              		.cfi_startproc
 898              		@ args = 0, pretend = 0, frame = 0
 899              		@ frame_needed = 0, uses_anonymous_args = 0
 900              		.loc 1 134 32 is_stmt 0 view .LVU269
 901 0000 08B5     		push	{r3, lr}
 902              	.LCFI14:
 903              		.cfi_def_cfa_offset 8
 904              		.cfi_offset 3, -8
 905              		.cfi_offset 14, -4
 906 0002 0146     		mov	r1, r0
 135:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     kthread_run(submit_bio_wait,bio,"_request io thread %d",number);
 907              		.loc 1 135 5 is_stmt 1 view .LVU270
 908 0004 0023     		movs	r3, #0
 909 0006 024A     		ldr	r2, .L41
 910 0008 0248     		ldr	r0, .L41+4
 911              	.LVL73:
 912              		.loc 1 135 5 is_stmt 0 view .LVU271
 913 000a FFF7FEFF 		bl	kthread_run
 914              	.LVL74:
 136:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** }
 915              		.loc 1 136 1 view .LVU272
 916 000e 08BD     		pop	{r3, pc}
 917              	.L42:
 918              		.align	2
 919              	.L41:
 920 0010 00000000 		.word	.LC0
 921 0014 00000000 		.word	submit_bio_wait
 922              		.cfi_endproc
 923              	.LFE1040:
 925              		.section	.text.__bio_add_page,"ax",%progbits
 926              		.align	1
 927              		.global	__bio_add_page
 928              		.syntax unified
 929              		.thumb
 930              		.thumb_func
ARM GAS  /tmp/cctjQXNb.s 			page 107


 932              	__bio_add_page:
 933              	.LVL75:
 934              	.LFB1037:
  93:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     struct bio_vec *bv;
 935              		.loc 1 93 1 is_stmt 1 view -0
 936              		.cfi_startproc
 937              		@ args = 0, pretend = 0, frame = 0
 938              		@ frame_needed = 0, uses_anonymous_args = 0
  94:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     if (unlikely(!bio || !page || off >= PAGE_SIZE)) return  -ENOMEM;;
 939              		.loc 1 94 5 view .LVU274
  95:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     if (bio->bi_vcnt >= bio->bi_max_vecs) return -ENOMEM;
 940              		.loc 1 95 5 view .LVU275
  95:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     if (bio->bi_vcnt >= bio->bi_max_vecs) return -ENOMEM;
 941              		.loc 1 95 8 is_stmt 0 discriminator 1 view .LVU276
 942 0000 48B3     		cbz	r0, .L45
 943 0002 8446     		mov	ip, r0
 944 0004 51B3     		cbz	r1, .L46
  95:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     if (bio->bi_vcnt >= bio->bi_max_vecs) return -ENOMEM;
 945              		.loc 1 95 9 discriminator 8 view .LVU277
 946 0006 B3F5805F 		cmp	r3, #4096
 947 000a 34BF     		ite	cc
 948 000c 0020     		movcc	r0, #0
 949              	.LVL76:
  95:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     if (bio->bi_vcnt >= bio->bi_max_vecs) return -ENOMEM;
 950              		.loc 1 95 9 discriminator 8 view .LVU278
 951 000e 0120     		movcs	r0, #1
  95:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     if (bio->bi_vcnt >= bio->bi_max_vecs) return -ENOMEM;
 952              		.loc 1 95 8 discriminator 1 view .LVU279
 953 0010 38BB     		cbnz	r0, .L47
  93:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     struct bio_vec *bv;
 954              		.loc 1 93 1 view .LVU280
 955 0012 30B5     		push	{r4, r5, lr}
 956              	.LCFI15:
 957              		.cfi_def_cfa_offset 12
 958              		.cfi_offset 4, -12
 959              		.cfi_offset 5, -8
 960              		.cfi_offset 14, -4
  95:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     if (bio->bi_vcnt >= bio->bi_max_vecs) return -ENOMEM;
 961              		.loc 1 95 70 is_stmt 1 discriminator 10 view .LVU281
  96:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     if (bio->bi_iter.bi_size + len > (256 << PAGE_SHIFT))return -ENOMEM;;
 962              		.loc 1 96 5 view .LVU282
  96:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     if (bio->bi_iter.bi_size + len > (256 << PAGE_SHIFT))return -ENOMEM;;
 963              		.loc 1 96 12 is_stmt 0 view .LVU283
 964 0014 BCF834E0 		ldrh	lr, [ip, #52]
  96:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     if (bio->bi_iter.bi_size + len > (256 << PAGE_SHIFT))return -ENOMEM;;
 965              		.loc 1 96 28 view .LVU284
 966 0018 BCF83640 		ldrh	r4, [ip, #54]
  96:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     if (bio->bi_iter.bi_size + len > (256 << PAGE_SHIFT))return -ENOMEM;;
 967              		.loc 1 96 8 view .LVU285
 968 001c A645     		cmp	lr, r4
 969 001e 23D2     		bcs	.L48
  97:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bv = &bio->bi_io_vec[bio->bi_vcnt];
 970              		.loc 1 97 5 is_stmt 1 view .LVU286
  97:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bv = &bio->bi_io_vec[bio->bi_vcnt];
 971              		.loc 1 97 21 is_stmt 0 view .LVU287
 972 0020 DCF81C40 		ldr	r4, [ip, #28]
  97:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bv = &bio->bi_io_vec[bio->bi_vcnt];
ARM GAS  /tmp/cctjQXNb.s 			page 108


 973              		.loc 1 97 30 view .LVU288
 974 0024 1444     		add	r4, r4, r2
  97:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bv = &bio->bi_io_vec[bio->bi_vcnt];
 975              		.loc 1 97 8 view .LVU289
 976 0026 B4F5801F 		cmp	r4, #1048576
 977 002a 20D8     		bhi	.L49
  97:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bv = &bio->bi_io_vec[bio->bi_vcnt];
 978              		.loc 1 97 73 is_stmt 1 discriminator 2 view .LVU290
  98:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bv->bv_page           = page;
 979              		.loc 1 98 5 view .LVU291
  98:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bv->bv_page           = page;
 980              		.loc 1 98 14 is_stmt 0 view .LVU292
 981 002c DCF83C50 		ldr	r5, [ip, #60]
  98:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bv->bv_page           = page;
 982              		.loc 1 98 25 view .LVU293
 983 0030 0EEB4E0E 		add	lr, lr, lr, lsl #1
  98:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bv->bv_page           = page;
 984              		.loc 1 98 8 view .LVU294
 985 0034 05EB8E04 		add	r4, r5, lr, lsl #2
 986              	.LVL77:
  99:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bv->bv_offset         = off;
 987              		.loc 1 99 5 is_stmt 1 view .LVU295
  99:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bv->bv_offset         = off;
 988              		.loc 1 99 27 is_stmt 0 view .LVU296
 989 0038 45F82E10 		str	r1, [r5, lr, lsl #2]
 100:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bv->bv_len            = len;
 990              		.loc 1 100 5 is_stmt 1 view .LVU297
 100:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bv->bv_len            = len;
 991              		.loc 1 100 27 is_stmt 0 view .LVU298
 992 003c A360     		str	r3, [r4, #8]
 101:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bio->bi_iter.bi_size += len;
 993              		.loc 1 101 5 is_stmt 1 view .LVU299
 101:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bio->bi_iter.bi_size += len;
 994              		.loc 1 101 27 is_stmt 0 view .LVU300
 995 003e 6260     		str	r2, [r4, #4]
 102:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bio->bi_vcnt++;
 996              		.loc 1 102 5 is_stmt 1 view .LVU301
 102:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bio->bi_vcnt++;
 997              		.loc 1 102 17 is_stmt 0 view .LVU302
 998 0040 DCF81C30 		ldr	r3, [ip, #28]
 999              	.LVL78:
 102:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bio->bi_vcnt++;
 1000              		.loc 1 102 26 view .LVU303
 1001 0044 1344     		add	r3, r3, r2
 1002 0046 CCF81C30 		str	r3, [ip, #28]
 1003              	.LVL79:
 103:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     return 0;
 1004              		.loc 1 103 5 is_stmt 1 view .LVU304
 103:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     return 0;
 1005              		.loc 1 103 8 is_stmt 0 view .LVU305
 1006 004a BCF83430 		ldrh	r3, [ip, #52]
 103:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     return 0;
 1007              		.loc 1 103 17 view .LVU306
 1008 004e 0133     		adds	r3, r3, #1
 1009 0050 ACF83430 		strh	r3, [ip, #52]	@ movhi
 104:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** }
 1010              		.loc 1 104 5 is_stmt 1 view .LVU307
ARM GAS  /tmp/cctjQXNb.s 			page 109


 1011              	.LVL80:
 1012              	.L43:
 105:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** 
 1013              		.loc 1 105 1 is_stmt 0 view .LVU308
 1014 0054 30BD     		pop	{r4, r5, pc}
 1015              	.LVL81:
 1016              	.L45:
 1017              	.LCFI16:
 1018              		.cfi_def_cfa_offset 0
 1019              		.cfi_restore 4
 1020              		.cfi_restore 5
 1021              		.cfi_restore 14
  95:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     if (bio->bi_vcnt >= bio->bi_max_vecs) return -ENOMEM;
 1022              		.loc 1 95 62 discriminator 9 view .LVU309
 1023 0056 6FF00B00 		mvn	r0, #11
 1024              	.LVL82:
  95:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     if (bio->bi_vcnt >= bio->bi_max_vecs) return -ENOMEM;
 1025              		.loc 1 95 62 discriminator 9 view .LVU310
 1026 005a 7047     		bx	lr
 1027              	.LVL83:
 1028              	.L46:
  95:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     if (bio->bi_vcnt >= bio->bi_max_vecs) return -ENOMEM;
 1029              		.loc 1 95 62 discriminator 9 view .LVU311
 1030 005c 6FF00B00 		mvn	r0, #11
 1031              	.LVL84:
  95:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     if (bio->bi_vcnt >= bio->bi_max_vecs) return -ENOMEM;
 1032              		.loc 1 95 62 discriminator 9 view .LVU312
 1033 0060 7047     		bx	lr
 1034              	.L47:
 1035 0062 6FF00B00 		mvn	r0, #11
 105:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** 
 1036              		.loc 1 105 1 view .LVU313
 1037 0066 7047     		bx	lr
 1038              	.L48:
 1039              	.LCFI17:
 1040              		.cfi_def_cfa_offset 12
 1041              		.cfi_offset 4, -12
 1042              		.cfi_offset 5, -8
 1043              		.cfi_offset 14, -4
  96:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     if (bio->bi_iter.bi_size + len > (256 << PAGE_SHIFT))return -ENOMEM;;
 1044              		.loc 1 96 50 discriminator 1 view .LVU314
 1045 0068 6FF00B00 		mvn	r0, #11
 1046 006c F2E7     		b	.L43
 1047              	.L49:
  97:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     bv = &bio->bi_io_vec[bio->bi_vcnt];
 1048              		.loc 1 97 65 discriminator 1 view .LVU315
 1049 006e 6FF00B00 		mvn	r0, #11
 1050 0072 EFE7     		b	.L43
 1051              		.cfi_endproc
 1052              	.LFE1037:
 1054              		.section	.text.bio_add_page,"ax",%progbits
 1055              		.align	1
 1056              		.global	bio_add_page
 1057              		.syntax unified
 1058              		.thumb
 1059              		.thumb_func
 1061              	bio_add_page:
ARM GAS  /tmp/cctjQXNb.s 			page 110


 1062              	.LVL85:
 1063              	.LFB1036:
  84:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     return __bio_add_page(bio,page,len,offset);
 1064              		.loc 1 84 1 is_stmt 1 view -0
 1065              		.cfi_startproc
 1066              		@ args = 0, pretend = 0, frame = 0
 1067              		@ frame_needed = 0, uses_anonymous_args = 0
  84:/mnt/c/Users/31740/Desktop/newcore/block/bio.c ****     return __bio_add_page(bio,page,len,offset);
 1068              		.loc 1 84 1 is_stmt 0 view .LVU317
 1069 0000 08B5     		push	{r3, lr}
 1070              	.LCFI18:
 1071              		.cfi_def_cfa_offset 8
 1072              		.cfi_offset 3, -8
 1073              		.cfi_offset 14, -4
  85:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** }
 1074              		.loc 1 85 5 is_stmt 1 view .LVU318
  85:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** }
 1075              		.loc 1 85 12 is_stmt 0 view .LVU319
 1076 0002 FFF7FEFF 		bl	__bio_add_page
 1077              	.LVL86:
  86:/mnt/c/Users/31740/Desktop/newcore/block/bio.c **** EXPORT_SYMBOL(bio_add_page);
 1078              		.loc 1 86 1 view .LVU320
 1079 0006 08BD     		pop	{r3, pc}
 1080              		.cfi_endproc
 1081              	.LFE1036:
 1083              		.section	.rodata.str1.4,"aMS",%progbits,1
 1084              		.align	2
 1085              	.LC1:
 1086 0000 7375626D 		.ascii	"submit_bh\000"
 1086      69745F62 
 1086      6800
 1087 000a 0000     		.align	2
 1088              	.LC2:
 1089 000c 00       		.ascii	"\000"
 1090              		.section	.export_table,"aw"
 1091              		.align	2
 1094              	submit_bh_export_struct:
 1095 0000 00000000 		.word	.LC1
 1096 0004 0C000000 		.word	.LC2
 1097 0008 00000000 		.word	submit_bh
 1098              		.section	.rodata.str1.4
 1099 000d 000000   		.align	2
 1100              	.LC3:
 1101 0010 7375626D 		.ascii	"submit_bio\000"
 1101      69745F62 
 1101      696F00
 1102              		.section	.export_table
 1103              		.align	2
 1106              	submit_bio_export_struct:
 1107 000c 10000000 		.word	.LC3
 1108 0010 0C000000 		.word	.LC2
 1109 0014 00000000 		.word	submit_bio
 1110              		.section	.rodata.str1.4
 1111 001b 00       		.align	2
 1112              	.LC4:
 1113 001c 7375626D 		.ascii	"submit_bio_wait\000"
 1113      69745F62 
ARM GAS  /tmp/cctjQXNb.s 			page 111


 1113      696F5F77 
 1113      61697400 
 1114              		.section	.export_table
 1115              		.align	2
 1118              	submit_bio_wait_export_struct:
 1119 0018 1C000000 		.word	.LC4
 1120 001c 0C000000 		.word	.LC2
 1121 0020 00000000 		.word	submit_bio_wait
 1122              		.section	.rodata.str1.4
 1123              		.align	2
 1124              	.LC5:
 1125 002c 62696F5F 		.ascii	"bio_add_page\000"
 1125      6164645F 
 1125      70616765 
 1125      00
 1126              		.section	.export_table
 1127              		.align	2
 1130              	bio_add_page_export_struct:
 1131 0024 2C000000 		.word	.LC5
 1132 0028 0C000000 		.word	.LC2
 1133 002c 00000000 		.word	bio_add_page
 1134              		.section	.rodata.str1.4
 1135 0039 000000   		.align	2
 1136              	.LC6:
 1137 003c 62696F5F 		.ascii	"bio_put\000"
 1137      70757400 
 1138              		.section	.export_table
 1139              		.align	2
 1142              	bio_put_export_struct:
 1143 0030 3C000000 		.word	.LC6
 1144 0034 0C000000 		.word	.LC2
 1145 0038 00000000 		.word	bio_put
 1146              		.section	.rodata.str1.4
 1147              		.align	2
 1148              	.LC7:
 1149 0044 62696F5F 		.ascii	"bio_alloc_bioset\000"
 1149      616C6C6F 
 1149      635F6269 
 1149      6F736574 
 1149      00
 1150              		.section	.export_table
 1151              		.align	2
 1154              	bio_alloc_bioset_export_struct:
 1155 003c 44000000 		.word	.LC7
 1156 0040 0C000000 		.word	.LC2
 1157 0044 00000000 		.word	bio_alloc_bioset
 1158              		.global	fs_bio_set
 1159              		.section	.bss.fs_bio_set,"aw",%nobits
 1160              		.align	2
 1163              	fs_bio_set:
 1164 0000 00000000 		.space	108
 1164      00000000 
 1164      00000000 
 1164      00000000 
 1164      00000000 
 1165              		.text
 1166              	.Letext0:
ARM GAS  /tmp/cctjQXNb.s 			page 112


 1167              		.file 11 "/mnt/c/Users/31740/Desktop/newcore/include/linux/stdarg.h"
 1168              		.file 12 "/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/int-l64.h"
 1169              		.file 13 "/mnt/c/Users/31740/Desktop/newcore/include/asm-generic/posix_types.h"
 1170              		.file 14 "/mnt/c/Users/31740/Desktop/newcore/include/uapi/linux/types.h"
 1171              		.file 15 "/mnt/c/Users/31740/Desktop/newcore/include/linux/types.h"
 1172              		.file 16 "/mnt/c/Users/31740/Desktop/newcore/include/linux/export.h"
 1173              		.file 17 "/mnt/c/Users/31740/Desktop/newcore/include/linux/time64.h"
 1174              		.file 18 "/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/sched.h"
 1175              		.file 19 "/mnt/c/Users/31740/Desktop/newcore/include/linux/sched.h"
 1176              		.file 20 "/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock_types_raw.h"
 1177              		.file 21 "/mnt/c/Users/31740/Desktop/newcore/include/linux/spinlock_types.h"
 1178              		.file 22 "/mnt/c/Users/31740/Desktop/newcore/include/linux/mutex.h"
 1179              		.file 23 "/mnt/c/Users/31740/Desktop/newcore/include/linux/errseq.h"
 1180              		.file 24 "/mnt/c/Users/31740/Desktop/newcore/include/linux/rbtree_types.h"
 1181              		.file 25 "/mnt/c/Users/31740/Desktop/newcore/include/linux/uidgid_types.h"
 1182              		.file 26 "/mnt/c/Users/31740/Desktop/newcore/include/linux/projid.h"
 1183              		.file 27 "/mnt/c/Users/31740/Desktop/newcore/include/linux/fs.h"
 1184              		.file 28 "/mnt/c/Users/31740/Desktop/newcore/include/linux/mnt_idmapping.h"
 1185              		.file 29 "/mnt/c/Users/31740/Desktop/newcore/include/linux/uio.h"
 1186              		.file 30 "/mnt/c/Users/31740/Desktop/newcore/include/linux/migrate_mode.h"
 1187              		.file 31 "/mnt/c/Users/31740/Desktop/newcore/include/linux/wait.h"
 1188              		.file 32 "/mnt/c/Users/31740/Desktop/newcore/include/linux/xarray.h"
 1189              		.file 33 "/mnt/c/Users/31740/Desktop/newcore/include/linux/lockref.h"
 1190              		.file 34 "/mnt/c/Users/31740/Desktop/newcore/include/linux/dcache.h"
 1191              		.file 35 "/mnt/c/Users/31740/Desktop/newcore/include/linux/path.h"
 1192              		.file 36 "/mnt/c/Users/31740/Desktop/newcore/include/linux/stddef.h"
 1193              		.file 37 "/mnt/c/Users/31740/Desktop/newcore/include/linux/gfp_types.h"
 1194              		.file 38 "/mnt/c/Users/31740/Desktop/newcore/include/linux/reciprocal_div.h"
 1195              		.file 39 "/mnt/c/Users/31740/Desktop/newcore/include/linux/mm_type.h"
 1196              		.file 40 "/mnt/c/Users/31740/Desktop/newcore/include/linux/statfs.h"
 1197              		.file 41 "/mnt/c/Users/31740/Desktop/newcore/include/linux/stat.h"
 1198              		.file 42 "/mnt/c/Users/31740/Desktop/newcore/include/linux/bvec.h"
 1199              		.file 43 "/mnt/c/Users/31740/Desktop/newcore/include/linux/blk_types.h"
 1200              		.file 44 "/mnt/c/Users/31740/Desktop/newcore/include/linux/rw_hint.h"
 1201              		.file 45 "/mnt/c/Users/31740/Desktop/newcore/include/linux/bio.h"
 1202              		.file 46 "/mnt/c/Users/31740/Desktop/newcore/include/linux/mempool_super_haper.h"
 1203              		.file 47 "/mnt/c/Users/31740/Desktop/newcore/include/linux/mempool.h"
 1204              		.file 48 "/mnt/c/Users/31740/Desktop/newcore/include/linux/lockdep_types.h"
 1205              		.file 49 "/mnt/c/Users/31740/Desktop/newcore/include/linux/workqueue_types.h"
 1206              		.file 50 "/mnt/c/Users/31740/Desktop/newcore/include/linux/blk-mq.h"
 1207              		.file 51 "/mnt/c/Users/31740/Desktop/newcore/include/uapi/linux/pr.h"
 1208              		.file 52 "/mnt/c/Users/31740/Desktop/newcore/include/linux/pr.h"
 1209              		.file 53 "/mnt/c/Users/31740/Desktop/newcore/include/linux/hdreg.h"
 1210              		.file 54 "/mnt/c/Users/31740/Desktop/newcore/include/linux/sprintf.h"
 1211              		.file 55 "/mnt/c/Users/31740/Desktop/newcore/arch/arm_m/include/asm/string.h"
 1212              		.file 56 "/mnt/c/Users/31740/Desktop/newcore/include/linux/instrumented.h"
 1213              		.file 57 "/mnt/c/Users/31740/Desktop/newcore/include/linux/kcsan-checks.h"
 1214              		.file 58 "/mnt/c/Users/31740/Desktop/newcore/include/linux/kasan-checks.h"
 1215              		.file 59 "<built-in>"
ARM GAS  /tmp/cctjQXNb.s 			page 113


DEFINED SYMBOLS
                            *ABS*:00000000 bio.c
     /tmp/cctjQXNb.s:21     .text.__spin_unlock:00000000 $t
     /tmp/cctjQXNb.s:26     .text.__spin_unlock:00000000 __spin_unlock
     /tmp/cctjQXNb.s:45     .text.spin_unlock:00000000 $t
     /tmp/cctjQXNb.s:50     .text.spin_unlock:00000000 spin_unlock
     /tmp/cctjQXNb.s:73     .text.bio_alloc_bioset:00000000 $t
     /tmp/cctjQXNb.s:79     .text.bio_alloc_bioset:00000000 bio_alloc_bioset
     /tmp/cctjQXNb.s:340    .text.bio_put:00000000 $t
     /tmp/cctjQXNb.s:346    .text.bio_put:00000000 bio_put
     /tmp/cctjQXNb.s:490    .text.__spin_lock:00000000 $t
     /tmp/cctjQXNb.s:495    .text.__spin_lock:00000000 __spin_lock
     /tmp/cctjQXNb.s:545    .text.spin_lock:00000000 $t
     /tmp/cctjQXNb.s:550    .text.spin_lock:00000000 spin_lock
     /tmp/cctjQXNb.s:610    .text.submit_bio_wait:00000000 $t
     /tmp/cctjQXNb.s:616    .text.submit_bio_wait:00000000 submit_bio_wait
     /tmp/cctjQXNb.s:753    .text.submit_bio:00000000 $t
     /tmp/cctjQXNb.s:759    .text.submit_bio:00000000 submit_bio
     /tmp/cctjQXNb.s:781    .text.kthread_run:00000000 $t
     /tmp/cctjQXNb.s:786    .text.kthread_run:00000000 kthread_run
     /tmp/cctjQXNb.s:883    .rodata.submit_bh.str1.4:00000000 $d
     /tmp/cctjQXNb.s:887    .text.submit_bh:00000000 $t
     /tmp/cctjQXNb.s:893    .text.submit_bh:00000000 submit_bh
     /tmp/cctjQXNb.s:920    .text.submit_bh:00000010 $d
     /tmp/cctjQXNb.s:926    .text.__bio_add_page:00000000 $t
     /tmp/cctjQXNb.s:932    .text.__bio_add_page:00000000 __bio_add_page
     /tmp/cctjQXNb.s:1055   .text.bio_add_page:00000000 $t
     /tmp/cctjQXNb.s:1061   .text.bio_add_page:00000000 bio_add_page
     /tmp/cctjQXNb.s:1084   .rodata.str1.4:00000000 $d
     /tmp/cctjQXNb.s:1091   .export_table:00000000 $d
     /tmp/cctjQXNb.s:1094   .export_table:00000000 submit_bh_export_struct
     /tmp/cctjQXNb.s:1106   .export_table:0000000c submit_bio_export_struct
     /tmp/cctjQXNb.s:1118   .export_table:00000018 submit_bio_wait_export_struct
     /tmp/cctjQXNb.s:1130   .export_table:00000024 bio_add_page_export_struct
     /tmp/cctjQXNb.s:1142   .export_table:00000030 bio_put_export_struct
     /tmp/cctjQXNb.s:1154   .export_table:0000003c bio_alloc_bioset_export_struct
     /tmp/cctjQXNb.s:1163   .bss.fs_bio_set:00000000 fs_bio_set
     /tmp/cctjQXNb.s:1160   .bss.fs_bio_set:00000000 $d

UNDEFINED SYMBOLS
__smalloc__
memset
__sfree__
stop_all_scheduler
start_all_scheduler
get_current_task
__delay
request_alloc
__blk_insert_request
request_queue_add
block_scheduler
vsnprintf
task_run
run_scheduler
